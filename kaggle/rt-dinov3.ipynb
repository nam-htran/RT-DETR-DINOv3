{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "254fbae3",
   "metadata": {
    "_cell_guid": "e5b73cd0-b726-43db-ba9a-eb5baf0303f5",
    "_uuid": "0001ce60-dd5f-44ec-a3c0-58b33fe96911",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-22T06:43:41.571026Z",
     "iopub.status.busy": "2025-10-22T06:43:41.570488Z",
     "iopub.status.idle": "2025-10-22T06:43:41.573941Z",
     "shell.execute_reply": "2025-10-22T06:43:41.573433Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01073,
     "end_time": "2025-10-22T06:43:41.575088",
     "exception": false,
     "start_time": "2025-10-22T06:43:41.564358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['PIP_DISABLE_PIP_VERSION_CHECK'] = '1'\n",
    "\n",
    "# !pip install -q --upgrade pip\n",
    "# !pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n",
    "# !pip install -q --upgrade numpy scipy scikit-learn\n",
    "# !pip install -q timm pycocotools faster-coco-eval\n",
    "# !pip install -q --upgrade transformers lightly-train\n",
    "# !pip install -q wandb\n",
    "# !pip install -q -U \"numpy<2.1\" matplotlib --force-reinstall --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b0c7c8c",
   "metadata": {
    "_cell_guid": "77f82b71-6d53-4285-9d40-20851702b6ba",
    "_uuid": "b04e36b5-d9e9-4363-9005-f8494eac2836",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-22T06:43:41.584666Z",
     "iopub.status.busy": "2025-10-22T06:43:41.584462Z",
     "iopub.status.idle": "2025-10-22T06:43:41.592247Z",
     "shell.execute_reply": "2025-10-22T06:43:41.591459Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01394,
     "end_time": "2025-10-22T06:43:41.593377",
     "exception": false,
     "start_time": "2025-10-22T06:43:41.579437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%writefile trainer_convnext.py\n",
    "# import os\n",
    "# import math\n",
    "# import time\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# from torch import Tensor\n",
    "# from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "# from torch.utils.data import DataLoader\n",
    "# from transformers import AutoModel, AutoConfig\n",
    "# from PIL import Image\n",
    "# from pycocotools.coco import COCO\n",
    "# from torchvision import transforms as T\n",
    "# from tqdm import tqdm\n",
    "# import wandb\n",
    "# import datetime\n",
    "# import torch.distributed as dist\n",
    "# from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "# from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "# class HuggingFaceTeacherWrapper(nn.Module):\n",
    "#     def __init__(self, model_id: str, token: str = None):\n",
    "#         super().__init__()\n",
    "#         if int(os.environ.get(\"RANK\", 0)) == 0:\n",
    "#             print(f\"Loading teacher model '{model_id}' from Hugging Face...\")\n",
    "#         config = AutoConfig.from_pretrained(model_id, token=token)\n",
    "#         self._model = AutoModel.from_pretrained(model_id, token=token)\n",
    "#         self.is_vit = \"vit\" in config.model_type.lower()\n",
    "#         self._feature_dim = (\n",
    "#             self._model.config.hidden_size\n",
    "#             if self.is_vit\n",
    "#             else self._model.config.hidden_sizes[-1]\n",
    "#         )\n",
    "#         if int(os.environ.get(\"RANK\", 0)) == 0:\n",
    "#             print(f\"Detected {'ViT' if self.is_vit else 'ConvNeXT'} architecture. Feature dim: {self._feature_dim}\")\n",
    "\n",
    "#     def feature_dim(self) -> int:\n",
    "#         return self._feature_dim\n",
    "\n",
    "#     def forward(self, x: Tensor) -> Tensor:\n",
    "#         outputs = self._model(pixel_values=x, output_hidden_states=True)\n",
    "#         if self.is_vit:\n",
    "#             patch_tokens = outputs.last_hidden_state[:, 1:, :]\n",
    "#             b, s, d = patch_tokens.shape\n",
    "#             h = w = int(math.sqrt(s))\n",
    "#             return patch_tokens.permute(0, 2, 1).reshape(b, d, h, w)\n",
    "#         return outputs.hidden_states[-1]\n",
    "\n",
    "# class CocoDetectionForDistill(torch.utils.data.Dataset):\n",
    "#     def __init__(self, root, ann_file, transforms):\n",
    "#         self.root = root\n",
    "#         self.coco = COCO(ann_file)\n",
    "#         self.ids = list(sorted(self.coco.imgs.keys()))\n",
    "#         self.transforms = transforms\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         img_id = self.ids[index]\n",
    "#         path = self.coco.loadImgs(img_id)[0][\"file_name\"]\n",
    "#         img = Image.open(os.path.join(self.root, path)).convert(\"RGB\")\n",
    "#         return self.transforms(img), 0\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.ids)\n",
    "\n",
    "# def setup_ddp():\n",
    "#     dist.init_process_group(backend=\"nccl\")\n",
    "#     torch.cuda.set_device(int(os.environ[\"LOCAL_RANK\"]))\n",
    "\n",
    "# def cleanup_ddp():\n",
    "#     dist.destroy_process_group()\n",
    "\n",
    "\n",
    "# def main_training_function(rank, world_size, config):\n",
    "#     device = rank\n",
    "    \n",
    "#     is_main_process = (rank == 0)\n",
    "    \n",
    "#     if is_main_process:\n",
    "#         print(f\"Running DDP on {world_size} GPUs.\")\n",
    "#         timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "#         run_name = f\"run_ddp_{timestamp}_lr{config['learning_rate']}_bs{config['batch_size_per_gpu']}\"\n",
    "#         try:\n",
    "#             from kaggle_secrets import UserSecretsClient\n",
    "#             from huggingface_hub import login\n",
    "#             secrets = UserSecretsClient()\n",
    "#             hf_token = secrets.get_secret(\"HUGGINGFACE_TOKEN\")\n",
    "#             wandb_key = secrets.get_secret(\"WANDB_API_KEY\")\n",
    "#             login(token=hf_token)\n",
    "#             wandb.login(key=wandb_key)\n",
    "#             wandb.init(project=config[\"wandb_project\"], config=config, name=run_name)\n",
    "#         except Exception:\n",
    "#             hf_token = None\n",
    "#             print(\"Could not log in, continuing without W&B.\")\n",
    "#     else:\n",
    "#         hf_token = None\n",
    "\n",
    "#     dist.barrier()\n",
    "    \n",
    "#     teacher_model = HuggingFaceTeacherWrapper(config[\"teacher_hf_id\"], token=hf_token).to(device)\n",
    "#     teacher_model.eval()\n",
    "\n",
    "#     if is_main_process:\n",
    "#         print(\"Đang tải student model trên tiến trình chính...\")\n",
    "#         torch.hub.load(\"lyuwenyu/RT-DETR\", \"rtdetrv2_l\", pretrained=True, trust_repo=True)\n",
    "\n",
    "#     dist.barrier()\n",
    "\n",
    "#     student_hub_model = torch.hub.load(\"lyuwenyu/RT-DETR\", \"rtdetrv2_l\", pretrained=True, trust_repo=True)\n",
    "#     student_model = student_hub_model.model.to(device)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         x = torch.randn(1, 3, 640, 640).to(device)\n",
    "#         student_channels = student_model.encoder(student_model.backbone(x))[-1].shape[1]\n",
    "#     teacher_channels = teacher_model.feature_dim()\n",
    "#     projection_layer = nn.Conv2d(student_channels, teacher_channels, kernel_size=1).to(device)\n",
    "\n",
    "#     student_model = DDP(student_model, device_ids=[device])\n",
    "#     projection_layer = DDP(projection_layer, device_ids=[device])\n",
    "    \n",
    "#     transforms = T.Compose([\n",
    "#         T.Resize((640, 640)), T.ToTensor(),\n",
    "#         T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ])\n",
    "\n",
    "#     train_dataset = CocoDetectionForDistill(\n",
    "#         root=os.path.join(config[\"dataset_dir\"], \"train2017\"),\n",
    "#         ann_file=os.path.join(config[\"dataset_dir\"], \"annotations/instances_train2017.json\"),\n",
    "#         transforms=transforms\n",
    "#     )\n",
    "#     val_dataset = CocoDetectionForDistill(\n",
    "#         root=os.path.join(config[\"dataset_dir\"], \"val2017\"),\n",
    "#         ann_file=os.path.join(config[\"dataset_dir\"], \"annotations/instances_val2017.json\"),\n",
    "#         transforms=transforms\n",
    "#     )\n",
    "#     if is_main_process:\n",
    "#         print(f\"Data loaded: {len(train_dataset)} training images, {len(val_dataset)} validation images.\")\n",
    "\n",
    "#     train_sampler = DistributedSampler(train_dataset, num_replicas=world_size, rank=rank, shuffle=True)\n",
    "#     val_sampler = DistributedSampler(val_dataset, num_replicas=world_size, rank=rank, shuffle=False)\n",
    "\n",
    "#     train_loader = DataLoader(\n",
    "#         train_dataset, batch_size=config[\"batch_size_per_gpu\"],\n",
    "#         shuffle=False, num_workers=config[\"num_workers\"], pin_memory=True, drop_last=True, sampler=train_sampler\n",
    "#     )\n",
    "#     val_loader = DataLoader(\n",
    "#         val_dataset, batch_size=config[\"batch_size_per_gpu\"],\n",
    "#         shuffle=False, num_workers=config[\"num_workers\"], pin_memory=True, drop_last=False, sampler=val_sampler\n",
    "#     )\n",
    "\n",
    "#     params = list(student_model.module.backbone.parameters()) + \\\n",
    "#              list(student_model.module.encoder.parameters()) + \\\n",
    "#              list(projection_layer.module.parameters())\n",
    "             \n",
    "#     optimizer = torch.optim.AdamW(params, lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
    "#     criterion = nn.MSELoss()\n",
    "#     scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=config['scheduler_factor'], patience=config['scheduler_patience'], verbose=is_main_process)\n",
    "\n",
    "#     if is_main_process and wandb.run:\n",
    "#         wandb.watch((student_model, projection_layer), log=\"all\", log_freq=100)\n",
    "    \n",
    "#     best_val_loss = float('inf')\n",
    "#     early_stopping_counter = 0\n",
    "\n",
    "#     if is_main_process:\n",
    "#         print(\"Starting training...\")\n",
    "        \n",
    "#     for epoch in range(config[\"epochs\"]):\n",
    "#         train_sampler.set_epoch(epoch)\n",
    "        \n",
    "#         start = time.time()\n",
    "#         student_model.train()\n",
    "#         projection_layer.train()\n",
    "#         total_train_loss = 0.0\n",
    "        \n",
    "#         train_iterator = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['epochs']} [Train]\") if is_main_process else train_loader\n",
    "\n",
    "#         for images, _ in train_iterator:\n",
    "#             images = images.to(device)\n",
    "#             with torch.no_grad():\n",
    "#                 teacher_features = teacher_model(images)\n",
    "#             student_features = student_model.module.encoder(student_model.module.backbone(images))[-1]\n",
    "#             projected = projection_layer(student_features)\n",
    "#             teacher_resized = F.interpolate(teacher_features, size=projected.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "#             loss = criterion(projected, teacher_resized)\n",
    "            \n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             total_train_loss += loss.item()\n",
    "        \n",
    "#         train_loss_tensor = torch.tensor(total_train_loss).to(device)\n",
    "#         dist.all_reduce(train_loss_tensor, op=dist.ReduceOp.SUM)\n",
    "#         avg_train_loss = train_loss_tensor.item() / (len(train_loader) * world_size)\n",
    "\n",
    "#         student_model.eval()\n",
    "#         projection_layer.eval()\n",
    "#         total_val_loss = 0.0\n",
    "        \n",
    "#         val_iterator = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{config['epochs']} [Val]\") if is_main_process else val_loader\n",
    "#         with torch.no_grad():\n",
    "#             for images, _ in val_iterator:\n",
    "#                 images = images.to(device)\n",
    "#                 teacher_features = teacher_model(images)\n",
    "#                 student_features = student_model.module.encoder(student_model.module.backbone(images))[-1]\n",
    "#                 projected = projection_layer(student_features)\n",
    "#                 teacher_resized = F.interpolate(teacher_features, size=projected.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "#                 loss = criterion(projected, teacher_resized)\n",
    "#                 total_val_loss += loss.item()\n",
    "                \n",
    "#         val_loss_tensor = torch.tensor(total_val_loss).to(device)\n",
    "#         dist.all_reduce(val_loss_tensor, op=dist.ReduceOp.SUM)\n",
    "#         avg_val_loss = val_loss_tensor.item() / (len(val_loader) * world_size)\n",
    "        \n",
    "#         if is_main_process:\n",
    "#             duration = time.time() - start\n",
    "#             print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Duration: {duration:.2f}s\")\n",
    "#             if wandb.run:\n",
    "#                 wandb.log({\"epoch\": epoch + 1, \"train/avg_loss\": avg_train_loss, \"val/avg_loss\": avg_val_loss, \"time/epoch_s\": duration, \"train/epoch_lr\": optimizer.param_groups[0]['lr']})\n",
    "\n",
    "#             scheduler.step(avg_val_loss)\n",
    "\n",
    "#             if avg_val_loss < best_val_loss:\n",
    "#                 best_val_loss = avg_val_loss\n",
    "#                 early_stopping_counter = 0\n",
    "#                 print(f\"Validation loss improved to {best_val_loss:.4f}. Saving best model...\")\n",
    "#                 best_weights = {**student_model.module.backbone.state_dict(), **student_model.module.encoder.state_dict()}\n",
    "#                 torch.save({'model': best_weights}, config[\"best_weights_filename\"])\n",
    "\n",
    "#             else:\n",
    "#                 early_stopping_counter += 1\n",
    "#                 print(f\"Validation loss did not improve. Early stopping counter: {early_stopping_counter}/{config['early_stopping_patience']}\")\n",
    "\n",
    "#         stop_training = torch.tensor(1 if early_stopping_counter >= config['early_stopping_patience'] else 0, device=device)\n",
    "#         dist.all_reduce(stop_training, op=dist.ReduceOp.MAX)\n",
    "#         if stop_training.item() == 1:\n",
    "#             if is_main_process:\n",
    "#                 print(\"Early stopping triggered. Training finished.\")\n",
    "#             break\n",
    "            \n",
    "#     if is_main_process:\n",
    "#         print(\"\\nDistillation finished.\")\n",
    "#         final_weights = {**student_model.module.backbone.state_dict(), **student_model.module.encoder.state_dict()}\n",
    "#         torch.save({'model': final_weights}, config[\"final_weights_filename\"])\n",
    "#         print(f\"Saved final epoch weights to '{config['final_weights_filename']}'\")\n",
    "#         print(f\"Best weights were saved to '{config['best_weights_filename']}' with val_loss: {best_val_loss:.4f}\")\n",
    "#         if wandb.run:\n",
    "#             wandb.summary[\"best_val_loss\"] = best_val_loss\n",
    "#             wandb.finish()\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     setup_ddp()\n",
    "#     rank = int(os.environ[\"RANK\"])\n",
    "#     world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "\n",
    "#     DATASET_DIR = \"/kaggle/input/dsp-pre-final/processed_taco_coco\"\n",
    "#     config = {\n",
    "#         \"learning_rate\": 1e-4, \"epochs\": 50, \"batch_size_per_gpu\": 16,\n",
    "#         \"num_workers\": 2, \"weight_decay\": 1e-5,\n",
    "#         \"teacher_hf_id\": \"facebook/dinov3-convnext-base-pretrain-lvd1689m\",\n",
    "#         \"dataset_dir\": DATASET_DIR,\n",
    "#         \"scheduler_patience\": 3, \"scheduler_factor\": 0.1,\n",
    "#         \"early_stopping_patience\": 7,\n",
    "#         \"best_weights_filename\": \"distilled_rtdetr_convnext_teacher_BEST.pth\",\n",
    "#         \"final_weights_filename\": \"distilled_rtdetr_convnext_teacher_FINAL.pth\",\n",
    "#         \"wandb_project\": \"Distill-RTDETR-ConvNeXt-Teacher\",\n",
    "#     }\n",
    "    \n",
    "#     main_training_function(rank, world_size, config)\n",
    "    \n",
    "#     cleanup_ddp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aab53b8a",
   "metadata": {
    "_cell_guid": "255abd5a-99c4-4450-9346-670d4d42af28",
    "_uuid": "8020f1b8-baa4-447d-83e2-412d6fb5d59e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-22T06:43:41.602224Z",
     "iopub.status.busy": "2025-10-22T06:43:41.601816Z",
     "iopub.status.idle": "2025-10-22T06:43:41.604829Z",
     "shell.execute_reply": "2025-10-22T06:43:41.604161Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.008511,
     "end_time": "2025-10-22T06:43:41.605935",
     "exception": false,
     "start_time": "2025-10-22T06:43:41.597424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !torchrun --nproc_per_node=2 trainer_convnext.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "966cb73b",
   "metadata": {
    "_cell_guid": "4421e5e2-273f-4844-a15f-82cde58f1584",
    "_uuid": "cbbe3063-565e-4c21-80e6-7d523aaf587c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-22T06:43:41.614840Z",
     "iopub.status.busy": "2025-10-22T06:43:41.614620Z",
     "iopub.status.idle": "2025-10-22T06:43:41.619076Z",
     "shell.execute_reply": "2025-10-22T06:43:41.618392Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.010195,
     "end_time": "2025-10-22T06:43:41.620198",
     "exception": false,
     "start_time": "2025-10-22T06:43:41.610003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%writefile trainer_vit.py\n",
    "# import os\n",
    "# import sys\n",
    "# import shutil\n",
    "# import torch\n",
    "# import wandb\n",
    "# import lightly_train\n",
    "# from lightly_train.model_wrappers import RTDETRModelWrapper\n",
    "# import datetime\n",
    "\n",
    "# def main_training_function(config):\n",
    "#     is_main_process = os.environ.get(\"LOCAL_RANK\", \"0\") == \"0\"\n",
    "\n",
    "#     if is_main_process:\n",
    "#         timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "#         run_name = f\"run_ddp_{timestamp}_lr{config['learning_rate']}_bs{config['batch_size_per_gpu']}\"\n",
    "#         try:\n",
    "#             from kaggle_secrets import UserSecretsClient\n",
    "#             wandb_key = UserSecretsClient().get_secret(\"WANDB_API_KEY\")\n",
    "#             wandb.login(key=wandb_key)\n",
    "#         except Exception as e:\n",
    "#             print(f\"W&B secrets not available. Skipping login. Error: {e}\")\n",
    "\n",
    "#         if os.path.exists(config['output_dir']):\n",
    "#             print(f\"Output directory '{config['output_dir']}' already exists. Deleting it.\")\n",
    "#             shutil.rmtree(config['output_dir'])\n",
    "\n",
    "#     if not is_main_process:\n",
    "#         run_name = \"\"\n",
    "\n",
    "#     if torch.distributed.is_initialized():\n",
    "#         torch.distributed.barrier()\n",
    "\n",
    "#     if is_main_process:\n",
    "#         print(\"Initializing Student Model (RT-DETR)...\")\n",
    "#     student_hub_model = torch.hub.load('lyuwenyu/RT-DETR', 'rtdetrv2_l', pretrained=True, trust_repo=True)\n",
    "#     wrapped_student = RTDETRModelWrapper(student_hub_model.model)\n",
    "    \n",
    "#     callbacks_config = {\n",
    "#         \"model_checkpoint\": {\n",
    "#             \"dirpath\": os.path.join(config['output_dir'], 'checkpoints'),\n",
    "#             \"filename\": 'best-model-{epoch}-{validation_loss:.4f}',\n",
    "#             \"monitor\": 'val_loss',\n",
    "#             \"mode\": 'min',\n",
    "#             \"save_top_k\": 1,\n",
    "#         },\n",
    "#         \"learning_rate_monitor\": {}\n",
    "#     }\n",
    "    \n",
    "#     global_batch_size = config['batch_size_per_gpu'] * config['num_gpus']\n",
    "\n",
    "#     if is_main_process:\n",
    "#         print(\"Starting distillation with lightly_train.train()...\")\n",
    "#         print(f\"Global batch size: {global_batch_size} ({config['batch_size_per_gpu']} per GPU)\")\n",
    "\n",
    "#     lightly_train.train(\n",
    "#         model=wrapped_student,\n",
    "#         method=\"distillationv1\",\n",
    "#         method_args={\n",
    "#             \"teacher\": config['teacher_name'],\n",
    "#             \"teacher_url\": config['teacher_url'],\n",
    "#         },\n",
    "#         data=[config['train_dir'], config['val_dir']],\n",
    "#         out=config['output_dir'],\n",
    "#         epochs=config['epochs'],\n",
    "#         batch_size=global_batch_size,\n",
    "#         num_workers=config['num_workers'],\n",
    "#         optim=config['optimizer_name'],\n",
    "#         optim_args={\"lr\": config['learning_rate'], \"weight_decay\": config['weight_decay']},\n",
    "#         callbacks=callbacks_config,\n",
    "#         loggers={\n",
    "#             \"wandb\": {\n",
    "#                 \"project\": config['wandb_project'],\n",
    "#                 \"name\": run_name,\n",
    "#             }\n",
    "#         },\n",
    "#         devices=config['num_gpus'],\n",
    "#         strategy='ddp_find_unused_parameters_true',\n",
    "#         accelerator='gpu'\n",
    "#     )\n",
    "#     if is_main_process:\n",
    "#         print(\"\\nDistillation finished.\")\n",
    "#         print(f\"Best model checkpoint saved in directory: {os.path.join(config['output_dir'], 'checkpoints')}\")\n",
    "        \n",
    "# if __name__ == '__main__':\n",
    "#     DINOV3_VIT_TEACHER_URL = \"\"\n",
    "#     try:\n",
    "#         from kaggle_secrets import UserSecretsClient\n",
    "#         DINOV3_VIT_TEACHER_URL = UserSecretsClient().get_secret(\"DINOV3_TEACHER_URL\")\n",
    "#     except Exception as e:\n",
    "#          print(f\"Could not read secret 'DINOV3_VIT_URL'. Please set it manually. Error: {e}\")\n",
    "\n",
    "#     if not DINOV3_VIT_TEACHER_URL:\n",
    "#         print(\"ERROR: Save your token key into kaggle secret\")\n",
    "#     else:\n",
    "#         BASE_DIR = \"/kaggle/input/dsp-pre-final/processed_taco_coco\"\n",
    "#         TRAIN_DIR = os.path.join(BASE_DIR, \"train2017\")\n",
    "#         VAL_DIR = os.path.join(BASE_DIR, \"val2017\")\n",
    "        \n",
    "#         config = {\n",
    "#             \"num_gpus\": 2,\n",
    "#             \"epochs\": 50, \"batch_size_per_gpu\": 8, \"num_workers\": 2,\n",
    "#             \"optimizer_name\": \"adamw\", \"learning_rate\": 1e-4, \"weight_decay\": 1e-5,\n",
    "#             \"early_stopping_patience\": 7,\n",
    "#             \"teacher_name\": \"dinov3/vitb16\", \n",
    "#             \"teacher_url\": DINOV3_VIT_TEACHER_URL,\n",
    "#             \"train_dir\": TRAIN_DIR,\n",
    "#             \"val_dir\": VAL_DIR,\n",
    "#             \"output_dir\": \"out/distill_vit_lightly\",\n",
    "#             \"wandb_project\": \"Distill-RTDETR-Distill-VIT\"\n",
    "#         }\n",
    "        \n",
    "#         main_training_function(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca828a55",
   "metadata": {
    "_cell_guid": "5e8f92c0-cf6d-4b60-a33f-b493d8a60ec1",
    "_uuid": "12326bcb-679f-4451-ad2d-4537c0e02201",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-22T06:43:41.628864Z",
     "iopub.status.busy": "2025-10-22T06:43:41.628672Z",
     "iopub.status.idle": "2025-10-22T06:43:41.631588Z",
     "shell.execute_reply": "2025-10-22T06:43:41.630939Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.008458,
     "end_time": "2025-10-22T06:43:41.632666",
     "exception": false,
     "start_time": "2025-10-22T06:43:41.624208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !torchrun --nproc_per_node=2 trainer_vit.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3ea089",
   "metadata": {
    "_cell_guid": "54298212-fe8c-4814-8632-9b4df70ca2eb",
    "_uuid": "4868cfb9-e897-4b49-875e-b0c9c45aa565",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.003784,
     "end_time": "2025-10-22T06:43:41.640358",
     "exception": false,
     "start_time": "2025-10-22T06:43:41.636574",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Finetune RT-DETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1099cfcc",
   "metadata": {
    "_cell_guid": "b4a68946-cb5b-4652-bd65-21a46aa1da91",
    "_uuid": "af76c78b-413c-408e-b3d3-c48da8212ac7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-22T06:43:41.649226Z",
     "iopub.status.busy": "2025-10-22T06:43:41.648740Z",
     "iopub.status.idle": "2025-10-22T06:43:41.651438Z",
     "shell.execute_reply": "2025-10-22T06:43:41.650950Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.008154,
     "end_time": "2025-10-22T06:43:41.652490",
     "exception": false,
     "start_time": "2025-10-22T06:43:41.644336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm -rf /kaggle/working/RT-DETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c8c7291",
   "metadata": {
    "_cell_guid": "cf22891d-f654-4149-8eab-1f076b652a17",
    "_uuid": "6022ca59-63e6-4993-9b02-18390c3e7536",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-22T06:43:41.661565Z",
     "iopub.status.busy": "2025-10-22T06:43:41.661084Z",
     "iopub.status.idle": "2025-10-22T06:47:22.115644Z",
     "shell.execute_reply": "2025-10-22T06:47:22.114883Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 220.460589,
     "end_time": "2025-10-22T06:47:22.117052",
     "exception": false,
     "start_time": "2025-10-22T06:43:41.656463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n",
      "Cloning into 'RT-DETR'...\r\n",
      "remote: Enumerating objects: 1100, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (23/23), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (18/18), done.\u001b[K\r\n",
      "remote: Total 1100 (delta 8), reused 5 (delta 5), pack-reused 1077 (from 2)\u001b[K\r\n",
      "Receiving objects: 100% (1100/1100), 660.70 KiB | 10.83 MiB/s, done.\r\n",
      "Resolving deltas: 100% (522/522), done.\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m490.0/490.0 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.2/323.2 kB\u001b[0m \u001b[31m236.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m44.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m89.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "google-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 6.33.0 which is incompatible.\r\n",
      "google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 6.33.0 which is incompatible.\r\n",
      "google-cloud-bigtable 2.32.0 requires google-api-core[grpc]<3.0.0,>=2.17.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.0 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.1 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "google-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "dataproc-spark-connect 0.8.3 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mcp: cannot stat '/kaggle/working/distilled_rtdetr_convnext_teacher_BEST.pth': No such file or directory\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "google-cloud-bigtable 2.32.0 requires google-api-core[grpc]<3.0.0,>=2.17.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.1 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "google-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "dataproc-spark-connect 0.8.3 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.4 which is incompatible.\r\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.16.2 which is incompatible.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.4 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.4 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.4 which is incompatible.\r\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\r\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.3.4 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires scipy<1.16,>=1.4.1, but you have scipy 1.16.2 which is incompatible.\r\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.2 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.2 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\r\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "transformers 4.53.3 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.0rc2 which is incompatible.\r\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.4 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.6 which is incompatible.\r\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.16.2 which is incompatible.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\r\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.6 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires scipy<1.16,>=1.4.1, but you have scipy 1.16.2 which is incompatible.\r\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.2 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.2 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.5.1 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.0.2 which is incompatible.\r\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.16.2 which is incompatible.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.0.2 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.0.2 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.0.2 which is incompatible.\r\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires matplotlib<=3.10,>=3.5, but you have matplotlib 3.10.7 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires scipy<1.16,>=1.4.1, but you have scipy 1.16.2 which is incompatible.\r\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.2 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.2 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "ibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\r\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "jupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\r\n",
      "dataproc-spark-connect 0.8.3 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working\n",
    "!git clone https://github.com/lyuwenyu/RT-DETR.git\n",
    "!cd RT-DETR/rtdetrv2_pytorch && pip install -r requirements.txt -q\n",
    "!cp \"/kaggle/working/distilled_rtdetr_convnext_teacher_BEST.pth\" \"./RT-DETR/\"\n",
    "!pip install -q protobuf==3.20.3\n",
    "!pip install -q tensorboard\n",
    "!pip install -q --upgrade pip\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n",
    "!pip install -q --upgrade numpy scipy scikit-learn\n",
    "!pip install -q timm pycocotools faster-coco-eval\n",
    "!pip install -q --upgrade transformers lightly-train\n",
    "!pip install -q wandb\n",
    "!pip install -q -U \"numpy<2.1\" matplotlib --force-reinstall --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5302c78",
   "metadata": {
    "_cell_guid": "6cfbc422-0448-4078-8329-84425a0bc3fd",
    "_uuid": "c1d4933a-c16e-44f5-9938-52172a951d4b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-22T06:47:22.169562Z",
     "iopub.status.busy": "2025-10-22T06:47:22.169331Z",
     "iopub.status.idle": "2025-10-22T06:47:22.173491Z",
     "shell.execute_reply": "2025-10-22T06:47:22.172963Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.031298,
     "end_time": "2025-10-22T06:47:22.174515",
     "exception": false,
     "start_time": "2025-10-22T06:47:22.143217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%writefile /kaggle/working/RT-DETR/rtdetrv2_pytorch/configs/rtdetrv2/rtdetrv2_taco_finetune_convnext.yml\n",
    "# __include__: [\n",
    "#   '../dataset/coco_detection.yml',\n",
    "#   '../runtime.yml',\n",
    "#   './include/dataloader.yml',\n",
    "#   './include/rtdetrv2_r50vd.yml',\n",
    "# ]\n",
    "\n",
    "# output_dir: ./output/rtdetrv2_finetune_taco_convnext_teacher\n",
    "\n",
    "# RTDETR:\n",
    "#   backbone: HGNetv2\n",
    "\n",
    "# HGNetv2:\n",
    "#   name: 'L'\n",
    "#   return_idx: [1, 2, 3]\n",
    "#   freeze_at: 0\n",
    "#   freeze_norm: True\n",
    "#   pretrained: True\n",
    "\n",
    "# task: detection\n",
    "# remap_mscoco_category: false\n",
    "# tuning: '../distilled_rtdetr_convnext_teacher_BEST.pth'\n",
    "# compile: true\n",
    "# epoches: 50\n",
    "\n",
    "# num_classes: 60\n",
    "\n",
    "# train_dataloader:\n",
    "#   num_workers: 4\n",
    "#   dataset:\n",
    "#     type: CocoDetection\n",
    "#     img_folder: /kaggle/input/dsp-pre-final/processed_taco_coco/train2017\n",
    "#     ann_file: /kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_train2017.json\n",
    "\n",
    "# val_dataloader:\n",
    "#   num_workers: 4\n",
    "#   dataset:\n",
    "#     type: CocoDetection\n",
    "#     img_folder: /kaggle/input/dsp-pre-final/processed_taco_coco/val2017\n",
    "#     ann_file: /kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_val2017.json\n",
    "\n",
    "# batch_size: 16\n",
    "\n",
    "# optimizer:\n",
    "#   type: AdamW\n",
    "#   params:\n",
    "#     - params: '^(?=.*backbone)'\n",
    "#       lr: 0.00001\n",
    "#   lr: 0.0001\n",
    "#   weight_decay: 0.0001\n",
    "#   betas: [0.9, 0.999]\n",
    "\n",
    "# lr_scheduler:\n",
    "#   type: OneCycleLR\n",
    "#   max_lr: 0.0001\n",
    "#   pct_start: 0.3\n",
    "#   total_steps: 4000\n",
    "\n",
    "# checkpoint_freq: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e3059a4",
   "metadata": {
    "_cell_guid": "0429d9f6-ae5e-466d-ba9d-67ce612e9b1f",
    "_uuid": "8a498933-2d2a-4961-a0ce-43ba1ffd6377",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-22T06:47:22.225888Z",
     "iopub.status.busy": "2025-10-22T06:47:22.225503Z",
     "iopub.status.idle": "2025-10-22T06:47:22.228423Z",
     "shell.execute_reply": "2025-10-22T06:47:22.227921Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.029621,
     "end_time": "2025-10-22T06:47:22.229440",
     "exception": false,
     "start_time": "2025-10-22T06:47:22.199819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %cd /kaggle/working/RT-DETR/rtdetrv2_pytorch/\n",
    "\n",
    "# !torchrun --nproc_per_node=2 tools/train.py \\\n",
    "#     -c configs/rtdetrv2/rtdetrv2_taco_finetune_convnext.yml \\\n",
    "#     --use-amp \\\n",
    "#     --seed=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ffe117b",
   "metadata": {
    "_cell_guid": "708dba40-acba-4833-8065-904ee83172cc",
    "_uuid": "8abfd2e9-5efb-42a8-8634-ad7af09d3bcb",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-22T06:47:22.281238Z",
     "iopub.status.busy": "2025-10-22T06:47:22.281056Z",
     "iopub.status.idle": "2025-10-22T06:47:22.284601Z",
     "shell.execute_reply": "2025-10-22T06:47:22.283936Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.030331,
     "end_time": "2025-10-22T06:47:22.285692",
     "exception": false,
     "start_time": "2025-10-22T06:47:22.255361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%writefile convert_vit.py\n",
    "# import torch\n",
    "# import glob\n",
    "# import os\n",
    "# import sys\n",
    "\n",
    "# RTDETR_PYTORCH_PATH = '/kaggle/working/RT-DETR/rtdetrv2_pytorch/'\n",
    "# if RTDETR_PYTORCH_PATH not in sys.path:\n",
    "#     sys.path.append(RTDETR_PYTORCH_PATH)\n",
    "# LIGHTLY_CHECKPOINT_DIR = '/kaggle/working/out/distill_vit_lightly/checkpoints/'\n",
    "# OUTPUT_WEIGHTS_PATH = '/kaggle/working/RT-DETR/distilled_rtdetr_vit_teacher_BEST.pth'\n",
    "\n",
    "# list_of_files = glob.glob(os.path.join(LIGHTLY_CHECKPOINT_DIR, '*.ckpt'))\n",
    "# if not list_of_files:\n",
    "#     raise FileNotFoundError(f\"Not found ckpt'{LIGHTLY_CHECKPOINT_DIR}'\")\n",
    "# latest_checkpoint_path = max(list_of_files, key=os.path.getctime)\n",
    "# lightly_checkpoint = torch.load(latest_checkpoint_path, map_location='cpu', weights_only=False)\n",
    "# original_state_dict = lightly_checkpoint['state_dict']\n",
    "\n",
    "# PREFIX_TO_REMOVE = \"student_embedding_model.wrapped_model.\"\n",
    "# clean_state_dict = {}\n",
    "# for key, value in original_state_dict.items():\n",
    "#     if key.startswith(PREFIX_TO_REMOVE):\n",
    "#         temp_key = key[len(PREFIX_TO_REMOVE):]\n",
    "#         if temp_key.startswith('_backbone') or temp_key.startswith('_encoder'):\n",
    "#             new_key = temp_key.lstrip('_')\n",
    "#             clean_state_dict[new_key] = value\n",
    "\n",
    "# if not clean_state_dict:\n",
    "#     raise ValueError(\"Can not extract\")\n",
    "\n",
    "# final_structure = {'model': clean_state_dict}\n",
    "# torch.save(final_structure, OUTPUT_WEIGHTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29c5b7a7",
   "metadata": {
    "_cell_guid": "c41f5af0-5b38-4961-8134-5041f0d5428f",
    "_uuid": "72ef5471-1a2f-4c12-9482-92ccb6fbddc8",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-22T06:47:22.336372Z",
     "iopub.status.busy": "2025-10-22T06:47:22.336206Z",
     "iopub.status.idle": "2025-10-22T06:47:22.339285Z",
     "shell.execute_reply": "2025-10-22T06:47:22.338602Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.029857,
     "end_time": "2025-10-22T06:47:22.340381",
     "exception": false,
     "start_time": "2025-10-22T06:47:22.310524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python convert_vit.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "052209bb",
   "metadata": {
    "_cell_guid": "c3d5358b-ae0d-44b8-ae1a-13eacfb7127b",
    "_uuid": "e4c9f3f1-1f7e-4903-a7f2-7b266d544ba1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-22T06:47:22.391210Z",
     "iopub.status.busy": "2025-10-22T06:47:22.390805Z",
     "iopub.status.idle": "2025-10-22T06:47:22.394156Z",
     "shell.execute_reply": "2025-10-22T06:47:22.393650Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.029725,
     "end_time": "2025-10-22T06:47:22.395150",
     "exception": false,
     "start_time": "2025-10-22T06:47:22.365425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%writefile /kaggle/working/RT-DETR/rtdetrv2_pytorch/configs/rtdetrv2/rtdetrv2_taco_finetune_vit.yml\n",
    "# __include__: [\n",
    "#   '../dataset/coco_detection.yml',\n",
    "#   '../runtime.yml',\n",
    "#   './include/dataloader.yml',\n",
    "#   './include/rtdetrv2_r50vd.yml',\n",
    "# ]\n",
    "\n",
    "# output_dir: ./output/rtdetrv2_finetune_taco_vit_teacher\n",
    "\n",
    "# RTDETR:\n",
    "#   backbone: HGNetv2\n",
    "\n",
    "# HGNetv2:\n",
    "#   name: 'L'\n",
    "#   return_idx: [1, 2, 3]\n",
    "#   freeze_at: 0\n",
    "#   freeze_norm: True\n",
    "#   pretrained: True\n",
    "\n",
    "# task: detection\n",
    "# remap_mscoco_category: false\n",
    "# tuning: '../distilled_rtdetr_vit_teacher_BEST.pth'\n",
    "# compile: true\n",
    "# epoches: 50\n",
    "\n",
    "# num_classes: 60\n",
    "\n",
    "# train_dataloader:\n",
    "#   num_workers: 4\n",
    "#   dataset:\n",
    "#     type: CocoDetection\n",
    "#     img_folder: /kaggle/input/dsp-pre-final/processed_taco_coco/train2017\n",
    "#     ann_file: /kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_train2017.json\n",
    "\n",
    "# val_dataloader:\n",
    "#   num_workers: 4\n",
    "#   dataset:\n",
    "#     type: CocoDetection\n",
    "#     img_folder: /kaggle/input/dsp-pre-final/processed_taco_coco/val2017\n",
    "#     ann_file: /kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_val2017.json\n",
    "\n",
    "# batch_size: 16\n",
    "\n",
    "# optimizer:\n",
    "#   type: AdamW\n",
    "#   params:\n",
    "#     - params: '^(?=.*backbone)'\n",
    "#       lr: 0.00001\n",
    "#   lr: 0.0001\n",
    "#   weight_decay: 0.0001\n",
    "#   betas: [0.9, 0.999]\n",
    "\n",
    "# lr_scheduler:\n",
    "#   type: OneCycleLR\n",
    "#   max_lr: 0.0001\n",
    "#   pct_start: 0.3\n",
    "#   total_steps: 4000\n",
    "\n",
    "# checkpoint_freq: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0adc9464",
   "metadata": {
    "_cell_guid": "9bcc5dc6-ae64-4b71-bc87-312b277a1b25",
    "_uuid": "45e49d72-c206-4aca-b41d-453224d3e25e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-22T06:47:22.445681Z",
     "iopub.status.busy": "2025-10-22T06:47:22.445265Z",
     "iopub.status.idle": "2025-10-22T06:47:22.447914Z",
     "shell.execute_reply": "2025-10-22T06:47:22.447425Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.028965,
     "end_time": "2025-10-22T06:47:22.448965",
     "exception": false,
     "start_time": "2025-10-22T06:47:22.420000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %cd /kaggle/working/RT-DETR/rtdetrv2_pytorch/\n",
    "\n",
    "# !torchrun --nproc_per_node=2 tools/train.py \\\n",
    "#     -c configs/rtdetrv2/rtdetrv2_taco_finetune_vit.yml \\\n",
    "#     --use-amp \\\n",
    "#     --seed=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54e7770",
   "metadata": {
    "_cell_guid": "915d0b8f-ecb7-4964-a165-f9c2e4fa570a",
    "_uuid": "798f3397-2277-47b7-91a8-0827f31453d4",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.024818,
     "end_time": "2025-10-22T06:47:22.499830",
     "exception": false,
     "start_time": "2025-10-22T06:47:22.475012",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# With baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e92f4b90",
   "metadata": {
    "_cell_guid": "49d56ad7-ac4c-470d-987f-b6fbc8341835",
    "_uuid": "7296ee67-0d55-46f1-a1e8-0cce2d3cd697",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-22T06:47:22.550319Z",
     "iopub.status.busy": "2025-10-22T06:47:22.550129Z",
     "iopub.status.idle": "2025-10-22T06:47:22.554394Z",
     "shell.execute_reply": "2025-10-22T06:47:22.553510Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.031004,
     "end_time": "2025-10-22T06:47:22.555567",
     "exception": false,
     "start_time": "2025-10-22T06:47:22.524563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%writefile /kaggle/working/RT-DETR/rtdetrv2_pytorch/configs/rtdetrv2/rtdetrv2_taco_finetune_BASELINE.yml\n",
    "# __include__: [\n",
    "#   '../dataset/coco_detection.yml',\n",
    "#   '../runtime.yml',\n",
    "#   './include/dataloader.yml',\n",
    "#   './include/rtdetrv2_r50vd.yml',\n",
    "# ]\n",
    "\n",
    "# output_dir: ./output/rtdetrv2_finetune_taco_BASELINE\n",
    "\n",
    "# RTDETR:\n",
    "#   backbone: HGNetv2\n",
    "\n",
    "# HGNetv2:\n",
    "#   name: 'L'\n",
    "#   return_idx: [1, 2, 3]\n",
    "#   freeze_at: 0\n",
    "#   freeze_norm: True\n",
    "#   pretrained: True \n",
    "\n",
    "# task: detection\n",
    "# remap_mscoco_category: false\n",
    "\n",
    "# compile: true\n",
    "# epoches: 50\n",
    "# num_classes: 60\n",
    "\n",
    "\n",
    "# train_dataloader:\n",
    "#   num_workers: 4\n",
    "#   dataset:\n",
    "#     type: CocoDetection\n",
    "#     img_folder: /kaggle/input/dsp-pre-final/processed_taco_coco/train2017\n",
    "#     ann_file: /kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_train2017.json\n",
    "\n",
    "# val_dataloader:\n",
    "#   num_workers: 4\n",
    "#   dataset:\n",
    "#     type: CocoDetection\n",
    "#     img_folder: /kaggle/input/dsp-pre-final/processed_taco_coco/val2017\n",
    "#     ann_file: /kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_val2017.json\n",
    "\n",
    "# batch_size: 16\n",
    "\n",
    "# optimizer:\n",
    "#   type: AdamW\n",
    "#   params:\n",
    "#     - params: '^(?=.*backbone)'\n",
    "#       lr: 0.00001\n",
    "#   lr: 0.0001\n",
    "#   weight_decay: 0.0001\n",
    "#   betas: [0.9, 0.999]\n",
    "\n",
    "# lr_scheduler:\n",
    "#   type: OneCycleLR\n",
    "#   max_lr: 0.0001\n",
    "#   pct_start: 0.3\n",
    "#   total_steps: 4000\n",
    "\n",
    "# checkpoint_freq: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "184b04e4",
   "metadata": {
    "_cell_guid": "ffb888ea-1cf2-48d8-98f2-a1ed1874d0ed",
    "_uuid": "205387e3-aa82-426b-bfcc-91a2198ec36c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-22T06:47:22.606880Z",
     "iopub.status.busy": "2025-10-22T06:47:22.606696Z",
     "iopub.status.idle": "2025-10-22T06:47:22.609603Z",
     "shell.execute_reply": "2025-10-22T06:47:22.609099Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.029962,
     "end_time": "2025-10-22T06:47:22.610541",
     "exception": false,
     "start_time": "2025-10-22T06:47:22.580579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %cd /kaggle/working/RT-DETR/rtdetrv2_pytorch/\n",
    "\n",
    "# !torchrun --nproc_per_node=2 tools/train.py \\\n",
    "#     -c configs/rtdetrv2/rtdetrv2_taco_finetune_BASELINE.yml \\\n",
    "#     --use-amp \\\n",
    "#     --seed=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78c324a6",
   "metadata": {
    "_cell_guid": "8dd03ed4-d87b-4d9d-ae7e-4a8e11f921b8",
    "_uuid": "7292df50-a1b0-4b0b-b329-80058c9fec8e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-22T06:47:22.661578Z",
     "iopub.status.busy": "2025-10-22T06:47:22.661202Z",
     "iopub.status.idle": "2025-10-22T06:47:25.739305Z",
     "shell.execute_reply": "2025-10-22T06:47:25.738345Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.105133,
     "end_time": "2025-10-22T06:47:25.740617",
     "exception": false,
     "start_time": "2025-10-22T06:47:22.635484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "!pip install -q ultralytics\n",
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09d261fa",
   "metadata": {
    "_cell_guid": "6ab8af32-b620-44d2-a104-3dae84b24142",
    "_uuid": "bb895dd4-b5ff-4c8e-8bc1-f34a83a9e77e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-22T06:47:25.793456Z",
     "iopub.status.busy": "2025-10-22T06:47:25.792762Z",
     "iopub.status.idle": "2025-10-22T06:47:39.733292Z",
     "shell.execute_reply": "2025-10-22T06:47:39.732336Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 13.968052,
     "end_time": "2025-10-22T06:47:39.734559",
     "exception": false,
     "start_time": "2025-10-22T06:47:25.766507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting instances_train2017.json: 100%|██████████| 4004/4004 [00:00<00:00, 29923.50it/s]\n",
      "Converting instances_val2017.json: 100%|██████████| 776/776 [00:00<00:00, 32674.58it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "YOLO_DATA_ROOT = '/kaggle/working/taco_yolo'\n",
    "IMAGE_TRAIN_DIR_DEST = os.path.join(YOLO_DATA_ROOT, 'images', 'train')\n",
    "IMAGE_VAL_DIR_DEST = os.path.join(YOLO_DATA_ROOT, 'images', 'val')\n",
    "LABEL_TRAIN_DIR_DEST = os.path.join(YOLO_DATA_ROOT, 'labels', 'train')\n",
    "LABEL_VAL_DIR_DEST = os.path.join(YOLO_DATA_ROOT, 'labels', 'val')\n",
    "\n",
    "os.makedirs(IMAGE_TRAIN_DIR_DEST, exist_ok=True)\n",
    "os.makedirs(IMAGE_VAL_DIR_DEST, exist_ok=True)\n",
    "os.makedirs(LABEL_TRAIN_DIR_DEST, exist_ok=True)\n",
    "os.makedirs(LABEL_VAL_DIR_DEST, exist_ok=True)\n",
    "\n",
    "IMAGE_TRAIN_DIR_SRC = '/kaggle/input/dsp-pre-final/processed_taco_coco/train2017'\n",
    "IMAGE_VAL_DIR_SRC = '/kaggle/input/dsp-pre-final/processed_taco_coco/val2017'\n",
    "\n",
    "!cp -n {IMAGE_TRAIN_DIR_SRC}/* {IMAGE_TRAIN_DIR_DEST}/\n",
    "!cp -n {IMAGE_VAL_DIR_SRC}/* {IMAGE_VAL_DIR_DEST}/\n",
    "\n",
    "COCO_ANNOTATIONS_TRAIN = '/kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_train2017.json'\n",
    "COCO_ANNOTATIONS_VAL = '/kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_val2017.json'\n",
    "\n",
    "def convert_coco_to_yolo(json_file, output_labels_dir):\n",
    "    with open(json_file) as f: data = json.load(f)\n",
    "    images_map = {img['id']: (img['file_name'], img['width'], img['height']) for img in data['images']}\n",
    "    for ann in tqdm(data['annotations'], desc=f\"Converting {os.path.basename(json_file)}\"):\n",
    "        image_id, class_id = ann['image_id'], ann['category_id']\n",
    "        if image_id not in images_map: continue\n",
    "        file_name, img_w, img_h = images_map[image_id]\n",
    "        box = ann['bbox']\n",
    "        x, y, w, h = box\n",
    "        x_center, y_center = (x + w / 2) / img_w, (y + h / 2) / img_h\n",
    "        norm_w, norm_h = w / img_w, h / img_h\n",
    "        label_file_name = os.path.splitext(file_name)[0] + '.txt'\n",
    "        label_file_path = os.path.join(output_labels_dir, label_file_name)\n",
    "        with open(label_file_path, 'a') as f:\n",
    "            f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {norm_w:.6f} {norm_h:.6f}\\n\")\n",
    "\n",
    "convert_coco_to_yolo(COCO_ANNOTATIONS_TRAIN, LABEL_TRAIN_DIR_DEST)\n",
    "convert_coco_to_yolo(COCO_ANNOTATIONS_VAL, LABEL_VAL_DIR_DEST)\n",
    "\n",
    "with open(COCO_ANNOTATIONS_TRAIN) as f: coco_data = json.load(f)\n",
    "categories = sorted(coco_data['categories'], key=lambda x: x['id'])\n",
    "class_names = [cat['name'] for cat in categories]\n",
    "\n",
    "taco_yaml_content = {\n",
    "    'path': YOLO_DATA_ROOT, 'train': 'images/train', 'val': 'images/val',\n",
    "    'nc': len(class_names), 'names': class_names\n",
    "}\n",
    "\n",
    "YAML_PATH = os.path.join(YOLO_DATA_ROOT, 'taco.yaml')\n",
    "with open(YAML_PATH, 'w') as f: yaml.dump(taco_yaml_content, f, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebeb4c12",
   "metadata": {
    "_cell_guid": "3e81bab1-7bd4-44bc-bf25-34f559204cf2",
    "_uuid": "2f5c8d18-9004-4b51-a50b-1ddeae5d7d8b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-22T06:47:39.787347Z",
     "iopub.status.busy": "2025-10-22T06:47:39.787120Z",
     "iopub.status.idle": "2025-10-22T06:47:39.805658Z",
     "shell.execute_reply": "2025-10-22T06:47:39.804942Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.045854,
     "end_time": "2025-10-22T06:47:39.806654",
     "exception": false,
     "start_time": "2025-10-22T06:47:39.760800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: /kaggle/working/taco_yolo\n",
      "train: images/train\n",
      "val: images/val\n",
      "nc: 60\n",
      "names:\n",
      "- Aluminium foil\n",
      "- Battery\n",
      "- Aluminium blister pack\n",
      "- Carded blister pack\n",
      "- Other plastic bottle\n",
      "- Clear plastic bottle\n",
      "- Glass bottle\n",
      "- Plastic bottle cap\n",
      "- Metal bottle cap\n",
      "- Broken glass\n",
      "- Food Can\n",
      "- Aerosol\n",
      "- Drink can\n",
      "- Toilet tube\n",
      "- Other carton\n",
      "- Egg carton\n",
      "- Drink carton\n",
      "- Corrugated carton\n",
      "- Meal carton\n",
      "- Pizza box\n",
      "- Paper cup\n",
      "- Disposable plastic cup\n",
      "- Foam cup\n",
      "- Glass cup\n",
      "- Other plastic cup\n",
      "- Food waste\n",
      "- Glass jar\n",
      "- Plastic lid\n",
      "- Metal lid\n",
      "- Other plastic\n",
      "- Magazine paper\n",
      "- Tissues\n",
      "- Wrapping paper\n",
      "- Normal paper\n",
      "- Paper bag\n",
      "- Plastified paper bag\n",
      "- Plastic film\n",
      "- Six pack rings\n",
      "- Garbage bag\n",
      "- Other plastic wrapper\n",
      "- Single-use carrier bag\n",
      "- Polypropylene bag\n",
      "- Crisp packet\n",
      "- Spread tub\n",
      "- Tupperware\n",
      "- Disposable food container\n",
      "- Foam food container\n",
      "- Other plastic container\n",
      "- Plastic glooves\n",
      "- Plastic utensils\n",
      "- Pop tab\n",
      "- Rope & strings\n",
      "- Scrap metal\n",
      "- Shoe\n",
      "- Squeezable tube\n",
      "- Plastic straw\n",
      "- Paper straw\n",
      "- Styrofoam piece\n",
      "- Unlabeled litter\n",
      "- Cigarette\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import json\n",
    "import os\n",
    "\n",
    "COCO_ANNOTATIONS_TRAIN = '/kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_train2017.json'\n",
    "YOLO_DATA_ROOT = '/kaggle/working/taco_yolo'\n",
    "\n",
    "with open(COCO_ANNOTATIONS_TRAIN) as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "categories = sorted(coco_data['categories'], key=lambda x: x['id'])\n",
    "class_names = [cat['name'] for cat in categories]\n",
    "\n",
    "taco_yaml_content = {\n",
    "    'path': YOLO_DATA_ROOT,\n",
    "    'train': 'images/train',\n",
    "    'val': 'images/val',\n",
    "    'nc': len(class_names),\n",
    "    'names': class_names\n",
    "}\n",
    "\n",
    "YAML_PATH = os.path.join(YOLO_DATA_ROOT, 'taco.yaml')\n",
    "with open(YAML_PATH, 'w') as f:\n",
    "    yaml.dump(taco_yaml_content, f, sort_keys=False)\n",
    "\n",
    "with open(YAML_PATH, 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e67157be",
   "metadata": {
    "_cell_guid": "3b09b13c-d5b5-42db-9b3d-875ae9d1ed96",
    "_uuid": "985a0699-45ca-46d3-8c77-356d014183c6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-22T06:47:39.858168Z",
     "iopub.status.busy": "2025-10-22T06:47:39.857974Z",
     "iopub.status.idle": "2025-10-22T06:47:39.863091Z",
     "shell.execute_reply": "2025-10-22T06:47:39.862533Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.03206,
     "end_time": "2025-10-22T06:47:39.864145",
     "exception": false,
     "start_time": "2025-10-22T06:47:39.832085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing training_yolov11.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile training_yolov11.py\n",
    "from ultralytics import YOLO\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "output_path = '/kaggle/working/yolo_checkpoints'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    secrets = UserSecretsClient()\n",
    "    wandb_key = secrets.get_secret(\"WANDB_API_KEY\")\n",
    "    wandb.login(key=wandb_key)\n",
    "except Exception as e:\n",
    "    print(f\"{e}\")\n",
    "    \n",
    "wandb.init(\n",
    "    project='yolo_runs_taco',\n",
    "    name='yolo11l_taco_finetune_baseline',\n",
    "    job_type='fine-tuning'\n",
    ")\n",
    "\n",
    "model = YOLO('yolo11l.pt')\n",
    "\n",
    "results = model.train(\n",
    "    data='/kaggle/working/taco_yolo/taco.yaml',\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=32,\n",
    "    project=output_path,\n",
    "    name='yolo11l_finetune_baseline',\n",
    "    exist_ok=True,\n",
    "    device=[0, 1]\n",
    ")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52fcd857",
   "metadata": {
    "_cell_guid": "57c63690-08ef-41e6-a0da-7314ba5614f2",
    "_uuid": "5c4da791-a9a1-4296-a0d5-73545c423308",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-22T06:47:39.915737Z",
     "iopub.status.busy": "2025-10-22T06:47:39.915538Z",
     "iopub.status.idle": "2025-10-22T07:21:34.160064Z",
     "shell.execute_reply": "2025-10-22T07:21:34.159303Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2034.272035,
     "end_time": "2025-10-22T07:21:34.161476",
     "exception": false,
     "start_time": "2025-10-22T06:47:39.889441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \r\n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\r\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnamthse182380\u001b[0m (\u001b[33mnamthse182380-fpt-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.0\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20251022_064744-d7vme7qn\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myolo11l_taco_finetune_baseline\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/namthse182380-fpt-university/yolo_runs_taco\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/namthse182380-fpt-university/yolo_runs_taco/runs/d7vme7qn\u001b[0m\r\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11l.pt to 'yolo11l.pt': 100% ━━━━━━━━━━━━ 49.0MB 183.2MB/s 0.3s\r\n",
      "Ultralytics 8.3.218 🚀 Python-3.11.13 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\r\n",
      "                                                       CUDA:1 (Tesla T4, 15095MiB)\r\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/taco_yolo/taco.yaml, degrees=0.0, deterministic=True, device=0,1, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo11l_finetune_baseline, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/yolo_checkpoints, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/yolo_checkpoints/yolo11l_finetune_baseline, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\r\n",
      "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 16.6MB/s 0.0s\r\n",
      "Overriding model.yaml nc=80 with nc=60\r\n",
      "\r\n",
      "                   from  n    params  module                                       arguments                     \r\n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \r\n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \r\n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \r\n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \r\n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \r\n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \r\n",
      "  6                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \r\n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \r\n",
      "  8                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \r\n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \r\n",
      " 10                  -1  2   1455616  ultralytics.nn.modules.block.C2PSA           [512, 512, 2]                 \r\n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 13                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \r\n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 16                  -1  2    756736  ultralytics.nn.modules.block.C3k2            [1024, 256, 2, True]          \r\n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \r\n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 19                  -1  2   2365440  ultralytics.nn.modules.block.C3k2            [768, 512, 2, True]           \r\n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \r\n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 22                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \r\n",
      " 23        [16, 19, 22]  1   1457284  ultralytics.nn.modules.head.Detect           [60, [256, 512, 512]]         \r\n",
      "YOLO11l summary: 357 layers, 25,356,740 parameters, 25,356,724 gradients, 87.5 GFLOPs\r\n",
      "\r\n",
      "Transferred 1009/1015 items from pretrained weights\r\n",
      "\u001b[34m\u001b[1mDDP:\u001b[0m debug command /usr/bin/python3 -m torch.distributed.run --nproc_per_node 2 --master_port 50501 /root/.config/Ultralytics/DDP/_temp_4oa2q2e7135963462835600.py\r\n",
      "Ultralytics 8.3.218 🚀 Python-3.11.13 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\r\n",
      "                                                       CUDA:1 (Tesla T4, 15095MiB)\r\n",
      "Overriding model.yaml nc=80 with nc=60\r\n",
      "Transferred 1009/1015 items from pretrained weights\r\n",
      "Freezing layer 'model.23.dfl.conv.weight'\r\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\r\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4MB 70.9MB/s 0.1s\r\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2180.6±1027.6 MB/s, size: 260.9 KB)\r\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/taco_yolo/labels/train... 1273 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1273/1273 1.5Kit/s 0.9s\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/taco_yolo/labels/train.cache\r\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1800.1±1026.0 MB/s, size: 234.5 KB)\r\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/taco_yolo/labels/val... 225 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 225/225 1.7Kit/s 0.1s\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/taco_yolo/labels/val.cache\r\n",
      "Plotting labels to /kaggle/working/yolo_checkpoints/yolo11l_finetune_baseline/labels.jpg... \r\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \r\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000156, momentum=0.9) with parameter groups 167 weight(decay=0.0), 174 weight(decay=0.0005), 173 bias(decay=0.0)\r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 4 dataloader workers\r\n",
      "Logging results to \u001b[1m/kaggle/working/yolo_checkpoints/yolo11l_finetune_baseline\u001b[0m\r\n",
      "Starting training for 50 epochs...\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K       1/50      10.2G      1.169      4.975      1.255         44        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.3s\r\n",
      "/usr/local/lib/python3.11/dist-packages/ultralytics/utils/metrics.py:73: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1442.)\r\n",
      "  inter = (torch.min(a2, b2) - torch.max(a1, b1)).clamp_(0).prod(2)\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.0it/s 3.9s\r\n",
      "                   all        225        776      0.578     0.0979     0.0596     0.0482\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K       2/50      10.3G      1.119      3.439      1.199         57        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.7s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.5s\r\n",
      "                   all        225        776      0.317      0.164     0.0892     0.0703\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K       3/50      10.3G      1.114      3.135      1.191         33        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 36.6s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.6s\r\n",
      "                   all        225        776      0.417      0.159      0.109     0.0893\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K       4/50      10.3G      1.114      2.797        1.2         48        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 34.3s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.6s\r\n",
      "                   all        225        776      0.512      0.146      0.134      0.104\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K       5/50      10.4G      1.087      2.634      1.194         56        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.1s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.6s\r\n",
      "                   all        225        776      0.355      0.178      0.124     0.0872\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K       6/50      10.3G      1.021      2.395      1.156         53        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.0s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.6s\r\n",
      "                   all        225        776      0.372       0.22       0.16      0.125\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K       7/50      10.3G      1.044       2.39      1.168         40        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 34.9s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.6s\r\n",
      "                   all        225        776      0.458      0.187      0.196       0.16\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K       8/50      10.3G      0.989      2.159      1.119         44        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.2s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.6s\r\n",
      "                   all        225        776       0.39      0.226      0.192      0.155\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K       9/50      10.3G     0.9747      2.023      1.126         62        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.2s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.6s\r\n",
      "                   all        225        776      0.441      0.218      0.209      0.169\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      10/50      10.3G     0.9787       1.99      1.147         53        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.2s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.6s\r\n",
      "                   all        225        776      0.379      0.232      0.193      0.157\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      11/50      10.3G      1.003      1.961      1.153         37        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.1s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.6s\r\n",
      "                   all        225        776      0.473      0.209      0.203      0.165\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      12/50      10.4G     0.9543      1.827      1.112         70        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.2s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.6s\r\n",
      "                   all        225        776      0.328      0.265      0.223      0.177\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      13/50      10.3G     0.9682      1.745      1.115         69        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.1s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.6s\r\n",
      "                   all        225        776      0.428      0.257      0.227      0.184\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      14/50      10.3G     0.9271      1.654      1.092         72        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.2s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.6s\r\n",
      "                   all        225        776      0.455      0.231      0.223      0.186\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      15/50      10.3G     0.8749      1.559      1.063         39        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.1s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.6s\r\n",
      "                   all        225        776      0.521      0.211      0.221      0.184\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      16/50      10.3G     0.9135      1.545      1.084         71        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.1s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.6s\r\n",
      "                   all        225        776      0.534       0.19      0.217      0.173\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      17/50      10.3G     0.8896      1.386      1.071         48        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.2s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.6s\r\n",
      "                   all        225        776      0.374      0.277      0.251      0.206\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      18/50      10.3G      0.876      1.408      1.056         74        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.2s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.6s\r\n",
      "                   all        225        776      0.363      0.256      0.246      0.207\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      19/50      10.4G     0.8378        1.3      1.044         89        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.2s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.6s\r\n",
      "                   all        225        776      0.482       0.21      0.226      0.181\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      20/50      10.3G     0.8527      1.321      1.061         34        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.2s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.6s\r\n",
      "                   all        225        776      0.469      0.251      0.243        0.2\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      21/50      10.4G     0.8642      1.276      1.062         64        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.1s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.6s\r\n",
      "                   all        225        776      0.559       0.23       0.25      0.205\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      22/50      10.4G     0.8174      1.134      1.021         76        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.3s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.6s\r\n",
      "                   all        225        776      0.293      0.274      0.241      0.194\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      23/50      10.4G     0.8279       1.12      1.039         99        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.3s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.6s\r\n",
      "                   all        225        776      0.324      0.257      0.239      0.195\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      24/50      10.4G      0.798      1.096      1.023         24        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.2s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.6s\r\n",
      "                   all        225        776      0.436      0.233      0.236      0.194\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      25/50      10.3G     0.7902      1.016       1.02         33        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.2s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.6s\r\n",
      "                   all        225        776      0.413       0.21      0.222       0.18\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      26/50      10.3G     0.8281      1.015      1.023         45        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 34.9s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.6s\r\n",
      "                   all        225        776      0.483      0.217      0.232      0.189\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      27/50      10.4G     0.7666     0.9764      1.015         58        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.5s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.6s\r\n",
      "                   all        225        776      0.451      0.246       0.25      0.208\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      28/50      10.4G     0.7668     0.9272      1.006         91        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 34.9s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.6s\r\n",
      "                   all        225        776      0.522      0.221      0.242      0.199\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      29/50      10.3G      0.782     0.9405      1.016         66        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.2s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.6s\r\n",
      "                   all        225        776      0.408      0.263      0.259      0.218\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      30/50      10.4G      0.756     0.8934      1.007         51        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.3s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.6s\r\n",
      "                   all        225        776      0.478       0.23      0.238      0.197\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      31/50      10.3G     0.7353     0.8251     0.9895         77        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.0s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.5s\r\n",
      "                   all        225        776      0.362       0.26      0.256      0.219\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      32/50      10.4G     0.7459     0.8319     0.9866         81        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.1s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.6s\r\n",
      "                   all        225        776      0.537       0.19       0.24      0.201\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      33/50      10.3G     0.7381     0.8245     0.9879         35        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.2s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.5s\r\n",
      "                   all        225        776      0.505      0.182      0.218      0.182\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      34/50      10.4G     0.7394     0.8337     0.9751         81        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.2s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.5s\r\n",
      "                   all        225        776      0.667       0.18      0.237        0.2\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      35/50      10.3G     0.7348     0.7913     0.9929         82        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.1s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.5s\r\n",
      "                   all        225        776      0.451      0.213       0.23      0.193\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      36/50      10.4G     0.7443     0.7646     0.9861         40        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.2s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.5s\r\n",
      "                   all        225        776      0.444      0.211      0.237        0.2\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      37/50      10.4G     0.7168     0.7411     0.9875         67        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.1s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.5s\r\n",
      "                   all        225        776      0.338      0.252      0.235      0.191\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      38/50      10.4G     0.6805     0.6963     0.9786         72        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.3s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.5s\r\n",
      "                   all        225        776      0.476      0.213      0.249      0.214\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      39/50      10.4G      0.669     0.7051     0.9743         51        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.1s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.5s\r\n",
      "                   all        225        776      0.524      0.227      0.252      0.214\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      40/50      10.3G     0.6572     0.6701     0.9516         27        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.1s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.5s\r\n",
      "                   all        225        776      0.609      0.187      0.242      0.206\r\n",
      "Closing dataloader mosaic\r\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      41/50      10.4G     0.5974     0.5814     0.9061         20        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 36.3s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.5s\r\n",
      "                   all        225        776      0.602      0.207      0.235      0.198\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      42/50      10.4G     0.5851     0.5371     0.8971         20        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.1s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.6s\r\n",
      "                   all        225        776      0.429      0.253       0.26      0.221\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      43/50      10.3G     0.5881     0.5192     0.8884         40        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.0s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.5s\r\n",
      "                   all        225        776      0.393      0.266      0.253      0.216\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      44/50      10.3G     0.5822     0.5143     0.8918         26        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.0s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.6s\r\n",
      "                   all        225        776      0.465      0.236      0.253      0.212\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      45/50      10.4G     0.5982     0.4988     0.8865         39        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.1s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.5s\r\n",
      "                   all        225        776      0.471      0.234      0.245      0.209\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      46/50      10.3G     0.5825     0.4941     0.8869         36        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.2s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.5s\r\n",
      "                   all        225        776      0.529      0.237      0.251      0.214\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      47/50      10.3G      0.576     0.5021     0.8994         61        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.1s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.5s\r\n",
      "                   all        225        776       0.35      0.275      0.259      0.223\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      48/50      10.3G     0.5473     0.4641     0.8748         29        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 34.9s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.5s\r\n",
      "                   all        225        776      0.403      0.266      0.263       0.23\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      49/50      10.3G     0.5672     0.4721     0.8772         21        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.0s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.5s\r\n",
      "                   all        225        776      0.485      0.225      0.262      0.227\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      50/50      10.4G     0.5314     0.4509     0.8719         42        640: 100% ━━━━━━━━━━━━ 40/40 1.1it/s 35.2s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.5s\r\n",
      "                   all        225        776      0.406      0.264      0.265      0.229\r\n",
      "\r\n",
      "50 epochs completed in 0.552 hours.\r\n",
      "Optimizer stripped from /kaggle/working/yolo_checkpoints/yolo11l_finetune_baseline/weights/last.pt, 51.3MB\r\n",
      "Optimizer stripped from /kaggle/working/yolo_checkpoints/yolo11l_finetune_baseline/weights/best.pt, 51.3MB\r\n",
      "\r\n",
      "Validating /kaggle/working/yolo_checkpoints/yolo11l_finetune_baseline/weights/best.pt...\r\n",
      "YOLO11l summary (fused): 190 layers, 25,325,572 parameters, 0 gradients, 86.8 GFLOPs\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.3it/s 3.2s\r\n",
      "                   all        225        776      0.403      0.265      0.263       0.23\r\n",
      "        Aluminium foil          6          7          0          0     0.0521     0.0402\r\n",
      "  Other plastic bottle          7          8      0.203       0.25      0.221      0.214\r\n",
      "  Clear plastic bottle         36         46      0.578       0.63       0.64       0.53\r\n",
      "          Glass bottle          5          6      0.204      0.167       0.13      0.124\r\n",
      "    Plastic bottle cap         36         44      0.547      0.412      0.475      0.318\r\n",
      "      Metal bottle cap         10         10      0.527        0.6      0.627       0.56\r\n",
      "          Broken glass          3          8          0          0          0          0\r\n",
      "              Food Can          3          8      0.111      0.125      0.207       0.18\r\n",
      "               Aerosol          3          3      0.309      0.333      0.349      0.349\r\n",
      "             Drink can         24         46      0.619      0.635      0.611      0.447\r\n",
      "          Other carton          9          9     0.0474      0.111      0.161       0.15\r\n",
      "            Egg carton          2          3          1          0          0          0\r\n",
      "          Drink carton          5          5      0.211        0.2      0.245      0.222\r\n",
      "     Corrugated carton          5          7      0.482      0.714      0.582      0.551\r\n",
      "           Meal carton          3          4       0.67        0.5      0.559      0.482\r\n",
      "             Paper cup         11         11      0.137     0.0909      0.183      0.106\r\n",
      "Disposable plastic cup          8         10      0.483        0.6      0.434      0.337\r\n",
      "              Foam cup          3          4          0          0          0          0\r\n",
      "             Glass cup          1          1          1          0          0          0\r\n",
      "            Food waste          2          2          0          0          0          0\r\n",
      "             Glass jar          1          2      0.878        0.5      0.578      0.578\r\n",
      "           Plastic lid         14         18       0.54      0.278      0.272      0.221\r\n",
      "             Metal lid          2          3          1          0          0          0\r\n",
      "         Other plastic         32         44      0.212      0.178       0.15      0.118\r\n",
      "               Tissues          5          6      0.209      0.167     0.0623     0.0544\r\n",
      "        Wrapping paper          5          5          0          0     0.0259     0.0186\r\n",
      "          Normal paper         11         15      0.125      0.133      0.131      0.117\r\n",
      "             Paper bag          3          3      0.633      0.667      0.448      0.448\r\n",
      "          Plastic film         40         60        0.3      0.317      0.268      0.221\r\n",
      "        Six pack rings          1          1      0.609          1      0.995      0.995\r\n",
      "           Garbage bag          3          4      0.251       0.25      0.268      0.243\r\n",
      " Other plastic wrapper         26         61       0.22      0.286      0.234      0.157\r\n",
      "Single-use carrier bag          7          9      0.112      0.222      0.152      0.118\r\n",
      "          Crisp packet          7          8      0.172       0.25      0.255      0.204\r\n",
      "            Spread tub          2          2          1          0          0          0\r\n",
      "Disposable food container          6          6      0.359      0.333      0.345      0.345\r\n",
      "   Foam food container          2          3      0.631          1      0.995      0.963\r\n",
      "       Plastic glooves          2          2      0.685        0.5      0.523      0.523\r\n",
      "      Plastic utensils          3          3          1          0     0.0601     0.0601\r\n",
      "               Pop tab         15         24      0.445      0.102      0.117     0.0865\r\n",
      "        Rope & strings          4          4      0.234       0.25      0.249      0.149\r\n",
      "                  Shoe          1          2          0          0          0          0\r\n",
      "       Squeezable tube          2          2          0          0          0          0\r\n",
      "         Plastic straw         18         22       0.58      0.318      0.348       0.28\r\n",
      "           Paper straw          2          2          1          0          0          0\r\n",
      "       Styrofoam piece         15         20      0.522        0.4      0.465      0.407\r\n",
      "      Unlabeled litter         44        124      0.205     0.0968     0.0725     0.0321\r\n",
      "             Cigarette         29         79      0.302      0.127      0.144     0.0741\r\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.0ms loss, 2.0ms postprocess per image\r\n",
      "Results saved to \u001b[1m/kaggle/working/yolo_checkpoints/yolo11l_finetune_baseline\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33myolo11l_taco_finetune_baseline\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/namthse182380-fpt-university/yolo_runs_taco/runs/d7vme7qn\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/namthse182380-fpt-university/yolo_runs_taco\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251022_064744-d7vme7qn/logs\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python training_yolov11.py"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8469591,
     "sourceId": 13441245,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8544211,
     "sourceId": 13460735,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31155,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2276.545264,
   "end_time": "2025-10-22T07:21:34.600922",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-22T06:43:38.055658",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
