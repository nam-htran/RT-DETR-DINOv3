{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed27c776",
   "metadata": {
    "_cell_guid": "0eaee57b-b046-48a4-8e75-0080b2c98450",
    "_uuid": "6615cf1e-a7ea-49e6-9dea-c8b1fefc58fa",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-30T15:33:51.531654Z",
     "iopub.status.busy": "2025-10-30T15:33:51.531445Z",
     "iopub.status.idle": "2025-10-30T15:37:18.501880Z",
     "shell.execute_reply": "2025-10-30T15:37:18.501042Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 206.977973,
     "end_time": "2025-10-30T15:37:18.503330",
     "exception": false,
     "start_time": "2025-10-30T15:33:51.525357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.4 which is incompatible.\r\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.16.3 which is incompatible.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.4 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.4 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.4 which is incompatible.\r\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\r\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.3.4 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires scipy<1.16,>=1.4.1, but you have scipy 1.16.3 which is incompatible.\r\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.2 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.2 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\r\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "transformers 4.53.3 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.0rc2 which is incompatible.\r\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.4 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.6 which is incompatible.\r\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.16.3 which is incompatible.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\r\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.6 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires scipy<1.16,>=1.4.1, but you have scipy 1.16.3 which is incompatible.\r\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.2 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.2 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.5.1 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.0.2 which is incompatible.\r\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.16.3 which is incompatible.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.0.2 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.0.2 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.0.2 which is incompatible.\r\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires matplotlib<=3.10,>=3.5, but you have matplotlib 3.10.7 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires scipy<1.16,>=1.4.1, but you have scipy 1.16.3 which is incompatible.\r\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.2 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.2 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "ibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\r\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "jupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\r\n",
      "dataproc-spark-connect 0.8.3 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PIP_DISABLE_PIP_VERSION_CHECK'] = '1'\n",
    "\n",
    "!pip install -q --upgrade pip\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n",
    "!pip install -q --upgrade numpy scipy scikit-learn\n",
    "!pip install -q timm pycocotools faster-coco-eval\n",
    "!pip install -q --upgrade transformers lightly-train\n",
    "!pip install -q wandb\n",
    "!pip install -q -U \"numpy<2.1\" matplotlib --force-reinstall --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d8ab74e",
   "metadata": {
    "_cell_guid": "2a760c63-9ab2-421e-bb62-339b640470ad",
    "_uuid": "935bf002-deca-44a3-9d44-2b289161e980",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-30T15:37:18.514394Z",
     "iopub.status.busy": "2025-10-30T15:37:18.514122Z",
     "iopub.status.idle": "2025-10-30T15:37:18.520957Z",
     "shell.execute_reply": "2025-10-30T15:37:18.520120Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013668,
     "end_time": "2025-10-30T15:37:18.522199",
     "exception": false,
     "start_time": "2025-10-30T15:37:18.508531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory structure for 'FINAL' created successfully.\n"
     ]
    }
   ],
   "source": [
    "FINAL_DIR = '/kaggle/working/FINAL'\n",
    "\n",
    "os.makedirs(os.path.join(FINAL_DIR, 'DISTILL-CONVNEXT'), exist_ok=True)\n",
    "os.makedirs(os.path.join(FINAL_DIR, 'DISTILL-VIT'), exist_ok=True)\n",
    "os.makedirs(os.path.join(FINAL_DIR, 'FINETUNE_BASELINE'), exist_ok=True)\n",
    "os.makedirs(os.path.join(FINAL_DIR, 'FINETUNE_DISTILLED'), exist_ok=True)\n",
    "os.makedirs(os.path.join(FINAL_DIR, 'YOLO'), exist_ok=True)\n",
    "os.makedirs(os.path.join(FINAL_DIR, 'CONFIG'), exist_ok=True)\n",
    "\n",
    "print(\"Directory structure for 'FINAL' created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc055d6b",
   "metadata": {
    "_cell_guid": "343c3d57-f2cc-473b-bb7d-d2e6f72c0641",
    "_uuid": "c4ff75be-b91a-4182-9c28-32d2e9201370",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-30T15:37:18.532671Z",
     "iopub.status.busy": "2025-10-30T15:37:18.532478Z",
     "iopub.status.idle": "2025-10-30T15:37:18.542003Z",
     "shell.execute_reply": "2025-10-30T15:37:18.541358Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.016339,
     "end_time": "2025-10-30T15:37:18.543130",
     "exception": false,
     "start_time": "2025-10-30T15:37:18.526791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing trainer_convnext.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile trainer_convnext.py\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModel, AutoConfig\n",
    "from PIL import Image\n",
    "from pycocotools.coco import COCO\n",
    "from torchvision import transforms as T\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import datetime\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "class HuggingFaceTeacherWrapper(nn.Module):\n",
    "    def __init__(self, model_id: str, token: str = None):\n",
    "        super().__init__()\n",
    "        if int(os.environ.get(\"RANK\", 0)) == 0:\n",
    "            print(f\"Loading teacher model '{model_id}' from Hugging Face...\")\n",
    "        \n",
    "        config = AutoConfig.from_pretrained(model_id, token=token, output_hidden_states=True)\n",
    "        self._model = AutoModel.from_pretrained(model_id, config=config, token=token)\n",
    "        \n",
    "        self.is_vit = \"vit\" in config.model_type.lower()\n",
    "        \n",
    "        all_hidden_sizes = self._model.config.hidden_sizes\n",
    "        self.feature_layers = [-3, -2, -1]\n",
    "        self.feature_dims = [all_hidden_sizes[i] for i in [1, 2, 3]]\n",
    "        \n",
    "        if int(os.environ.get(\"RANK\", 0)) == 0:\n",
    "            print(f\"Architecture: {'ViT' if self.is_vit else 'ConvNeXT'}.\")\n",
    "            print(f\"Extracting features from layers with dimensions: {self.feature_dims}\")\n",
    "\n",
    "    def forward(self, x: Tensor) -> list[Tensor]:\n",
    "        outputs = self._model(pixel_values=x)\n",
    "        selected_hidden_states = [outputs.hidden_states[i] for i in [2, 3, 4]]\n",
    "        return selected_hidden_states\n",
    "\n",
    "class CocoDetectionForDistill(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, ann_file, transforms):\n",
    "        self.root = root\n",
    "        self.coco = COCO(ann_file)\n",
    "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_id = self.ids[index]\n",
    "        path = self.coco.loadImgs(img_id)[0][\"file_name\"]\n",
    "        img = Image.open(os.path.join(self.root, path)).convert(\"RGB\")\n",
    "        return self.transforms(img), 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "def setup_ddp():\n",
    "    dist.init_process_group(backend=\"nccl\")\n",
    "    torch.cuda.set_device(int(os.environ[\"LOCAL_RANK\"]))\n",
    "\n",
    "def cleanup_ddp():\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "def main_training_function(rank, world_size, config):\n",
    "    device = rank\n",
    "    is_main_process = (rank == 0)\n",
    "    \n",
    "    if is_main_process:\n",
    "        print(f\"Running DDP on {world_size} GPUs.\")\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "        run_name = f\"run_ddp_convnext_{timestamp}_lr{config['learning_rate']}_bs{config['batch_size_per_gpu']}\"\n",
    "        try:\n",
    "            from kaggle_secrets import UserSecretsClient\n",
    "            from huggingface_hub import login\n",
    "            secrets = UserSecretsClient()\n",
    "            hf_token = secrets.get_secret(\"HUGGINGFACE_TOKEN\")\n",
    "            wandb_key = secrets.get_secret(\"WANDB_API_KEY\")\n",
    "            login(token=hf_token)\n",
    "            wandb.login(key=wandb_key)\n",
    "            wandb.init(project=config[\"wandb_project\"], config=config, name=run_name)\n",
    "        except Exception:\n",
    "            hf_token = None\n",
    "            print(\"Could not log in, continuing without W&B.\")\n",
    "    else:\n",
    "        hf_token = None\n",
    "\n",
    "    dist.barrier()\n",
    "    \n",
    "    teacher_model = HuggingFaceTeacherWrapper(config[\"teacher_hf_id\"], token=hf_token).to(device)\n",
    "    teacher_model.eval()\n",
    "\n",
    "    if is_main_process:\n",
    "        print(\"Loading student model on main process...\")\n",
    "        torch.hub.load(\"lyuwenyu/RT-DETR\", \"rtdetrv2_l\", pretrained=True, trust_repo=True)\n",
    "\n",
    "    dist.barrier()\n",
    "\n",
    "    student_hub_model = torch.hub.load(\"lyuwenyu/RT-DETR\", \"rtdetrv2_l\", pretrained=True, trust_repo=True)\n",
    "    student_model = student_hub_model.model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x = torch.randn(1, 3, 640, 640).to(device)\n",
    "        student_features_list = student_model.encoder(student_model.backbone(x))\n",
    "        student_channels = [f.shape[1] for f in student_features_list]\n",
    "    \n",
    "    teacher_dims = teacher_model.feature_dims \n",
    "    projection_layers = nn.ModuleList([\n",
    "        nn.Conv2d(student_channels[i], teacher_dims[i], kernel_size=1) for i in range(len(student_channels))\n",
    "    ]).to(device)\n",
    "    \n",
    "    if is_main_process:\n",
    "        for i in range(len(projection_layers)):\n",
    "            print(f\"Projection layer {i}: {student_channels[i]} -> {teacher_dims[i]}\")\n",
    "\n",
    "    student_model = DDP(student_model, device_ids=[device], find_unused_parameters=True)\n",
    "    projection_layers = DDP(projection_layers, device_ids=[device], find_unused_parameters=True)\n",
    "    \n",
    "    transforms = T.Compose([\n",
    "        T.Resize((640, 640)), T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    train_dataset = CocoDetectionForDistill(root=config[\"dataset_dir\"]+\"/train2017\", ann_file=config[\"dataset_dir\"]+\"/annotations/instances_train2017.json\", transforms=transforms)\n",
    "    val_dataset = CocoDetectionForDistill(root=config[\"dataset_dir\"]+\"/val2017\", ann_file=config[\"dataset_dir\"]+\"/annotations/instances_val2017.json\", transforms=transforms)\n",
    "    \n",
    "    if is_main_process:\n",
    "        print(f\"Data loaded: {len(train_dataset)} training images, {len(val_dataset)} validation images.\")\n",
    "\n",
    "    train_sampler = DistributedSampler(train_dataset, num_replicas=world_size, rank=rank, shuffle=True)\n",
    "    val_sampler = DistributedSampler(val_dataset, num_replicas=world_size, rank=rank, shuffle=False)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size_per_gpu\"], shuffle=False, num_workers=config[\"num_workers\"], pin_memory=True, drop_last=True, sampler=train_sampler)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size_per_gpu\"], shuffle=False, num_workers=config[\"num_workers\"], pin_memory=True, drop_last=False, sampler=val_sampler)\n",
    "\n",
    "    params = list(student_model.module.backbone.parameters()) + list(student_model.module.encoder.parameters()) + list(projection_layers.module.parameters())\n",
    "             \n",
    "    optimizer = torch.optim.AdamW(params, lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
    "    criterion = nn.MSELoss()\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=config['scheduler_factor'], patience=config['scheduler_patience'], verbose=is_main_process)\n",
    "\n",
    "    if is_main_process and wandb.run:\n",
    "        wandb.watch((student_model, projection_layers), log=\"all\", log_freq=100)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    early_stopping_counter = 0\n",
    "\n",
    "    if is_main_process:\n",
    "        print(\"Starting training...\")\n",
    "        \n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        train_sampler.set_epoch(epoch)\n",
    "        start = time.time()\n",
    "        student_model.train()\n",
    "        projection_layers.train()\n",
    "        total_train_loss = 0.0\n",
    "        \n",
    "        train_iterator = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['epochs']} [Train]\") if is_main_process else train_loader\n",
    "\n",
    "        for images, _ in train_iterator:\n",
    "            images = images.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                teacher_features_list = teacher_model(images)\n",
    "            \n",
    "            student_features_list = student_model.module.encoder(student_model.module.backbone(images))\n",
    "            \n",
    "            total_loss = 0\n",
    "            for i in range(len(student_features_list)):\n",
    "                student_feat = student_features_list[i]\n",
    "                teacher_feat = teacher_features_list[i]\n",
    "                \n",
    "                projected_feat = projection_layers.module[i](student_feat)\n",
    "                teacher_resized = F.interpolate(teacher_feat, size=projected_feat.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "                \n",
    "                total_loss += criterion(projected_feat, teacher_resized)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += total_loss.item()\n",
    "        \n",
    "        train_loss_tensor = torch.tensor(total_train_loss).to(device)\n",
    "        dist.all_reduce(train_loss_tensor, op=dist.ReduceOp.SUM)\n",
    "        avg_train_loss = train_loss_tensor.item() / (len(train_loader) * world_size)\n",
    "\n",
    "        student_model.eval()\n",
    "        projection_layers.eval()\n",
    "        total_val_loss = 0.0\n",
    "        \n",
    "        val_iterator = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{config['epochs']} [Val]\") if is_main_process else val_loader\n",
    "        with torch.no_grad():\n",
    "            for images, _ in val_iterator:\n",
    "                images = images.to(device)\n",
    "                teacher_features_list = teacher_model(images)\n",
    "                student_features_list = student_model.module.encoder(student_model.module.backbone(images))\n",
    "                \n",
    "                loss = 0\n",
    "                for i in range(len(student_features_list)):\n",
    "                    projected = projection_layers.module[i](student_features_list[i])\n",
    "                    teacher_resized = F.interpolate(teacher_features_list[i], size=projected.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "                    loss += criterion(projected, teacher_resized)\n",
    "                total_val_loss += loss.item()\n",
    "                \n",
    "        val_loss_tensor = torch.tensor(total_val_loss).to(device)\n",
    "        dist.all_reduce(val_loss_tensor, op=dist.ReduceOp.SUM)\n",
    "        avg_val_loss = val_loss_tensor.item() / (len(val_loader) * world_size)\n",
    "        \n",
    "        if is_main_process:\n",
    "            duration = time.time() - start\n",
    "            print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Duration: {duration:.2f}s\")\n",
    "            if wandb.run: wandb.log({\"epoch\": epoch + 1, \"train/avg_loss\": avg_train_loss, \"val/avg_loss\": avg_val_loss})\n",
    "            scheduler.step(avg_val_loss)\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                early_stopping_counter = 0\n",
    "                print(f\"Validation loss improved. Saving best model...\")\n",
    "                best_weights = {**student_model.module.backbone.state_dict(), **student_model.module.encoder.state_dict()}\n",
    "                torch.save({'model': best_weights}, config[\"best_weights_filename\"])\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                print(f\"Validation loss did not improve. Counter: {early_stopping_counter}/{config['early_stopping_patience']}\")\n",
    "\n",
    "        stop_training = torch.tensor(1 if early_stopping_counter >= config['early_stopping_patience'] else 0, device=device)\n",
    "        dist.all_reduce(stop_training, op=dist.ReduceOp.MAX)\n",
    "        if stop_training.item() == 1:\n",
    "            if is_main_process: print(\"Early stopping triggered.\")\n",
    "            break\n",
    "            \n",
    "    if is_main_process:\n",
    "        print(\"\\nDistillation finished.\")\n",
    "        if wandb.run: wandb.finish()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    setup_ddp()\n",
    "    rank = int(os.environ[\"RANK\"])\n",
    "    world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "\n",
    "    config = {\n",
    "        \"learning_rate\": 1e-4, \"epochs\": 50, \"batch_size_per_gpu\": 16,\n",
    "        \"num_workers\": 2, \"weight_decay\": 1e-5,\n",
    "        \"teacher_hf_id\": \"facebook/dinov3-convnext-base-pretrain-lvd1689m\",\n",
    "        \"dataset_dir\": \"/kaggle/input/dsp-pre-final/processed_taco_coco\",\n",
    "        \"scheduler_patience\": 3, \"scheduler_factor\": 0.1,\n",
    "        \"early_stopping_patience\": 7,\n",
    "        \"best_weights_filename\": \"/kaggle/working/FINAL/DISTILL-CONVNEXT/distilled_rtdetr_convnext_teacher_BEST.pth\",\n",
    "        \"final_weights_filename\": \"/kaggle/working/FINAL/DISTILL-CONVNEXT/distilled_rtdetr_convnext_teacher_FINAL.pth\",\n",
    "        \"wandb_project\": \"Distill-RTDETR-ConvNeXt-Teacher\",\n",
    "    }\n",
    "    main_training_function(rank, world_size, config)\n",
    "    cleanup_ddp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eec9d7e",
   "metadata": {
    "_cell_guid": "f480a80d-f34b-4d78-9af5-e3c6d10117a1",
    "_uuid": "0a8fce3f-c31b-4500-b0cb-14c50dc5306c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-30T15:37:18.553434Z",
     "iopub.status.busy": "2025-10-30T15:37:18.553231Z",
     "iopub.status.idle": "2025-10-30T17:38:29.622083Z",
     "shell.execute_reply": "2025-10-30T17:38:29.621114Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 7271.07599,
     "end_time": "2025-10-30T17:38:29.623722",
     "exception": false,
     "start_time": "2025-10-30T15:37:18.547732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1030 15:37:20.378000 69 torch/distributed/run.py:793] \r\n",
      "W1030 15:37:20.378000 69 torch/distributed/run.py:793] *****************************************\r\n",
      "W1030 15:37:20.378000 69 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \r\n",
      "W1030 15:37:20.378000 69 torch/distributed/run.py:793] *****************************************\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "Running DDP on 2 GPUs.\r\n",
      "[rank1]:[W1030 15:37:32.942637281 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnamthse182380\u001b[0m (\u001b[33mnamthse182380-fpt-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.0\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20251030_153733-3su7rxs0\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrun_ddp_convnext_2025-10-30_15-37_lr0.0001_bs16\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/namthse182380-fpt-university/Distill-RTDETR-ConvNeXt-Teacher\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/namthse182380-fpt-university/Distill-RTDETR-ConvNeXt-Teacher/runs/3su7rxs0\u001b[0m\r\n",
      "[rank0]:[W1030 15:37:34.006830291 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\r\n",
      "Loading teacher model 'facebook/dinov3-convnext-base-pretrain-lvd1689m' from Hugging Face...\r\n",
      "config.json: 100%|██████████████████████████████| 449/449 [00:00<00:00, 855kB/s]\r\n",
      "2025-10-30 15:37:36.722542: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2025-10-30 15:37:36.722541: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1761838656.872330      74 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1761838656.872313      75 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1761838656.912257      74 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "E0000 00:00:1761838656.912272      75 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "model.safetensors: 100%|██████████████████████| 350M/350M [00:02<00:00, 164MB/s]\r\n",
      "Architecture: ConvNeXT.\r\n",
      "Extracting features from layers with dimensions: [256, 512, 1024]\r\n",
      "Loading student model on main process...\r\n",
      "Downloading: \"https://github.com/lyuwenyu/RT-DETR/zipball/main\" to /root/.cache/torch/hub/main.zip\r\n",
      "Downloading: \"https://github.com/lyuwenyu/storage/releases/download/v0.1/rtdetrv2_r50vd_6x_coco_ema.pth\" to /root/.cache/torch/hub/checkpoints/rtdetrv2_r50vd_6x_coco_ema.pth\r\n",
      "100%|█████████████████████████████████████████| 165M/165M [00:00<00:00, 186MB/s]\r\n",
      "Downloading: \"https://github.com/lyuwenyu/storage/releases/download/v0.1/ResNet50_vd_ssld_v2_pretrained_from_paddle.pth\" to /root/.cache/torch/hub/checkpoints/ResNet50_vd_ssld_v2_pretrained_from_paddle.pth\r\n",
      "100%|███████████████████████████████████████| 90.0M/90.0M [00:00<00:00, 157MB/s]\r\n",
      "Load PResNet50 state_dict\r\n",
      "Using cache found in /root/.cache/torch/hub/lyuwenyu_RT-DETR_main\r\n",
      "Using cache found in /root/.cache/torch/hub/lyuwenyu_RT-DETR_main\r\n",
      "Load PResNet50 state_dict\r\n",
      "Load PResNet50 state_dict\r\n",
      "Projection layer 0: 256 -> 256\r\n",
      "Projection layer 1: 256 -> 512\r\n",
      "Projection layer 2: 256 -> 1024\r\n",
      "loading annotations into memory...loading annotations into memory...\r\n",
      "\r\n",
      "Done (t=0.04s)\r\n",
      "creating index...\r\n",
      "Done (t=0.04s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "loading annotations into memory...\r\n",
      "index created!\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.01s)Done (t=0.01s)\r\n",
      "creating index...\r\n",
      "\r\n",
      "creating index...index created!\r\n",
      "\r\n",
      "index created!\r\n",
      "Data loaded: 1273 training images, 225 validation images.\r\n",
      "Starting training...\r\n",
      "Epoch 1/50 [Train]: 100%|███████████████████████| 39/39 [01:57<00:00,  3.01s/it]\r\n",
      "Epoch 1/50 [Val]: 100%|███████████████████████████| 8/8 [00:16<00:00,  2.11s/it]\r\n",
      "Epoch 1 | Train Loss: 34.9199 | Val Loss: 16.3375 | Duration: 134.20s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 2/50 [Train]: 100%|███████████████████████| 39/39 [02:06<00:00,  3.26s/it]\r\n",
      "Epoch 2/50 [Val]: 100%|███████████████████████████| 8/8 [00:16<00:00,  2.02s/it]\r\n",
      "Epoch 2 | Train Loss: 7.5105 | Val Loss: 5.7968 | Duration: 143.10s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 3/50 [Train]: 100%|███████████████████████| 39/39 [02:07<00:00,  3.28s/it]\r\n",
      "Epoch 3/50 [Val]: 100%|███████████████████████████| 8/8 [00:16<00:00,  2.04s/it]\r\n",
      "Epoch 3 | Train Loss: 5.3497 | Val Loss: 5.1545 | Duration: 144.24s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 4/50 [Train]: 100%|███████████████████████| 39/39 [02:08<00:00,  3.28s/it]\r\n",
      "Epoch 4/50 [Val]: 100%|███████████████████████████| 8/8 [00:16<00:00,  2.04s/it]\r\n",
      "Epoch 4 | Train Loss: 4.9616 | Val Loss: 4.9333 | Duration: 144.37s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 5/50 [Train]: 100%|███████████████████████| 39/39 [02:07<00:00,  3.28s/it]\r\n",
      "Epoch 5/50 [Val]: 100%|███████████████████████████| 8/8 [00:16<00:00,  2.04s/it]\r\n",
      "Epoch 5 | Train Loss: 4.6361 | Val Loss: 4.5359 | Duration: 144.31s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 6/50 [Train]: 100%|███████████████████████| 39/39 [02:08<00:00,  3.29s/it]\r\n",
      "Epoch 6/50 [Val]: 100%|███████████████████████████| 8/8 [00:16<00:00,  2.03s/it]\r\n",
      "Epoch 6 | Train Loss: 4.4578 | Val Loss: 4.4612 | Duration: 144.79s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 7/50 [Train]: 100%|███████████████████████| 39/39 [02:07<00:00,  3.28s/it]\r\n",
      "Epoch 7/50 [Val]: 100%|███████████████████████████| 8/8 [00:16<00:00,  2.04s/it]\r\n",
      "Epoch 7 | Train Loss: 4.3561 | Val Loss: 4.3182 | Duration: 144.30s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 8/50 [Train]: 100%|███████████████████████| 39/39 [02:08<00:00,  3.28s/it]\r\n",
      "Epoch 8/50 [Val]: 100%|███████████████████████████| 8/8 [00:16<00:00,  2.04s/it]\r\n",
      "Epoch 8 | Train Loss: 4.2343 | Val Loss: 4.2515 | Duration: 144.34s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 9/50 [Train]: 100%|███████████████████████| 39/39 [02:08<00:00,  3.29s/it]\r\n",
      "Epoch 9/50 [Val]: 100%|███████████████████████████| 8/8 [00:16<00:00,  2.04s/it]\r\n",
      "Epoch 9 | Train Loss: 4.1399 | Val Loss: 4.1843 | Duration: 144.66s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 10/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.29s/it]\r\n",
      "Epoch 10/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.04s/it]\r\n",
      "Epoch 10 | Train Loss: 4.0880 | Val Loss: 4.2896 | Duration: 144.55s\r\n",
      "Validation loss did not improve. Counter: 1/7\r\n",
      "Epoch 11/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.28s/it]\r\n",
      "Epoch 11/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.04s/it]\r\n",
      "Epoch 11 | Train Loss: 3.9856 | Val Loss: 4.0990 | Duration: 144.39s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 12/50 [Train]: 100%|██████████████████████| 39/39 [02:07<00:00,  3.27s/it]\r\n",
      "Epoch 12/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.02s/it]\r\n",
      "Epoch 12 | Train Loss: 3.9950 | Val Loss: 4.0992 | Duration: 143.65s\r\n",
      "Validation loss did not improve. Counter: 1/7\r\n",
      "Epoch 13/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.29s/it]\r\n",
      "Epoch 13/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.02s/it]\r\n",
      "Epoch 13 | Train Loss: 3.8864 | Val Loss: 4.1073 | Duration: 144.34s\r\n",
      "Validation loss did not improve. Counter: 2/7\r\n",
      "Epoch 14/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.29s/it]\r\n",
      "Epoch 14/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.04s/it]\r\n",
      "Epoch 14 | Train Loss: 3.8243 | Val Loss: 4.0023 | Duration: 144.59s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 15/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.29s/it]\r\n",
      "Epoch 15/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.03s/it]\r\n",
      "Epoch 15 | Train Loss: 3.7706 | Val Loss: 3.9476 | Duration: 144.39s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 16/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.29s/it]\r\n",
      "Epoch 16/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.03s/it]\r\n",
      "Epoch 16 | Train Loss: 3.7391 | Val Loss: 3.8982 | Duration: 144.39s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 17/50 [Train]: 100%|██████████████████████| 39/39 [02:07<00:00,  3.28s/it]\r\n",
      "Epoch 17/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.04s/it]\r\n",
      "Epoch 17 | Train Loss: 3.6949 | Val Loss: 3.8686 | Duration: 144.21s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 18/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.29s/it]\r\n",
      "Epoch 18/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.05s/it]\r\n",
      "Epoch 18 | Train Loss: 3.6078 | Val Loss: 3.8391 | Duration: 144.77s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 19/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.28s/it]\r\n",
      "Epoch 19/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.04s/it]\r\n",
      "Epoch 19 | Train Loss: 3.5596 | Val Loss: 3.8496 | Duration: 144.41s\r\n",
      "Validation loss did not improve. Counter: 1/7\r\n",
      "Epoch 20/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.29s/it]\r\n",
      "Epoch 20/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.05s/it]\r\n",
      "Epoch 20 | Train Loss: 3.5283 | Val Loss: 3.7838 | Duration: 144.64s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 21/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.29s/it]\r\n",
      "Epoch 21/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.04s/it]\r\n",
      "Epoch 21 | Train Loss: 3.4818 | Val Loss: 3.7654 | Duration: 144.62s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 22/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.29s/it]\r\n",
      "Epoch 22/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.03s/it]\r\n",
      "Epoch 22 | Train Loss: 3.4272 | Val Loss: 3.7843 | Duration: 144.52s\r\n",
      "Validation loss did not improve. Counter: 1/7\r\n",
      "Epoch 23/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.29s/it]\r\n",
      "Epoch 23/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.05s/it]\r\n",
      "Epoch 23 | Train Loss: 3.3717 | Val Loss: 3.7791 | Duration: 144.65s\r\n",
      "Validation loss did not improve. Counter: 2/7\r\n",
      "Epoch 24/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.29s/it]\r\n",
      "Epoch 24/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.05s/it]\r\n",
      "Epoch 24 | Train Loss: 3.3197 | Val Loss: 3.7238 | Duration: 144.81s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 25/50 [Train]: 100%|██████████████████████| 39/39 [02:07<00:00,  3.28s/it]\r\n",
      "Epoch 25/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.04s/it]\r\n",
      "Epoch 25 | Train Loss: 3.2455 | Val Loss: 3.5966 | Duration: 144.26s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 26/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.29s/it]\r\n",
      "Epoch 26/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.04s/it]\r\n",
      "Epoch 26 | Train Loss: 3.2104 | Val Loss: 3.6163 | Duration: 144.79s\r\n",
      "Validation loss did not improve. Counter: 1/7\r\n",
      "Epoch 27/50 [Train]: 100%|██████████████████████| 39/39 [02:07<00:00,  3.27s/it]\r\n",
      "Epoch 27/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.02s/it]\r\n",
      "Epoch 27 | Train Loss: 3.1781 | Val Loss: 3.5986 | Duration: 143.77s\r\n",
      "Validation loss did not improve. Counter: 2/7\r\n",
      "Epoch 28/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.29s/it]\r\n",
      "Epoch 28/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.04s/it]\r\n",
      "Epoch 28 | Train Loss: 3.1318 | Val Loss: 3.5856 | Duration: 144.74s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 29/50 [Train]: 100%|██████████████████████| 39/39 [02:07<00:00,  3.28s/it]\r\n",
      "Epoch 29/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.02s/it]\r\n",
      "Epoch 29 | Train Loss: 3.1107 | Val Loss: 3.5388 | Duration: 144.15s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 30/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.29s/it]\r\n",
      "Epoch 30/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.04s/it]\r\n",
      "Epoch 30 | Train Loss: 3.0219 | Val Loss: 3.5329 | Duration: 144.42s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 31/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.29s/it]\r\n",
      "Epoch 31/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.04s/it]\r\n",
      "Epoch 31 | Train Loss: 2.9868 | Val Loss: 3.5310 | Duration: 144.73s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 32/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.30s/it]\r\n",
      "Epoch 32/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.05s/it]\r\n",
      "Epoch 32 | Train Loss: 2.9609 | Val Loss: 3.5310 | Duration: 145.02s\r\n",
      "Validation loss did not improve. Counter: 1/7\r\n",
      "Epoch 33/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.29s/it]\r\n",
      "Epoch 33/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.05s/it]\r\n",
      "Epoch 33 | Train Loss: 2.8791 | Val Loss: 3.5027 | Duration: 144.77s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 34/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.29s/it]\r\n",
      "Epoch 34/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.06s/it]\r\n",
      "Epoch 34 | Train Loss: 2.8401 | Val Loss: 3.4994 | Duration: 144.95s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 35/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.29s/it]\r\n",
      "Epoch 35/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.03s/it]\r\n",
      "Epoch 35 | Train Loss: 2.7423 | Val Loss: 3.4137 | Duration: 144.53s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 36/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.28s/it]\r\n",
      "Epoch 36/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.05s/it]\r\n",
      "Epoch 36 | Train Loss: 2.6477 | Val Loss: 3.4498 | Duration: 144.50s\r\n",
      "Validation loss did not improve. Counter: 1/7\r\n",
      "Epoch 37/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.30s/it]\r\n",
      "Epoch 37/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.05s/it]\r\n",
      "Epoch 37 | Train Loss: 2.5878 | Val Loss: 3.3669 | Duration: 145.10s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 38/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.30s/it]\r\n",
      "Epoch 38/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.03s/it]\r\n",
      "Epoch 38 | Train Loss: 2.5218 | Val Loss: 3.3548 | Duration: 144.88s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 39/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.29s/it]\r\n",
      "Epoch 39/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.04s/it]\r\n",
      "Epoch 39 | Train Loss: 2.4542 | Val Loss: 3.2973 | Duration: 144.61s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 40/50 [Train]: 100%|██████████████████████| 39/39 [02:07<00:00,  3.28s/it]\r\n",
      "Epoch 40/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.03s/it]\r\n",
      "Epoch 40 | Train Loss: 2.4126 | Val Loss: 3.3562 | Duration: 144.18s\r\n",
      "Validation loss did not improve. Counter: 1/7\r\n",
      "Epoch 41/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.29s/it]\r\n",
      "Epoch 41/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.05s/it]\r\n",
      "Epoch 41 | Train Loss: 2.3762 | Val Loss: 3.2753 | Duration: 144.76s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 42/50 [Train]: 100%|██████████████████████| 39/39 [02:07<00:00,  3.28s/it]\r\n",
      "Epoch 42/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.04s/it]\r\n",
      "Epoch 42 | Train Loss: 2.3474 | Val Loss: 3.2787 | Duration: 144.29s\r\n",
      "Validation loss did not improve. Counter: 1/7\r\n",
      "Epoch 43/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.30s/it]\r\n",
      "Epoch 43/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.04s/it]\r\n",
      "Epoch 43 | Train Loss: 2.2641 | Val Loss: 3.2876 | Duration: 144.84s\r\n",
      "Validation loss did not improve. Counter: 2/7\r\n",
      "Epoch 44/50 [Train]: 100%|██████████████████████| 39/39 [02:07<00:00,  3.27s/it]\r\n",
      "Epoch 44/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.03s/it]\r\n",
      "Epoch 44 | Train Loss: 2.2229 | Val Loss: 3.3638 | Duration: 143.92s\r\n",
      "Validation loss did not improve. Counter: 3/7\r\n",
      "Epoch 45/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.29s/it]\r\n",
      "Epoch 45/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.05s/it]\r\n",
      "Epoch 45 | Train Loss: 2.2263 | Val Loss: 3.3498 | Duration: 144.66s\r\n",
      "Validation loss did not improve. Counter: 4/7\r\n",
      "Epoch 46/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.30s/it]\r\n",
      "Epoch 46/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.04s/it]\r\n",
      "Epoch 46 | Train Loss: 2.1314 | Val Loss: 3.2485 | Duration: 144.98s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 47/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.30s/it]\r\n",
      "Epoch 47/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.03s/it]\r\n",
      "Epoch 47 | Train Loss: 2.0798 | Val Loss: 3.2541 | Duration: 145.02s\r\n",
      "Validation loss did not improve. Counter: 1/7\r\n",
      "Epoch 48/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.30s/it]\r\n",
      "Epoch 48/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.04s/it]\r\n",
      "Epoch 48 | Train Loss: 2.0583 | Val Loss: 3.3265 | Duration: 145.00s\r\n",
      "Validation loss did not improve. Counter: 2/7\r\n",
      "Epoch 49/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.30s/it]\r\n",
      "Epoch 49/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.05s/it]\r\n",
      "Epoch 49 | Train Loss: 2.0320 | Val Loss: 3.2685 | Duration: 144.93s\r\n",
      "Validation loss did not improve. Counter: 3/7\r\n",
      "Epoch 50/50 [Train]: 100%|██████████████████████| 39/39 [02:08<00:00,  3.29s/it]\r\n",
      "Epoch 50/50 [Val]: 100%|██████████████████████████| 8/8 [00:16<00:00,  2.03s/it]\r\n",
      "Epoch 50 | Train Loss: 2.0174 | Val Loss: 3.2858 | Duration: 144.75s\r\n",
      "Validation loss did not improve. Counter: 4/7\r\n",
      "\r\n",
      "Distillation finished.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/avg_loss █▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val/avg_loss █▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 50\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/avg_loss 2.01736\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val/avg_loss 3.28579\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mrun_ddp_convnext_2025-10-30_15-37_lr0.0001_bs16\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/namthse182380-fpt-university/Distill-RTDETR-ConvNeXt-Teacher/runs/3su7rxs0\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/namthse182380-fpt-university/Distill-RTDETR-ConvNeXt-Teacher\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251030_153733-3su7rxs0/logs\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!torchrun --nproc_per_node=2 trainer_convnext.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ce0f717",
   "metadata": {
    "_cell_guid": "886c9c81-ce91-4b43-8869-c314a5bf8171",
    "_uuid": "13510511-9ad1-4f1c-ab43-5319a57bc792",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-30T17:38:29.840141Z",
     "iopub.status.busy": "2025-10-30T17:38:29.839846Z",
     "iopub.status.idle": "2025-10-30T17:38:29.848741Z",
     "shell.execute_reply": "2025-10-30T17:38:29.847888Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.115732,
     "end_time": "2025-10-30T17:38:29.850128",
     "exception": false,
     "start_time": "2025-10-30T17:38:29.734396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing trainer_vit.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile trainer_vit.py\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModel, AutoConfig\n",
    "from PIL import Image\n",
    "from pycocotools.coco import COCO\n",
    "from torchvision import transforms as T\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import datetime\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "class HuggingFaceTeacherWrapper(nn.Module):\n",
    "    def __init__(self, model_id: str, token: str = None):\n",
    "        super().__init__()\n",
    "        if int(os.environ.get(\"RANK\", 0)) == 0:\n",
    "            print(f\"Loading teacher model '{model_id}' from Hugging Face...\")\n",
    "        \n",
    "        config = AutoConfig.from_pretrained(model_id, token=token)\n",
    "        self._model = AutoModel.from_pretrained(model_id, config=config, token=token)\n",
    "        self.feature_dim = self._model.config.hidden_size\n",
    "        \n",
    "        if int(os.environ.get(\"RANK\", 0)) == 0:\n",
    "            print(f\"Architecture: ViT. Feature dim: {self.feature_dim}\")\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        outputs = self._model(pixel_values=x)\n",
    "        patch_tokens = outputs.last_hidden_state[:, 1:, :]\n",
    "        return patch_tokens\n",
    "\n",
    "class CocoDetectionForDistill(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, ann_file, transforms):\n",
    "        self.root = root\n",
    "        self.coco = COCO(ann_file)\n",
    "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_id = self.ids[index]\n",
    "        path = self.coco.loadImgs(img_id)[0][\"file_name\"]\n",
    "        img = Image.open(os.path.join(self.root, path)).convert(\"RGB\")\n",
    "        return self.transforms(img), 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "def setup_ddp():\n",
    "    dist.init_process_group(backend=\"nccl\")\n",
    "    torch.cuda.set_device(int(os.environ[\"LOCAL_RANK\"]))\n",
    "\n",
    "def cleanup_ddp():\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "def main_training_function(rank, world_size, config):\n",
    "    device = rank\n",
    "    is_main_process = (rank == 0)\n",
    "    \n",
    "    if is_main_process:\n",
    "        print(f\"Running DDP on {world_size} GPUs.\")\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "        run_name = f\"run_ddp_vit_{timestamp}_lr{config['learning_rate']}_bs{config['batch_size_per_gpu']}\"\n",
    "        try:\n",
    "            from kaggle_secrets import UserSecretsClient\n",
    "            from huggingface_hub import login\n",
    "            secrets = UserSecretsClient()\n",
    "            hf_token = secrets.get_secret(\"HUGGINGFACE_TOKEN\")\n",
    "            wandb_key = secrets.get_secret(\"WANDB_API_KEY\")\n",
    "            login(token=hf_token)\n",
    "            wandb.login(key=wandb_key)\n",
    "            wandb.init(project=config[\"wandb_project\"], config=config, name=run_name)\n",
    "        except Exception:\n",
    "            hf_token = None\n",
    "            print(\"Could not log in, continuing without W&B.\")\n",
    "    else:\n",
    "        hf_token = None\n",
    "\n",
    "    dist.barrier()\n",
    "    \n",
    "    teacher_model = HuggingFaceTeacherWrapper(config[\"teacher_hf_id\"], token=hf_token).to(device)\n",
    "    teacher_model.eval()\n",
    "\n",
    "    if is_main_process:\n",
    "        print(\"Loading student model on main process...\")\n",
    "        torch.hub.load(\"lyuwenyu/RT-DETR\", \"rtdetrv2_l\", pretrained=True, trust_repo=True)\n",
    "\n",
    "    dist.barrier()\n",
    "\n",
    "    student_hub_model = torch.hub.load(\"lyuwenyu/RT-DETR\", \"rtdetrv2_l\", pretrained=True, trust_repo=True)\n",
    "    student_model = student_hub_model.model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x = torch.randn(1, 3, 640, 640).to(device)\n",
    "        student_channels = student_model.encoder(student_model.backbone(x))[-1].shape[1]\n",
    "    \n",
    "    teacher_channels = teacher_model.feature_dim\n",
    "    projection_layer = nn.Linear(student_channels, teacher_channels).to(device)\n",
    "\n",
    "    student_model = DDP(student_model, device_ids=[device], find_unused_parameters=True)\n",
    "    projection_layer = DDP(projection_layer, device_ids=[device], find_unused_parameters=True)\n",
    "    \n",
    "    transforms = T.Compose([\n",
    "        T.Resize((640, 640)), T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    train_dataset = CocoDetectionForDistill(root=config[\"dataset_dir\"]+\"/train2017\", ann_file=config[\"dataset_dir\"]+\"/annotations/instances_train2017.json\", transforms=transforms)\n",
    "    val_dataset = CocoDetectionForDistill(root=config[\"dataset_dir\"]+\"/val2017\", ann_file=config[\"dataset_dir\"]+\"/annotations/instances_val2017.json\", transforms=transforms)\n",
    "    \n",
    "    if is_main_process: print(f\"Data loaded: {len(train_dataset)} train, {len(val_dataset)} val.\")\n",
    "\n",
    "    train_sampler = DistributedSampler(train_dataset, num_replicas=world_size, rank=rank, shuffle=True)\n",
    "    val_sampler = DistributedSampler(val_dataset, num_replicas=world_size, rank=rank, shuffle=False)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size_per_gpu\"], shuffle=False, num_workers=config[\"num_workers\"], pin_memory=True, drop_last=True, sampler=train_sampler)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size_per_gpu\"], shuffle=False, num_workers=config[\"num_workers\"], pin_memory=True, drop_last=False, sampler=val_sampler)\n",
    "\n",
    "    params = list(student_model.module.backbone.parameters()) + list(student_model.module.encoder.parameters()) + list(projection_layer.module.parameters())\n",
    "             \n",
    "    optimizer = torch.optim.AdamW(params, lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
    "    criterion = nn.MSELoss()\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=config['scheduler_factor'], patience=config['scheduler_patience'], verbose=is_main_process)\n",
    "\n",
    "    if is_main_process and wandb.run:\n",
    "        wandb.watch((student_model, projection_layer), log=\"all\", log_freq=100)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    early_stopping_counter = 0\n",
    "\n",
    "    if is_main_process: print(\"Starting training...\")\n",
    "        \n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        train_sampler.set_epoch(epoch)\n",
    "        start = time.time()\n",
    "        student_model.train()\n",
    "        projection_layer.train()\n",
    "        total_train_loss = 0.0\n",
    "        \n",
    "        train_iterator = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['epochs']} [Train]\") if is_main_process else train_loader\n",
    "\n",
    "        for images, _ in train_iterator:\n",
    "            images = images.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                teacher_tokens = teacher_model(images)\n",
    "            \n",
    "            student_features_2d = student_model.module.encoder(student_model.module.backbone(images))[-1]\n",
    "            \n",
    "            b, c, h, w = student_features_2d.shape\n",
    "            student_tokens = student_features_2d.flatten(2).permute(0, 2, 1)\n",
    "\n",
    "            projected_tokens = projection_layer(student_tokens)\n",
    "\n",
    "            teacher_tokens_resized = F.interpolate(\n",
    "                teacher_tokens.permute(0, 2, 1),\n",
    "                size=student_tokens.shape[1],\n",
    "                mode='linear',\n",
    "                align_corners=False\n",
    "            ).permute(0, 2, 1)\n",
    "            \n",
    "            loss = criterion(projected_tokens, teacher_tokens_resized)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "        \n",
    "        train_loss_tensor = torch.tensor(total_train_loss).to(device)\n",
    "        dist.all_reduce(train_loss_tensor, op=dist.ReduceOp.SUM)\n",
    "        avg_train_loss = train_loss_tensor.item() / (len(train_loader) * world_size)\n",
    "\n",
    "        student_model.eval()\n",
    "        projection_layer.eval()\n",
    "        total_val_loss = 0.0\n",
    "        \n",
    "        val_iterator = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{config['epochs']} [Val]\") if is_main_process else val_loader\n",
    "        with torch.no_grad():\n",
    "            for images, _ in val_iterator:\n",
    "                images = images.to(device)\n",
    "                teacher_tokens = teacher_model(images)\n",
    "                student_features_2d = student_model.module.encoder(student_model.module.backbone(images))[-1]\n",
    "                \n",
    "                b, c, h, w = student_features_2d.shape\n",
    "                student_tokens = student_features_2d.flatten(2).permute(0, 2, 1)\n",
    "                \n",
    "                projected = projection_layer(student_tokens)\n",
    "                \n",
    "                teacher_resized = F.interpolate(\n",
    "                    teacher_tokens.permute(0, 2, 1),\n",
    "                    size=student_tokens.shape[1],\n",
    "                    mode='linear',\n",
    "                    align_corners=False\n",
    "                ).permute(0, 2, 1)\n",
    "                \n",
    "                loss = criterion(projected, teacher_resized)\n",
    "                total_val_loss += loss.item()\n",
    "                \n",
    "        val_loss_tensor = torch.tensor(total_val_loss).to(device)\n",
    "        dist.all_reduce(val_loss_tensor, op=dist.ReduceOp.SUM)\n",
    "        avg_val_loss = val_loss_tensor.item() / (len(val_loader) * world_size)\n",
    "        \n",
    "        if is_main_process:\n",
    "            duration = time.time() - start\n",
    "            print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Duration: {duration:.2f}s\")\n",
    "            if wandb.run: wandb.log({\"epoch\": epoch + 1, \"train/avg_loss\": avg_train_loss, \"val/avg_loss\": avg_val_loss})\n",
    "            scheduler.step(avg_val_loss)\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                early_stopping_counter = 0\n",
    "                print(f\"Validation loss improved. Saving best model...\")\n",
    "                best_weights = {**student_model.module.backbone.state_dict(), **student_model.module.encoder.state_dict()}\n",
    "                torch.save({'model': best_weights}, config[\"best_weights_filename\"])\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                print(f\"Validation loss did not improve. Counter: {early_stopping_counter}/{config['early_stopping_patience']}\")\n",
    "\n",
    "        stop_training = torch.tensor(1 if early_stopping_counter >= config['early_stopping_patience'] else 0, device=device)\n",
    "        dist.all_reduce(stop_training, op=dist.ReduceOp.MAX)\n",
    "        if stop_training.item() == 1:\n",
    "            if is_main_process: print(\"Early stopping triggered.\")\n",
    "            break\n",
    "            \n",
    "    if is_main_process:\n",
    "        print(\"\\nDistillation finished.\")\n",
    "        if wandb.run: wandb.finish()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    setup_ddp()\n",
    "    rank = int(os.environ[\"RANK\"])\n",
    "    world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "\n",
    "    config = {\n",
    "        \"learning_rate\": 1e-4, \"epochs\": 50, \"batch_size_per_gpu\": 16,\n",
    "        \"num_workers\": 2, \"weight_decay\": 1e-5,\n",
    "        \"teacher_hf_id\": \"facebook/dinov3-vitb16-pretrain-lvd1689m\", \n",
    "        \"dataset_dir\": \"/kaggle/input/dsp-pre-final/processed_taco_coco\",\n",
    "        \"scheduler_patience\": 3, \"scheduler_factor\": 0.1,\n",
    "        \"early_stopping_patience\": 7,\n",
    "        \"best_weights_filename\": \"/kaggle/working/FINAL/DISTILL-VIT/distilled_rtdetr_vit_teacher_BEST.pth\",\n",
    "        \"final_weights_filename\": \"/kaggle/working/FINAL/DISTILL-VIT/distilled_rtdetr_vit_teacher_FINAL.pth\",\n",
    "        \"wandb_project\": \"Distill-RTDETR-DINOv3-ViT-Teacher\",\n",
    "    }\n",
    "    main_training_function(rank, world_size, config)\n",
    "    cleanup_ddp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "461e5594",
   "metadata": {
    "_cell_guid": "4fb31eb1-efed-464e-97e6-3b01b06b3b05",
    "_uuid": "99a19010-e8c8-4171-b80f-62a83d4deab1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-30T17:38:30.059733Z",
     "iopub.status.busy": "2025-10-30T17:38:30.059482Z",
     "iopub.status.idle": "2025-10-30T20:05:45.495832Z",
     "shell.execute_reply": "2025-10-30T20:05:45.494926Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 8835.540986,
     "end_time": "2025-10-30T20:05:45.497410",
     "exception": false,
     "start_time": "2025-10-30T17:38:29.956424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1030 17:38:31.802000 2207 torch/distributed/run.py:793] \r\n",
      "W1030 17:38:31.802000 2207 torch/distributed/run.py:793] *****************************************\r\n",
      "W1030 17:38:31.802000 2207 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \r\n",
      "W1030 17:38:31.802000 2207 torch/distributed/run.py:793] *****************************************\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "Running DDP on 2 GPUs.\r\n",
      "[rank1]:[W1030 17:38:38.868469987 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnamthse182380\u001b[0m (\u001b[33mnamthse182380-fpt-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.0\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20251030_173839-x8lq0zxw\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrun_ddp_vit_2025-10-30_17-38_lr0.0001_bs16\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/namthse182380-fpt-university/Distill-RTDETR-DINOv3-ViT-Teacher\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/namthse182380-fpt-university/Distill-RTDETR-DINOv3-ViT-Teacher/runs/x8lq0zxw\u001b[0m\r\n",
      "[rank0]:[W1030 17:38:40.784338559 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\r\n",
      "Loading teacher model 'facebook/dinov3-vitb16-pretrain-lvd1689m' from Hugging Face...\r\n",
      "config.json: 100%|█████████████████████████████| 744/744 [00:00<00:00, 1.56MB/s]\r\n",
      "2025-10-30 17:38:41.518797: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2025-10-30 17:38:41.518800: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1761845921.542778    2212 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1761845921.542768    2213 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1761845921.549858    2212 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "E0000 00:00:1761845921.549858    2213 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "model.safetensors: 100%|██████████████████████| 343M/343M [00:01<00:00, 203MB/s]\r\n",
      "Architecture: ViT. Feature dim: 768\r\n",
      "Loading student model on main process...\r\n",
      "Using cache found in /root/.cache/torch/hub/lyuwenyu_RT-DETR_main\r\n",
      "Load PResNet50 state_dict\r\n",
      "Using cache found in /root/.cache/torch/hub/lyuwenyu_RT-DETR_main\r\n",
      "Using cache found in /root/.cache/torch/hub/lyuwenyu_RT-DETR_main\r\n",
      "Load PResNet50 state_dict\r\n",
      "Load PResNet50 state_dict\r\n",
      "loading annotations into memory...loading annotations into memory...\r\n",
      "\r\n",
      "Done (t=0.01s)\r\n",
      "creating index...\r\n",
      "Done (t=0.01s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "loading annotations into memory...\r\n",
      "index created!\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Done (t=0.00s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Data loaded: 1273 train, 225 val.\r\n",
      "Starting training...\r\n",
      "Epoch 1/50 [Train]:   0%|                                | 0/39 [00:00<?, ?it/s][rank1]:[W1030 17:38:54.807850478 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\r\n",
      "[rank0]:[W1030 17:38:54.999196963 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\r\n",
      "Epoch 1/50 [Train]: 100%|███████████████████████| 39/39 [02:35<00:00,  4.00s/it]\r\n",
      "Epoch 1/50 [Val]: 100%|███████████████████████████| 8/8 [00:21<00:00,  2.65s/it]\r\n",
      "Epoch 1 | Train Loss: 0.2473 | Val Loss: 0.1679 | Duration: 177.11s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 2/50 [Train]: 100%|███████████████████████| 39/39 [02:34<00:00,  3.96s/it]\r\n",
      "Epoch 2/50 [Val]: 100%|███████████████████████████| 8/8 [00:21<00:00,  2.66s/it]\r\n",
      "Epoch 2 | Train Loss: 0.1285 | Val Loss: 0.1054 | Duration: 175.59s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 3/50 [Train]: 100%|███████████████████████| 39/39 [02:34<00:00,  3.96s/it]\r\n",
      "Epoch 3/50 [Val]: 100%|███████████████████████████| 8/8 [00:21<00:00,  2.66s/it]\r\n",
      "Epoch 3 | Train Loss: 0.1020 | Val Loss: 0.0953 | Duration: 175.84s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 4/50 [Train]: 100%|███████████████████████| 39/39 [02:34<00:00,  3.96s/it]\r\n",
      "Epoch 4/50 [Val]: 100%|███████████████████████████| 8/8 [00:21<00:00,  2.67s/it]\r\n",
      "Epoch 4 | Train Loss: 0.0931 | Val Loss: 0.0867 | Duration: 175.79s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 5/50 [Train]: 100%|███████████████████████| 39/39 [02:34<00:00,  3.96s/it]\r\n",
      "Epoch 5/50 [Val]: 100%|███████████████████████████| 8/8 [00:21<00:00,  2.66s/it]\r\n",
      "Epoch 5 | Train Loss: 0.0844 | Val Loss: 0.0786 | Duration: 175.94s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 6/50 [Train]: 100%|███████████████████████| 39/39 [02:34<00:00,  3.97s/it]\r\n",
      "Epoch 6/50 [Val]: 100%|███████████████████████████| 8/8 [00:21<00:00,  2.67s/it]\r\n",
      "Epoch 6 | Train Loss: 0.0776 | Val Loss: 0.0737 | Duration: 176.03s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 7/50 [Train]: 100%|███████████████████████| 39/39 [02:34<00:00,  3.96s/it]\r\n",
      "Epoch 7/50 [Val]: 100%|███████████████████████████| 8/8 [00:21<00:00,  2.67s/it]\r\n",
      "Epoch 7 | Train Loss: 0.0743 | Val Loss: 0.0712 | Duration: 175.98s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 8/50 [Train]: 100%|███████████████████████| 39/39 [02:34<00:00,  3.97s/it]\r\n",
      "Epoch 8/50 [Val]: 100%|███████████████████████████| 8/8 [00:21<00:00,  2.67s/it]\r\n",
      "Epoch 8 | Train Loss: 0.0722 | Val Loss: 0.0693 | Duration: 176.00s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 9/50 [Train]: 100%|███████████████████████| 39/39 [02:34<00:00,  3.96s/it]\r\n",
      "Epoch 9/50 [Val]: 100%|███████████████████████████| 8/8 [00:21<00:00,  2.65s/it]\r\n",
      "Epoch 9 | Train Loss: 0.0708 | Val Loss: 0.0682 | Duration: 175.73s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 10/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.96s/it]\r\n",
      "Epoch 10/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.66s/it]\r\n",
      "Epoch 10 | Train Loss: 0.0694 | Val Loss: 0.0667 | Duration: 175.86s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 11/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.97s/it]\r\n",
      "Epoch 11/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.67s/it]\r\n",
      "Epoch 11 | Train Loss: 0.0685 | Val Loss: 0.0673 | Duration: 176.03s\r\n",
      "Validation loss did not improve. Counter: 1/7\r\n",
      "Epoch 12/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.96s/it]\r\n",
      "Epoch 12/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.67s/it]\r\n",
      "Epoch 12 | Train Loss: 0.0676 | Val Loss: 0.0664 | Duration: 175.76s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 13/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.97s/it]\r\n",
      "Epoch 13/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.67s/it]\r\n",
      "Epoch 13 | Train Loss: 0.0665 | Val Loss: 0.0642 | Duration: 176.17s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 14/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.96s/it]\r\n",
      "Epoch 14/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.66s/it]\r\n",
      "Epoch 14 | Train Loss: 0.0661 | Val Loss: 0.0653 | Duration: 175.67s\r\n",
      "Validation loss did not improve. Counter: 1/7\r\n",
      "Epoch 15/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.97s/it]\r\n",
      "Epoch 15/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.67s/it]\r\n",
      "Epoch 15 | Train Loss: 0.0655 | Val Loss: 0.0629 | Duration: 176.12s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 16/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.97s/it]\r\n",
      "Epoch 16/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.66s/it]\r\n",
      "Epoch 16 | Train Loss: 0.0645 | Val Loss: 0.0635 | Duration: 175.94s\r\n",
      "Validation loss did not improve. Counter: 1/7\r\n",
      "Epoch 17/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.96s/it]\r\n",
      "Epoch 17/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.67s/it]\r\n",
      "Epoch 17 | Train Loss: 0.0642 | Val Loss: 0.0625 | Duration: 175.69s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 18/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.97s/it]\r\n",
      "Epoch 18/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.67s/it]\r\n",
      "Epoch 18 | Train Loss: 0.0637 | Val Loss: 0.0628 | Duration: 176.07s\r\n",
      "Validation loss did not improve. Counter: 1/7\r\n",
      "Epoch 19/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.97s/it]\r\n",
      "Epoch 19/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.66s/it]\r\n",
      "Epoch 19 | Train Loss: 0.0634 | Val Loss: 0.0631 | Duration: 176.16s\r\n",
      "Validation loss did not improve. Counter: 2/7\r\n",
      "Epoch 20/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.96s/it]\r\n",
      "Epoch 20/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.66s/it]\r\n",
      "Epoch 20 | Train Loss: 0.0628 | Val Loss: 0.0604 | Duration: 175.75s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 21/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.97s/it]\r\n",
      "Epoch 21/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.66s/it]\r\n",
      "Epoch 21 | Train Loss: 0.0622 | Val Loss: 0.0610 | Duration: 176.04s\r\n",
      "Validation loss did not improve. Counter: 1/7\r\n",
      "Epoch 22/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.97s/it]\r\n",
      "Epoch 22/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.66s/it]\r\n",
      "Epoch 22 | Train Loss: 0.0619 | Val Loss: 0.0611 | Duration: 175.96s\r\n",
      "Validation loss did not improve. Counter: 2/7\r\n",
      "Epoch 23/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.97s/it]\r\n",
      "Epoch 23/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.67s/it]\r\n",
      "Epoch 23 | Train Loss: 0.0617 | Val Loss: 0.0610 | Duration: 176.06s\r\n",
      "Validation loss did not improve. Counter: 3/7\r\n",
      "Epoch 24/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.97s/it]\r\n",
      "Epoch 24/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.68s/it]\r\n",
      "Epoch 24 | Train Loss: 0.0615 | Val Loss: 0.0617 | Duration: 176.20s\r\n",
      "Validation loss did not improve. Counter: 4/7\r\n",
      "Epoch 25/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.97s/it]\r\n",
      "Epoch 25/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.67s/it]\r\n",
      "Epoch 25 | Train Loss: 0.0609 | Val Loss: 0.0586 | Duration: 176.26s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 26/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.97s/it]\r\n",
      "Epoch 26/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.67s/it]\r\n",
      "Epoch 26 | Train Loss: 0.0604 | Val Loss: 0.0594 | Duration: 176.29s\r\n",
      "Validation loss did not improve. Counter: 1/7\r\n",
      "Epoch 27/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.97s/it]\r\n",
      "Epoch 27/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.66s/it]\r\n",
      "Epoch 27 | Train Loss: 0.0604 | Val Loss: 0.0582 | Duration: 176.19s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 28/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.97s/it]\r\n",
      "Epoch 28/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.67s/it]\r\n",
      "Epoch 28 | Train Loss: 0.0599 | Val Loss: 0.0585 | Duration: 176.09s\r\n",
      "Validation loss did not improve. Counter: 1/7\r\n",
      "Epoch 29/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.97s/it]\r\n",
      "Epoch 29/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.67s/it]\r\n",
      "Epoch 29 | Train Loss: 0.0600 | Val Loss: 0.0580 | Duration: 176.07s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 30/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.97s/it]\r\n",
      "Epoch 30/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.67s/it]\r\n",
      "Epoch 30 | Train Loss: 0.0599 | Val Loss: 0.0585 | Duration: 176.16s\r\n",
      "Validation loss did not improve. Counter: 1/7\r\n",
      "Epoch 31/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.96s/it]\r\n",
      "Epoch 31/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.66s/it]\r\n",
      "Epoch 31 | Train Loss: 0.0596 | Val Loss: 0.0587 | Duration: 175.80s\r\n",
      "Validation loss did not improve. Counter: 2/7\r\n",
      "Epoch 32/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.97s/it]\r\n",
      "Epoch 32/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.67s/it]\r\n",
      "Epoch 32 | Train Loss: 0.0596 | Val Loss: 0.0578 | Duration: 176.04s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 33/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.96s/it]\r\n",
      "Epoch 33/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.66s/it]\r\n",
      "Epoch 33 | Train Loss: 0.0594 | Val Loss: 0.0581 | Duration: 175.82s\r\n",
      "Validation loss did not improve. Counter: 1/7\r\n",
      "Epoch 34/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.97s/it]\r\n",
      "Epoch 34/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.66s/it]\r\n",
      "Epoch 34 | Train Loss: 0.0592 | Val Loss: 0.0576 | Duration: 176.21s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 35/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.97s/it]\r\n",
      "Epoch 35/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.67s/it]\r\n",
      "Epoch 35 | Train Loss: 0.0591 | Val Loss: 0.0579 | Duration: 176.28s\r\n",
      "Validation loss did not improve. Counter: 1/7\r\n",
      "Epoch 36/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.97s/it]\r\n",
      "Epoch 36/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.66s/it]\r\n",
      "Epoch 36 | Train Loss: 0.0589 | Val Loss: 0.0572 | Duration: 176.18s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 37/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.97s/it]\r\n",
      "Epoch 37/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.67s/it]\r\n",
      "Epoch 37 | Train Loss: 0.0587 | Val Loss: 0.0586 | Duration: 176.31s\r\n",
      "Validation loss did not improve. Counter: 1/7\r\n",
      "Epoch 38/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.97s/it]\r\n",
      "Epoch 38/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.67s/it]\r\n",
      "Epoch 38 | Train Loss: 0.0588 | Val Loss: 0.0573 | Duration: 176.32s\r\n",
      "Validation loss did not improve. Counter: 2/7\r\n",
      "Epoch 39/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.97s/it]\r\n",
      "Epoch 39/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.66s/it]\r\n",
      "Epoch 39 | Train Loss: 0.0585 | Val Loss: 0.0576 | Duration: 176.01s\r\n",
      "Validation loss did not improve. Counter: 3/7\r\n",
      "Epoch 40/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.96s/it]\r\n",
      "Epoch 40/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.68s/it]\r\n",
      "Epoch 40 | Train Loss: 0.0583 | Val Loss: 0.0577 | Duration: 175.96s\r\n",
      "Validation loss did not improve. Counter: 4/7\r\n",
      "Epoch 41/50 [Train]: 100%|██████████████████████| 39/39 [02:33<00:00,  3.95s/it]\r\n",
      "Epoch 41/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.66s/it]\r\n",
      "Epoch 41 | Train Loss: 0.0582 | Val Loss: 0.0569 | Duration: 175.22s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 42/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.96s/it]\r\n",
      "Epoch 42/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.66s/it]\r\n",
      "Epoch 42 | Train Loss: 0.0580 | Val Loss: 0.0569 | Duration: 175.74s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 43/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.96s/it]\r\n",
      "Epoch 43/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.65s/it]\r\n",
      "Epoch 43 | Train Loss: 0.0579 | Val Loss: 0.0569 | Duration: 175.49s\r\n",
      "Validation loss did not improve. Counter: 1/7\r\n",
      "Epoch 44/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.96s/it]\r\n",
      "Epoch 44/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.67s/it]\r\n",
      "Epoch 44 | Train Loss: 0.0579 | Val Loss: 0.0568 | Duration: 175.82s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 45/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.97s/it]\r\n",
      "Epoch 45/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.65s/it]\r\n",
      "Epoch 45 | Train Loss: 0.0578 | Val Loss: 0.0582 | Duration: 175.86s\r\n",
      "Validation loss did not improve. Counter: 1/7\r\n",
      "Epoch 46/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.96s/it]\r\n",
      "Epoch 46/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.66s/it]\r\n",
      "Epoch 46 | Train Loss: 0.0575 | Val Loss: 0.0566 | Duration: 175.84s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 47/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.97s/it]\r\n",
      "Epoch 47/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.67s/it]\r\n",
      "Epoch 47 | Train Loss: 0.0576 | Val Loss: 0.0563 | Duration: 176.11s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 48/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.96s/it]\r\n",
      "Epoch 48/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.65s/it]\r\n",
      "Epoch 48 | Train Loss: 0.0573 | Val Loss: 0.0567 | Duration: 175.84s\r\n",
      "Validation loss did not improve. Counter: 1/7\r\n",
      "Epoch 49/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.96s/it]\r\n",
      "Epoch 49/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.65s/it]\r\n",
      "Epoch 49 | Train Loss: 0.0572 | Val Loss: 0.0561 | Duration: 175.76s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "Epoch 50/50 [Train]: 100%|██████████████████████| 39/39 [02:34<00:00,  3.96s/it]\r\n",
      "Epoch 50/50 [Val]: 100%|██████████████████████████| 8/8 [00:21<00:00,  2.65s/it]\r\n",
      "Epoch 50 | Train Loss: 0.0571 | Val Loss: 0.0558 | Duration: 175.49s\r\n",
      "Validation loss improved. Saving best model...\r\n",
      "\r\n",
      "Distillation finished.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/avg_loss █▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val/avg_loss █▄▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 50\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/avg_loss 0.05714\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val/avg_loss 0.05585\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mrun_ddp_vit_2025-10-30_17-38_lr0.0001_bs16\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/namthse182380-fpt-university/Distill-RTDETR-DINOv3-ViT-Teacher/runs/x8lq0zxw\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/namthse182380-fpt-university/Distill-RTDETR-DINOv3-ViT-Teacher\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251030_173839-x8lq0zxw/logs\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!torchrun --nproc_per_node=2 trainer_vit.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e286bd0",
   "metadata": {
    "_cell_guid": "06540bbb-82e0-410b-b8e0-977128e89b7f",
    "_uuid": "bc54e9e7-b5ef-4a41-9cc2-b519a5b6bb08",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.202057,
     "end_time": "2025-10-30T20:05:45.903412",
     "exception": false,
     "start_time": "2025-10-30T20:05:45.701355",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Finetune RT-DETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e5d3a7e",
   "metadata": {
    "_cell_guid": "7e0065bf-af70-4cfe-afc9-3bd90ce14f75",
    "_uuid": "0770a377-1f20-499e-9b12-7a02b8056c0d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-30T20:05:46.306916Z",
     "iopub.status.busy": "2025-10-30T20:05:46.306621Z",
     "iopub.status.idle": "2025-10-30T20:05:46.426402Z",
     "shell.execute_reply": "2025-10-30T20:05:46.425459Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.325117,
     "end_time": "2025-10-30T20:05:46.427882",
     "exception": false,
     "start_time": "2025-10-30T20:05:46.102765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf /kaggle/working/RT-DETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f858f9c9",
   "metadata": {
    "_cell_guid": "72edc809-14e5-4d88-beaf-d2150edd70f1",
    "_uuid": "adbd4800-919d-4815-b080-803d5111b729",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-30T20:05:46.917770Z",
     "iopub.status.busy": "2025-10-30T20:05:46.917470Z",
     "iopub.status.idle": "2025-10-30T20:10:45.636922Z",
     "shell.execute_reply": "2025-10-30T20:10:45.636118Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 298.925962,
     "end_time": "2025-10-30T20:10:45.638466",
     "exception": false,
     "start_time": "2025-10-30T20:05:46.712504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n",
      "Cloning into 'RT-DETR'...\r\n",
      "remote: Enumerating objects: 1100, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (23/23), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (18/18), done.\u001b[K\r\n",
      "remote: Total 1100 (delta 8), reused 5 (delta 5), pack-reused 1077 (from 2)\u001b[K\r\n",
      "Receiving objects: 100% (1100/1100), 660.70 KiB | 6.48 MiB/s, done.\r\n",
      "Resolving deltas: 100% (522/522), done.\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "google-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 6.33.0 which is incompatible.\r\n",
      "google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 6.33.0 which is incompatible.\r\n",
      "google-cloud-bigtable 2.32.0 requires google-api-core[grpc]<3.0.0,>=2.17.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.0 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.1 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "google-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\r\n",
      "dataproc-spark-connect 0.8.3 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "google-cloud-bigtable 2.32.0 requires google-api-core[grpc]<3.0.0,>=2.17.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.1 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "google-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "dataproc-spark-connect 0.8.3 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "lightly-train 0.11.4 requires torch<2.6,>=2.1.0, but you have torch 2.9.0+cu126 which is incompatible.\r\n",
      "fastai 2.8.4 requires torch<2.9,>=1.10, but you have torch 2.9.0+cu126 which is incompatible.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "lightly-train 0.11.4 requires torch<2.6,>=2.1.0, but you have torch 2.9.0+cu126 which is incompatible.\r\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.4 which is incompatible.\r\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.16.3 which is incompatible.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.4 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.4 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.4 which is incompatible.\r\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\r\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires matplotlib<=3.10,>=3.5, but you have matplotlib 3.10.7 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.3.4 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires scipy<1.16,>=1.4.1, but you have scipy 1.16.3 which is incompatible.\r\n",
      "fastai 2.8.4 requires torch<2.9,>=1.10, but you have torch 2.9.0+cu126 which is incompatible.\r\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.2 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.2 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\r\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\r\n",
      "gradio 5.38.1 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.4 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.5.1 which is incompatible.\r\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.6 which is incompatible.\r\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.16.3 which is incompatible.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\r\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires matplotlib<=3.10,>=3.5, but you have matplotlib 3.10.7 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.6 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires scipy<1.16,>=1.4.1, but you have scipy 1.16.3 which is incompatible.\r\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.2 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.2 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.0.2 which is incompatible.\r\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.16.3 which is incompatible.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.0.2 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.0.2 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.0.2 which is incompatible.\r\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires matplotlib<=3.10,>=3.5, but you have matplotlib 3.10.7 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires scipy<1.16,>=1.4.1, but you have scipy 1.16.3 which is incompatible.\r\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.2 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.2 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "ibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\r\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "jupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\r\n",
      "dataproc-spark-connect 0.8.3 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working\n",
    "!git clone https://github.com/lyuwenyu/RT-DETR.git\n",
    "!cd RT-DETR/rtdetrv2_pytorch && pip install -r requirements.txt -q\n",
    "!pip install -q protobuf==3.20.3\n",
    "!pip install -q tensorboard\n",
    "!pip install -q --upgrade pip\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n",
    "!pip install -q --upgrade numpy scipy scikit-learn\n",
    "!pip install -q timm pycocotools faster-coco-eval\n",
    "!pip install -q --upgrade transformers lightly-train\n",
    "!pip install -q wandb\n",
    "!pip install -q -U \"numpy<2.1\" matplotlib --force-reinstall --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a18ffa38",
   "metadata": {
    "_cell_guid": "7792c6d4-e688-4da3-b78d-2648e041884f",
    "_uuid": "4ed3c793-823d-41bc-bc07-b9dbb45d944c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-30T20:10:46.046491Z",
     "iopub.status.busy": "2025-10-30T20:10:46.045755Z",
     "iopub.status.idle": "2025-10-30T20:10:46.051961Z",
     "shell.execute_reply": "2025-10-30T20:10:46.051270Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.209821,
     "end_time": "2025-10-30T20:10:46.053053",
     "exception": false,
     "start_time": "2025-10-30T20:10:45.843232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/RT-DETR/rtdetrv2_pytorch/configs/rtdetrv2/rtdetrv2_taco_finetune_convnext.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/RT-DETR/rtdetrv2_pytorch/configs/rtdetrv2/rtdetrv2_taco_finetune_convnext.yml\n",
    "__include__: [\n",
    "  '../dataset/coco_detection.yml',\n",
    "  '../runtime.yml',\n",
    "  './include/dataloader.yml',\n",
    "  './include/rtdetrv2_r50vd.yml',\n",
    "]\n",
    "\n",
    "output_dir: /kaggle/working/FINAL/FINETUNE_DISTILLED/rtdetrv2_finetune_taco_convnext_teacher\n",
    "\n",
    "RTDETR:\n",
    "  backbone: PResNet\n",
    "\n",
    "PResNet:\n",
    "  depth: 50\n",
    "  variant: d\n",
    "  freeze_at: 0\n",
    "  return_idx: [1, 2, 3]\n",
    "  num_stages: 4\n",
    "  freeze_norm: True\n",
    "  pretrained: False\n",
    "\n",
    "task: detection\n",
    "remap_mscoco_category: false\n",
    "tuning: '/kaggle/working/FINAL/DISTILL-CONVNEXT/distilled_rtdetr_convnext_teacher_BEST.pth'\n",
    "compile: true\n",
    "epoches: 50\n",
    "\n",
    "num_classes: 60\n",
    "\n",
    "train_dataloader:\n",
    "  num_workers: 4\n",
    "  dataset:\n",
    "    type: CocoDetection\n",
    "    img_folder: /kaggle/input/dsp-pre-final/processed_taco_coco/train2017\n",
    "    ann_file: /kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_train2017.json\n",
    "\n",
    "val_dataloader:\n",
    "  num_workers: 4\n",
    "  dataset:\n",
    "    type: CocoDetection\n",
    "    img_folder: /kaggle/input/dsp-pre-final/processed_taco_coco/val2017\n",
    "    ann_file: /kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_val2017.json\n",
    "\n",
    "batch_size: 16\n",
    "\n",
    "optimizer:\n",
    "  type: AdamW\n",
    "  params:\n",
    "    - params: '^(?=.*backbone)'\n",
    "      lr: 0.00001\n",
    "    - params: '^(?=.*encoder)'\n",
    "      lr: 0.00005\n",
    "  lr: 0.0001\n",
    "  weight_decay: 0.0001\n",
    "  betas: [0.9, 0.999]\n",
    "\n",
    "lr_scheduler:\n",
    "  type: MultiStepLR\n",
    "  milestones: [40]\n",
    "  gamma: 0.1\n",
    "\n",
    "checkpoint_freq: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8f44378",
   "metadata": {
    "_cell_guid": "3042f90e-8bb1-4977-9872-3a5ed62e434d",
    "_uuid": "28ba2386-fe6d-4901-b89d-7dfb83a11c12",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-30T20:10:46.459530Z",
     "iopub.status.busy": "2025-10-30T20:10:46.459261Z",
     "iopub.status.idle": "2025-10-30T21:33:58.568294Z",
     "shell.execute_reply": "2025-10-30T21:33:58.567123Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 4992.315059,
     "end_time": "2025-10-30T21:33:58.570193",
     "exception": false,
     "start_time": "2025-10-30T20:10:46.255134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/RT-DETR/rtdetrv2_pytorch\n",
      "W1030 20:10:48.179000 4396 torch/distributed/run.py:793] \r\n",
      "W1030 20:10:48.179000 4396 torch/distributed/run.py:793] *****************************************\r\n",
      "W1030 20:10:48.179000 4396 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \r\n",
      "W1030 20:10:48.179000 4396 torch/distributed/run.py:793] *****************************************\r\n",
      "2025-10-30 20:10:50.601606: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2025-10-30 20:10:50.601606: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1761855050.622635    4401 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1761855050.622684    4402 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1761855050.629360    4401 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "E0000 00:00:1761855050.629360    4402 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Initialized distributed mode...\r\n",
      "cfg:  {'task': 'detection', '_model': None, '_postprocessor': None, '_criterion': None, '_optimizer': None, '_lr_scheduler': None, '_lr_warmup_scheduler': None, '_train_dataloader': None, '_val_dataloader': None, '_ema': None, '_scaler': None, '_train_dataset': None, '_val_dataset': None, '_collate_fn': None, '_evaluator': None, '_writer': None, 'num_workers': 0, 'batch_size': 16, '_train_batch_size': None, '_val_batch_size': None, '_train_shuffle': None, '_val_shuffle': None, 'resume': None, 'tuning': '/kaggle/working/FINAL/DISTILL-CONVNEXT/distilled_rtdetr_convnext_teacher_BEST.pth', 'epoches': 50, 'last_epoch': -1, 'use_amp': True, 'use_ema': False, 'ema_decay': 0.9999, 'ema_warmups': 2000, 'sync_bn': True, 'clip_max_norm': 0.0, 'find_unused_parameters': False, 'seed': 0, 'print_freq': 100, 'checkpoint_freq': 10, 'output_dir': '/kaggle/working/FINAL/FINETUNE_DISTILLED/rtdetrv2_finetune_taco_convnext_teacher', 'summary_dir': None, 'device': '', 'yaml_cfg': {'task': 'detection', 'evaluator': {'type': 'CocoEvaluator', 'iou_types': ['bbox']}, 'num_classes': 60, 'remap_mscoco_category': False, 'train_dataloader': {'type': 'DataLoader', 'dataset': {'type': 'CocoDetection', 'img_folder': '/kaggle/input/dsp-pre-final/processed_taco_coco/train2017', 'ann_file': '/kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_train2017.json', 'return_masks': False, 'transforms': {'type': 'Compose', 'ops': [{'type': 'RandomPhotometricDistort', 'p': 0.5}, {'type': 'RandomZoomOut', 'fill': 0}, {'type': 'RandomIoUCrop', 'p': 0.8}, {'type': 'SanitizeBoundingBoxes', 'min_size': 1}, {'type': 'RandomHorizontalFlip'}, {'type': 'Resize', 'size': [640, 640]}, {'type': 'SanitizeBoundingBoxes', 'min_size': 1}, {'type': 'ConvertPILImage', 'dtype': 'float32', 'scale': True}, {'type': 'ConvertBoxes', 'fmt': 'cxcywh', 'normalize': True}], 'policy': {'name': 'stop_epoch', 'epoch': 71, 'ops': ['RandomPhotometricDistort', 'RandomZoomOut', 'RandomIoUCrop']}}}, 'shuffle': True, 'num_workers': 4, 'drop_last': True, 'collate_fn': {'type': 'BatchImageCollateFuncion', 'scales': [480, 512, 544, 576, 608, 640, 640, 640, 672, 704, 736, 768, 800], 'stop_epoch': 71}, 'total_batch_size': 16}, 'val_dataloader': {'type': 'DataLoader', 'dataset': {'type': 'CocoDetection', 'img_folder': '/kaggle/input/dsp-pre-final/processed_taco_coco/val2017', 'ann_file': '/kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_val2017.json', 'return_masks': False, 'transforms': {'type': 'Compose', 'ops': [{'type': 'Resize', 'size': [640, 640]}, {'type': 'ConvertPILImage', 'dtype': 'float32', 'scale': True}]}}, 'shuffle': False, 'num_workers': 4, 'drop_last': False, 'collate_fn': {'type': 'BatchImageCollateFuncion'}, 'total_batch_size': 32}, 'print_freq': 100, 'output_dir': '/kaggle/working/FINAL/FINETUNE_DISTILLED/rtdetrv2_finetune_taco_convnext_teacher', 'checkpoint_freq': 10, 'sync_bn': True, 'find_unused_parameters': False, 'use_amp': True, 'scaler': {'type': 'GradScaler', 'enabled': True}, 'use_ema': False, 'ema': {'type': 'ModelEMA', 'decay': 0.9999, 'warmups': 2000}, 'model': 'RTDETR', 'criterion': 'RTDETRCriterionv2', 'postprocessor': 'RTDETRPostProcessor', 'use_focal_loss': True, 'eval_spatial_size': [640, 640], 'RTDETR': {'backbone': 'PResNet', 'encoder': 'HybridEncoder', 'decoder': 'RTDETRTransformerv2'}, 'PResNet': {'depth': 50, 'variant': 'd', 'freeze_at': 0, 'return_idx': [1, 2, 3], 'num_stages': 4, 'freeze_norm': True, 'pretrained': False}, 'HybridEncoder': {'in_channels': [512, 1024, 2048], 'feat_strides': [8, 16, 32], 'hidden_dim': 256, 'use_encoder_idx': [2], 'num_encoder_layers': 1, 'nhead': 8, 'dim_feedforward': 1024, 'dropout': 0.0, 'enc_act': 'gelu', 'expansion': 1.0, 'depth_mult': 1, 'act': 'silu'}, 'RTDETRTransformerv2': {'feat_channels': [256, 256, 256], 'feat_strides': [8, 16, 32], 'hidden_dim': 256, 'num_levels': 3, 'num_layers': 6, 'num_queries': 300, 'num_denoising': 100, 'label_noise_ratio': 0.5, 'box_noise_scale': 1.0, 'eval_idx': -1, 'num_points': [4, 4, 4], 'cross_attn_method': 'default', 'query_select_method': 'default'}, 'RTDETRPostProcessor': {'num_top_queries': 300}, 'RTDETRCriterionv2': {'weight_dict': {'loss_vfl': 1, 'loss_bbox': 5, 'loss_giou': 2}, 'losses': ['vfl', 'boxes'], 'alpha': 0.75, 'gamma': 2.0, 'matcher': {'type': 'HungarianMatcher', 'weight_dict': {'cost_class': 2, 'cost_bbox': 5, 'cost_giou': 2}, 'alpha': 0.25, 'gamma': 2.0}}, '__include__': ['../dataset/coco_detection.yml', '../runtime.yml', './include/dataloader.yml', './include/rtdetrv2_r50vd.yml'], 'tuning': '/kaggle/working/FINAL/DISTILL-CONVNEXT/distilled_rtdetr_convnext_teacher_BEST.pth', 'compile': True, 'epoches': 50, 'batch_size': 16, 'optimizer': {'type': 'AdamW', 'params': [{'params': '^(?=.*backbone)', 'lr': 1e-05}, {'params': '^(?=.*encoder)', 'lr': 5e-05}], 'lr': 0.0001, 'weight_decay': 0.0001, 'betas': [0.9, 0.999]}, 'lr_scheduler': {'type': 'MultiStepLR', 'milestones': [40], 'gamma': 0.1}, 'config': 'configs/rtdetrv2/rtdetrv2_taco_finetune_convnext.yml', 'seed': 0, 'test_only': False, 'print_method': 'builtin', 'print_rank': 0}}\r\n",
      "Start training\r\n",
      "Initialized distributed mode...\r\n",
      "tuning checkpoint from /kaggle/working/FINAL/DISTILL-CONVNEXT/distilled_rtdetr_convnext_teacher_BEST.pth\r\n",
      "/kaggle/working/RT-DETR/rtdetrv2_pytorch/tools/../src/solver/_solver.py:155: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  state = torch.load(path, map_location='cpu')\r\n",
      "/kaggle/working/RT-DETR/rtdetrv2_pytorch/tools/../src/solver/_solver.py:155: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  state = torch.load(path, map_location='cpu')\r\n",
      "Load model.state_dict, {'missed': ['backbone.conv1.conv1_1.conv.weight', 'backbone.conv1.conv1_1.norm.weight', 'backbone.conv1.conv1_1.norm.bias', 'backbone.conv1.conv1_1.norm.running_mean', 'backbone.conv1.conv1_1.norm.running_var', 'backbone.conv1.conv1_2.conv.weight', 'backbone.conv1.conv1_2.norm.weight', 'backbone.conv1.conv1_2.norm.bias', 'backbone.conv1.conv1_2.norm.running_mean', 'backbone.conv1.conv1_2.norm.running_var', 'backbone.conv1.conv1_3.conv.weight', 'backbone.conv1.conv1_3.norm.weight', 'backbone.conv1.conv1_3.norm.bias', 'backbone.conv1.conv1_3.norm.running_mean', 'backbone.conv1.conv1_3.norm.running_var', 'backbone.res_layers.0.blocks.0.branch2a.conv.weight', 'backbone.res_layers.0.blocks.0.branch2a.norm.weight', 'backbone.res_layers.0.blocks.0.branch2a.norm.bias', 'backbone.res_layers.0.blocks.0.branch2a.norm.running_mean', 'backbone.res_layers.0.blocks.0.branch2a.norm.running_var', 'backbone.res_layers.0.blocks.0.branch2b.conv.weight', 'backbone.res_layers.0.blocks.0.branch2b.norm.weight', 'backbone.res_layers.0.blocks.0.branch2b.norm.bias', 'backbone.res_layers.0.blocks.0.branch2b.norm.running_mean', 'backbone.res_layers.0.blocks.0.branch2b.norm.running_var', 'backbone.res_layers.0.blocks.0.branch2c.conv.weight', 'backbone.res_layers.0.blocks.0.branch2c.norm.weight', 'backbone.res_layers.0.blocks.0.branch2c.norm.bias', 'backbone.res_layers.0.blocks.0.branch2c.norm.running_mean', 'backbone.res_layers.0.blocks.0.branch2c.norm.running_var', 'backbone.res_layers.0.blocks.0.short.conv.weight', 'backbone.res_layers.0.blocks.0.short.norm.weight', 'backbone.res_layers.0.blocks.0.short.norm.bias', 'backbone.res_layers.0.blocks.0.short.norm.running_mean', 'backbone.res_layers.0.blocks.0.short.norm.running_var', 'backbone.res_layers.0.blocks.1.branch2a.conv.weight', 'backbone.res_layers.0.blocks.1.branch2a.norm.weight', 'backbone.res_layers.0.blocks.1.branch2a.norm.bias', 'backbone.res_layers.0.blocks.1.branch2a.norm.running_mean', 'backbone.res_layers.0.blocks.1.branch2a.norm.running_var', 'backbone.res_layers.0.blocks.1.branch2b.conv.weight', 'backbone.res_layers.0.blocks.1.branch2b.norm.weight', 'backbone.res_layers.0.blocks.1.branch2b.norm.bias', 'backbone.res_layers.0.blocks.1.branch2b.norm.running_mean', 'backbone.res_layers.0.blocks.1.branch2b.norm.running_var', 'backbone.res_layers.0.blocks.1.branch2c.conv.weight', 'backbone.res_layers.0.blocks.1.branch2c.norm.weight', 'backbone.res_layers.0.blocks.1.branch2c.norm.bias', 'backbone.res_layers.0.blocks.1.branch2c.norm.running_mean', 'backbone.res_layers.0.blocks.1.branch2c.norm.running_var', 'backbone.res_layers.0.blocks.2.branch2a.conv.weight', 'backbone.res_layers.0.blocks.2.branch2a.norm.weight', 'backbone.res_layers.0.blocks.2.branch2a.norm.bias', 'backbone.res_layers.0.blocks.2.branch2a.norm.running_mean', 'backbone.res_layers.0.blocks.2.branch2a.norm.running_var', 'backbone.res_layers.0.blocks.2.branch2b.conv.weight', 'backbone.res_layers.0.blocks.2.branch2b.norm.weight', 'backbone.res_layers.0.blocks.2.branch2b.norm.bias', 'backbone.res_layers.0.blocks.2.branch2b.norm.running_mean', 'backbone.res_layers.0.blocks.2.branch2b.norm.running_var', 'backbone.res_layers.0.blocks.2.branch2c.conv.weight', 'backbone.res_layers.0.blocks.2.branch2c.norm.weight', 'backbone.res_layers.0.blocks.2.branch2c.norm.bias', 'backbone.res_layers.0.blocks.2.branch2c.norm.running_mean', 'backbone.res_layers.0.blocks.2.branch2c.norm.running_var', 'backbone.res_layers.1.blocks.0.branch2a.conv.weight', 'backbone.res_layers.1.blocks.0.branch2a.norm.weight', 'backbone.res_layers.1.blocks.0.branch2a.norm.bias', 'backbone.res_layers.1.blocks.0.branch2a.norm.running_mean', 'backbone.res_layers.1.blocks.0.branch2a.norm.running_var', 'backbone.res_layers.1.blocks.0.branch2b.conv.weight', 'backbone.res_layers.1.blocks.0.branch2b.norm.weight', 'backbone.res_layers.1.blocks.0.branch2b.norm.bias', 'backbone.res_layers.1.blocks.0.branch2b.norm.running_mean', 'backbone.res_layers.1.blocks.0.branch2b.norm.running_var', 'backbone.res_layers.1.blocks.0.branch2c.conv.weight', 'backbone.res_layers.1.blocks.0.branch2c.norm.weight', 'backbone.res_layers.1.blocks.0.branch2c.norm.bias', 'backbone.res_layers.1.blocks.0.branch2c.norm.running_mean', 'backbone.res_layers.1.blocks.0.branch2c.norm.running_var', 'backbone.res_layers.1.blocks.0.short.conv.conv.weight', 'backbone.res_layers.1.blocks.0.short.conv.norm.weight', 'backbone.res_layers.1.blocks.0.short.conv.norm.bias', 'backbone.res_layers.1.blocks.0.short.conv.norm.running_mean', 'backbone.res_layers.1.blocks.0.short.conv.norm.running_var', 'backbone.res_layers.1.blocks.1.branch2a.conv.weight', 'backbone.res_layers.1.blocks.1.branch2a.norm.weight', 'backbone.res_layers.1.blocks.1.branch2a.norm.bias', 'backbone.res_layers.1.blocks.1.branch2a.norm.running_mean', 'backbone.res_layers.1.blocks.1.branch2a.norm.running_var', 'backbone.res_layers.1.blocks.1.branch2b.conv.weight', 'backbone.res_layers.1.blocks.1.branch2b.norm.weight', 'backbone.res_layers.1.blocks.1.branch2b.norm.bias', 'backbone.res_layers.1.blocks.1.branch2b.norm.running_mean', 'backbone.res_layers.1.blocks.1.branch2b.norm.running_var', 'backbone.res_layers.1.blocks.1.branch2c.conv.weight', 'backbone.res_layers.1.blocks.1.branch2c.norm.weight', 'backbone.res_layers.1.blocks.1.branch2c.norm.bias', 'backbone.res_layers.1.blocks.1.branch2c.norm.running_mean', 'backbone.res_layers.1.blocks.1.branch2c.norm.running_var', 'backbone.res_layers.1.blocks.2.branch2a.conv.weight', 'backbone.res_layers.1.blocks.2.branch2a.norm.weight', 'backbone.res_layers.1.blocks.2.branch2a.norm.bias', 'backbone.res_layers.1.blocks.2.branch2a.norm.running_mean', 'backbone.res_layers.1.blocks.2.branch2a.norm.running_var', 'backbone.res_layers.1.blocks.2.branch2b.conv.weight', 'backbone.res_layers.1.blocks.2.branch2b.norm.weight', 'backbone.res_layers.1.blocks.2.branch2b.norm.bias', 'backbone.res_layers.1.blocks.2.branch2b.norm.running_mean', 'backbone.res_layers.1.blocks.2.branch2b.norm.running_var', 'backbone.res_layers.1.blocks.2.branch2c.conv.weight', 'backbone.res_layers.1.blocks.2.branch2c.norm.weight', 'backbone.res_layers.1.blocks.2.branch2c.norm.bias', 'backbone.res_layers.1.blocks.2.branch2c.norm.running_mean', 'backbone.res_layers.1.blocks.2.branch2c.norm.running_var', 'backbone.res_layers.1.blocks.3.branch2a.conv.weight', 'backbone.res_layers.1.blocks.3.branch2a.norm.weight', 'backbone.res_layers.1.blocks.3.branch2a.norm.bias', 'backbone.res_layers.1.blocks.3.branch2a.norm.running_mean', 'backbone.res_layers.1.blocks.3.branch2a.norm.running_var', 'backbone.res_layers.1.blocks.3.branch2b.conv.weight', 'backbone.res_layers.1.blocks.3.branch2b.norm.weight', 'backbone.res_layers.1.blocks.3.branch2b.norm.bias', 'backbone.res_layers.1.blocks.3.branch2b.norm.running_mean', 'backbone.res_layers.1.blocks.3.branch2b.norm.running_var', 'backbone.res_layers.1.blocks.3.branch2c.conv.weight', 'backbone.res_layers.1.blocks.3.branch2c.norm.weight', 'backbone.res_layers.1.blocks.3.branch2c.norm.bias', 'backbone.res_layers.1.blocks.3.branch2c.norm.running_mean', 'backbone.res_layers.1.blocks.3.branch2c.norm.running_var', 'backbone.res_layers.2.blocks.0.branch2a.conv.weight', 'backbone.res_layers.2.blocks.0.branch2a.norm.weight', 'backbone.res_layers.2.blocks.0.branch2a.norm.bias', 'backbone.res_layers.2.blocks.0.branch2a.norm.running_mean', 'backbone.res_layers.2.blocks.0.branch2a.norm.running_var', 'backbone.res_layers.2.blocks.0.branch2b.conv.weight', 'backbone.res_layers.2.blocks.0.branch2b.norm.weight', 'backbone.res_layers.2.blocks.0.branch2b.norm.bias', 'backbone.res_layers.2.blocks.0.branch2b.norm.running_mean', 'backbone.res_layers.2.blocks.0.branch2b.norm.running_var', 'backbone.res_layers.2.blocks.0.branch2c.conv.weight', 'backbone.res_layers.2.blocks.0.branch2c.norm.weight', 'backbone.res_layers.2.blocks.0.branch2c.norm.bias', 'backbone.res_layers.2.blocks.0.branch2c.norm.running_mean', 'backbone.res_layers.2.blocks.0.branch2c.norm.running_var', 'backbone.res_layers.2.blocks.0.short.conv.conv.weight', 'backbone.res_layers.2.blocks.0.short.conv.norm.weight', 'backbone.res_layers.2.blocks.0.short.conv.norm.bias', 'backbone.res_layers.2.blocks.0.short.conv.norm.running_mean', 'backbone.res_layers.2.blocks.0.short.conv.norm.running_var', 'backbone.res_layers.2.blocks.1.branch2a.conv.weight', 'backbone.res_layers.2.blocks.1.branch2a.norm.weight', 'backbone.res_layers.2.blocks.1.branch2a.norm.bias', 'backbone.res_layers.2.blocks.1.branch2a.norm.running_mean', 'backbone.res_layers.2.blocks.1.branch2a.norm.running_var', 'backbone.res_layers.2.blocks.1.branch2b.conv.weight', 'backbone.res_layers.2.blocks.1.branch2b.norm.weight', 'backbone.res_layers.2.blocks.1.branch2b.norm.bias', 'backbone.res_layers.2.blocks.1.branch2b.norm.running_mean', 'backbone.res_layers.2.blocks.1.branch2b.norm.running_var', 'backbone.res_layers.2.blocks.1.branch2c.conv.weight', 'backbone.res_layers.2.blocks.1.branch2c.norm.weight', 'backbone.res_layers.2.blocks.1.branch2c.norm.bias', 'backbone.res_layers.2.blocks.1.branch2c.norm.running_mean', 'backbone.res_layers.2.blocks.1.branch2c.norm.running_var', 'backbone.res_layers.2.blocks.2.branch2a.conv.weight', 'backbone.res_layers.2.blocks.2.branch2a.norm.weight', 'backbone.res_layers.2.blocks.2.branch2a.norm.bias', 'backbone.res_layers.2.blocks.2.branch2a.norm.running_mean', 'backbone.res_layers.2.blocks.2.branch2a.norm.running_var', 'backbone.res_layers.2.blocks.2.branch2b.conv.weight', 'backbone.res_layers.2.blocks.2.branch2b.norm.weight', 'backbone.res_layers.2.blocks.2.branch2b.norm.bias', 'backbone.res_layers.2.blocks.2.branch2b.norm.running_mean', 'backbone.res_layers.2.blocks.2.branch2b.norm.running_var', 'backbone.res_layers.2.blocks.2.branch2c.conv.weight', 'backbone.res_layers.2.blocks.2.branch2c.norm.weight', 'backbone.res_layers.2.blocks.2.branch2c.norm.bias', 'backbone.res_layers.2.blocks.2.branch2c.norm.running_mean', 'backbone.res_layers.2.blocks.2.branch2c.norm.running_var', 'backbone.res_layers.2.blocks.3.branch2a.conv.weight', 'backbone.res_layers.2.blocks.3.branch2a.norm.weight', 'backbone.res_layers.2.blocks.3.branch2a.norm.bias', 'backbone.res_layers.2.blocks.3.branch2a.norm.running_mean', 'backbone.res_layers.2.blocks.3.branch2a.norm.running_var', 'backbone.res_layers.2.blocks.3.branch2b.conv.weight', 'backbone.res_layers.2.blocks.3.branch2b.norm.weight', 'backbone.res_layers.2.blocks.3.branch2b.norm.bias', 'backbone.res_layers.2.blocks.3.branch2b.norm.running_mean', 'backbone.res_layers.2.blocks.3.branch2b.norm.running_var', 'backbone.res_layers.2.blocks.3.branch2c.conv.weight', 'backbone.res_layers.2.blocks.3.branch2c.norm.weight', 'backbone.res_layers.2.blocks.3.branch2c.norm.bias', 'backbone.res_layers.2.blocks.3.branch2c.norm.running_mean', 'backbone.res_layers.2.blocks.3.branch2c.norm.running_var', 'backbone.res_layers.2.blocks.4.branch2a.conv.weight', 'backbone.res_layers.2.blocks.4.branch2a.norm.weight', 'backbone.res_layers.2.blocks.4.branch2a.norm.bias', 'backbone.res_layers.2.blocks.4.branch2a.norm.running_mean', 'backbone.res_layers.2.blocks.4.branch2a.norm.running_var', 'backbone.res_layers.2.blocks.4.branch2b.conv.weight', 'backbone.res_layers.2.blocks.4.branch2b.norm.weight', 'backbone.res_layers.2.blocks.4.branch2b.norm.bias', 'backbone.res_layers.2.blocks.4.branch2b.norm.running_mean', 'backbone.res_layers.2.blocks.4.branch2b.norm.running_var', 'backbone.res_layers.2.blocks.4.branch2c.conv.weight', 'backbone.res_layers.2.blocks.4.branch2c.norm.weight', 'backbone.res_layers.2.blocks.4.branch2c.norm.bias', 'backbone.res_layers.2.blocks.4.branch2c.norm.running_mean', 'backbone.res_layers.2.blocks.4.branch2c.norm.running_var', 'backbone.res_layers.2.blocks.5.branch2a.conv.weight', 'backbone.res_layers.2.blocks.5.branch2a.norm.weight', 'backbone.res_layers.2.blocks.5.branch2a.norm.bias', 'backbone.res_layers.2.blocks.5.branch2a.norm.running_mean', 'backbone.res_layers.2.blocks.5.branch2a.norm.running_var', 'backbone.res_layers.2.blocks.5.branch2b.conv.weight', 'backbone.res_layers.2.blocks.5.branch2b.norm.weight', 'backbone.res_layers.2.blocks.5.branch2b.norm.bias', 'backbone.res_layers.2.blocks.5.branch2b.norm.running_mean', 'backbone.res_layers.2.blocks.5.branch2b.norm.running_var', 'backbone.res_layers.2.blocks.5.branch2c.conv.weight', 'backbone.res_layers.2.blocks.5.branch2c.norm.weight', 'backbone.res_layers.2.blocks.5.branch2c.norm.bias', 'backbone.res_layers.2.blocks.5.branch2c.norm.running_mean', 'backbone.res_layers.2.blocks.5.branch2c.norm.running_var', 'backbone.res_layers.3.blocks.0.branch2a.conv.weight', 'backbone.res_layers.3.blocks.0.branch2a.norm.weight', 'backbone.res_layers.3.blocks.0.branch2a.norm.bias', 'backbone.res_layers.3.blocks.0.branch2a.norm.running_mean', 'backbone.res_layers.3.blocks.0.branch2a.norm.running_var', 'backbone.res_layers.3.blocks.0.branch2b.conv.weight', 'backbone.res_layers.3.blocks.0.branch2b.norm.weight', 'backbone.res_layers.3.blocks.0.branch2b.norm.bias', 'backbone.res_layers.3.blocks.0.branch2b.norm.running_mean', 'backbone.res_layers.3.blocks.0.branch2b.norm.running_var', 'backbone.res_layers.3.blocks.0.branch2c.conv.weight', 'backbone.res_layers.3.blocks.0.branch2c.norm.weight', 'backbone.res_layers.3.blocks.0.branch2c.norm.bias', 'backbone.res_layers.3.blocks.0.branch2c.norm.running_mean', 'backbone.res_layers.3.blocks.0.branch2c.norm.running_var', 'backbone.res_layers.3.blocks.0.short.conv.conv.weight', 'backbone.res_layers.3.blocks.0.short.conv.norm.weight', 'backbone.res_layers.3.blocks.0.short.conv.norm.bias', 'backbone.res_layers.3.blocks.0.short.conv.norm.running_mean', 'backbone.res_layers.3.blocks.0.short.conv.norm.running_var', 'backbone.res_layers.3.blocks.1.branch2a.conv.weight', 'backbone.res_layers.3.blocks.1.branch2a.norm.weight', 'backbone.res_layers.3.blocks.1.branch2a.norm.bias', 'backbone.res_layers.3.blocks.1.branch2a.norm.running_mean', 'backbone.res_layers.3.blocks.1.branch2a.norm.running_var', 'backbone.res_layers.3.blocks.1.branch2b.conv.weight', 'backbone.res_layers.3.blocks.1.branch2b.norm.weight', 'backbone.res_layers.3.blocks.1.branch2b.norm.bias', 'backbone.res_layers.3.blocks.1.branch2b.norm.running_mean', 'backbone.res_layers.3.blocks.1.branch2b.norm.running_var', 'backbone.res_layers.3.blocks.1.branch2c.conv.weight', 'backbone.res_layers.3.blocks.1.branch2c.norm.weight', 'backbone.res_layers.3.blocks.1.branch2c.norm.bias', 'backbone.res_layers.3.blocks.1.branch2c.norm.running_mean', 'backbone.res_layers.3.blocks.1.branch2c.norm.running_var', 'backbone.res_layers.3.blocks.2.branch2a.conv.weight', 'backbone.res_layers.3.blocks.2.branch2a.norm.weight', 'backbone.res_layers.3.blocks.2.branch2a.norm.bias', 'backbone.res_layers.3.blocks.2.branch2a.norm.running_mean', 'backbone.res_layers.3.blocks.2.branch2a.norm.running_var', 'backbone.res_layers.3.blocks.2.branch2b.conv.weight', 'backbone.res_layers.3.blocks.2.branch2b.norm.weight', 'backbone.res_layers.3.blocks.2.branch2b.norm.bias', 'backbone.res_layers.3.blocks.2.branch2b.norm.running_mean', 'backbone.res_layers.3.blocks.2.branch2b.norm.running_var', 'backbone.res_layers.3.blocks.2.branch2c.conv.weight', 'backbone.res_layers.3.blocks.2.branch2c.norm.weight', 'backbone.res_layers.3.blocks.2.branch2c.norm.bias', 'backbone.res_layers.3.blocks.2.branch2c.norm.running_mean', 'backbone.res_layers.3.blocks.2.branch2c.norm.running_var', 'decoder.anchors', 'decoder.valid_mask', 'decoder.input_proj.0.conv.weight', 'decoder.input_proj.0.norm.weight', 'decoder.input_proj.0.norm.bias', 'decoder.input_proj.0.norm.running_mean', 'decoder.input_proj.0.norm.running_var', 'decoder.input_proj.0.norm.num_batches_tracked', 'decoder.input_proj.1.conv.weight', 'decoder.input_proj.1.norm.weight', 'decoder.input_proj.1.norm.bias', 'decoder.input_proj.1.norm.running_mean', 'decoder.input_proj.1.norm.running_var', 'decoder.input_proj.1.norm.num_batches_tracked', 'decoder.input_proj.2.conv.weight', 'decoder.input_proj.2.norm.weight', 'decoder.input_proj.2.norm.bias', 'decoder.input_proj.2.norm.running_mean', 'decoder.input_proj.2.norm.running_var', 'decoder.input_proj.2.norm.num_batches_tracked', 'decoder.decoder.layers.0.self_attn.in_proj_weight', 'decoder.decoder.layers.0.self_attn.in_proj_bias', 'decoder.decoder.layers.0.self_attn.out_proj.weight', 'decoder.decoder.layers.0.self_attn.out_proj.bias', 'decoder.decoder.layers.0.norm1.weight', 'decoder.decoder.layers.0.norm1.bias', 'decoder.decoder.layers.0.cross_attn.num_points_scale', 'decoder.decoder.layers.0.cross_attn.sampling_offsets.weight', 'decoder.decoder.layers.0.cross_attn.sampling_offsets.bias', 'decoder.decoder.layers.0.cross_attn.attention_weights.weight', 'decoder.decoder.layers.0.cross_attn.attention_weights.bias', 'decoder.decoder.layers.0.cross_attn.value_proj.weight', 'decoder.decoder.layers.0.cross_attn.value_proj.bias', 'decoder.decoder.layers.0.cross_attn.output_proj.weight', 'decoder.decoder.layers.0.cross_attn.output_proj.bias', 'decoder.decoder.layers.0.norm2.weight', 'decoder.decoder.layers.0.norm2.bias', 'decoder.decoder.layers.0.linear1.weight', 'decoder.decoder.layers.0.linear1.bias', 'decoder.decoder.layers.0.linear2.weight', 'decoder.decoder.layers.0.linear2.bias', 'decoder.decoder.layers.0.norm3.weight', 'decoder.decoder.layers.0.norm3.bias', 'decoder.decoder.layers.1.self_attn.in_proj_weight', 'decoder.decoder.layers.1.self_attn.in_proj_bias', 'decoder.decoder.layers.1.self_attn.out_proj.weight', 'decoder.decoder.layers.1.self_attn.out_proj.bias', 'decoder.decoder.layers.1.norm1.weight', 'decoder.decoder.layers.1.norm1.bias', 'decoder.decoder.layers.1.cross_attn.num_points_scale', 'decoder.decoder.layers.1.cross_attn.sampling_offsets.weight', 'decoder.decoder.layers.1.cross_attn.sampling_offsets.bias', 'decoder.decoder.layers.1.cross_attn.attention_weights.weight', 'decoder.decoder.layers.1.cross_attn.attention_weights.bias', 'decoder.decoder.layers.1.cross_attn.value_proj.weight', 'decoder.decoder.layers.1.cross_attn.value_proj.bias', 'decoder.decoder.layers.1.cross_attn.output_proj.weight', 'decoder.decoder.layers.1.cross_attn.output_proj.bias', 'decoder.decoder.layers.1.norm2.weight', 'decoder.decoder.layers.1.norm2.bias', 'decoder.decoder.layers.1.linear1.weight', 'decoder.decoder.layers.1.linear1.bias', 'decoder.decoder.layers.1.linear2.weight', 'decoder.decoder.layers.1.linear2.bias', 'decoder.decoder.layers.1.norm3.weight', 'decoder.decoder.layers.1.norm3.bias', 'decoder.decoder.layers.2.self_attn.in_proj_weight', 'decoder.decoder.layers.2.self_attn.in_proj_bias', 'decoder.decoder.layers.2.self_attn.out_proj.weight', 'decoder.decoder.layers.2.self_attn.out_proj.bias', 'decoder.decoder.layers.2.norm1.weight', 'decoder.decoder.layers.2.norm1.bias', 'decoder.decoder.layers.2.cross_attn.num_points_scale', 'decoder.decoder.layers.2.cross_attn.sampling_offsets.weight', 'decoder.decoder.layers.2.cross_attn.sampling_offsets.bias', 'decoder.decoder.layers.2.cross_attn.attention_weights.weight', 'decoder.decoder.layers.2.cross_attn.attention_weights.bias', 'decoder.decoder.layers.2.cross_attn.value_proj.weight', 'decoder.decoder.layers.2.cross_attn.value_proj.bias', 'decoder.decoder.layers.2.cross_attn.output_proj.weight', 'decoder.decoder.layers.2.cross_attn.output_proj.bias', 'decoder.decoder.layers.2.norm2.weight', 'decoder.decoder.layers.2.norm2.bias', 'decoder.decoder.layers.2.linear1.weight', 'decoder.decoder.layers.2.linear1.bias', 'decoder.decoder.layers.2.linear2.weight', 'decoder.decoder.layers.2.linear2.bias', 'decoder.decoder.layers.2.norm3.weight', 'decoder.decoder.layers.2.norm3.bias', 'decoder.decoder.layers.3.self_attn.in_proj_weight', 'decoder.decoder.layers.3.self_attn.in_proj_bias', 'decoder.decoder.layers.3.self_attn.out_proj.weight', 'decoder.decoder.layers.3.self_attn.out_proj.bias', 'decoder.decoder.layers.3.norm1.weight', 'decoder.decoder.layers.3.norm1.bias', 'decoder.decoder.layers.3.cross_attn.num_points_scale', 'decoder.decoder.layers.3.cross_attn.sampling_offsets.weight', 'decoder.decoder.layers.3.cross_attn.sampling_offsets.bias', 'decoder.decoder.layers.3.cross_attn.attention_weights.weight', 'decoder.decoder.layers.3.cross_attn.attention_weights.bias', 'decoder.decoder.layers.3.cross_attn.value_proj.weight', 'decoder.decoder.layers.3.cross_attn.value_proj.bias', 'decoder.decoder.layers.3.cross_attn.output_proj.weight', 'decoder.decoder.layers.3.cross_attn.output_proj.bias', 'decoder.decoder.layers.3.norm2.weight', 'decoder.decoder.layers.3.norm2.bias', 'decoder.decoder.layers.3.linear1.weight', 'decoder.decoder.layers.3.linear1.bias', 'decoder.decoder.layers.3.linear2.weight', 'decoder.decoder.layers.3.linear2.bias', 'decoder.decoder.layers.3.norm3.weight', 'decoder.decoder.layers.3.norm3.bias', 'decoder.decoder.layers.4.self_attn.in_proj_weight', 'decoder.decoder.layers.4.self_attn.in_proj_bias', 'decoder.decoder.layers.4.self_attn.out_proj.weight', 'decoder.decoder.layers.4.self_attn.out_proj.bias', 'decoder.decoder.layers.4.norm1.weight', 'decoder.decoder.layers.4.norm1.bias', 'decoder.decoder.layers.4.cross_attn.num_points_scale', 'decoder.decoder.layers.4.cross_attn.sampling_offsets.weight', 'decoder.decoder.layers.4.cross_attn.sampling_offsets.bias', 'decoder.decoder.layers.4.cross_attn.attention_weights.weight', 'decoder.decoder.layers.4.cross_attn.attention_weights.bias', 'decoder.decoder.layers.4.cross_attn.value_proj.weight', 'decoder.decoder.layers.4.cross_attn.value_proj.bias', 'decoder.decoder.layers.4.cross_attn.output_proj.weight', 'decoder.decoder.layers.4.cross_attn.output_proj.bias', 'decoder.decoder.layers.4.norm2.weight', 'decoder.decoder.layers.4.norm2.bias', 'decoder.decoder.layers.4.linear1.weight', 'decoder.decoder.layers.4.linear1.bias', 'decoder.decoder.layers.4.linear2.weight', 'decoder.decoder.layers.4.linear2.bias', 'decoder.decoder.layers.4.norm3.weight', 'decoder.decoder.layers.4.norm3.bias', 'decoder.decoder.layers.5.self_attn.in_proj_weight', 'decoder.decoder.layers.5.self_attn.in_proj_bias', 'decoder.decoder.layers.5.self_attn.out_proj.weight', 'decoder.decoder.layers.5.self_attn.out_proj.bias', 'decoder.decoder.layers.5.norm1.weight', 'decoder.decoder.layers.5.norm1.bias', 'decoder.decoder.layers.5.cross_attn.num_points_scale', 'decoder.decoder.layers.5.cross_attn.sampling_offsets.weight', 'decoder.decoder.layers.5.cross_attn.sampling_offsets.bias', 'decoder.decoder.layers.5.cross_attn.attention_weights.weight', 'decoder.decoder.layers.5.cross_attn.attention_weights.bias', 'decoder.decoder.layers.5.cross_attn.value_proj.weight', 'decoder.decoder.layers.5.cross_attn.value_proj.bias', 'decoder.decoder.layers.5.cross_attn.output_proj.weight', 'decoder.decoder.layers.5.cross_attn.output_proj.bias', 'decoder.decoder.layers.5.norm2.weight', 'decoder.decoder.layers.5.norm2.bias', 'decoder.decoder.layers.5.linear1.weight', 'decoder.decoder.layers.5.linear1.bias', 'decoder.decoder.layers.5.linear2.weight', 'decoder.decoder.layers.5.linear2.bias', 'decoder.decoder.layers.5.norm3.weight', 'decoder.decoder.layers.5.norm3.bias', 'decoder.denoising_class_embed.weight', 'decoder.query_pos_head.layers.0.weight', 'decoder.query_pos_head.layers.0.bias', 'decoder.query_pos_head.layers.1.weight', 'decoder.query_pos_head.layers.1.bias', 'decoder.enc_output.proj.weight', 'decoder.enc_output.proj.bias', 'decoder.enc_output.norm.weight', 'decoder.enc_output.norm.bias', 'decoder.enc_score_head.weight', 'decoder.enc_score_head.bias', 'decoder.enc_bbox_head.layers.0.weight', 'decoder.enc_bbox_head.layers.0.bias', 'decoder.enc_bbox_head.layers.1.weight', 'decoder.enc_bbox_head.layers.1.bias', 'decoder.enc_bbox_head.layers.2.weight', 'decoder.enc_bbox_head.layers.2.bias', 'decoder.dec_score_head.0.weight', 'decoder.dec_score_head.0.bias', 'decoder.dec_score_head.1.weight', 'decoder.dec_score_head.1.bias', 'decoder.dec_score_head.2.weight', 'decoder.dec_score_head.2.bias', 'decoder.dec_score_head.3.weight', 'decoder.dec_score_head.3.bias', 'decoder.dec_score_head.4.weight', 'decoder.dec_score_head.4.bias', 'decoder.dec_score_head.5.weight', 'decoder.dec_score_head.5.bias', 'decoder.dec_bbox_head.0.layers.0.weight', 'decoder.dec_bbox_head.0.layers.0.bias', 'decoder.dec_bbox_head.0.layers.1.weight', 'decoder.dec_bbox_head.0.layers.1.bias', 'decoder.dec_bbox_head.0.layers.2.weight', 'decoder.dec_bbox_head.0.layers.2.bias', 'decoder.dec_bbox_head.1.layers.0.weight', 'decoder.dec_bbox_head.1.layers.0.bias', 'decoder.dec_bbox_head.1.layers.1.weight', 'decoder.dec_bbox_head.1.layers.1.bias', 'decoder.dec_bbox_head.1.layers.2.weight', 'decoder.dec_bbox_head.1.layers.2.bias', 'decoder.dec_bbox_head.2.layers.0.weight', 'decoder.dec_bbox_head.2.layers.0.bias', 'decoder.dec_bbox_head.2.layers.1.weight', 'decoder.dec_bbox_head.2.layers.1.bias', 'decoder.dec_bbox_head.2.layers.2.weight', 'decoder.dec_bbox_head.2.layers.2.bias', 'decoder.dec_bbox_head.3.layers.0.weight', 'decoder.dec_bbox_head.3.layers.0.bias', 'decoder.dec_bbox_head.3.layers.1.weight', 'decoder.dec_bbox_head.3.layers.1.bias', 'decoder.dec_bbox_head.3.layers.2.weight', 'decoder.dec_bbox_head.3.layers.2.bias', 'decoder.dec_bbox_head.4.layers.0.weight', 'decoder.dec_bbox_head.4.layers.0.bias', 'decoder.dec_bbox_head.4.layers.1.weight', 'decoder.dec_bbox_head.4.layers.1.bias', 'decoder.dec_bbox_head.4.layers.2.weight', 'decoder.dec_bbox_head.4.layers.2.bias', 'decoder.dec_bbox_head.5.layers.0.weight', 'decoder.dec_bbox_head.5.layers.0.bias', 'decoder.dec_bbox_head.5.layers.1.weight', 'decoder.dec_bbox_head.5.layers.1.bias', 'decoder.dec_bbox_head.5.layers.2.weight', 'decoder.dec_bbox_head.5.layers.2.bias', 'encoder.input_proj.0.conv.weight', 'encoder.input_proj.0.norm.weight', 'encoder.input_proj.0.norm.bias', 'encoder.input_proj.0.norm.running_mean', 'encoder.input_proj.0.norm.running_var', 'encoder.input_proj.0.norm.num_batches_tracked', 'encoder.input_proj.1.conv.weight', 'encoder.input_proj.1.norm.weight', 'encoder.input_proj.1.norm.bias', 'encoder.input_proj.1.norm.running_mean', 'encoder.input_proj.1.norm.running_var', 'encoder.input_proj.1.norm.num_batches_tracked', 'encoder.input_proj.2.conv.weight', 'encoder.input_proj.2.norm.weight', 'encoder.input_proj.2.norm.bias', 'encoder.input_proj.2.norm.running_mean', 'encoder.input_proj.2.norm.running_var', 'encoder.input_proj.2.norm.num_batches_tracked', 'encoder.encoder.0.layers.0.self_attn.in_proj_weight', 'encoder.encoder.0.layers.0.self_attn.in_proj_bias', 'encoder.encoder.0.layers.0.self_attn.out_proj.weight', 'encoder.encoder.0.layers.0.self_attn.out_proj.bias', 'encoder.encoder.0.layers.0.linear1.weight', 'encoder.encoder.0.layers.0.linear1.bias', 'encoder.encoder.0.layers.0.linear2.weight', 'encoder.encoder.0.layers.0.linear2.bias', 'encoder.encoder.0.layers.0.norm1.weight', 'encoder.encoder.0.layers.0.norm1.bias', 'encoder.encoder.0.layers.0.norm2.weight', 'encoder.encoder.0.layers.0.norm2.bias', 'encoder.lateral_convs.0.conv.weight', 'encoder.lateral_convs.0.norm.weight', 'encoder.lateral_convs.0.norm.bias', 'encoder.lateral_convs.0.norm.running_mean', 'encoder.lateral_convs.0.norm.running_var', 'encoder.lateral_convs.0.norm.num_batches_tracked', 'encoder.lateral_convs.1.conv.weight', 'encoder.lateral_convs.1.norm.weight', 'encoder.lateral_convs.1.norm.bias', 'encoder.lateral_convs.1.norm.running_mean', 'encoder.lateral_convs.1.norm.running_var', 'encoder.lateral_convs.1.norm.num_batches_tracked', 'encoder.fpn_blocks.0.conv1.conv.weight', 'encoder.fpn_blocks.0.conv1.norm.weight', 'encoder.fpn_blocks.0.conv1.norm.bias', 'encoder.fpn_blocks.0.conv1.norm.running_mean', 'encoder.fpn_blocks.0.conv1.norm.running_var', 'encoder.fpn_blocks.0.conv1.norm.num_batches_tracked', 'encoder.fpn_blocks.0.conv2.conv.weight', 'encoder.fpn_blocks.0.conv2.norm.weight', 'encoder.fpn_blocks.0.conv2.norm.bias', 'encoder.fpn_blocks.0.conv2.norm.running_mean', 'encoder.fpn_blocks.0.conv2.norm.running_var', 'encoder.fpn_blocks.0.conv2.norm.num_batches_tracked', 'encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight', 'encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight', 'encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias', 'encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.running_mean', 'encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.running_var', 'encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.num_batches_tracked', 'encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight', 'encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight', 'encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias', 'encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.running_mean', 'encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.running_var', 'encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.num_batches_tracked', 'encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight', 'encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight', 'encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias', 'encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.running_mean', 'encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.running_var', 'encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.num_batches_tracked', 'encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight', 'encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight', 'encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias', 'encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.running_mean', 'encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.running_var', 'encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.num_batches_tracked', 'encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight', 'encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight', 'encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias', 'encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.running_mean', 'encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.running_var', 'encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.num_batches_tracked', 'encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight', 'encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight', 'encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias', 'encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.running_mean', 'encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.running_var', 'encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.num_batches_tracked', 'encoder.fpn_blocks.1.conv1.conv.weight', 'encoder.fpn_blocks.1.conv1.norm.weight', 'encoder.fpn_blocks.1.conv1.norm.bias', 'encoder.fpn_blocks.1.conv1.norm.running_mean', 'encoder.fpn_blocks.1.conv1.norm.running_var', 'encoder.fpn_blocks.1.conv1.norm.num_batches_tracked', 'encoder.fpn_blocks.1.conv2.conv.weight', 'encoder.fpn_blocks.1.conv2.norm.weight', 'encoder.fpn_blocks.1.conv2.norm.bias', 'encoder.fpn_blocks.1.conv2.norm.running_mean', 'encoder.fpn_blocks.1.conv2.norm.running_var', 'encoder.fpn_blocks.1.conv2.norm.num_batches_tracked', 'encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight', 'encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight', 'encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias', 'encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.running_mean', 'encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.running_var', 'encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.num_batches_tracked', 'encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight', 'encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight', 'encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias', 'encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.running_mean', 'encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.running_var', 'encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.num_batches_tracked', 'encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight', 'encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight', 'encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias', 'encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.running_mean', 'encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.running_var', 'encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.num_batches_tracked', 'encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight', 'encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight', 'encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias', 'encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.running_mean', 'encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.running_var', 'encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.num_batches_tracked', 'encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight', 'encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight', 'encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias', 'encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.running_mean', 'encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.running_var', 'encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.num_batches_tracked', 'encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight', 'encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight', 'encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias', 'encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.running_mean', 'encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.running_var', 'encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.num_batches_tracked', 'encoder.downsample_convs.0.conv.weight', 'encoder.downsample_convs.0.norm.weight', 'encoder.downsample_convs.0.norm.bias', 'encoder.downsample_convs.0.norm.running_mean', 'encoder.downsample_convs.0.norm.running_var', 'encoder.downsample_convs.0.norm.num_batches_tracked', 'encoder.downsample_convs.1.conv.weight', 'encoder.downsample_convs.1.norm.weight', 'encoder.downsample_convs.1.norm.bias', 'encoder.downsample_convs.1.norm.running_mean', 'encoder.downsample_convs.1.norm.running_var', 'encoder.downsample_convs.1.norm.num_batches_tracked', 'encoder.pan_blocks.0.conv1.conv.weight', 'encoder.pan_blocks.0.conv1.norm.weight', 'encoder.pan_blocks.0.conv1.norm.bias', 'encoder.pan_blocks.0.conv1.norm.running_mean', 'encoder.pan_blocks.0.conv1.norm.running_var', 'encoder.pan_blocks.0.conv1.norm.num_batches_tracked', 'encoder.pan_blocks.0.conv2.conv.weight', 'encoder.pan_blocks.0.conv2.norm.weight', 'encoder.pan_blocks.0.conv2.norm.bias', 'encoder.pan_blocks.0.conv2.norm.running_mean', 'encoder.pan_blocks.0.conv2.norm.running_var', 'encoder.pan_blocks.0.conv2.norm.num_batches_tracked', 'encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight', 'encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight', 'encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias', 'encoder.pan_blocks.0.bottlenecks.0.conv1.norm.running_mean', 'encoder.pan_blocks.0.bottlenecks.0.conv1.norm.running_var', 'encoder.pan_blocks.0.bottlenecks.0.conv1.norm.num_batches_tracked', 'encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight', 'encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight', 'encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias', 'encoder.pan_blocks.0.bottlenecks.0.conv2.norm.running_mean', 'encoder.pan_blocks.0.bottlenecks.0.conv2.norm.running_var', 'encoder.pan_blocks.0.bottlenecks.0.conv2.norm.num_batches_tracked', 'encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight', 'encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight', 'encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias', 'encoder.pan_blocks.0.bottlenecks.1.conv1.norm.running_mean', 'encoder.pan_blocks.0.bottlenecks.1.conv1.norm.running_var', 'encoder.pan_blocks.0.bottlenecks.1.conv1.norm.num_batches_tracked', 'encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight', 'encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight', 'encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias', 'encoder.pan_blocks.0.bottlenecks.1.conv2.norm.running_mean', 'encoder.pan_blocks.0.bottlenecks.1.conv2.norm.running_var', 'encoder.pan_blocks.0.bottlenecks.1.conv2.norm.num_batches_tracked', 'encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight', 'encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight', 'encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias', 'encoder.pan_blocks.0.bottlenecks.2.conv1.norm.running_mean', 'encoder.pan_blocks.0.bottlenecks.2.conv1.norm.running_var', 'encoder.pan_blocks.0.bottlenecks.2.conv1.norm.num_batches_tracked', 'encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight', 'encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight', 'encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias', 'encoder.pan_blocks.0.bottlenecks.2.conv2.norm.running_mean', 'encoder.pan_blocks.0.bottlenecks.2.conv2.norm.running_var', 'encoder.pan_blocks.0.bottlenecks.2.conv2.norm.num_batches_tracked', 'encoder.pan_blocks.1.conv1.conv.weight', 'encoder.pan_blocks.1.conv1.norm.weight', 'encoder.pan_blocks.1.conv1.norm.bias', 'encoder.pan_blocks.1.conv1.norm.running_mean', 'encoder.pan_blocks.1.conv1.norm.running_var', 'encoder.pan_blocks.1.conv1.norm.num_batches_tracked', 'encoder.pan_blocks.1.conv2.conv.weight', 'encoder.pan_blocks.1.conv2.norm.weight', 'encoder.pan_blocks.1.conv2.norm.bias', 'encoder.pan_blocks.1.conv2.norm.running_mean', 'encoder.pan_blocks.1.conv2.norm.running_var', 'encoder.pan_blocks.1.conv2.norm.num_batches_tracked', 'encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight', 'encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight', 'encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias', 'encoder.pan_blocks.1.bottlenecks.0.conv1.norm.running_mean', 'encoder.pan_blocks.1.bottlenecks.0.conv1.norm.running_var', 'encoder.pan_blocks.1.bottlenecks.0.conv1.norm.num_batches_tracked', 'encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight', 'encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight', 'encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias', 'encoder.pan_blocks.1.bottlenecks.0.conv2.norm.running_mean', 'encoder.pan_blocks.1.bottlenecks.0.conv2.norm.running_var', 'encoder.pan_blocks.1.bottlenecks.0.conv2.norm.num_batches_tracked', 'encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight', 'encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight', 'encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias', 'encoder.pan_blocks.1.bottlenecks.1.conv1.norm.running_mean', 'encoder.pan_blocks.1.bottlenecks.1.conv1.norm.running_var', 'encoder.pan_blocks.1.bottlenecks.1.conv1.norm.num_batches_tracked', 'encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight', 'encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight', 'encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias', 'encoder.pan_blocks.1.bottlenecks.1.conv2.norm.running_mean', 'encoder.pan_blocks.1.bottlenecks.1.conv2.norm.running_var', 'encoder.pan_blocks.1.bottlenecks.1.conv2.norm.num_batches_tracked', 'encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight', 'encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight', 'encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias', 'encoder.pan_blocks.1.bottlenecks.2.conv1.norm.running_mean', 'encoder.pan_blocks.1.bottlenecks.2.conv1.norm.running_var', 'encoder.pan_blocks.1.bottlenecks.2.conv1.norm.num_batches_tracked', 'encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight', 'encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight', 'encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias', 'encoder.pan_blocks.1.bottlenecks.2.conv2.norm.running_mean', 'encoder.pan_blocks.1.bottlenecks.2.conv2.norm.running_var', 'encoder.pan_blocks.1.bottlenecks.2.conv2.norm.num_batches_tracked'], 'unmatched': []}\r\n",
      "/kaggle/working/RT-DETR/rtdetrv2_pytorch/tools/../src/core/workspace.py:179: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\r\n",
      "  return module(**module_kwargs)\r\n",
      "/kaggle/working/RT-DETR/rtdetrv2_pytorch/tools/../src/core/workspace.py:179: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\r\n",
      "  return module(**module_kwargs)\r\n",
      "Initial lr: [1e-05, 5e-05, 0.0001]\r\n",
      "building train_dataloader with batch_size=8...\r\n",
      "building val_dataloader with batch_size=16...\r\n",
      "number of trainable parameters: 42821760\r\n",
      "Epoch: [0]  [ 0/79]  eta: 0:08:50  lr: 0.000010  loss: 36.6440 (36.6440)  loss_bbox: 0.7998 (0.7998)  loss_bbox_aux_0: 0.8393 (0.8393)  loss_bbox_aux_1: 0.8246 (0.8246)  loss_bbox_aux_2: 0.7953 (0.7953)  loss_bbox_aux_3: 0.8299 (0.8299)  loss_bbox_aux_4: 0.8143 (0.8143)  loss_bbox_dn_0: 0.4249 (0.4249)  loss_bbox_dn_1: 0.4249 (0.4249)  loss_bbox_dn_2: 0.4249 (0.4249)  loss_bbox_dn_3: 0.4249 (0.4249)  loss_bbox_dn_4: 0.4249 (0.4249)  loss_bbox_dn_5: 0.4249 (0.4249)  loss_bbox_enc_0: 0.8313 (0.8313)  loss_giou: 1.8573 (1.8573)  loss_giou_aux_0: 1.8459 (1.8459)  loss_giou_aux_1: 1.8473 (1.8473)  loss_giou_aux_2: 1.8874 (1.8874)  loss_giou_aux_3: 1.8201 (1.8201)  loss_giou_aux_4: 1.8360 (1.8360)  loss_giou_dn_0: 1.3827 (1.3827)  loss_giou_dn_1: 1.3827 (1.3827)  loss_giou_dn_2: 1.3827 (1.3827)  loss_giou_dn_3: 1.3827 (1.3827)  loss_giou_dn_4: 1.3827 (1.3827)  loss_giou_dn_5: 1.3827 (1.3827)  loss_giou_enc_0: 1.8677 (1.8677)  loss_vfl: 0.3421 (0.3421)  loss_vfl_aux_0: 0.3530 (0.3530)  loss_vfl_aux_1: 0.3052 (0.3052)  loss_vfl_aux_2: 0.3124 (0.3124)  loss_vfl_aux_3: 0.3624 (0.3624)  loss_vfl_aux_4: 0.3417 (0.3417)  loss_vfl_dn_0: 0.8298 (0.8298)  loss_vfl_dn_1: 0.7654 (0.7654)  loss_vfl_dn_2: 0.7646 (0.7646)  loss_vfl_dn_3: 0.8049 (0.8049)  loss_vfl_dn_4: 0.7761 (0.7761)  loss_vfl_dn_5: 0.8066 (0.8066)  loss_vfl_enc_0: 0.3377 (0.3377)  time: 6.7133  data: 2.7367  max mem: 7012\r\n",
      "Epoch: [0]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 35.8251 (37.0938)  loss_bbox: 0.9221 (1.0003)  loss_bbox_aux_0: 0.9234 (1.0181)  loss_bbox_aux_1: 0.9349 (1.0041)  loss_bbox_aux_2: 0.9418 (1.0045)  loss_bbox_aux_3: 0.8997 (1.0014)  loss_bbox_aux_4: 0.9306 (0.9998)  loss_bbox_dn_0: 0.5003 (0.4988)  loss_bbox_dn_1: 0.5011 (0.4999)  loss_bbox_dn_2: 0.5014 (0.5010)  loss_bbox_dn_3: 0.5016 (0.5018)  loss_bbox_dn_4: 0.5017 (0.5027)  loss_bbox_dn_5: 0.5015 (0.5035)  loss_bbox_enc_0: 0.9710 (1.0450)  loss_giou: 1.6714 (1.7640)  loss_giou_aux_0: 1.6914 (1.7784)  loss_giou_aux_1: 1.6838 (1.7730)  loss_giou_aux_2: 1.6805 (1.7678)  loss_giou_aux_3: 1.6865 (1.7660)  loss_giou_aux_4: 1.6758 (1.7641)  loss_giou_dn_0: 1.3712 (1.3713)  loss_giou_dn_1: 1.3705 (1.3746)  loss_giou_dn_2: 1.3709 (1.3799)  loss_giou_dn_3: 1.3723 (1.3855)  loss_giou_dn_4: 1.3753 (1.3920)  loss_giou_dn_5: 1.3786 (1.3987)  loss_giou_enc_0: 1.7054 (1.7940)  loss_vfl: 0.5278 (0.4076)  loss_vfl_aux_0: 0.4377 (0.3540)  loss_vfl_aux_1: 0.4718 (0.3763)  loss_vfl_aux_2: 0.4943 (0.3790)  loss_vfl_aux_3: 0.5095 (0.3976)  loss_vfl_aux_4: 0.5135 (0.4047)  loss_vfl_dn_0: 0.4711 (0.5962)  loss_vfl_dn_1: 0.4972 (0.6071)  loss_vfl_dn_2: 0.5057 (0.6113)  loss_vfl_dn_3: 0.5250 (0.6203)  loss_vfl_dn_4: 0.5371 (0.6063)  loss_vfl_dn_5: 0.5455 (0.6103)  loss_vfl_enc_0: 0.3815 (0.3332)  time: 0.9606  data: 0.0303  max mem: 10338\r\n",
      "Epoch: [0] Total time: 0:01:25 (1.0774 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 35.8251 (37.0938)  loss_bbox: 0.9221 (1.0003)  loss_bbox_aux_0: 0.9234 (1.0181)  loss_bbox_aux_1: 0.9349 (1.0041)  loss_bbox_aux_2: 0.9418 (1.0045)  loss_bbox_aux_3: 0.8997 (1.0014)  loss_bbox_aux_4: 0.9306 (0.9998)  loss_bbox_dn_0: 0.5003 (0.4988)  loss_bbox_dn_1: 0.5011 (0.4999)  loss_bbox_dn_2: 0.5014 (0.5010)  loss_bbox_dn_3: 0.5016 (0.5018)  loss_bbox_dn_4: 0.5017 (0.5027)  loss_bbox_dn_5: 0.5015 (0.5035)  loss_bbox_enc_0: 0.9710 (1.0450)  loss_giou: 1.6714 (1.7640)  loss_giou_aux_0: 1.6914 (1.7784)  loss_giou_aux_1: 1.6838 (1.7730)  loss_giou_aux_2: 1.6805 (1.7678)  loss_giou_aux_3: 1.6865 (1.7660)  loss_giou_aux_4: 1.6758 (1.7641)  loss_giou_dn_0: 1.3712 (1.3713)  loss_giou_dn_1: 1.3705 (1.3746)  loss_giou_dn_2: 1.3709 (1.3799)  loss_giou_dn_3: 1.3723 (1.3855)  loss_giou_dn_4: 1.3753 (1.3920)  loss_giou_dn_5: 1.3786 (1.3987)  loss_giou_enc_0: 1.7054 (1.7940)  loss_vfl: 0.5278 (0.4076)  loss_vfl_aux_0: 0.4377 (0.3540)  loss_vfl_aux_1: 0.4718 (0.3763)  loss_vfl_aux_2: 0.4943 (0.3790)  loss_vfl_aux_3: 0.5095 (0.3976)  loss_vfl_aux_4: 0.5135 (0.4047)  loss_vfl_dn_0: 0.4711 (0.5962)  loss_vfl_dn_1: 0.4972 (0.6071)  loss_vfl_dn_2: 0.5057 (0.6113)  loss_vfl_dn_3: 0.5250 (0.6203)  loss_vfl_dn_4: 0.5371 (0.6063)  loss_vfl_dn_5: 0.5455 (0.6103)  loss_vfl_enc_0: 0.3815 (0.3332)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.4846  data: 1.3322  max mem: 10338\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0606  data: 0.2181  max mem: 10338\r\n",
      "Test: Total time: 0:00:08 (1.0753 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.16s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      "best_stat: {'epoch': 0, 'coco_eval_bbox': 7.648526813342844e-07}\r\n",
      "Epoch: [1]  [ 0/79]  eta: 0:05:07  lr: 0.000010  loss: 33.9947 (33.9947)  loss_bbox: 0.7390 (0.7390)  loss_bbox_aux_0: 0.7737 (0.7737)  loss_bbox_aux_1: 0.7611 (0.7611)  loss_bbox_aux_2: 0.7460 (0.7460)  loss_bbox_aux_3: 0.7529 (0.7529)  loss_bbox_aux_4: 0.7339 (0.7339)  loss_bbox_dn_0: 0.3486 (0.3486)  loss_bbox_dn_1: 0.3498 (0.3498)  loss_bbox_dn_2: 0.3504 (0.3504)  loss_bbox_dn_3: 0.3509 (0.3509)  loss_bbox_dn_4: 0.3513 (0.3513)  loss_bbox_dn_5: 0.3513 (0.3513)  loss_bbox_enc_0: 0.8435 (0.8435)  loss_giou: 1.7340 (1.7340)  loss_giou_aux_0: 1.7330 (1.7330)  loss_giou_aux_1: 1.7344 (1.7344)  loss_giou_aux_2: 1.7293 (1.7293)  loss_giou_aux_3: 1.7235 (1.7235)  loss_giou_aux_4: 1.7417 (1.7417)  loss_giou_dn_0: 1.3991 (1.3991)  loss_giou_dn_1: 1.4007 (1.4007)  loss_giou_dn_2: 1.4047 (1.4047)  loss_giou_dn_3: 1.4112 (1.4112)  loss_giou_dn_4: 1.4244 (1.4244)  loss_giou_dn_5: 1.4322 (1.4322)  loss_giou_enc_0: 1.7130 (1.7130)  loss_vfl: 0.4501 (0.4501)  loss_vfl_aux_0: 0.3787 (0.3787)  loss_vfl_aux_1: 0.3979 (0.3979)  loss_vfl_aux_2: 0.4373 (0.4373)  loss_vfl_aux_3: 0.4442 (0.4442)  loss_vfl_aux_4: 0.4591 (0.4591)  loss_vfl_dn_0: 0.4698 (0.4698)  loss_vfl_dn_1: 0.4677 (0.4677)  loss_vfl_dn_2: 0.5038 (0.5038)  loss_vfl_dn_3: 0.5198 (0.5198)  loss_vfl_dn_4: 0.5288 (0.5288)  loss_vfl_dn_5: 0.5444 (0.5444)  loss_vfl_enc_0: 0.3597 (0.3597)  time: 3.8919  data: 2.5764  max mem: 10338\r\n",
      "Epoch: [1]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 34.4938 (35.4403)  loss_bbox: 0.7446 (0.8518)  loss_bbox_aux_0: 0.7701 (0.8808)  loss_bbox_aux_1: 0.7560 (0.8668)  loss_bbox_aux_2: 0.7583 (0.8682)  loss_bbox_aux_3: 0.7558 (0.8566)  loss_bbox_aux_4: 0.7413 (0.8562)  loss_bbox_dn_0: 0.4073 (0.4972)  loss_bbox_dn_1: 0.4067 (0.4973)  loss_bbox_dn_2: 0.4061 (0.4971)  loss_bbox_dn_3: 0.4056 (0.4969)  loss_bbox_dn_4: 0.4051 (0.4965)  loss_bbox_dn_5: 0.4047 (0.4963)  loss_bbox_enc_0: 0.7805 (0.8988)  loss_giou: 1.5251 (1.5990)  loss_giou_aux_0: 1.5560 (1.6022)  loss_giou_aux_1: 1.5393 (1.6056)  loss_giou_aux_2: 1.5388 (1.6007)  loss_giou_aux_3: 1.5247 (1.6054)  loss_giou_aux_4: 1.5261 (1.6006)  loss_giou_dn_0: 1.3673 (1.3700)  loss_giou_dn_1: 1.3755 (1.3706)  loss_giou_dn_2: 1.3753 (1.3718)  loss_giou_dn_3: 1.3726 (1.3731)  loss_giou_dn_4: 1.3733 (1.3743)  loss_giou_dn_5: 1.3735 (1.3754)  loss_giou_enc_0: 1.5314 (1.6128)  loss_vfl: 0.6176 (0.6269)  loss_vfl_aux_0: 0.5560 (0.5442)  loss_vfl_aux_1: 0.5719 (0.5648)  loss_vfl_aux_2: 0.5737 (0.5752)  loss_vfl_aux_3: 0.6062 (0.5934)  loss_vfl_aux_4: 0.6128 (0.6108)  loss_vfl_dn_0: 0.4163 (0.4384)  loss_vfl_dn_1: 0.4166 (0.4476)  loss_vfl_dn_2: 0.4321 (0.4671)  loss_vfl_dn_3: 0.4579 (0.4956)  loss_vfl_dn_4: 0.4740 (0.5119)  loss_vfl_dn_5: 0.4918 (0.5305)  loss_vfl_enc_0: 0.5190 (0.5118)  time: 0.9609  data: 0.0337  max mem: 10356\r\n",
      "Epoch: [1] Total time: 0:01:24 (1.0691 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 34.4938 (35.4403)  loss_bbox: 0.7446 (0.8518)  loss_bbox_aux_0: 0.7701 (0.8808)  loss_bbox_aux_1: 0.7560 (0.8668)  loss_bbox_aux_2: 0.7583 (0.8682)  loss_bbox_aux_3: 0.7558 (0.8566)  loss_bbox_aux_4: 0.7413 (0.8562)  loss_bbox_dn_0: 0.4073 (0.4972)  loss_bbox_dn_1: 0.4067 (0.4973)  loss_bbox_dn_2: 0.4061 (0.4971)  loss_bbox_dn_3: 0.4056 (0.4969)  loss_bbox_dn_4: 0.4051 (0.4965)  loss_bbox_dn_5: 0.4047 (0.4963)  loss_bbox_enc_0: 0.7805 (0.8988)  loss_giou: 1.5251 (1.5990)  loss_giou_aux_0: 1.5560 (1.6022)  loss_giou_aux_1: 1.5393 (1.6056)  loss_giou_aux_2: 1.5388 (1.6007)  loss_giou_aux_3: 1.5247 (1.6054)  loss_giou_aux_4: 1.5261 (1.6006)  loss_giou_dn_0: 1.3673 (1.3700)  loss_giou_dn_1: 1.3755 (1.3706)  loss_giou_dn_2: 1.3753 (1.3718)  loss_giou_dn_3: 1.3726 (1.3731)  loss_giou_dn_4: 1.3733 (1.3743)  loss_giou_dn_5: 1.3735 (1.3754)  loss_giou_enc_0: 1.5314 (1.6128)  loss_vfl: 0.6176 (0.6269)  loss_vfl_aux_0: 0.5560 (0.5442)  loss_vfl_aux_1: 0.5719 (0.5648)  loss_vfl_aux_2: 0.5737 (0.5752)  loss_vfl_aux_3: 0.6062 (0.5934)  loss_vfl_aux_4: 0.6128 (0.6108)  loss_vfl_dn_0: 0.4163 (0.4384)  loss_vfl_dn_1: 0.4166 (0.4476)  loss_vfl_dn_2: 0.4321 (0.4671)  loss_vfl_dn_3: 0.4579 (0.4956)  loss_vfl_dn_4: 0.4740 (0.5119)  loss_vfl_dn_5: 0.4918 (0.5305)  loss_vfl_enc_0: 0.5190 (0.5118)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.2091  data: 1.2863  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0583  data: 0.2163  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0764 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.14s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.004\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.015\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.005\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.020\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\r\n",
      "best_stat: {'epoch': 1, 'coco_eval_bbox': 1.2463163226225024e-05}\r\n",
      "Epoch: [2]  [ 0/79]  eta: 0:05:13  lr: 0.000010  loss: 36.0420 (36.0420)  loss_bbox: 0.8682 (0.8682)  loss_bbox_aux_0: 0.8744 (0.8744)  loss_bbox_aux_1: 0.8906 (0.8906)  loss_bbox_aux_2: 0.8838 (0.8838)  loss_bbox_aux_3: 0.8616 (0.8616)  loss_bbox_aux_4: 0.8744 (0.8744)  loss_bbox_dn_0: 0.3848 (0.3848)  loss_bbox_dn_1: 0.3841 (0.3841)  loss_bbox_dn_2: 0.3834 (0.3834)  loss_bbox_dn_3: 0.3829 (0.3829)  loss_bbox_dn_4: 0.3823 (0.3823)  loss_bbox_dn_5: 0.3820 (0.3820)  loss_bbox_enc_0: 0.8821 (0.8821)  loss_giou: 1.8199 (1.8199)  loss_giou_aux_0: 1.8236 (1.8236)  loss_giou_aux_1: 1.8297 (1.8297)  loss_giou_aux_2: 1.8219 (1.8219)  loss_giou_aux_3: 1.8398 (1.8398)  loss_giou_aux_4: 1.8170 (1.8170)  loss_giou_dn_0: 1.3630 (1.3630)  loss_giou_dn_1: 1.3638 (1.3638)  loss_giou_dn_2: 1.3650 (1.3650)  loss_giou_dn_3: 1.3659 (1.3659)  loss_giou_dn_4: 1.3663 (1.3663)  loss_giou_dn_5: 1.3666 (1.3666)  loss_giou_enc_0: 1.8413 (1.8413)  loss_vfl: 0.5857 (0.5857)  loss_vfl_aux_0: 0.5615 (0.5615)  loss_vfl_aux_1: 0.5374 (0.5374)  loss_vfl_aux_2: 0.5397 (0.5397)  loss_vfl_aux_3: 0.5447 (0.5447)  loss_vfl_aux_4: 0.5637 (0.5637)  loss_vfl_dn_0: 0.4354 (0.4354)  loss_vfl_dn_1: 0.4393 (0.4393)  loss_vfl_dn_2: 0.4520 (0.4520)  loss_vfl_dn_3: 0.4714 (0.4714)  loss_vfl_dn_4: 0.4895 (0.4895)  loss_vfl_dn_5: 0.5002 (0.5002)  loss_vfl_enc_0: 0.5029 (0.5029)  time: 3.9676  data: 2.5837  max mem: 10356\r\n",
      "Epoch: [2]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 33.9745 (34.6892)  loss_bbox: 0.6912 (0.7645)  loss_bbox_aux_0: 0.7272 (0.7880)  loss_bbox_aux_1: 0.7105 (0.7803)  loss_bbox_aux_2: 0.7106 (0.7779)  loss_bbox_aux_3: 0.6989 (0.7695)  loss_bbox_aux_4: 0.6936 (0.7687)  loss_bbox_dn_0: 0.4131 (0.5197)  loss_bbox_dn_1: 0.4104 (0.5183)  loss_bbox_dn_2: 0.4090 (0.5175)  loss_bbox_dn_3: 0.4087 (0.5172)  loss_bbox_dn_4: 0.4088 (0.5168)  loss_bbox_dn_5: 0.4087 (0.5169)  loss_bbox_enc_0: 0.7380 (0.7999)  loss_giou: 1.5260 (1.5739)  loss_giou_aux_0: 1.5051 (1.5670)  loss_giou_aux_1: 1.5070 (1.5732)  loss_giou_aux_2: 1.5163 (1.5726)  loss_giou_aux_3: 1.5391 (1.5772)  loss_giou_aux_4: 1.5345 (1.5740)  loss_giou_dn_0: 1.3678 (1.3681)  loss_giou_dn_1: 1.3668 (1.3695)  loss_giou_dn_2: 1.3646 (1.3713)  loss_giou_dn_3: 1.3648 (1.3732)  loss_giou_dn_4: 1.3643 (1.3761)  loss_giou_dn_5: 1.3637 (1.3789)  loss_giou_enc_0: 1.5492 (1.5811)  loss_vfl: 0.6094 (0.6303)  loss_vfl_aux_0: 0.6477 (0.6224)  loss_vfl_aux_1: 0.6141 (0.6103)  loss_vfl_aux_2: 0.6079 (0.6087)  loss_vfl_aux_3: 0.6013 (0.6122)  loss_vfl_aux_4: 0.6108 (0.6168)  loss_vfl_dn_0: 0.3969 (0.4062)  loss_vfl_dn_1: 0.3931 (0.4059)  loss_vfl_dn_2: 0.4049 (0.4154)  loss_vfl_dn_3: 0.4189 (0.4312)  loss_vfl_dn_4: 0.4382 (0.4487)  loss_vfl_dn_5: 0.4526 (0.4630)  loss_vfl_enc_0: 0.6245 (0.6067)  time: 1.0067  data: 0.0316  max mem: 10356\r\n",
      "Epoch: [2] Total time: 0:01:26 (1.0937 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 33.9745 (34.6892)  loss_bbox: 0.6912 (0.7645)  loss_bbox_aux_0: 0.7272 (0.7880)  loss_bbox_aux_1: 0.7105 (0.7803)  loss_bbox_aux_2: 0.7106 (0.7779)  loss_bbox_aux_3: 0.6989 (0.7695)  loss_bbox_aux_4: 0.6936 (0.7687)  loss_bbox_dn_0: 0.4131 (0.5197)  loss_bbox_dn_1: 0.4104 (0.5183)  loss_bbox_dn_2: 0.4090 (0.5175)  loss_bbox_dn_3: 0.4087 (0.5172)  loss_bbox_dn_4: 0.4088 (0.5168)  loss_bbox_dn_5: 0.4087 (0.5169)  loss_bbox_enc_0: 0.7380 (0.7999)  loss_giou: 1.5260 (1.5739)  loss_giou_aux_0: 1.5051 (1.5670)  loss_giou_aux_1: 1.5070 (1.5732)  loss_giou_aux_2: 1.5163 (1.5726)  loss_giou_aux_3: 1.5391 (1.5772)  loss_giou_aux_4: 1.5345 (1.5740)  loss_giou_dn_0: 1.3678 (1.3681)  loss_giou_dn_1: 1.3668 (1.3695)  loss_giou_dn_2: 1.3646 (1.3713)  loss_giou_dn_3: 1.3648 (1.3732)  loss_giou_dn_4: 1.3643 (1.3761)  loss_giou_dn_5: 1.3637 (1.3789)  loss_giou_enc_0: 1.5492 (1.5811)  loss_vfl: 0.6094 (0.6303)  loss_vfl_aux_0: 0.6477 (0.6224)  loss_vfl_aux_1: 0.6141 (0.6103)  loss_vfl_aux_2: 0.6079 (0.6087)  loss_vfl_aux_3: 0.6013 (0.6122)  loss_vfl_aux_4: 0.6108 (0.6168)  loss_vfl_dn_0: 0.3969 (0.4062)  loss_vfl_dn_1: 0.3931 (0.4059)  loss_vfl_dn_2: 0.4049 (0.4154)  loss_vfl_dn_3: 0.4189 (0.4312)  loss_vfl_dn_4: 0.4382 (0.4487)  loss_vfl_dn_5: 0.4526 (0.4630)  loss_vfl_enc_0: 0.6245 (0.6067)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3003  data: 1.3822  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0660  data: 0.2271  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0824 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.17s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.011\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.023\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.026\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.055\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.029\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.077\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.011\r\n",
      "best_stat: {'epoch': 2, 'coco_eval_bbox': 0.0005762983980114799}\r\n",
      "Epoch: [3]  [ 0/79]  eta: 0:06:40  lr: 0.000010  loss: 31.9509 (31.9509)  loss_bbox: 0.6157 (0.6157)  loss_bbox_aux_0: 0.6416 (0.6416)  loss_bbox_aux_1: 0.5780 (0.5780)  loss_bbox_aux_2: 0.6164 (0.6164)  loss_bbox_aux_3: 0.6182 (0.6182)  loss_bbox_aux_4: 0.6195 (0.6195)  loss_bbox_dn_0: 0.4237 (0.4237)  loss_bbox_dn_1: 0.4235 (0.4235)  loss_bbox_dn_2: 0.4232 (0.4232)  loss_bbox_dn_3: 0.4236 (0.4236)  loss_bbox_dn_4: 0.4235 (0.4235)  loss_bbox_dn_5: 0.4237 (0.4237)  loss_bbox_enc_0: 0.6456 (0.6456)  loss_giou: 1.6104 (1.6104)  loss_giou_aux_0: 1.6020 (1.6020)  loss_giou_aux_1: 1.6542 (1.6542)  loss_giou_aux_2: 1.6223 (1.6223)  loss_giou_aux_3: 1.6099 (1.6099)  loss_giou_aux_4: 1.6084 (1.6084)  loss_giou_dn_0: 1.3508 (1.3508)  loss_giou_dn_1: 1.3521 (1.3521)  loss_giou_dn_2: 1.3545 (1.3545)  loss_giou_dn_3: 1.3569 (1.3569)  loss_giou_dn_4: 1.3580 (1.3580)  loss_giou_dn_5: 1.3620 (1.3620)  loss_giou_enc_0: 1.6007 (1.6007)  loss_vfl: 0.4395 (0.4395)  loss_vfl_aux_0: 0.4867 (0.4867)  loss_vfl_aux_1: 0.4554 (0.4554)  loss_vfl_aux_2: 0.4326 (0.4326)  loss_vfl_aux_3: 0.4390 (0.4390)  loss_vfl_aux_4: 0.4287 (0.4287)  loss_vfl_dn_0: 0.3966 (0.3966)  loss_vfl_dn_1: 0.3883 (0.3883)  loss_vfl_dn_2: 0.3878 (0.3878)  loss_vfl_dn_3: 0.3993 (0.3993)  loss_vfl_dn_4: 0.4214 (0.4214)  loss_vfl_dn_5: 0.4291 (0.4291)  loss_vfl_enc_0: 0.5281 (0.5281)  time: 5.0634  data: 3.7652  max mem: 10356\r\n",
      "Epoch: [3]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 34.4603 (34.1863)  loss_bbox: 0.6489 (0.6819)  loss_bbox_aux_0: 0.6582 (0.7101)  loss_bbox_aux_1: 0.6407 (0.6970)  loss_bbox_aux_2: 0.6491 (0.6949)  loss_bbox_aux_3: 0.6556 (0.6908)  loss_bbox_aux_4: 0.6324 (0.6845)  loss_bbox_dn_0: 0.4992 (0.5326)  loss_bbox_dn_1: 0.4934 (0.5295)  loss_bbox_dn_2: 0.4890 (0.5273)  loss_bbox_dn_3: 0.4877 (0.5263)  loss_bbox_dn_4: 0.4888 (0.5255)  loss_bbox_dn_5: 0.4883 (0.5257)  loss_bbox_enc_0: 0.6863 (0.7256)  loss_giou: 1.4607 (1.5180)  loss_giou_aux_0: 1.4947 (1.5283)  loss_giou_aux_1: 1.4868 (1.5292)  loss_giou_aux_2: 1.4531 (1.5252)  loss_giou_aux_3: 1.4609 (1.5226)  loss_giou_aux_4: 1.4467 (1.5172)  loss_giou_dn_0: 1.3762 (1.3673)  loss_giou_dn_1: 1.3683 (1.3643)  loss_giou_dn_2: 1.3647 (1.3621)  loss_giou_dn_3: 1.3574 (1.3610)  loss_giou_dn_4: 1.3529 (1.3600)  loss_giou_dn_5: 1.3507 (1.3615)  loss_giou_enc_0: 1.5140 (1.5428)  loss_vfl: 0.7319 (0.7015)  loss_vfl_aux_0: 0.6934 (0.6680)  loss_vfl_aux_1: 0.6848 (0.6701)  loss_vfl_aux_2: 0.7036 (0.6696)  loss_vfl_aux_3: 0.7161 (0.6814)  loss_vfl_aux_4: 0.7258 (0.6932)  loss_vfl_dn_0: 0.3868 (0.3946)  loss_vfl_dn_1: 0.3884 (0.3960)  loss_vfl_dn_2: 0.3966 (0.4068)  loss_vfl_dn_3: 0.4160 (0.4243)  loss_vfl_dn_4: 0.4315 (0.4433)  loss_vfl_dn_5: 0.4515 (0.4580)  loss_vfl_enc_0: 0.6797 (0.6686)  time: 0.9410  data: 0.0314  max mem: 10356\r\n",
      "Epoch: [3] Total time: 0:01:27 (1.1058 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 34.4603 (34.1863)  loss_bbox: 0.6489 (0.6819)  loss_bbox_aux_0: 0.6582 (0.7101)  loss_bbox_aux_1: 0.6407 (0.6970)  loss_bbox_aux_2: 0.6491 (0.6949)  loss_bbox_aux_3: 0.6556 (0.6908)  loss_bbox_aux_4: 0.6324 (0.6845)  loss_bbox_dn_0: 0.4992 (0.5326)  loss_bbox_dn_1: 0.4934 (0.5295)  loss_bbox_dn_2: 0.4890 (0.5273)  loss_bbox_dn_3: 0.4877 (0.5263)  loss_bbox_dn_4: 0.4888 (0.5255)  loss_bbox_dn_5: 0.4883 (0.5257)  loss_bbox_enc_0: 0.6863 (0.7256)  loss_giou: 1.4607 (1.5180)  loss_giou_aux_0: 1.4947 (1.5283)  loss_giou_aux_1: 1.4868 (1.5292)  loss_giou_aux_2: 1.4531 (1.5252)  loss_giou_aux_3: 1.4609 (1.5226)  loss_giou_aux_4: 1.4467 (1.5172)  loss_giou_dn_0: 1.3762 (1.3673)  loss_giou_dn_1: 1.3683 (1.3643)  loss_giou_dn_2: 1.3647 (1.3621)  loss_giou_dn_3: 1.3574 (1.3610)  loss_giou_dn_4: 1.3529 (1.3600)  loss_giou_dn_5: 1.3507 (1.3615)  loss_giou_enc_0: 1.5140 (1.5428)  loss_vfl: 0.7319 (0.7015)  loss_vfl_aux_0: 0.6934 (0.6680)  loss_vfl_aux_1: 0.6848 (0.6701)  loss_vfl_aux_2: 0.7036 (0.6696)  loss_vfl_aux_3: 0.7161 (0.6814)  loss_vfl_aux_4: 0.7258 (0.6932)  loss_vfl_dn_0: 0.3868 (0.3946)  loss_vfl_dn_1: 0.3884 (0.3960)  loss_vfl_dn_2: 0.3966 (0.4068)  loss_vfl_dn_3: 0.4160 (0.4243)  loss_vfl_dn_4: 0.4315 (0.4433)  loss_vfl_dn_5: 0.4515 (0.4580)  loss_vfl_enc_0: 0.6797 (0.6686)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3686  data: 1.3932  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0746  data: 0.2274  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0909 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.17s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.005\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.023\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.045\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.049\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.108\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.047\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.108\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.039\r\n",
      "best_stat: {'epoch': 3, 'coco_eval_bbox': 0.0021261522850302573}\r\n",
      "Epoch: [4]  [ 0/79]  eta: 0:05:41  lr: 0.000010  loss: 33.2605 (33.2605)  loss_bbox: 0.5323 (0.5323)  loss_bbox_aux_0: 0.5644 (0.5644)  loss_bbox_aux_1: 0.5381 (0.5381)  loss_bbox_aux_2: 0.5200 (0.5200)  loss_bbox_aux_3: 0.5231 (0.5231)  loss_bbox_aux_4: 0.5379 (0.5379)  loss_bbox_dn_0: 0.5662 (0.5662)  loss_bbox_dn_1: 0.5604 (0.5604)  loss_bbox_dn_2: 0.5574 (0.5574)  loss_bbox_dn_3: 0.5562 (0.5562)  loss_bbox_dn_4: 0.5555 (0.5555)  loss_bbox_dn_5: 0.5558 (0.5558)  loss_bbox_enc_0: 0.5551 (0.5551)  loss_giou: 1.3086 (1.3086)  loss_giou_aux_0: 1.3353 (1.3353)  loss_giou_aux_1: 1.3524 (1.3524)  loss_giou_aux_2: 1.3426 (1.3426)  loss_giou_aux_3: 1.3421 (1.3421)  loss_giou_aux_4: 1.3119 (1.3119)  loss_giou_dn_0: 1.3639 (1.3639)  loss_giou_dn_1: 1.3624 (1.3624)  loss_giou_dn_2: 1.3567 (1.3567)  loss_giou_dn_3: 1.3543 (1.3543)  loss_giou_dn_4: 1.3514 (1.3514)  loss_giou_dn_5: 1.3525 (1.3525)  loss_giou_enc_0: 1.3502 (1.3502)  loss_vfl: 0.8807 (0.8807)  loss_vfl_aux_0: 0.7703 (0.7703)  loss_vfl_aux_1: 0.7897 (0.7897)  loss_vfl_aux_2: 0.8032 (0.8032)  loss_vfl_aux_3: 0.8328 (0.8328)  loss_vfl_aux_4: 0.8418 (0.8418)  loss_vfl_dn_0: 0.4428 (0.4428)  loss_vfl_dn_1: 0.4510 (0.4510)  loss_vfl_dn_2: 0.4778 (0.4778)  loss_vfl_dn_3: 0.4862 (0.4862)  loss_vfl_dn_4: 0.5176 (0.5176)  loss_vfl_dn_5: 0.5287 (0.5287)  loss_vfl_enc_0: 0.8312 (0.8312)  time: 4.3209  data: 2.9819  max mem: 10356\r\n",
      "Epoch: [4]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 33.1045 (33.0228)  loss_bbox: 0.5172 (0.5704)  loss_bbox_aux_0: 0.5680 (0.6068)  loss_bbox_aux_1: 0.5443 (0.5866)  loss_bbox_aux_2: 0.5253 (0.5788)  loss_bbox_aux_3: 0.5420 (0.5776)  loss_bbox_aux_4: 0.5337 (0.5739)  loss_bbox_dn_0: 0.5092 (0.4945)  loss_bbox_dn_1: 0.4986 (0.4830)  loss_bbox_dn_2: 0.4897 (0.4781)  loss_bbox_dn_3: 0.4834 (0.4758)  loss_bbox_dn_4: 0.4796 (0.4743)  loss_bbox_dn_5: 0.4791 (0.4741)  loss_bbox_enc_0: 0.5964 (0.6354)  loss_giou: 1.4059 (1.4223)  loss_giou_aux_0: 1.4274 (1.4558)  loss_giou_aux_1: 1.4126 (1.4402)  loss_giou_aux_2: 1.4125 (1.4349)  loss_giou_aux_3: 1.3951 (1.4285)  loss_giou_aux_4: 1.4024 (1.4247)  loss_giou_dn_0: 1.3242 (1.3482)  loss_giou_dn_1: 1.2970 (1.3217)  loss_giou_dn_2: 1.2839 (1.3105)  loss_giou_dn_3: 1.2720 (1.3051)  loss_giou_dn_4: 1.2645 (1.3004)  loss_giou_dn_5: 1.2599 (1.3003)  loss_giou_enc_0: 1.4689 (1.4974)  loss_vfl: 0.8389 (0.8054)  loss_vfl_aux_0: 0.7422 (0.7263)  loss_vfl_aux_1: 0.8108 (0.7610)  loss_vfl_aux_2: 0.8208 (0.7724)  loss_vfl_aux_3: 0.8274 (0.7876)  loss_vfl_aux_4: 0.8481 (0.7929)  loss_vfl_dn_0: 0.4023 (0.3973)  loss_vfl_dn_1: 0.4202 (0.4145)  loss_vfl_dn_2: 0.4362 (0.4326)  loss_vfl_dn_3: 0.4607 (0.4542)  loss_vfl_dn_4: 0.4899 (0.4804)  loss_vfl_dn_5: 0.5144 (0.4984)  loss_vfl_enc_0: 0.6763 (0.7006)  time: 0.9823  data: 0.0313  max mem: 10356\r\n",
      "Epoch: [4] Total time: 0:01:22 (1.0450 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 33.1045 (33.0228)  loss_bbox: 0.5172 (0.5704)  loss_bbox_aux_0: 0.5680 (0.6068)  loss_bbox_aux_1: 0.5443 (0.5866)  loss_bbox_aux_2: 0.5253 (0.5788)  loss_bbox_aux_3: 0.5420 (0.5776)  loss_bbox_aux_4: 0.5337 (0.5739)  loss_bbox_dn_0: 0.5092 (0.4945)  loss_bbox_dn_1: 0.4986 (0.4830)  loss_bbox_dn_2: 0.4897 (0.4781)  loss_bbox_dn_3: 0.4834 (0.4758)  loss_bbox_dn_4: 0.4796 (0.4743)  loss_bbox_dn_5: 0.4791 (0.4741)  loss_bbox_enc_0: 0.5964 (0.6354)  loss_giou: 1.4059 (1.4223)  loss_giou_aux_0: 1.4274 (1.4558)  loss_giou_aux_1: 1.4126 (1.4402)  loss_giou_aux_2: 1.4125 (1.4349)  loss_giou_aux_3: 1.3951 (1.4285)  loss_giou_aux_4: 1.4024 (1.4247)  loss_giou_dn_0: 1.3242 (1.3482)  loss_giou_dn_1: 1.2970 (1.3217)  loss_giou_dn_2: 1.2839 (1.3105)  loss_giou_dn_3: 1.2720 (1.3051)  loss_giou_dn_4: 1.2645 (1.3004)  loss_giou_dn_5: 1.2599 (1.3003)  loss_giou_enc_0: 1.4689 (1.4974)  loss_vfl: 0.8389 (0.8054)  loss_vfl_aux_0: 0.7422 (0.7263)  loss_vfl_aux_1: 0.8108 (0.7610)  loss_vfl_aux_2: 0.8208 (0.7724)  loss_vfl_aux_3: 0.8274 (0.7876)  loss_vfl_aux_4: 0.8481 (0.7929)  loss_vfl_dn_0: 0.4023 (0.3973)  loss_vfl_dn_1: 0.4202 (0.4145)  loss_vfl_dn_2: 0.4362 (0.4326)  loss_vfl_dn_3: 0.4607 (0.4542)  loss_vfl_dn_4: 0.4899 (0.4804)  loss_vfl_dn_5: 0.5144 (0.4984)  loss_vfl_enc_0: 0.6763 (0.7006)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.1879  data: 1.2713  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0395  data: 0.2052  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0546 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.17s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.006\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.007\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.029\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.058\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.061\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.116\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.086\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.150\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.044\r\n",
      "best_stat: {'epoch': 3, 'coco_eval_bbox': 0.0021261522850302573}\r\n",
      "Epoch: [5]  [ 0/79]  eta: 0:05:50  lr: 0.000010  loss: 36.9867 (36.9867)  loss_bbox: 0.7449 (0.7449)  loss_bbox_aux_0: 0.8252 (0.8252)  loss_bbox_aux_1: 0.8118 (0.8118)  loss_bbox_aux_2: 0.8494 (0.8494)  loss_bbox_aux_3: 0.7837 (0.7837)  loss_bbox_aux_4: 0.7712 (0.7712)  loss_bbox_dn_0: 0.8138 (0.8138)  loss_bbox_dn_1: 0.7898 (0.7898)  loss_bbox_dn_2: 0.7760 (0.7760)  loss_bbox_dn_3: 0.7671 (0.7671)  loss_bbox_dn_4: 0.7613 (0.7613)  loss_bbox_dn_5: 0.7601 (0.7601)  loss_bbox_enc_0: 0.9010 (0.9010)  loss_giou: 1.3869 (1.3869)  loss_giou_aux_0: 1.4899 (1.4899)  loss_giou_aux_1: 1.4438 (1.4438)  loss_giou_aux_2: 1.3779 (1.3779)  loss_giou_aux_3: 1.3882 (1.3882)  loss_giou_aux_4: 1.3872 (1.3872)  loss_giou_dn_0: 1.3494 (1.3494)  loss_giou_dn_1: 1.3341 (1.3341)  loss_giou_dn_2: 1.3172 (1.3172)  loss_giou_dn_3: 1.3041 (1.3041)  loss_giou_dn_4: 1.2970 (1.2970)  loss_giou_dn_5: 1.2960 (1.2960)  loss_giou_enc_0: 1.5150 (1.5150)  loss_vfl: 0.9985 (0.9985)  loss_vfl_aux_0: 0.8096 (0.8096)  loss_vfl_aux_1: 0.8289 (0.8289)  loss_vfl_aux_2: 0.8518 (0.8518)  loss_vfl_aux_3: 0.8982 (0.8982)  loss_vfl_aux_4: 0.9399 (0.9399)  loss_vfl_dn_0: 0.3936 (0.3936)  loss_vfl_dn_1: 0.4103 (0.4103)  loss_vfl_dn_2: 0.4255 (0.4255)  loss_vfl_dn_3: 0.4509 (0.4509)  loss_vfl_dn_4: 0.4668 (0.4668)  loss_vfl_dn_5: 0.4852 (0.4852)  loss_vfl_enc_0: 0.7854 (0.7854)  time: 4.4426  data: 2.6885  max mem: 10356\r\n",
      "Epoch: [5]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 31.6416 (32.9998)  loss_bbox: 0.4854 (0.5475)  loss_bbox_aux_0: 0.4975 (0.5844)  loss_bbox_aux_1: 0.4880 (0.5697)  loss_bbox_aux_2: 0.4778 (0.5606)  loss_bbox_aux_3: 0.4832 (0.5571)  loss_bbox_aux_4: 0.4886 (0.5529)  loss_bbox_dn_0: 0.4246 (0.4978)  loss_bbox_dn_1: 0.4010 (0.4848)  loss_bbox_dn_2: 0.3906 (0.4783)  loss_bbox_dn_3: 0.3828 (0.4747)  loss_bbox_dn_4: 0.3784 (0.4732)  loss_bbox_dn_5: 0.3779 (0.4730)  loss_bbox_enc_0: 0.5387 (0.6275)  loss_giou: 1.3143 (1.3996)  loss_giou_aux_0: 1.3546 (1.4308)  loss_giou_aux_1: 1.3721 (1.4253)  loss_giou_aux_2: 1.3549 (1.4107)  loss_giou_aux_3: 1.3281 (1.4104)  loss_giou_aux_4: 1.3215 (1.4029)  loss_giou_dn_0: 1.2927 (1.3126)  loss_giou_dn_1: 1.2515 (1.2791)  loss_giou_dn_2: 1.2415 (1.2641)  loss_giou_dn_3: 1.2377 (1.2547)  loss_giou_dn_4: 1.2261 (1.2484)  loss_giou_dn_5: 1.2273 (1.2489)  loss_giou_enc_0: 1.4327 (1.5003)  loss_vfl: 0.8494 (0.8631)  loss_vfl_aux_0: 0.7517 (0.7808)  loss_vfl_aux_1: 0.8132 (0.7929)  loss_vfl_aux_2: 0.7905 (0.8244)  loss_vfl_aux_3: 0.8149 (0.8365)  loss_vfl_aux_4: 0.8257 (0.8568)  loss_vfl_dn_0: 0.4161 (0.4158)  loss_vfl_dn_1: 0.4321 (0.4368)  loss_vfl_dn_2: 0.4589 (0.4611)  loss_vfl_dn_3: 0.4894 (0.4900)  loss_vfl_dn_4: 0.5229 (0.5196)  loss_vfl_dn_5: 0.5451 (0.5419)  loss_vfl_enc_0: 0.6886 (0.7111)  time: 0.9632  data: 0.0322  max mem: 10356\r\n",
      "Epoch: [5] Total time: 0:01:25 (1.0845 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 31.6416 (32.9998)  loss_bbox: 0.4854 (0.5475)  loss_bbox_aux_0: 0.4975 (0.5844)  loss_bbox_aux_1: 0.4880 (0.5697)  loss_bbox_aux_2: 0.4778 (0.5606)  loss_bbox_aux_3: 0.4832 (0.5571)  loss_bbox_aux_4: 0.4886 (0.5529)  loss_bbox_dn_0: 0.4246 (0.4978)  loss_bbox_dn_1: 0.4010 (0.4848)  loss_bbox_dn_2: 0.3906 (0.4783)  loss_bbox_dn_3: 0.3828 (0.4747)  loss_bbox_dn_4: 0.3784 (0.4732)  loss_bbox_dn_5: 0.3779 (0.4730)  loss_bbox_enc_0: 0.5387 (0.6275)  loss_giou: 1.3143 (1.3996)  loss_giou_aux_0: 1.3546 (1.4308)  loss_giou_aux_1: 1.3721 (1.4253)  loss_giou_aux_2: 1.3549 (1.4107)  loss_giou_aux_3: 1.3281 (1.4104)  loss_giou_aux_4: 1.3215 (1.4029)  loss_giou_dn_0: 1.2927 (1.3126)  loss_giou_dn_1: 1.2515 (1.2791)  loss_giou_dn_2: 1.2415 (1.2641)  loss_giou_dn_3: 1.2377 (1.2547)  loss_giou_dn_4: 1.2261 (1.2484)  loss_giou_dn_5: 1.2273 (1.2489)  loss_giou_enc_0: 1.4327 (1.5003)  loss_vfl: 0.8494 (0.8631)  loss_vfl_aux_0: 0.7517 (0.7808)  loss_vfl_aux_1: 0.8132 (0.7929)  loss_vfl_aux_2: 0.7905 (0.8244)  loss_vfl_aux_3: 0.8149 (0.8365)  loss_vfl_aux_4: 0.8257 (0.8568)  loss_vfl_dn_0: 0.4161 (0.4158)  loss_vfl_dn_1: 0.4321 (0.4368)  loss_vfl_dn_2: 0.4589 (0.4611)  loss_vfl_dn_3: 0.4894 (0.4900)  loss_vfl_dn_4: 0.5229 (0.5196)  loss_vfl_dn_5: 0.5451 (0.5419)  loss_vfl_enc_0: 0.6886 (0.7111)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3167  data: 1.3626  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0654  data: 0.2173  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0818 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.16s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.012\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.024\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.018\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.074\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.105\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.111\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.201\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.138\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.191\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.114\r\n",
      "best_stat: {'epoch': 5, 'coco_eval_bbox': 0.007053691346047607}\r\n",
      "Epoch: [6]  [ 0/79]  eta: 0:04:15  lr: 0.000010  loss: 33.8650 (33.8650)  loss_bbox: 0.6753 (0.6753)  loss_bbox_aux_0: 0.7239 (0.7239)  loss_bbox_aux_1: 0.7204 (0.7204)  loss_bbox_aux_2: 0.7031 (0.7031)  loss_bbox_aux_3: 0.6747 (0.6747)  loss_bbox_aux_4: 0.6780 (0.6780)  loss_bbox_dn_0: 0.5897 (0.5897)  loss_bbox_dn_1: 0.5758 (0.5758)  loss_bbox_dn_2: 0.5689 (0.5689)  loss_bbox_dn_3: 0.5625 (0.5625)  loss_bbox_dn_4: 0.5564 (0.5564)  loss_bbox_dn_5: 0.5557 (0.5557)  loss_bbox_enc_0: 0.7816 (0.7816)  loss_giou: 1.5905 (1.5905)  loss_giou_aux_0: 1.6060 (1.6060)  loss_giou_aux_1: 1.6151 (1.6151)  loss_giou_aux_2: 1.6015 (1.6015)  loss_giou_aux_3: 1.5957 (1.5957)  loss_giou_aux_4: 1.5797 (1.5797)  loss_giou_dn_0: 1.3098 (1.3098)  loss_giou_dn_1: 1.2785 (1.2785)  loss_giou_dn_2: 1.2626 (1.2626)  loss_giou_dn_3: 1.2534 (1.2534)  loss_giou_dn_4: 1.2446 (1.2446)  loss_giou_dn_5: 1.2446 (1.2446)  loss_giou_enc_0: 1.6408 (1.6408)  loss_vfl: 0.5861 (0.5861)  loss_vfl_aux_0: 0.5688 (0.5688)  loss_vfl_aux_1: 0.5199 (0.5199)  loss_vfl_aux_2: 0.5588 (0.5588)  loss_vfl_aux_3: 0.5570 (0.5570)  loss_vfl_aux_4: 0.5781 (0.5781)  loss_vfl_dn_0: 0.4187 (0.4187)  loss_vfl_dn_1: 0.4355 (0.4355)  loss_vfl_dn_2: 0.4468 (0.4468)  loss_vfl_dn_3: 0.4707 (0.4707)  loss_vfl_dn_4: 0.4998 (0.4998)  loss_vfl_dn_5: 0.5212 (0.5212)  loss_vfl_enc_0: 0.5146 (0.5146)  time: 3.2397  data: 2.0145  max mem: 10356\r\n",
      "Epoch: [6]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 32.0966 (32.3524)  loss_bbox: 0.5079 (0.5202)  loss_bbox_aux_0: 0.5722 (0.5627)  loss_bbox_aux_1: 0.5419 (0.5468)  loss_bbox_aux_2: 0.5163 (0.5349)  loss_bbox_aux_3: 0.5154 (0.5284)  loss_bbox_aux_4: 0.5035 (0.5245)  loss_bbox_dn_0: 0.3846 (0.4670)  loss_bbox_dn_1: 0.3666 (0.4512)  loss_bbox_dn_2: 0.3539 (0.4438)  loss_bbox_dn_3: 0.3469 (0.4393)  loss_bbox_dn_4: 0.3454 (0.4371)  loss_bbox_dn_5: 0.3456 (0.4369)  loss_bbox_enc_0: 0.5987 (0.6027)  loss_giou: 1.3155 (1.3544)  loss_giou_aux_0: 1.4101 (1.4056)  loss_giou_aux_1: 1.4082 (1.3900)  loss_giou_aux_2: 1.3188 (1.3742)  loss_giou_aux_3: 1.3147 (1.3689)  loss_giou_aux_4: 1.3211 (1.3578)  loss_giou_dn_0: 1.2893 (1.2878)  loss_giou_dn_1: 1.2409 (1.2459)  loss_giou_dn_2: 1.2248 (1.2262)  loss_giou_dn_3: 1.2111 (1.2147)  loss_giou_dn_4: 1.2068 (1.2075)  loss_giou_dn_5: 1.2080 (1.2085)  loss_giou_enc_0: 1.4847 (1.4786)  loss_vfl: 0.8840 (0.8892)  loss_vfl_aux_0: 0.7478 (0.7896)  loss_vfl_aux_1: 0.7996 (0.8158)  loss_vfl_aux_2: 0.8438 (0.8493)  loss_vfl_aux_3: 0.8467 (0.8680)  loss_vfl_aux_4: 0.8733 (0.8827)  loss_vfl_dn_0: 0.4186 (0.4223)  loss_vfl_dn_1: 0.4509 (0.4492)  loss_vfl_dn_2: 0.4692 (0.4745)  loss_vfl_dn_3: 0.5048 (0.5006)  loss_vfl_dn_4: 0.5339 (0.5296)  loss_vfl_dn_5: 0.5476 (0.5508)  loss_vfl_enc_0: 0.6648 (0.7150)  time: 0.9875  data: 0.0315  max mem: 10356\r\n",
      "Epoch: [6] Total time: 0:01:23 (1.0534 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 32.0966 (32.3524)  loss_bbox: 0.5079 (0.5202)  loss_bbox_aux_0: 0.5722 (0.5627)  loss_bbox_aux_1: 0.5419 (0.5468)  loss_bbox_aux_2: 0.5163 (0.5349)  loss_bbox_aux_3: 0.5154 (0.5284)  loss_bbox_aux_4: 0.5035 (0.5245)  loss_bbox_dn_0: 0.3846 (0.4670)  loss_bbox_dn_1: 0.3666 (0.4512)  loss_bbox_dn_2: 0.3539 (0.4438)  loss_bbox_dn_3: 0.3469 (0.4393)  loss_bbox_dn_4: 0.3454 (0.4371)  loss_bbox_dn_5: 0.3456 (0.4369)  loss_bbox_enc_0: 0.5987 (0.6027)  loss_giou: 1.3155 (1.3544)  loss_giou_aux_0: 1.4101 (1.4056)  loss_giou_aux_1: 1.4082 (1.3900)  loss_giou_aux_2: 1.3188 (1.3742)  loss_giou_aux_3: 1.3147 (1.3689)  loss_giou_aux_4: 1.3211 (1.3578)  loss_giou_dn_0: 1.2893 (1.2878)  loss_giou_dn_1: 1.2409 (1.2459)  loss_giou_dn_2: 1.2248 (1.2262)  loss_giou_dn_3: 1.2111 (1.2147)  loss_giou_dn_4: 1.2068 (1.2075)  loss_giou_dn_5: 1.2080 (1.2085)  loss_giou_enc_0: 1.4847 (1.4786)  loss_vfl: 0.8840 (0.8892)  loss_vfl_aux_0: 0.7478 (0.7896)  loss_vfl_aux_1: 0.7996 (0.8158)  loss_vfl_aux_2: 0.8438 (0.8493)  loss_vfl_aux_3: 0.8467 (0.8680)  loss_vfl_aux_4: 0.8733 (0.8827)  loss_vfl_dn_0: 0.4186 (0.4223)  loss_vfl_dn_1: 0.4509 (0.4492)  loss_vfl_dn_2: 0.4692 (0.4745)  loss_vfl_dn_3: 0.5048 (0.5006)  loss_vfl_dn_4: 0.5339 (0.5296)  loss_vfl_dn_5: 0.5476 (0.5508)  loss_vfl_enc_0: 0.6648 (0.7150)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.1358  data: 1.1916  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0544  data: 0.2066  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0703 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.17s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.014\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.009\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.022\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.011\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.085\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.108\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.113\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.029\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.199\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.141\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.195\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.114\r\n",
      "best_stat: {'epoch': 6, 'coco_eval_bbox': 0.00790462649868164}\r\n",
      "Epoch: [7]  [ 0/79]  eta: 0:04:35  lr: 0.000010  loss: 29.3855 (29.3855)  loss_bbox: 0.3207 (0.3207)  loss_bbox_aux_0: 0.3714 (0.3714)  loss_bbox_aux_1: 0.3577 (0.3577)  loss_bbox_aux_2: 0.3613 (0.3613)  loss_bbox_aux_3: 0.3414 (0.3414)  loss_bbox_aux_4: 0.3238 (0.3238)  loss_bbox_dn_0: 0.3488 (0.3488)  loss_bbox_dn_1: 0.3146 (0.3146)  loss_bbox_dn_2: 0.3020 (0.3020)  loss_bbox_dn_3: 0.2950 (0.2950)  loss_bbox_dn_4: 0.2950 (0.2950)  loss_bbox_dn_5: 0.2946 (0.2946)  loss_bbox_enc_0: 0.4436 (0.4436)  loss_giou: 1.0637 (1.0637)  loss_giou_aux_0: 1.1475 (1.1475)  loss_giou_aux_1: 1.1057 (1.1057)  loss_giou_aux_2: 1.0950 (1.0950)  loss_giou_aux_3: 1.0855 (1.0855)  loss_giou_aux_4: 1.0570 (1.0570)  loss_giou_dn_0: 1.2054 (1.2054)  loss_giou_dn_1: 1.1151 (1.1151)  loss_giou_dn_2: 1.0859 (1.0859)  loss_giou_dn_3: 1.0563 (1.0563)  loss_giou_dn_4: 1.0559 (1.0559)  loss_giou_dn_5: 1.0583 (1.0583)  loss_giou_enc_0: 1.3037 (1.3037)  loss_vfl: 1.0935 (1.0935)  loss_vfl_aux_0: 0.9695 (0.9695)  loss_vfl_aux_1: 1.0193 (1.0193)  loss_vfl_aux_2: 1.0308 (1.0308)  loss_vfl_aux_3: 1.0859 (1.0859)  loss_vfl_aux_4: 1.1243 (1.1243)  loss_vfl_dn_0: 0.4531 (0.4531)  loss_vfl_dn_1: 0.5156 (0.5156)  loss_vfl_dn_2: 0.5515 (0.5515)  loss_vfl_dn_3: 0.6080 (0.6080)  loss_vfl_dn_4: 0.6427 (0.6427)  loss_vfl_dn_5: 0.6632 (0.6632)  loss_vfl_enc_0: 0.8230 (0.8230)  time: 3.4931  data: 2.2488  max mem: 10356\r\n",
      "Epoch: [7]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 31.4757 (31.8723)  loss_bbox: 0.4298 (0.4780)  loss_bbox_aux_0: 0.4655 (0.5174)  loss_bbox_aux_1: 0.4606 (0.5037)  loss_bbox_aux_2: 0.4414 (0.4890)  loss_bbox_aux_3: 0.4356 (0.4827)  loss_bbox_aux_4: 0.4304 (0.4806)  loss_bbox_dn_0: 0.4303 (0.4719)  loss_bbox_dn_1: 0.4078 (0.4525)  loss_bbox_dn_2: 0.3927 (0.4437)  loss_bbox_dn_3: 0.3869 (0.4380)  loss_bbox_dn_4: 0.3840 (0.4354)  loss_bbox_dn_5: 0.3842 (0.4351)  loss_bbox_enc_0: 0.5274 (0.5637)  loss_giou: 1.2542 (1.2857)  loss_giou_aux_0: 1.2977 (1.3400)  loss_giou_aux_1: 1.2758 (1.3172)  loss_giou_aux_2: 1.2571 (1.3032)  loss_giou_aux_3: 1.2552 (1.2959)  loss_giou_aux_4: 1.2421 (1.2914)  loss_giou_dn_0: 1.2315 (1.2465)  loss_giou_dn_1: 1.1768 (1.1967)  loss_giou_dn_2: 1.1522 (1.1746)  loss_giou_dn_3: 1.1359 (1.1622)  loss_giou_dn_4: 1.1353 (1.1546)  loss_giou_dn_5: 1.1369 (1.1547)  loss_giou_enc_0: 1.4395 (1.4163)  loss_vfl: 0.9272 (0.9476)  loss_vfl_aux_0: 0.8105 (0.8608)  loss_vfl_aux_1: 0.8643 (0.8871)  loss_vfl_aux_2: 0.9114 (0.9164)  loss_vfl_aux_3: 0.9309 (0.9362)  loss_vfl_aux_4: 0.8955 (0.9348)  loss_vfl_dn_0: 0.4520 (0.4442)  loss_vfl_dn_1: 0.4824 (0.4722)  loss_vfl_dn_2: 0.5103 (0.4985)  loss_vfl_dn_3: 0.5323 (0.5269)  loss_vfl_dn_4: 0.5677 (0.5565)  loss_vfl_dn_5: 0.5879 (0.5791)  loss_vfl_enc_0: 0.7395 (0.7811)  time: 1.0510  data: 0.0299  max mem: 10356\r\n",
      "Epoch: [7] Total time: 0:01:25 (1.0817 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 31.4757 (31.8723)  loss_bbox: 0.4298 (0.4780)  loss_bbox_aux_0: 0.4655 (0.5174)  loss_bbox_aux_1: 0.4606 (0.5037)  loss_bbox_aux_2: 0.4414 (0.4890)  loss_bbox_aux_3: 0.4356 (0.4827)  loss_bbox_aux_4: 0.4304 (0.4806)  loss_bbox_dn_0: 0.4303 (0.4719)  loss_bbox_dn_1: 0.4078 (0.4525)  loss_bbox_dn_2: 0.3927 (0.4437)  loss_bbox_dn_3: 0.3869 (0.4380)  loss_bbox_dn_4: 0.3840 (0.4354)  loss_bbox_dn_5: 0.3842 (0.4351)  loss_bbox_enc_0: 0.5274 (0.5637)  loss_giou: 1.2542 (1.2857)  loss_giou_aux_0: 1.2977 (1.3400)  loss_giou_aux_1: 1.2758 (1.3172)  loss_giou_aux_2: 1.2571 (1.3032)  loss_giou_aux_3: 1.2552 (1.2959)  loss_giou_aux_4: 1.2421 (1.2914)  loss_giou_dn_0: 1.2315 (1.2465)  loss_giou_dn_1: 1.1768 (1.1967)  loss_giou_dn_2: 1.1522 (1.1746)  loss_giou_dn_3: 1.1359 (1.1622)  loss_giou_dn_4: 1.1353 (1.1546)  loss_giou_dn_5: 1.1369 (1.1547)  loss_giou_enc_0: 1.4395 (1.4163)  loss_vfl: 0.9272 (0.9476)  loss_vfl_aux_0: 0.8105 (0.8608)  loss_vfl_aux_1: 0.8643 (0.8871)  loss_vfl_aux_2: 0.9114 (0.9164)  loss_vfl_aux_3: 0.9309 (0.9362)  loss_vfl_aux_4: 0.8955 (0.9348)  loss_vfl_dn_0: 0.4520 (0.4442)  loss_vfl_dn_1: 0.4824 (0.4722)  loss_vfl_dn_2: 0.5103 (0.4985)  loss_vfl_dn_3: 0.5323 (0.5269)  loss_vfl_dn_4: 0.5677 (0.5565)  loss_vfl_dn_5: 0.5879 (0.5791)  loss_vfl_enc_0: 0.7395 (0.7811)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.1948  data: 1.2574  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0508  data: 0.2024  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0677 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.009\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.014\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.010\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.012\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.019\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.072\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.114\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.119\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.033\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.187\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.156\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.206\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.115\r\n",
      "best_stat: {'epoch': 7, 'coco_eval_bbox': 0.00874203691379466}\r\n",
      "Epoch: [8]  [ 0/79]  eta: 0:04:52  lr: 0.000010  loss: 32.3594 (32.3594)  loss_bbox: 0.4830 (0.4830)  loss_bbox_aux_0: 0.4943 (0.4943)  loss_bbox_aux_1: 0.5012 (0.5012)  loss_bbox_aux_2: 0.4723 (0.4723)  loss_bbox_aux_3: 0.4836 (0.4836)  loss_bbox_aux_4: 0.4847 (0.4847)  loss_bbox_dn_0: 0.4725 (0.4725)  loss_bbox_dn_1: 0.4407 (0.4407)  loss_bbox_dn_2: 0.4225 (0.4225)  loss_bbox_dn_3: 0.4116 (0.4116)  loss_bbox_dn_4: 0.4047 (0.4047)  loss_bbox_dn_5: 0.4044 (0.4044)  loss_bbox_enc_0: 0.5294 (0.5294)  loss_giou: 1.2363 (1.2363)  loss_giou_aux_0: 1.3111 (1.3111)  loss_giou_aux_1: 1.2934 (1.2934)  loss_giou_aux_2: 1.2700 (1.2700)  loss_giou_aux_3: 1.2343 (1.2343)  loss_giou_aux_4: 1.2327 (1.2327)  loss_giou_dn_0: 1.2709 (1.2709)  loss_giou_dn_1: 1.2195 (1.2195)  loss_giou_dn_2: 1.1997 (1.1997)  loss_giou_dn_3: 1.1841 (1.1841)  loss_giou_dn_4: 1.1768 (1.1768)  loss_giou_dn_5: 1.1772 (1.1772)  loss_giou_enc_0: 1.3374 (1.3374)  loss_vfl: 1.0183 (1.0183)  loss_vfl_aux_0: 0.9597 (0.9597)  loss_vfl_aux_1: 0.9714 (0.9714)  loss_vfl_aux_2: 0.9988 (0.9988)  loss_vfl_aux_3: 1.0183 (1.0183)  loss_vfl_aux_4: 1.0342 (1.0342)  loss_vfl_dn_0: 0.4590 (0.4590)  loss_vfl_dn_1: 0.4951 (0.4951)  loss_vfl_dn_2: 0.5349 (0.5349)  loss_vfl_dn_3: 0.5637 (0.5637)  loss_vfl_dn_4: 0.6204 (0.6204)  loss_vfl_dn_5: 0.6267 (0.6267)  loss_vfl_enc_0: 0.9106 (0.9106)  time: 3.6981  data: 2.4330  max mem: 10356\r\n",
      "Epoch: [8]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 31.2510 (31.6978)  loss_bbox: 0.4004 (0.4708)  loss_bbox_aux_0: 0.4450 (0.5170)  loss_bbox_aux_1: 0.4237 (0.4959)  loss_bbox_aux_2: 0.4270 (0.4817)  loss_bbox_aux_3: 0.4008 (0.4767)  loss_bbox_aux_4: 0.4073 (0.4743)  loss_bbox_dn_0: 0.4268 (0.4625)  loss_bbox_dn_1: 0.4024 (0.4411)  loss_bbox_dn_2: 0.3889 (0.4319)  loss_bbox_dn_3: 0.3799 (0.4266)  loss_bbox_dn_4: 0.3732 (0.4240)  loss_bbox_dn_5: 0.3729 (0.4240)  loss_bbox_enc_0: 0.5232 (0.5625)  loss_giou: 1.1966 (1.2748)  loss_giou_aux_0: 1.2511 (1.3411)  loss_giou_aux_1: 1.2114 (1.3138)  loss_giou_aux_2: 1.2029 (1.2969)  loss_giou_aux_3: 1.2166 (1.2890)  loss_giou_aux_4: 1.2039 (1.2804)  loss_giou_dn_0: 1.2236 (1.2380)  loss_giou_dn_1: 1.1700 (1.1821)  loss_giou_dn_2: 1.1522 (1.1593)  loss_giou_dn_3: 1.1433 (1.1464)  loss_giou_dn_4: 1.1338 (1.1397)  loss_giou_dn_5: 1.1342 (1.1401)  loss_giou_enc_0: 1.3606 (1.4187)  loss_vfl: 0.9438 (0.9618)  loss_vfl_aux_0: 0.8428 (0.8495)  loss_vfl_aux_1: 0.9075 (0.8920)  loss_vfl_aux_2: 0.9219 (0.9201)  loss_vfl_aux_3: 0.9387 (0.9412)  loss_vfl_aux_4: 0.9202 (0.9510)  loss_vfl_dn_0: 0.4524 (0.4480)  loss_vfl_dn_1: 0.4757 (0.4776)  loss_vfl_dn_2: 0.5048 (0.5009)  loss_vfl_dn_3: 0.5316 (0.5276)  loss_vfl_dn_4: 0.5547 (0.5577)  loss_vfl_dn_5: 0.5830 (0.5832)  loss_vfl_enc_0: 0.7700 (0.7780)  time: 0.9945  data: 0.0324  max mem: 10356\r\n",
      "Epoch: [8] Total time: 0:01:23 (1.0632 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 31.2510 (31.6978)  loss_bbox: 0.4004 (0.4708)  loss_bbox_aux_0: 0.4450 (0.5170)  loss_bbox_aux_1: 0.4237 (0.4959)  loss_bbox_aux_2: 0.4270 (0.4817)  loss_bbox_aux_3: 0.4008 (0.4767)  loss_bbox_aux_4: 0.4073 (0.4743)  loss_bbox_dn_0: 0.4268 (0.4625)  loss_bbox_dn_1: 0.4024 (0.4411)  loss_bbox_dn_2: 0.3889 (0.4319)  loss_bbox_dn_3: 0.3799 (0.4266)  loss_bbox_dn_4: 0.3732 (0.4240)  loss_bbox_dn_5: 0.3729 (0.4240)  loss_bbox_enc_0: 0.5232 (0.5625)  loss_giou: 1.1966 (1.2748)  loss_giou_aux_0: 1.2511 (1.3411)  loss_giou_aux_1: 1.2114 (1.3138)  loss_giou_aux_2: 1.2029 (1.2969)  loss_giou_aux_3: 1.2166 (1.2890)  loss_giou_aux_4: 1.2039 (1.2804)  loss_giou_dn_0: 1.2236 (1.2380)  loss_giou_dn_1: 1.1700 (1.1821)  loss_giou_dn_2: 1.1522 (1.1593)  loss_giou_dn_3: 1.1433 (1.1464)  loss_giou_dn_4: 1.1338 (1.1397)  loss_giou_dn_5: 1.1342 (1.1401)  loss_giou_enc_0: 1.3606 (1.4187)  loss_vfl: 0.9438 (0.9618)  loss_vfl_aux_0: 0.8428 (0.8495)  loss_vfl_aux_1: 0.9075 (0.8920)  loss_vfl_aux_2: 0.9219 (0.9201)  loss_vfl_aux_3: 0.9387 (0.9412)  loss_vfl_aux_4: 0.9202 (0.9510)  loss_vfl_dn_0: 0.4524 (0.4480)  loss_vfl_dn_1: 0.4757 (0.4776)  loss_vfl_dn_2: 0.5048 (0.5009)  loss_vfl_dn_3: 0.5316 (0.5276)  loss_vfl_dn_4: 0.5547 (0.5577)  loss_vfl_dn_5: 0.5830 (0.5832)  loss_vfl_enc_0: 0.7700 (0.7780)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.1717  data: 1.2593  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0582  data: 0.2130  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0760 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.011\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.014\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.018\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.073\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.107\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.111\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.024\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.209\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.130\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.188\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.117\r\n",
      "best_stat: {'epoch': 7, 'coco_eval_bbox': 0.00874203691379466}\r\n",
      "Epoch: [9]  [ 0/79]  eta: 0:06:46  lr: 0.000010  loss: 33.2965 (33.2965)  loss_bbox: 0.6286 (0.6286)  loss_bbox_aux_0: 0.6617 (0.6617)  loss_bbox_aux_1: 0.6150 (0.6150)  loss_bbox_aux_2: 0.5889 (0.5889)  loss_bbox_aux_3: 0.5836 (0.5836)  loss_bbox_aux_4: 0.6158 (0.6158)  loss_bbox_dn_0: 0.4039 (0.4039)  loss_bbox_dn_1: 0.3845 (0.3845)  loss_bbox_dn_2: 0.3756 (0.3756)  loss_bbox_dn_3: 0.3726 (0.3726)  loss_bbox_dn_4: 0.3726 (0.3726)  loss_bbox_dn_5: 0.3727 (0.3727)  loss_bbox_enc_0: 0.6399 (0.6399)  loss_giou: 1.5656 (1.5656)  loss_giou_aux_0: 1.6896 (1.6896)  loss_giou_aux_1: 1.6947 (1.6947)  loss_giou_aux_2: 1.6593 (1.6593)  loss_giou_aux_3: 1.6369 (1.6369)  loss_giou_aux_4: 1.5718 (1.5718)  loss_giou_dn_0: 1.2767 (1.2767)  loss_giou_dn_1: 1.2367 (1.2367)  loss_giou_dn_2: 1.2127 (1.2127)  loss_giou_dn_3: 1.2152 (1.2152)  loss_giou_dn_4: 1.2120 (1.2120)  loss_giou_dn_5: 1.2150 (1.2150)  loss_giou_enc_0: 1.6784 (1.6784)  loss_vfl: 0.7837 (0.7837)  loss_vfl_aux_0: 0.6606 (0.6606)  loss_vfl_aux_1: 0.6980 (0.6980)  loss_vfl_aux_2: 0.7212 (0.7212)  loss_vfl_aux_3: 0.7654 (0.7654)  loss_vfl_aux_4: 0.7810 (0.7810)  loss_vfl_dn_0: 0.4174 (0.4174)  loss_vfl_dn_1: 0.4451 (0.4451)  loss_vfl_dn_2: 0.4561 (0.4561)  loss_vfl_dn_3: 0.4705 (0.4705)  loss_vfl_dn_4: 0.4908 (0.4908)  loss_vfl_dn_5: 0.5057 (0.5057)  loss_vfl_enc_0: 0.6211 (0.6211)  time: 5.1517  data: 2.5378  max mem: 10356\r\n",
      "Epoch: [9]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 31.0757 (31.4431)  loss_bbox: 0.4132 (0.4566)  loss_bbox_aux_0: 0.4617 (0.4991)  loss_bbox_aux_1: 0.4512 (0.4842)  loss_bbox_aux_2: 0.4392 (0.4720)  loss_bbox_aux_3: 0.4194 (0.4658)  loss_bbox_aux_4: 0.4174 (0.4617)  loss_bbox_dn_0: 0.4435 (0.4521)  loss_bbox_dn_1: 0.4443 (0.4320)  loss_bbox_dn_2: 0.4353 (0.4239)  loss_bbox_dn_3: 0.4223 (0.4191)  loss_bbox_dn_4: 0.4157 (0.4171)  loss_bbox_dn_5: 0.4152 (0.4171)  loss_bbox_enc_0: 0.4735 (0.5391)  loss_giou: 1.2349 (1.2774)  loss_giou_aux_0: 1.3469 (1.3355)  loss_giou_aux_1: 1.2785 (1.3126)  loss_giou_aux_2: 1.2768 (1.2932)  loss_giou_aux_3: 1.2793 (1.2859)  loss_giou_aux_4: 1.2515 (1.2786)  loss_giou_dn_0: 1.2149 (1.2287)  loss_giou_dn_1: 1.1597 (1.1713)  loss_giou_dn_2: 1.1247 (1.1488)  loss_giou_dn_3: 1.1065 (1.1368)  loss_giou_dn_4: 1.0919 (1.1295)  loss_giou_dn_5: 1.0925 (1.1298)  loss_giou_enc_0: 1.3992 (1.4080)  loss_vfl: 0.9729 (0.9486)  loss_vfl_aux_0: 0.8240 (0.8572)  loss_vfl_aux_1: 0.9182 (0.8948)  loss_vfl_aux_2: 0.9939 (0.9238)  loss_vfl_aux_3: 0.9417 (0.9342)  loss_vfl_aux_4: 0.9563 (0.9429)  loss_vfl_dn_0: 0.4537 (0.4522)  loss_vfl_dn_1: 0.4744 (0.4819)  loss_vfl_dn_2: 0.4932 (0.5009)  loss_vfl_dn_3: 0.5063 (0.5223)  loss_vfl_dn_4: 0.5284 (0.5502)  loss_vfl_dn_5: 0.5571 (0.5715)  loss_vfl_enc_0: 0.7788 (0.7867)  time: 1.0390  data: 0.0311  max mem: 10356\r\n",
      "Epoch: [9] Total time: 0:01:26 (1.0893 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 31.0757 (31.4431)  loss_bbox: 0.4132 (0.4566)  loss_bbox_aux_0: 0.4617 (0.4991)  loss_bbox_aux_1: 0.4512 (0.4842)  loss_bbox_aux_2: 0.4392 (0.4720)  loss_bbox_aux_3: 0.4194 (0.4658)  loss_bbox_aux_4: 0.4174 (0.4617)  loss_bbox_dn_0: 0.4435 (0.4521)  loss_bbox_dn_1: 0.4443 (0.4320)  loss_bbox_dn_2: 0.4353 (0.4239)  loss_bbox_dn_3: 0.4223 (0.4191)  loss_bbox_dn_4: 0.4157 (0.4171)  loss_bbox_dn_5: 0.4152 (0.4171)  loss_bbox_enc_0: 0.4735 (0.5391)  loss_giou: 1.2349 (1.2774)  loss_giou_aux_0: 1.3469 (1.3355)  loss_giou_aux_1: 1.2785 (1.3126)  loss_giou_aux_2: 1.2768 (1.2932)  loss_giou_aux_3: 1.2793 (1.2859)  loss_giou_aux_4: 1.2515 (1.2786)  loss_giou_dn_0: 1.2149 (1.2287)  loss_giou_dn_1: 1.1597 (1.1713)  loss_giou_dn_2: 1.1247 (1.1488)  loss_giou_dn_3: 1.1065 (1.1368)  loss_giou_dn_4: 1.0919 (1.1295)  loss_giou_dn_5: 1.0925 (1.1298)  loss_giou_enc_0: 1.3992 (1.4080)  loss_vfl: 0.9729 (0.9486)  loss_vfl_aux_0: 0.8240 (0.8572)  loss_vfl_aux_1: 0.9182 (0.8948)  loss_vfl_aux_2: 0.9939 (0.9238)  loss_vfl_aux_3: 0.9417 (0.9342)  loss_vfl_aux_4: 0.9563 (0.9429)  loss_vfl_dn_0: 0.4537 (0.4522)  loss_vfl_dn_1: 0.4744 (0.4819)  loss_vfl_dn_2: 0.4932 (0.5009)  loss_vfl_dn_3: 0.5063 (0.5223)  loss_vfl_dn_4: 0.5284 (0.5502)  loss_vfl_dn_5: 0.5571 (0.5715)  loss_vfl_enc_0: 0.7788 (0.7867)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3314  data: 1.3977  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0886  data: 0.2305  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1055 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.31s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.014\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.020\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.016\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.033\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.016\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.097\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.154\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.161\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.053\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.226\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.208\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.253\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.164\r\n",
      "best_stat: {'epoch': 9, 'coco_eval_bbox': 0.013764974978446747}\r\n",
      "Epoch: [10]  [ 0/79]  eta: 0:04:10  lr: 0.000010  loss: 29.9197 (29.9197)  loss_bbox: 0.3814 (0.3814)  loss_bbox_aux_0: 0.4123 (0.4123)  loss_bbox_aux_1: 0.4199 (0.4199)  loss_bbox_aux_2: 0.3836 (0.3836)  loss_bbox_aux_3: 0.3942 (0.3942)  loss_bbox_aux_4: 0.3857 (0.3857)  loss_bbox_dn_0: 0.2707 (0.2707)  loss_bbox_dn_1: 0.2688 (0.2688)  loss_bbox_dn_2: 0.2704 (0.2704)  loss_bbox_dn_3: 0.2718 (0.2718)  loss_bbox_dn_4: 0.2802 (0.2802)  loss_bbox_dn_5: 0.2808 (0.2808)  loss_bbox_enc_0: 0.4414 (0.4414)  loss_giou: 1.2229 (1.2229)  loss_giou_aux_0: 1.2811 (1.2811)  loss_giou_aux_1: 1.2406 (1.2406)  loss_giou_aux_2: 1.2308 (1.2308)  loss_giou_aux_3: 1.2282 (1.2282)  loss_giou_aux_4: 1.2313 (1.2313)  loss_giou_dn_0: 1.1857 (1.1857)  loss_giou_dn_1: 1.1128 (1.1128)  loss_giou_dn_2: 1.0919 (1.0919)  loss_giou_dn_3: 1.0853 (1.0853)  loss_giou_dn_4: 1.1057 (1.1057)  loss_giou_dn_5: 1.1078 (1.1078)  loss_giou_enc_0: 1.4003 (1.4003)  loss_vfl: 1.0347 (1.0347)  loss_vfl_aux_0: 0.9534 (0.9534)  loss_vfl_aux_1: 0.9683 (0.9683)  loss_vfl_aux_2: 0.9658 (0.9658)  loss_vfl_aux_3: 1.0181 (1.0181)  loss_vfl_aux_4: 1.0361 (1.0361)  loss_vfl_dn_0: 0.4650 (0.4650)  loss_vfl_dn_1: 0.5128 (0.5128)  loss_vfl_dn_2: 0.5168 (0.5168)  loss_vfl_dn_3: 0.5527 (0.5527)  loss_vfl_dn_4: 0.5734 (0.5734)  loss_vfl_dn_5: 0.5974 (0.5974)  loss_vfl_enc_0: 0.7397 (0.7397)  time: 3.1661  data: 1.9443  max mem: 10356\r\n",
      "Epoch: [10]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 31.4968 (31.3374)  loss_bbox: 0.4567 (0.4370)  loss_bbox_aux_0: 0.5175 (0.4847)  loss_bbox_aux_1: 0.4860 (0.4655)  loss_bbox_aux_2: 0.4698 (0.4493)  loss_bbox_aux_3: 0.4638 (0.4442)  loss_bbox_aux_4: 0.4671 (0.4417)  loss_bbox_dn_0: 0.4402 (0.4529)  loss_bbox_dn_1: 0.4254 (0.4295)  loss_bbox_dn_2: 0.4207 (0.4201)  loss_bbox_dn_3: 0.4178 (0.4147)  loss_bbox_dn_4: 0.4164 (0.4123)  loss_bbox_dn_5: 0.4164 (0.4121)  loss_bbox_enc_0: 0.5524 (0.5321)  loss_giou: 1.1971 (1.2371)  loss_giou_aux_0: 1.2678 (1.3025)  loss_giou_aux_1: 1.2018 (1.2726)  loss_giou_aux_2: 1.1917 (1.2580)  loss_giou_aux_3: 1.1859 (1.2500)  loss_giou_aux_4: 1.1915 (1.2403)  loss_giou_dn_0: 1.2083 (1.2134)  loss_giou_dn_1: 1.1466 (1.1509)  loss_giou_dn_2: 1.1245 (1.1275)  loss_giou_dn_3: 1.1158 (1.1157)  loss_giou_dn_4: 1.1159 (1.1092)  loss_giou_dn_5: 1.1145 (1.1097)  loss_giou_enc_0: 1.3431 (1.3887)  loss_vfl: 0.9663 (1.0134)  loss_vfl_aux_0: 0.9097 (0.8925)  loss_vfl_aux_1: 0.9680 (0.9458)  loss_vfl_aux_2: 0.9526 (0.9744)  loss_vfl_aux_3: 0.9431 (0.9916)  loss_vfl_aux_4: 0.9539 (1.0075)  loss_vfl_dn_0: 0.4725 (0.4603)  loss_vfl_dn_1: 0.4905 (0.4897)  loss_vfl_dn_2: 0.5045 (0.5087)  loss_vfl_dn_3: 0.5188 (0.5304)  loss_vfl_dn_4: 0.5503 (0.5604)  loss_vfl_dn_5: 0.5693 (0.5825)  loss_vfl_enc_0: 0.7874 (0.8083)  time: 0.9637  data: 0.0327  max mem: 10356\r\n",
      "Epoch: [10] Total time: 0:01:24 (1.0635 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 31.4968 (31.3374)  loss_bbox: 0.4567 (0.4370)  loss_bbox_aux_0: 0.5175 (0.4847)  loss_bbox_aux_1: 0.4860 (0.4655)  loss_bbox_aux_2: 0.4698 (0.4493)  loss_bbox_aux_3: 0.4638 (0.4442)  loss_bbox_aux_4: 0.4671 (0.4417)  loss_bbox_dn_0: 0.4402 (0.4529)  loss_bbox_dn_1: 0.4254 (0.4295)  loss_bbox_dn_2: 0.4207 (0.4201)  loss_bbox_dn_3: 0.4178 (0.4147)  loss_bbox_dn_4: 0.4164 (0.4123)  loss_bbox_dn_5: 0.4164 (0.4121)  loss_bbox_enc_0: 0.5524 (0.5321)  loss_giou: 1.1971 (1.2371)  loss_giou_aux_0: 1.2678 (1.3025)  loss_giou_aux_1: 1.2018 (1.2726)  loss_giou_aux_2: 1.1917 (1.2580)  loss_giou_aux_3: 1.1859 (1.2500)  loss_giou_aux_4: 1.1915 (1.2403)  loss_giou_dn_0: 1.2083 (1.2134)  loss_giou_dn_1: 1.1466 (1.1509)  loss_giou_dn_2: 1.1245 (1.1275)  loss_giou_dn_3: 1.1158 (1.1157)  loss_giou_dn_4: 1.1159 (1.1092)  loss_giou_dn_5: 1.1145 (1.1097)  loss_giou_enc_0: 1.3431 (1.3887)  loss_vfl: 0.9663 (1.0134)  loss_vfl_aux_0: 0.9097 (0.8925)  loss_vfl_aux_1: 0.9680 (0.9458)  loss_vfl_aux_2: 0.9526 (0.9744)  loss_vfl_aux_3: 0.9431 (0.9916)  loss_vfl_aux_4: 0.9539 (1.0075)  loss_vfl_dn_0: 0.4725 (0.4603)  loss_vfl_dn_1: 0.4905 (0.4897)  loss_vfl_dn_2: 0.5045 (0.5087)  loss_vfl_dn_3: 0.5188 (0.5304)  loss_vfl_dn_4: 0.5503 (0.5604)  loss_vfl_dn_5: 0.5693 (0.5825)  loss_vfl_enc_0: 0.7874 (0.8083)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.4468  data: 1.5087  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0911  data: 0.2324  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1077 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.013\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.019\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.025\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.095\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.135\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.144\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.039\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.241\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.190\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.228\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.146\r\n",
      "best_stat: {'epoch': 9, 'coco_eval_bbox': 0.013764974978446747}\r\n",
      "Epoch: [11]  [ 0/79]  eta: 0:06:40  lr: 0.000010  loss: 33.0769 (33.0769)  loss_bbox: 0.5831 (0.5831)  loss_bbox_aux_0: 0.6587 (0.6587)  loss_bbox_aux_1: 0.6101 (0.6101)  loss_bbox_aux_2: 0.6007 (0.6007)  loss_bbox_aux_3: 0.5912 (0.5912)  loss_bbox_aux_4: 0.6019 (0.6019)  loss_bbox_dn_0: 0.4636 (0.4636)  loss_bbox_dn_1: 0.4457 (0.4457)  loss_bbox_dn_2: 0.4400 (0.4400)  loss_bbox_dn_3: 0.4385 (0.4385)  loss_bbox_dn_4: 0.4398 (0.4398)  loss_bbox_dn_5: 0.4404 (0.4404)  loss_bbox_enc_0: 0.6525 (0.6525)  loss_giou: 1.5923 (1.5923)  loss_giou_aux_0: 1.5585 (1.5585)  loss_giou_aux_1: 1.6075 (1.6075)  loss_giou_aux_2: 1.6010 (1.6010)  loss_giou_aux_3: 1.5976 (1.5976)  loss_giou_aux_4: 1.5911 (1.5911)  loss_giou_dn_0: 1.2484 (1.2484)  loss_giou_dn_1: 1.1980 (1.1980)  loss_giou_dn_2: 1.1823 (1.1823)  loss_giou_dn_3: 1.1741 (1.1741)  loss_giou_dn_4: 1.1695 (1.1695)  loss_giou_dn_5: 1.1699 (1.1699)  loss_giou_enc_0: 1.5792 (1.5792)  loss_vfl: 0.7759 (0.7759)  loss_vfl_aux_0: 0.6450 (0.6450)  loss_vfl_aux_1: 0.6843 (0.6843)  loss_vfl_aux_2: 0.7390 (0.7390)  loss_vfl_aux_3: 0.7671 (0.7671)  loss_vfl_aux_4: 0.7883 (0.7883)  loss_vfl_dn_0: 0.4205 (0.4205)  loss_vfl_dn_1: 0.4423 (0.4423)  loss_vfl_dn_2: 0.4594 (0.4594)  loss_vfl_dn_3: 0.4635 (0.4635)  loss_vfl_dn_4: 0.4792 (0.4792)  loss_vfl_dn_5: 0.4825 (0.4825)  loss_vfl_enc_0: 0.6943 (0.6943)  time: 5.0741  data: 3.3362  max mem: 10356\r\n",
      "Epoch: [11]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 30.8461 (31.2076)  loss_bbox: 0.3925 (0.4344)  loss_bbox_aux_0: 0.4242 (0.4767)  loss_bbox_aux_1: 0.4255 (0.4588)  loss_bbox_aux_2: 0.4047 (0.4494)  loss_bbox_aux_3: 0.4019 (0.4424)  loss_bbox_aux_4: 0.3881 (0.4375)  loss_bbox_dn_0: 0.4192 (0.4403)  loss_bbox_dn_1: 0.4106 (0.4161)  loss_bbox_dn_2: 0.3961 (0.4065)  loss_bbox_dn_3: 0.3916 (0.4017)  loss_bbox_dn_4: 0.3871 (0.3994)  loss_bbox_dn_5: 0.3871 (0.3992)  loss_bbox_enc_0: 0.4573 (0.5181)  loss_giou: 1.1895 (1.2414)  loss_giou_aux_0: 1.2415 (1.2926)  loss_giou_aux_1: 1.2242 (1.2763)  loss_giou_aux_2: 1.2230 (1.2611)  loss_giou_aux_3: 1.2276 (1.2501)  loss_giou_aux_4: 1.2156 (1.2454)  loss_giou_dn_0: 1.2166 (1.2023)  loss_giou_dn_1: 1.1480 (1.1362)  loss_giou_dn_2: 1.1206 (1.1110)  loss_giou_dn_3: 1.1200 (1.0996)  loss_giou_dn_4: 1.1101 (1.0925)  loss_giou_dn_5: 1.1118 (1.0932)  loss_giou_enc_0: 1.3289 (1.3670)  loss_vfl: 0.9661 (1.0043)  loss_vfl_aux_0: 0.9043 (0.9369)  loss_vfl_aux_1: 0.9248 (0.9579)  loss_vfl_aux_2: 0.9634 (0.9789)  loss_vfl_aux_3: 0.9333 (0.9919)  loss_vfl_aux_4: 0.9565 (1.0030)  loss_vfl_dn_0: 0.4609 (0.4664)  loss_vfl_dn_1: 0.4912 (0.4943)  loss_vfl_dn_2: 0.5104 (0.5116)  loss_vfl_dn_3: 0.5183 (0.5276)  loss_vfl_dn_4: 0.5460 (0.5538)  loss_vfl_dn_5: 0.5698 (0.5707)  loss_vfl_enc_0: 0.8069 (0.8609)  time: 1.0318  data: 0.0317  max mem: 10356\r\n",
      "Epoch: [11] Total time: 0:01:27 (1.1021 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 30.8461 (31.2076)  loss_bbox: 0.3925 (0.4344)  loss_bbox_aux_0: 0.4242 (0.4767)  loss_bbox_aux_1: 0.4255 (0.4588)  loss_bbox_aux_2: 0.4047 (0.4494)  loss_bbox_aux_3: 0.4019 (0.4424)  loss_bbox_aux_4: 0.3881 (0.4375)  loss_bbox_dn_0: 0.4192 (0.4403)  loss_bbox_dn_1: 0.4106 (0.4161)  loss_bbox_dn_2: 0.3961 (0.4065)  loss_bbox_dn_3: 0.3916 (0.4017)  loss_bbox_dn_4: 0.3871 (0.3994)  loss_bbox_dn_5: 0.3871 (0.3992)  loss_bbox_enc_0: 0.4573 (0.5181)  loss_giou: 1.1895 (1.2414)  loss_giou_aux_0: 1.2415 (1.2926)  loss_giou_aux_1: 1.2242 (1.2763)  loss_giou_aux_2: 1.2230 (1.2611)  loss_giou_aux_3: 1.2276 (1.2501)  loss_giou_aux_4: 1.2156 (1.2454)  loss_giou_dn_0: 1.2166 (1.2023)  loss_giou_dn_1: 1.1480 (1.1362)  loss_giou_dn_2: 1.1206 (1.1110)  loss_giou_dn_3: 1.1200 (1.0996)  loss_giou_dn_4: 1.1101 (1.0925)  loss_giou_dn_5: 1.1118 (1.0932)  loss_giou_enc_0: 1.3289 (1.3670)  loss_vfl: 0.9661 (1.0043)  loss_vfl_aux_0: 0.9043 (0.9369)  loss_vfl_aux_1: 0.9248 (0.9579)  loss_vfl_aux_2: 0.9634 (0.9789)  loss_vfl_aux_3: 0.9333 (0.9919)  loss_vfl_aux_4: 0.9565 (1.0030)  loss_vfl_dn_0: 0.4609 (0.4664)  loss_vfl_dn_1: 0.4912 (0.4943)  loss_vfl_dn_2: 0.5104 (0.5116)  loss_vfl_dn_3: 0.5183 (0.5276)  loss_vfl_dn_4: 0.5460 (0.5538)  loss_vfl_dn_5: 0.5698 (0.5707)  loss_vfl_enc_0: 0.8069 (0.8609)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.4508  data: 1.5094  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0821  data: 0.2303  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0983 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.28s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.024\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.031\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.027\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.057\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.028\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.105\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.132\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.138\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.038\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.228\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.179\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.208\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.146\r\n",
      "best_stat: {'epoch': 11, 'coco_eval_bbox': 0.02448199311538112}\r\n",
      "Epoch: [12]  [ 0/79]  eta: 0:04:43  lr: 0.000010  loss: 33.6798 (33.6798)  loss_bbox: 0.5349 (0.5349)  loss_bbox_aux_0: 0.6377 (0.6377)  loss_bbox_aux_1: 0.6108 (0.6108)  loss_bbox_aux_2: 0.6139 (0.6139)  loss_bbox_aux_3: 0.5297 (0.5297)  loss_bbox_aux_4: 0.5446 (0.5446)  loss_bbox_dn_0: 0.5698 (0.5698)  loss_bbox_dn_1: 0.5452 (0.5452)  loss_bbox_dn_2: 0.5387 (0.5387)  loss_bbox_dn_3: 0.5336 (0.5336)  loss_bbox_dn_4: 0.5308 (0.5308)  loss_bbox_dn_5: 0.5308 (0.5308)  loss_bbox_enc_0: 0.6350 (0.6350)  loss_giou: 1.0832 (1.0832)  loss_giou_aux_0: 1.2530 (1.2530)  loss_giou_aux_1: 1.2128 (1.2128)  loss_giou_aux_2: 1.1155 (1.1155)  loss_giou_aux_3: 1.1037 (1.1037)  loss_giou_aux_4: 1.1016 (1.1016)  loss_giou_dn_0: 1.1870 (1.1870)  loss_giou_dn_1: 1.1227 (1.1227)  loss_giou_dn_2: 1.0927 (1.0927)  loss_giou_dn_3: 1.0821 (1.0821)  loss_giou_dn_4: 1.0758 (1.0758)  loss_giou_dn_5: 1.0762 (1.0762)  loss_giou_enc_0: 1.2858 (1.2858)  loss_vfl: 1.3481 (1.3481)  loss_vfl_aux_0: 1.0627 (1.0627)  loss_vfl_aux_1: 1.1191 (1.1191)  loss_vfl_aux_2: 1.2153 (1.2153)  loss_vfl_aux_3: 1.2671 (1.2671)  loss_vfl_aux_4: 1.2427 (1.2427)  loss_vfl_dn_0: 0.4635 (0.4635)  loss_vfl_dn_1: 0.5022 (0.5022)  loss_vfl_dn_2: 0.5361 (0.5361)  loss_vfl_dn_3: 0.5613 (0.5613)  loss_vfl_dn_4: 0.5825 (0.5825)  loss_vfl_dn_5: 0.6172 (0.6172)  loss_vfl_enc_0: 1.0142 (1.0142)  time: 3.5874  data: 2.3207  max mem: 10356\r\n",
      "Epoch: [12]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 30.3109 (30.6410)  loss_bbox: 0.3947 (0.3992)  loss_bbox_aux_0: 0.4346 (0.4382)  loss_bbox_aux_1: 0.4331 (0.4193)  loss_bbox_aux_2: 0.4172 (0.4118)  loss_bbox_aux_3: 0.4139 (0.4057)  loss_bbox_aux_4: 0.3967 (0.4010)  loss_bbox_dn_0: 0.3950 (0.4253)  loss_bbox_dn_1: 0.3826 (0.3993)  loss_bbox_dn_2: 0.3754 (0.3898)  loss_bbox_dn_3: 0.3694 (0.3849)  loss_bbox_dn_4: 0.3659 (0.3828)  loss_bbox_dn_5: 0.3664 (0.3828)  loss_bbox_enc_0: 0.4789 (0.4853)  loss_giou: 1.0730 (1.1946)  loss_giou_aux_0: 1.1418 (1.2519)  loss_giou_aux_1: 1.1319 (1.2327)  loss_giou_aux_2: 1.0903 (1.2146)  loss_giou_aux_3: 1.0794 (1.2050)  loss_giou_aux_4: 1.0766 (1.1997)  loss_giou_dn_0: 1.1663 (1.1841)  loss_giou_dn_1: 1.0884 (1.1146)  loss_giou_dn_2: 1.0664 (1.0901)  loss_giou_dn_3: 1.0558 (1.0791)  loss_giou_dn_4: 1.0476 (1.0728)  loss_giou_dn_5: 1.0488 (1.0736)  loss_giou_enc_0: 1.2494 (1.3339)  loss_vfl: 1.0679 (1.0321)  loss_vfl_aux_0: 1.0042 (0.9610)  loss_vfl_aux_1: 1.0552 (0.9901)  loss_vfl_aux_2: 1.0496 (1.0051)  loss_vfl_aux_3: 1.1030 (1.0254)  loss_vfl_aux_4: 1.0977 (1.0319)  loss_vfl_dn_0: 0.4794 (0.4724)  loss_vfl_dn_1: 0.5092 (0.4996)  loss_vfl_dn_2: 0.5186 (0.5147)  loss_vfl_dn_3: 0.5382 (0.5326)  loss_vfl_dn_4: 0.5651 (0.5528)  loss_vfl_dn_5: 0.5842 (0.5693)  loss_vfl_enc_0: 0.9978 (0.8819)  time: 1.0291  data: 0.0315  max mem: 10356\r\n",
      "Epoch: [12] Total time: 0:01:24 (1.0728 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 30.3109 (30.6410)  loss_bbox: 0.3947 (0.3992)  loss_bbox_aux_0: 0.4346 (0.4382)  loss_bbox_aux_1: 0.4331 (0.4193)  loss_bbox_aux_2: 0.4172 (0.4118)  loss_bbox_aux_3: 0.4139 (0.4057)  loss_bbox_aux_4: 0.3967 (0.4010)  loss_bbox_dn_0: 0.3950 (0.4253)  loss_bbox_dn_1: 0.3826 (0.3993)  loss_bbox_dn_2: 0.3754 (0.3898)  loss_bbox_dn_3: 0.3694 (0.3849)  loss_bbox_dn_4: 0.3659 (0.3828)  loss_bbox_dn_5: 0.3664 (0.3828)  loss_bbox_enc_0: 0.4789 (0.4853)  loss_giou: 1.0730 (1.1946)  loss_giou_aux_0: 1.1418 (1.2519)  loss_giou_aux_1: 1.1319 (1.2327)  loss_giou_aux_2: 1.0903 (1.2146)  loss_giou_aux_3: 1.0794 (1.2050)  loss_giou_aux_4: 1.0766 (1.1997)  loss_giou_dn_0: 1.1663 (1.1841)  loss_giou_dn_1: 1.0884 (1.1146)  loss_giou_dn_2: 1.0664 (1.0901)  loss_giou_dn_3: 1.0558 (1.0791)  loss_giou_dn_4: 1.0476 (1.0728)  loss_giou_dn_5: 1.0488 (1.0736)  loss_giou_enc_0: 1.2494 (1.3339)  loss_vfl: 1.0679 (1.0321)  loss_vfl_aux_0: 1.0042 (0.9610)  loss_vfl_aux_1: 1.0552 (0.9901)  loss_vfl_aux_2: 1.0496 (1.0051)  loss_vfl_aux_3: 1.1030 (1.0254)  loss_vfl_aux_4: 1.0977 (1.0319)  loss_vfl_dn_0: 0.4794 (0.4724)  loss_vfl_dn_1: 0.5092 (0.4996)  loss_vfl_dn_2: 0.5186 (0.5147)  loss_vfl_dn_3: 0.5382 (0.5326)  loss_vfl_dn_4: 0.5651 (0.5528)  loss_vfl_dn_5: 0.5842 (0.5693)  loss_vfl_enc_0: 0.9978 (0.8819)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.4197  data: 1.4684  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0930  data: 0.2339  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1112 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.011\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.017\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.012\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.030\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.027\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.105\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.144\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.150\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.059\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.243\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.181\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.235\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.158\r\n",
      "best_stat: {'epoch': 11, 'coco_eval_bbox': 0.02448199311538112}\r\n",
      "Epoch: [13]  [ 0/79]  eta: 0:06:34  lr: 0.000010  loss: 28.3912 (28.3912)  loss_bbox: 0.2492 (0.2492)  loss_bbox_aux_0: 0.2723 (0.2723)  loss_bbox_aux_1: 0.2618 (0.2618)  loss_bbox_aux_2: 0.2585 (0.2585)  loss_bbox_aux_3: 0.2579 (0.2579)  loss_bbox_aux_4: 0.2456 (0.2456)  loss_bbox_dn_0: 0.3208 (0.3208)  loss_bbox_dn_1: 0.2871 (0.2871)  loss_bbox_dn_2: 0.2748 (0.2748)  loss_bbox_dn_3: 0.2675 (0.2675)  loss_bbox_dn_4: 0.2602 (0.2602)  loss_bbox_dn_5: 0.2596 (0.2596)  loss_bbox_enc_0: 0.3406 (0.3406)  loss_giou: 1.2041 (1.2041)  loss_giou_aux_0: 1.2613 (1.2613)  loss_giou_aux_1: 1.2366 (1.2366)  loss_giou_aux_2: 1.2141 (1.2141)  loss_giou_aux_3: 1.2119 (1.2119)  loss_giou_aux_4: 1.2003 (1.2003)  loss_giou_dn_0: 1.1513 (1.1513)  loss_giou_dn_1: 1.0583 (1.0583)  loss_giou_dn_2: 1.0301 (1.0301)  loss_giou_dn_3: 1.0211 (1.0211)  loss_giou_dn_4: 1.0111 (1.0111)  loss_giou_dn_5: 1.0112 (1.0112)  loss_giou_enc_0: 1.3711 (1.3711)  loss_vfl: 1.0298 (1.0298)  loss_vfl_aux_0: 0.8694 (0.8694)  loss_vfl_aux_1: 0.9458 (0.9458)  loss_vfl_aux_2: 0.9919 (0.9919)  loss_vfl_aux_3: 1.0059 (1.0059)  loss_vfl_aux_4: 1.0525 (1.0525)  loss_vfl_dn_0: 0.4669 (0.4669)  loss_vfl_dn_1: 0.5078 (0.5078)  loss_vfl_dn_2: 0.5277 (0.5277)  loss_vfl_dn_3: 0.5431 (0.5431)  loss_vfl_dn_4: 0.5782 (0.5782)  loss_vfl_dn_5: 0.5944 (0.5944)  loss_vfl_enc_0: 0.7395 (0.7395)  time: 4.9928  data: 2.6769  max mem: 10356\r\n",
      "Epoch: [13]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 30.0402 (30.4809)  loss_bbox: 0.3602 (0.3895)  loss_bbox_aux_0: 0.4076 (0.4294)  loss_bbox_aux_1: 0.3728 (0.4123)  loss_bbox_aux_2: 0.3824 (0.4006)  loss_bbox_aux_3: 0.3623 (0.3941)  loss_bbox_aux_4: 0.3610 (0.3910)  loss_bbox_dn_0: 0.4577 (0.4289)  loss_bbox_dn_1: 0.4328 (0.4013)  loss_bbox_dn_2: 0.4233 (0.3900)  loss_bbox_dn_3: 0.4162 (0.3844)  loss_bbox_dn_4: 0.4157 (0.3821)  loss_bbox_dn_5: 0.4156 (0.3821)  loss_bbox_enc_0: 0.4652 (0.4708)  loss_giou: 1.1970 (1.2023)  loss_giou_aux_0: 1.2760 (1.2608)  loss_giou_aux_1: 1.2459 (1.2396)  loss_giou_aux_2: 1.2160 (1.2209)  loss_giou_aux_3: 1.1926 (1.2125)  loss_giou_aux_4: 1.1915 (1.2055)  loss_giou_dn_0: 1.1708 (1.1726)  loss_giou_dn_1: 1.1070 (1.1031)  loss_giou_dn_2: 1.0783 (1.0750)  loss_giou_dn_3: 1.0710 (1.0640)  loss_giou_dn_4: 1.0639 (1.0567)  loss_giou_dn_5: 1.0625 (1.0570)  loss_giou_enc_0: 1.3413 (1.3394)  loss_vfl: 1.0168 (1.0317)  loss_vfl_aux_0: 0.8870 (0.9446)  loss_vfl_aux_1: 0.9463 (0.9739)  loss_vfl_aux_2: 0.9854 (1.0001)  loss_vfl_aux_3: 0.9907 (1.0161)  loss_vfl_aux_4: 0.9995 (1.0249)  loss_vfl_dn_0: 0.4727 (0.4757)  loss_vfl_dn_1: 0.4884 (0.4991)  loss_vfl_dn_2: 0.5043 (0.5155)  loss_vfl_dn_3: 0.5233 (0.5336)  loss_vfl_dn_4: 0.5369 (0.5562)  loss_vfl_dn_5: 0.5392 (0.5691)  loss_vfl_enc_0: 0.8704 (0.8747)  time: 1.0162  data: 0.0324  max mem: 10356\r\n",
      "Epoch: [13] Total time: 0:01:25 (1.0792 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 30.0402 (30.4809)  loss_bbox: 0.3602 (0.3895)  loss_bbox_aux_0: 0.4076 (0.4294)  loss_bbox_aux_1: 0.3728 (0.4123)  loss_bbox_aux_2: 0.3824 (0.4006)  loss_bbox_aux_3: 0.3623 (0.3941)  loss_bbox_aux_4: 0.3610 (0.3910)  loss_bbox_dn_0: 0.4577 (0.4289)  loss_bbox_dn_1: 0.4328 (0.4013)  loss_bbox_dn_2: 0.4233 (0.3900)  loss_bbox_dn_3: 0.4162 (0.3844)  loss_bbox_dn_4: 0.4157 (0.3821)  loss_bbox_dn_5: 0.4156 (0.3821)  loss_bbox_enc_0: 0.4652 (0.4708)  loss_giou: 1.1970 (1.2023)  loss_giou_aux_0: 1.2760 (1.2608)  loss_giou_aux_1: 1.2459 (1.2396)  loss_giou_aux_2: 1.2160 (1.2209)  loss_giou_aux_3: 1.1926 (1.2125)  loss_giou_aux_4: 1.1915 (1.2055)  loss_giou_dn_0: 1.1708 (1.1726)  loss_giou_dn_1: 1.1070 (1.1031)  loss_giou_dn_2: 1.0783 (1.0750)  loss_giou_dn_3: 1.0710 (1.0640)  loss_giou_dn_4: 1.0639 (1.0567)  loss_giou_dn_5: 1.0625 (1.0570)  loss_giou_enc_0: 1.3413 (1.3394)  loss_vfl: 1.0168 (1.0317)  loss_vfl_aux_0: 0.8870 (0.9446)  loss_vfl_aux_1: 0.9463 (0.9739)  loss_vfl_aux_2: 0.9854 (1.0001)  loss_vfl_aux_3: 0.9907 (1.0161)  loss_vfl_aux_4: 0.9995 (1.0249)  loss_vfl_dn_0: 0.4727 (0.4757)  loss_vfl_dn_1: 0.4884 (0.4991)  loss_vfl_dn_2: 0.5043 (0.5155)  loss_vfl_dn_3: 0.5233 (0.5336)  loss_vfl_dn_4: 0.5369 (0.5562)  loss_vfl_dn_5: 0.5392 (0.5691)  loss_vfl_enc_0: 0.8704 (0.8747)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.3823  data: 1.3752  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0968  data: 0.2281  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1145 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.011\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.017\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.013\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.037\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.020\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.097\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.136\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.145\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.037\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.222\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.194\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.239\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.148\r\n",
      "best_stat: {'epoch': 11, 'coco_eval_bbox': 0.02448199311538112}\r\n",
      "Epoch: [14]  [ 0/79]  eta: 0:06:57  lr: 0.000010  loss: 28.6171 (28.6171)  loss_bbox: 0.3629 (0.3629)  loss_bbox_aux_0: 0.3983 (0.3983)  loss_bbox_aux_1: 0.3622 (0.3622)  loss_bbox_aux_2: 0.3636 (0.3636)  loss_bbox_aux_3: 0.3661 (0.3661)  loss_bbox_aux_4: 0.3706 (0.3706)  loss_bbox_dn_0: 0.3354 (0.3354)  loss_bbox_dn_1: 0.3218 (0.3218)  loss_bbox_dn_2: 0.3160 (0.3160)  loss_bbox_dn_3: 0.3173 (0.3173)  loss_bbox_dn_4: 0.3229 (0.3229)  loss_bbox_dn_5: 0.3238 (0.3238)  loss_bbox_enc_0: 0.4173 (0.4173)  loss_giou: 1.3087 (1.3087)  loss_giou_aux_0: 1.3350 (1.3350)  loss_giou_aux_1: 1.3367 (1.3367)  loss_giou_aux_2: 1.3144 (1.3144)  loss_giou_aux_3: 1.3076 (1.3076)  loss_giou_aux_4: 1.3177 (1.3177)  loss_giou_dn_0: 1.1883 (1.1883)  loss_giou_dn_1: 1.1387 (1.1387)  loss_giou_dn_2: 1.1310 (1.1310)  loss_giou_dn_3: 1.1277 (1.1277)  loss_giou_dn_4: 1.1370 (1.1370)  loss_giou_dn_5: 1.1370 (1.1370)  loss_giou_enc_0: 1.3647 (1.3647)  loss_vfl: 0.7651 (0.7651)  loss_vfl_aux_0: 0.6968 (0.6968)  loss_vfl_aux_1: 0.7119 (0.7119)  loss_vfl_aux_2: 0.7307 (0.7307)  loss_vfl_aux_3: 0.7419 (0.7419)  loss_vfl_aux_4: 0.7573 (0.7573)  loss_vfl_dn_0: 0.4581 (0.4581)  loss_vfl_dn_1: 0.4592 (0.4592)  loss_vfl_dn_2: 0.4667 (0.4667)  loss_vfl_dn_3: 0.4673 (0.4673)  loss_vfl_dn_4: 0.4761 (0.4761)  loss_vfl_dn_5: 0.4840 (0.4840)  loss_vfl_enc_0: 0.6792 (0.6792)  time: 5.2811  data: 3.3421  max mem: 10356\r\n",
      "Epoch: [14]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 29.2971 (30.3868)  loss_bbox: 0.3675 (0.3992)  loss_bbox_aux_0: 0.3879 (0.4390)  loss_bbox_aux_1: 0.3762 (0.4197)  loss_bbox_aux_2: 0.3743 (0.4081)  loss_bbox_aux_3: 0.3636 (0.4031)  loss_bbox_aux_4: 0.3618 (0.3997)  loss_bbox_dn_0: 0.3544 (0.4101)  loss_bbox_dn_1: 0.3307 (0.3816)  loss_bbox_dn_2: 0.3175 (0.3705)  loss_bbox_dn_3: 0.3083 (0.3655)  loss_bbox_dn_4: 0.3113 (0.3634)  loss_bbox_dn_5: 0.3113 (0.3635)  loss_bbox_enc_0: 0.4187 (0.4826)  loss_giou: 1.0674 (1.1988)  loss_giou_aux_0: 1.1688 (1.2505)  loss_giou_aux_1: 1.1228 (1.2254)  loss_giou_aux_2: 1.0963 (1.2129)  loss_giou_aux_3: 1.0906 (1.2032)  loss_giou_aux_4: 1.0652 (1.2030)  loss_giou_dn_0: 1.1460 (1.1608)  loss_giou_dn_1: 1.0613 (1.0894)  loss_giou_dn_2: 1.0374 (1.0633)  loss_giou_dn_3: 1.0347 (1.0525)  loss_giou_dn_4: 1.0255 (1.0459)  loss_giou_dn_5: 1.0267 (1.0461)  loss_giou_enc_0: 1.2304 (1.3367)  loss_vfl: 1.0923 (1.0295)  loss_vfl_aux_0: 0.9749 (0.9601)  loss_vfl_aux_1: 1.0376 (1.0001)  loss_vfl_aux_2: 1.0237 (1.0136)  loss_vfl_aux_3: 1.0942 (1.0266)  loss_vfl_aux_4: 1.1025 (1.0302)  loss_vfl_dn_0: 0.4938 (0.4816)  loss_vfl_dn_1: 0.5074 (0.5016)  loss_vfl_dn_2: 0.5271 (0.5158)  loss_vfl_dn_3: 0.5438 (0.5293)  loss_vfl_dn_4: 0.5647 (0.5519)  loss_vfl_dn_5: 0.5825 (0.5623)  loss_vfl_enc_0: 0.9241 (0.8896)  time: 1.0171  data: 0.0322  max mem: 10356\r\n",
      "Epoch: [14] Total time: 0:01:25 (1.0880 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 29.2971 (30.3868)  loss_bbox: 0.3675 (0.3992)  loss_bbox_aux_0: 0.3879 (0.4390)  loss_bbox_aux_1: 0.3762 (0.4197)  loss_bbox_aux_2: 0.3743 (0.4081)  loss_bbox_aux_3: 0.3636 (0.4031)  loss_bbox_aux_4: 0.3618 (0.3997)  loss_bbox_dn_0: 0.3544 (0.4101)  loss_bbox_dn_1: 0.3307 (0.3816)  loss_bbox_dn_2: 0.3175 (0.3705)  loss_bbox_dn_3: 0.3083 (0.3655)  loss_bbox_dn_4: 0.3113 (0.3634)  loss_bbox_dn_5: 0.3113 (0.3635)  loss_bbox_enc_0: 0.4187 (0.4826)  loss_giou: 1.0674 (1.1988)  loss_giou_aux_0: 1.1688 (1.2505)  loss_giou_aux_1: 1.1228 (1.2254)  loss_giou_aux_2: 1.0963 (1.2129)  loss_giou_aux_3: 1.0906 (1.2032)  loss_giou_aux_4: 1.0652 (1.2030)  loss_giou_dn_0: 1.1460 (1.1608)  loss_giou_dn_1: 1.0613 (1.0894)  loss_giou_dn_2: 1.0374 (1.0633)  loss_giou_dn_3: 1.0347 (1.0525)  loss_giou_dn_4: 1.0255 (1.0459)  loss_giou_dn_5: 1.0267 (1.0461)  loss_giou_enc_0: 1.2304 (1.3367)  loss_vfl: 1.0923 (1.0295)  loss_vfl_aux_0: 0.9749 (0.9601)  loss_vfl_aux_1: 1.0376 (1.0001)  loss_vfl_aux_2: 1.0237 (1.0136)  loss_vfl_aux_3: 1.0942 (1.0266)  loss_vfl_aux_4: 1.1025 (1.0302)  loss_vfl_dn_0: 0.4938 (0.4816)  loss_vfl_dn_1: 0.5074 (0.5016)  loss_vfl_dn_2: 0.5271 (0.5158)  loss_vfl_dn_3: 0.5438 (0.5293)  loss_vfl_dn_4: 0.5647 (0.5519)  loss_vfl_dn_5: 0.5825 (0.5623)  loss_vfl_enc_0: 0.9241 (0.8896)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.3832  data: 1.4214  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0929  data: 0.2329  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1102 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.19s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.016\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.022\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.019\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.043\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.023\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.129\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.179\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.186\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.052\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.279\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.236\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.279\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.212\r\n",
      "best_stat: {'epoch': 11, 'coco_eval_bbox': 0.02448199311538112}\r\n",
      "Epoch: [15]  [ 0/79]  eta: 0:06:05  lr: 0.000010  loss: 35.6989 (35.6989)  loss_bbox: 0.9033 (0.9033)  loss_bbox_aux_0: 0.9648 (0.9648)  loss_bbox_aux_1: 0.8790 (0.8790)  loss_bbox_aux_2: 0.9114 (0.9114)  loss_bbox_aux_3: 0.9037 (0.9037)  loss_bbox_aux_4: 0.9503 (0.9503)  loss_bbox_dn_0: 0.1901 (0.1901)  loss_bbox_dn_1: 0.1779 (0.1779)  loss_bbox_dn_2: 0.1718 (0.1718)  loss_bbox_dn_3: 0.1705 (0.1705)  loss_bbox_dn_4: 0.1694 (0.1694)  loss_bbox_dn_5: 0.1694 (0.1694)  loss_bbox_enc_0: 0.9169 (0.9169)  loss_giou: 2.2238 (2.2238)  loss_giou_aux_0: 2.1526 (2.1526)  loss_giou_aux_1: 2.2434 (2.2434)  loss_giou_aux_2: 2.2089 (2.2089)  loss_giou_aux_3: 2.2203 (2.2203)  loss_giou_aux_4: 2.1789 (2.1789)  loss_giou_dn_0: 1.2889 (1.2889)  loss_giou_dn_1: 1.2809 (1.2809)  loss_giou_dn_2: 1.2656 (1.2656)  loss_giou_dn_3: 1.2623 (1.2623)  loss_giou_dn_4: 1.2575 (1.2575)  loss_giou_dn_5: 1.2591 (1.2591)  loss_giou_enc_0: 2.1986 (2.1986)  loss_vfl: 0.3933 (0.3933)  loss_vfl_aux_0: 0.3795 (0.3795)  loss_vfl_aux_1: 0.3947 (0.3947)  loss_vfl_aux_2: 0.3906 (0.3906)  loss_vfl_aux_3: 0.3674 (0.3674)  loss_vfl_aux_4: 0.3848 (0.3848)  loss_vfl_dn_0: 0.4460 (0.4460)  loss_vfl_dn_1: 0.4139 (0.4139)  loss_vfl_dn_2: 0.4041 (0.4041)  loss_vfl_dn_3: 0.4156 (0.4156)  loss_vfl_dn_4: 0.4185 (0.4185)  loss_vfl_dn_5: 0.4172 (0.4172)  loss_vfl_enc_0: 0.3539 (0.3539)  time: 4.6229  data: 3.0214  max mem: 10356\r\n",
      "Epoch: [15]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 29.5518 (30.4833)  loss_bbox: 0.3386 (0.4005)  loss_bbox_aux_0: 0.3805 (0.4413)  loss_bbox_aux_1: 0.3459 (0.4207)  loss_bbox_aux_2: 0.3627 (0.4119)  loss_bbox_aux_3: 0.3456 (0.4053)  loss_bbox_aux_4: 0.3431 (0.4011)  loss_bbox_dn_0: 0.3812 (0.4343)  loss_bbox_dn_1: 0.3542 (0.4038)  loss_bbox_dn_2: 0.3490 (0.3918)  loss_bbox_dn_3: 0.3451 (0.3862)  loss_bbox_dn_4: 0.3459 (0.3836)  loss_bbox_dn_5: 0.3461 (0.3836)  loss_bbox_enc_0: 0.4439 (0.4888)  loss_giou: 1.2018 (1.1650)  loss_giou_aux_0: 1.2061 (1.2277)  loss_giou_aux_1: 1.1993 (1.2036)  loss_giou_aux_2: 1.2050 (1.1808)  loss_giou_aux_3: 1.2022 (1.1752)  loss_giou_aux_4: 1.2034 (1.1693)  loss_giou_dn_0: 1.1744 (1.1563)  loss_giou_dn_1: 1.1086 (1.0796)  loss_giou_dn_2: 1.0937 (1.0515)  loss_giou_dn_3: 1.0824 (1.0396)  loss_giou_dn_4: 1.0687 (1.0320)  loss_giou_dn_5: 1.0683 (1.0323)  loss_giou_enc_0: 1.2801 (1.3117)  loss_vfl: 0.9495 (1.0648)  loss_vfl_aux_0: 0.8923 (0.9865)  loss_vfl_aux_1: 0.9575 (1.0230)  loss_vfl_aux_2: 0.9395 (1.0457)  loss_vfl_aux_3: 0.9509 (1.0511)  loss_vfl_aux_4: 0.9712 (1.0586)  loss_vfl_dn_0: 0.4755 (0.4853)  loss_vfl_dn_1: 0.4880 (0.5093)  loss_vfl_dn_2: 0.5148 (0.5206)  loss_vfl_dn_3: 0.5199 (0.5316)  loss_vfl_dn_4: 0.5397 (0.5527)  loss_vfl_dn_5: 0.5474 (0.5643)  loss_vfl_enc_0: 0.8748 (0.9124)  time: 0.9998  data: 0.0343  max mem: 10356\r\n",
      "Epoch: [15] Total time: 0:01:24 (1.0752 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 29.5518 (30.4833)  loss_bbox: 0.3386 (0.4005)  loss_bbox_aux_0: 0.3805 (0.4413)  loss_bbox_aux_1: 0.3459 (0.4207)  loss_bbox_aux_2: 0.3627 (0.4119)  loss_bbox_aux_3: 0.3456 (0.4053)  loss_bbox_aux_4: 0.3431 (0.4011)  loss_bbox_dn_0: 0.3812 (0.4343)  loss_bbox_dn_1: 0.3542 (0.4038)  loss_bbox_dn_2: 0.3490 (0.3918)  loss_bbox_dn_3: 0.3451 (0.3862)  loss_bbox_dn_4: 0.3459 (0.3836)  loss_bbox_dn_5: 0.3461 (0.3836)  loss_bbox_enc_0: 0.4439 (0.4888)  loss_giou: 1.2018 (1.1650)  loss_giou_aux_0: 1.2061 (1.2277)  loss_giou_aux_1: 1.1993 (1.2036)  loss_giou_aux_2: 1.2050 (1.1808)  loss_giou_aux_3: 1.2022 (1.1752)  loss_giou_aux_4: 1.2034 (1.1693)  loss_giou_dn_0: 1.1744 (1.1563)  loss_giou_dn_1: 1.1086 (1.0796)  loss_giou_dn_2: 1.0937 (1.0515)  loss_giou_dn_3: 1.0824 (1.0396)  loss_giou_dn_4: 1.0687 (1.0320)  loss_giou_dn_5: 1.0683 (1.0323)  loss_giou_enc_0: 1.2801 (1.3117)  loss_vfl: 0.9495 (1.0648)  loss_vfl_aux_0: 0.8923 (0.9865)  loss_vfl_aux_1: 0.9575 (1.0230)  loss_vfl_aux_2: 0.9395 (1.0457)  loss_vfl_aux_3: 0.9509 (1.0511)  loss_vfl_aux_4: 0.9712 (1.0586)  loss_vfl_dn_0: 0.4755 (0.4853)  loss_vfl_dn_1: 0.4880 (0.5093)  loss_vfl_dn_2: 0.5148 (0.5206)  loss_vfl_dn_3: 0.5199 (0.5316)  loss_vfl_dn_4: 0.5397 (0.5527)  loss_vfl_dn_5: 0.5474 (0.5643)  loss_vfl_enc_0: 0.8748 (0.9124)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.2564  data: 1.2985  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0649  data: 0.2129  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0802 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.17s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.015\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.022\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.018\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.035\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.020\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.115\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.166\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.173\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.058\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.265\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.217\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.269\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.183\r\n",
      "best_stat: {'epoch': 11, 'coco_eval_bbox': 0.02448199311538112}\r\n",
      "Epoch: [16]  [ 0/79]  eta: 0:05:41  lr: 0.000010  loss: 28.9715 (28.9715)  loss_bbox: 0.3043 (0.3043)  loss_bbox_aux_0: 0.4043 (0.4043)  loss_bbox_aux_1: 0.3607 (0.3607)  loss_bbox_aux_2: 0.3352 (0.3352)  loss_bbox_aux_3: 0.3145 (0.3145)  loss_bbox_aux_4: 0.3029 (0.3029)  loss_bbox_dn_0: 0.4114 (0.4114)  loss_bbox_dn_1: 0.3629 (0.3629)  loss_bbox_dn_2: 0.3388 (0.3388)  loss_bbox_dn_3: 0.3277 (0.3277)  loss_bbox_dn_4: 0.3214 (0.3214)  loss_bbox_dn_5: 0.3211 (0.3211)  loss_bbox_enc_0: 0.4577 (0.4577)  loss_giou: 0.9090 (0.9090)  loss_giou_aux_0: 1.0151 (1.0151)  loss_giou_aux_1: 0.9815 (0.9815)  loss_giou_aux_2: 0.9501 (0.9501)  loss_giou_aux_3: 0.9250 (0.9250)  loss_giou_aux_4: 0.9107 (0.9107)  loss_giou_dn_0: 1.0713 (1.0713)  loss_giou_dn_1: 0.9757 (0.9757)  loss_giou_dn_2: 0.9203 (0.9203)  loss_giou_dn_3: 0.9026 (0.9026)  loss_giou_dn_4: 0.8867 (0.8867)  loss_giou_dn_5: 0.8870 (0.8870)  loss_giou_enc_0: 1.1365 (1.1365)  loss_vfl: 1.2734 (1.2734)  loss_vfl_aux_0: 1.1650 (1.1650)  loss_vfl_aux_1: 1.2852 (1.2852)  loss_vfl_aux_2: 1.2129 (1.2129)  loss_vfl_aux_3: 1.2764 (1.2764)  loss_vfl_aux_4: 1.2656 (1.2656)  loss_vfl_dn_0: 0.5203 (0.5203)  loss_vfl_dn_1: 0.5431 (0.5431)  loss_vfl_dn_2: 0.5515 (0.5515)  loss_vfl_dn_3: 0.5498 (0.5498)  loss_vfl_dn_4: 0.5752 (0.5752)  loss_vfl_dn_5: 0.5994 (0.5994)  loss_vfl_enc_0: 1.1191 (1.1191)  time: 4.3281  data: 2.5140  max mem: 10356\r\n",
      "Epoch: [16]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 29.9979 (30.0032)  loss_bbox: 0.3660 (0.3697)  loss_bbox_aux_0: 0.4012 (0.4040)  loss_bbox_aux_1: 0.3816 (0.3854)  loss_bbox_aux_2: 0.3710 (0.3785)  loss_bbox_aux_3: 0.3633 (0.3719)  loss_bbox_aux_4: 0.3783 (0.3719)  loss_bbox_dn_0: 0.3503 (0.4153)  loss_bbox_dn_1: 0.3372 (0.3820)  loss_bbox_dn_2: 0.3319 (0.3704)  loss_bbox_dn_3: 0.3208 (0.3649)  loss_bbox_dn_4: 0.3152 (0.3627)  loss_bbox_dn_5: 0.3149 (0.3627)  loss_bbox_enc_0: 0.4447 (0.4511)  loss_giou: 1.1982 (1.1366)  loss_giou_aux_0: 1.2391 (1.1929)  loss_giou_aux_1: 1.2099 (1.1709)  loss_giou_aux_2: 1.2108 (1.1546)  loss_giou_aux_3: 1.2034 (1.1483)  loss_giou_aux_4: 1.2018 (1.1402)  loss_giou_dn_0: 1.1532 (1.1486)  loss_giou_dn_1: 1.1015 (1.0681)  loss_giou_dn_2: 1.0829 (1.0394)  loss_giou_dn_3: 1.0777 (1.0280)  loss_giou_dn_4: 1.0722 (1.0206)  loss_giou_dn_5: 1.0728 (1.0212)  loss_giou_enc_0: 1.3181 (1.2755)  loss_vfl: 1.0571 (1.0798)  loss_vfl_aux_0: 0.9875 (1.0302)  loss_vfl_aux_1: 0.9993 (1.0429)  loss_vfl_aux_2: 1.0220 (1.0626)  loss_vfl_aux_3: 1.0461 (1.0700)  loss_vfl_aux_4: 1.0317 (1.0757)  loss_vfl_dn_0: 0.4840 (0.4871)  loss_vfl_dn_1: 0.4890 (0.5073)  loss_vfl_dn_2: 0.4957 (0.5221)  loss_vfl_dn_3: 0.5090 (0.5346)  loss_vfl_dn_4: 0.5344 (0.5536)  loss_vfl_dn_5: 0.5421 (0.5652)  loss_vfl_enc_0: 0.8677 (0.9369)  time: 1.0281  data: 0.0314  max mem: 10356\r\n",
      "Epoch: [16] Total time: 0:01:27 (1.1059 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 29.9979 (30.0032)  loss_bbox: 0.3660 (0.3697)  loss_bbox_aux_0: 0.4012 (0.4040)  loss_bbox_aux_1: 0.3816 (0.3854)  loss_bbox_aux_2: 0.3710 (0.3785)  loss_bbox_aux_3: 0.3633 (0.3719)  loss_bbox_aux_4: 0.3783 (0.3719)  loss_bbox_dn_0: 0.3503 (0.4153)  loss_bbox_dn_1: 0.3372 (0.3820)  loss_bbox_dn_2: 0.3319 (0.3704)  loss_bbox_dn_3: 0.3208 (0.3649)  loss_bbox_dn_4: 0.3152 (0.3627)  loss_bbox_dn_5: 0.3149 (0.3627)  loss_bbox_enc_0: 0.4447 (0.4511)  loss_giou: 1.1982 (1.1366)  loss_giou_aux_0: 1.2391 (1.1929)  loss_giou_aux_1: 1.2099 (1.1709)  loss_giou_aux_2: 1.2108 (1.1546)  loss_giou_aux_3: 1.2034 (1.1483)  loss_giou_aux_4: 1.2018 (1.1402)  loss_giou_dn_0: 1.1532 (1.1486)  loss_giou_dn_1: 1.1015 (1.0681)  loss_giou_dn_2: 1.0829 (1.0394)  loss_giou_dn_3: 1.0777 (1.0280)  loss_giou_dn_4: 1.0722 (1.0206)  loss_giou_dn_5: 1.0728 (1.0212)  loss_giou_enc_0: 1.3181 (1.2755)  loss_vfl: 1.0571 (1.0798)  loss_vfl_aux_0: 0.9875 (1.0302)  loss_vfl_aux_1: 0.9993 (1.0429)  loss_vfl_aux_2: 1.0220 (1.0626)  loss_vfl_aux_3: 1.0461 (1.0700)  loss_vfl_aux_4: 1.0317 (1.0757)  loss_vfl_dn_0: 0.4840 (0.4871)  loss_vfl_dn_1: 0.4890 (0.5073)  loss_vfl_dn_2: 0.4957 (0.5221)  loss_vfl_dn_3: 0.5090 (0.5346)  loss_vfl_dn_4: 0.5344 (0.5536)  loss_vfl_dn_5: 0.5421 (0.5652)  loss_vfl_enc_0: 0.8677 (0.9369)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.3893  data: 1.3770  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0906  data: 0.2281  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1072 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.018\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.026\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.019\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.034\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.037\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.121\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.185\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.197\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.034\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.290\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.274\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.276\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.214\r\n",
      "best_stat: {'epoch': 11, 'coco_eval_bbox': 0.02448199311538112}\r\n",
      "Epoch: [17]  [ 0/79]  eta: 0:06:21  lr: 0.000010  loss: 29.6417 (29.6417)  loss_bbox: 0.3485 (0.3485)  loss_bbox_aux_0: 0.3970 (0.3970)  loss_bbox_aux_1: 0.3852 (0.3852)  loss_bbox_aux_2: 0.3439 (0.3439)  loss_bbox_aux_3: 0.3421 (0.3421)  loss_bbox_aux_4: 0.3443 (0.3443)  loss_bbox_dn_0: 0.3776 (0.3776)  loss_bbox_dn_1: 0.3473 (0.3473)  loss_bbox_dn_2: 0.3314 (0.3314)  loss_bbox_dn_3: 0.3259 (0.3259)  loss_bbox_dn_4: 0.3220 (0.3220)  loss_bbox_dn_5: 0.3217 (0.3217)  loss_bbox_enc_0: 0.5174 (0.5174)  loss_giou: 1.2874 (1.2874)  loss_giou_aux_0: 1.3638 (1.3638)  loss_giou_aux_1: 1.3117 (1.3117)  loss_giou_aux_2: 1.3194 (1.3194)  loss_giou_aux_3: 1.3015 (1.3015)  loss_giou_aux_4: 1.2932 (1.2932)  loss_giou_dn_0: 1.1889 (1.1889)  loss_giou_dn_1: 1.1086 (1.1086)  loss_giou_dn_2: 1.0740 (1.0740)  loss_giou_dn_3: 1.0655 (1.0655)  loss_giou_dn_4: 1.0587 (1.0587)  loss_giou_dn_5: 1.0587 (1.0587)  loss_giou_enc_0: 1.3781 (1.3781)  loss_vfl: 0.9019 (0.9019)  loss_vfl_aux_0: 0.8359 (0.8359)  loss_vfl_aux_1: 0.9570 (0.9570)  loss_vfl_aux_2: 0.9082 (0.9082)  loss_vfl_aux_3: 0.9463 (0.9463)  loss_vfl_aux_4: 0.9392 (0.9392)  loss_vfl_dn_0: 0.4437 (0.4437)  loss_vfl_dn_1: 0.4718 (0.4718)  loss_vfl_dn_2: 0.4781 (0.4781)  loss_vfl_dn_3: 0.5004 (0.5004)  loss_vfl_dn_4: 0.5052 (0.5052)  loss_vfl_dn_5: 0.5140 (0.5140)  loss_vfl_enc_0: 0.7261 (0.7261)  time: 4.8343  data: 3.3741  max mem: 10356\r\n",
      "Epoch: [17]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 29.9861 (29.6761)  loss_bbox: 0.3567 (0.3511)  loss_bbox_aux_0: 0.3815 (0.3856)  loss_bbox_aux_1: 0.3695 (0.3673)  loss_bbox_aux_2: 0.3625 (0.3582)  loss_bbox_aux_3: 0.3566 (0.3540)  loss_bbox_aux_4: 0.3567 (0.3532)  loss_bbox_dn_0: 0.3740 (0.4057)  loss_bbox_dn_1: 0.3333 (0.3732)  loss_bbox_dn_2: 0.3152 (0.3616)  loss_bbox_dn_3: 0.3100 (0.3563)  loss_bbox_dn_4: 0.3066 (0.3538)  loss_bbox_dn_5: 0.3066 (0.3538)  loss_bbox_enc_0: 0.4301 (0.4355)  loss_giou: 1.1150 (1.1113)  loss_giou_aux_0: 1.1522 (1.1744)  loss_giou_aux_1: 1.1564 (1.1480)  loss_giou_aux_2: 1.1363 (1.1281)  loss_giou_aux_3: 1.1221 (1.1205)  loss_giou_aux_4: 1.1124 (1.1148)  loss_giou_dn_0: 1.1222 (1.1357)  loss_giou_dn_1: 1.0307 (1.0563)  loss_giou_dn_2: 0.9949 (1.0275)  loss_giou_dn_3: 0.9869 (1.0159)  loss_giou_dn_4: 0.9802 (1.0090)  loss_giou_dn_5: 0.9800 (1.0095)  loss_giou_enc_0: 1.2486 (1.2520)  loss_vfl: 1.0200 (1.0920)  loss_vfl_aux_0: 0.9783 (1.0334)  loss_vfl_aux_1: 0.9636 (1.0631)  loss_vfl_aux_2: 0.9841 (1.0773)  loss_vfl_aux_3: 1.0381 (1.0876)  loss_vfl_aux_4: 1.0198 (1.0946)  loss_vfl_dn_0: 0.4836 (0.4884)  loss_vfl_dn_1: 0.5016 (0.5098)  loss_vfl_dn_2: 0.5115 (0.5206)  loss_vfl_dn_3: 0.5173 (0.5326)  loss_vfl_dn_4: 0.5265 (0.5470)  loss_vfl_dn_5: 0.5366 (0.5564)  loss_vfl_enc_0: 0.9565 (0.9608)  time: 1.0296  data: 0.0309  max mem: 10356\r\n",
      "Epoch: [17] Total time: 0:01:27 (1.1037 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 29.9861 (29.6761)  loss_bbox: 0.3567 (0.3511)  loss_bbox_aux_0: 0.3815 (0.3856)  loss_bbox_aux_1: 0.3695 (0.3673)  loss_bbox_aux_2: 0.3625 (0.3582)  loss_bbox_aux_3: 0.3566 (0.3540)  loss_bbox_aux_4: 0.3567 (0.3532)  loss_bbox_dn_0: 0.3740 (0.4057)  loss_bbox_dn_1: 0.3333 (0.3732)  loss_bbox_dn_2: 0.3152 (0.3616)  loss_bbox_dn_3: 0.3100 (0.3563)  loss_bbox_dn_4: 0.3066 (0.3538)  loss_bbox_dn_5: 0.3066 (0.3538)  loss_bbox_enc_0: 0.4301 (0.4355)  loss_giou: 1.1150 (1.1113)  loss_giou_aux_0: 1.1522 (1.1744)  loss_giou_aux_1: 1.1564 (1.1480)  loss_giou_aux_2: 1.1363 (1.1281)  loss_giou_aux_3: 1.1221 (1.1205)  loss_giou_aux_4: 1.1124 (1.1148)  loss_giou_dn_0: 1.1222 (1.1357)  loss_giou_dn_1: 1.0307 (1.0563)  loss_giou_dn_2: 0.9949 (1.0275)  loss_giou_dn_3: 0.9869 (1.0159)  loss_giou_dn_4: 0.9802 (1.0090)  loss_giou_dn_5: 0.9800 (1.0095)  loss_giou_enc_0: 1.2486 (1.2520)  loss_vfl: 1.0200 (1.0920)  loss_vfl_aux_0: 0.9783 (1.0334)  loss_vfl_aux_1: 0.9636 (1.0631)  loss_vfl_aux_2: 0.9841 (1.0773)  loss_vfl_aux_3: 1.0381 (1.0876)  loss_vfl_aux_4: 1.0198 (1.0946)  loss_vfl_dn_0: 0.4836 (0.4884)  loss_vfl_dn_1: 0.5016 (0.5098)  loss_vfl_dn_2: 0.5115 (0.5206)  loss_vfl_dn_3: 0.5173 (0.5326)  loss_vfl_dn_4: 0.5265 (0.5470)  loss_vfl_dn_5: 0.5366 (0.5564)  loss_vfl_enc_0: 0.9565 (0.9608)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.4966  data: 1.5784  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0847  data: 0.2369  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1024 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.19s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.019\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.029\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.021\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.032\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.038\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.121\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.191\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.200\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.061\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.285\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.296\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.308\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.214\r\n",
      "best_stat: {'epoch': 11, 'coco_eval_bbox': 0.02448199311538112}\r\n",
      "Epoch: [18]  [ 0/79]  eta: 0:06:16  lr: 0.000010  loss: 32.1091 (32.1091)  loss_bbox: 0.3187 (0.3187)  loss_bbox_aux_0: 0.4482 (0.4482)  loss_bbox_aux_1: 0.3969 (0.3969)  loss_bbox_aux_2: 0.3578 (0.3578)  loss_bbox_aux_3: 0.3093 (0.3093)  loss_bbox_aux_4: 0.3192 (0.3192)  loss_bbox_dn_0: 0.6331 (0.6331)  loss_bbox_dn_1: 0.5442 (0.5442)  loss_bbox_dn_2: 0.4848 (0.4848)  loss_bbox_dn_3: 0.4549 (0.4549)  loss_bbox_dn_4: 0.4369 (0.4369)  loss_bbox_dn_5: 0.4373 (0.4373)  loss_bbox_enc_0: 0.5582 (0.5582)  loss_giou: 0.7793 (0.7793)  loss_giou_aux_0: 0.9025 (0.9025)  loss_giou_aux_1: 0.8350 (0.8350)  loss_giou_aux_2: 0.8086 (0.8086)  loss_giou_aux_3: 0.8408 (0.8408)  loss_giou_aux_4: 0.7801 (0.7801)  loss_giou_dn_0: 1.0324 (1.0324)  loss_giou_dn_1: 0.9140 (0.9140)  loss_giou_dn_2: 0.8411 (0.8411)  loss_giou_dn_3: 0.8092 (0.8092)  loss_giou_dn_4: 0.7921 (0.7921)  loss_giou_dn_5: 0.7932 (0.7932)  loss_giou_enc_0: 1.0205 (1.0205)  loss_vfl: 1.7163 (1.7163)  loss_vfl_aux_0: 1.6724 (1.6724)  loss_vfl_aux_1: 1.6680 (1.6680)  loss_vfl_aux_2: 1.7578 (1.7578)  loss_vfl_aux_3: 1.7505 (1.7505)  loss_vfl_aux_4: 1.7632 (1.7632)  loss_vfl_dn_0: 0.5283 (0.5283)  loss_vfl_dn_1: 0.5620 (0.5620)  loss_vfl_dn_2: 0.5996 (0.5996)  loss_vfl_dn_3: 0.6323 (0.6323)  loss_vfl_dn_4: 0.6379 (0.6379)  loss_vfl_dn_5: 0.6565 (0.6565)  loss_vfl_enc_0: 1.3159 (1.3159)  time: 4.7628  data: 3.0964  max mem: 10356\r\n",
      "Epoch: [18]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 29.4676 (29.8027)  loss_bbox: 0.3164 (0.3472)  loss_bbox_aux_0: 0.3734 (0.3916)  loss_bbox_aux_1: 0.3396 (0.3716)  loss_bbox_aux_2: 0.3415 (0.3617)  loss_bbox_aux_3: 0.3284 (0.3558)  loss_bbox_aux_4: 0.3196 (0.3492)  loss_bbox_dn_0: 0.4258 (0.4117)  loss_bbox_dn_1: 0.3758 (0.3747)  loss_bbox_dn_2: 0.3697 (0.3617)  loss_bbox_dn_3: 0.3637 (0.3561)  loss_bbox_dn_4: 0.3583 (0.3531)  loss_bbox_dn_5: 0.3581 (0.3532)  loss_bbox_enc_0: 0.4361 (0.4410)  loss_giou: 0.9621 (1.1288)  loss_giou_aux_0: 1.0354 (1.1888)  loss_giou_aux_1: 0.9951 (1.1639)  loss_giou_aux_2: 0.9753 (1.1459)  loss_giou_aux_3: 0.9483 (1.1402)  loss_giou_aux_4: 0.9741 (1.1340)  loss_giou_dn_0: 1.1229 (1.1374)  loss_giou_dn_1: 1.0289 (1.0563)  loss_giou_dn_2: 0.9930 (1.0250)  loss_giou_dn_3: 0.9825 (1.0130)  loss_giou_dn_4: 0.9721 (1.0061)  loss_giou_dn_5: 0.9718 (1.0062)  loss_giou_enc_0: 1.1480 (1.2753)  loss_vfl: 1.2012 (1.1015)  loss_vfl_aux_0: 1.1450 (1.0306)  loss_vfl_aux_1: 1.1543 (1.0582)  loss_vfl_aux_2: 1.1985 (1.0804)  loss_vfl_aux_3: 1.1870 (1.0919)  loss_vfl_aux_4: 1.1899 (1.1005)  loss_vfl_dn_0: 0.5057 (0.4898)  loss_vfl_dn_1: 0.5370 (0.5109)  loss_vfl_dn_2: 0.5415 (0.5203)  loss_vfl_dn_3: 0.5579 (0.5306)  loss_vfl_dn_4: 0.5776 (0.5439)  loss_vfl_dn_5: 0.5884 (0.5531)  loss_vfl_enc_0: 1.0142 (0.9415)  time: 1.0039  data: 0.0325  max mem: 10356\r\n",
      "Epoch: [18] Total time: 0:01:26 (1.0905 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 29.4676 (29.8027)  loss_bbox: 0.3164 (0.3472)  loss_bbox_aux_0: 0.3734 (0.3916)  loss_bbox_aux_1: 0.3396 (0.3716)  loss_bbox_aux_2: 0.3415 (0.3617)  loss_bbox_aux_3: 0.3284 (0.3558)  loss_bbox_aux_4: 0.3196 (0.3492)  loss_bbox_dn_0: 0.4258 (0.4117)  loss_bbox_dn_1: 0.3758 (0.3747)  loss_bbox_dn_2: 0.3697 (0.3617)  loss_bbox_dn_3: 0.3637 (0.3561)  loss_bbox_dn_4: 0.3583 (0.3531)  loss_bbox_dn_5: 0.3581 (0.3532)  loss_bbox_enc_0: 0.4361 (0.4410)  loss_giou: 0.9621 (1.1288)  loss_giou_aux_0: 1.0354 (1.1888)  loss_giou_aux_1: 0.9951 (1.1639)  loss_giou_aux_2: 0.9753 (1.1459)  loss_giou_aux_3: 0.9483 (1.1402)  loss_giou_aux_4: 0.9741 (1.1340)  loss_giou_dn_0: 1.1229 (1.1374)  loss_giou_dn_1: 1.0289 (1.0563)  loss_giou_dn_2: 0.9930 (1.0250)  loss_giou_dn_3: 0.9825 (1.0130)  loss_giou_dn_4: 0.9721 (1.0061)  loss_giou_dn_5: 0.9718 (1.0062)  loss_giou_enc_0: 1.1480 (1.2753)  loss_vfl: 1.2012 (1.1015)  loss_vfl_aux_0: 1.1450 (1.0306)  loss_vfl_aux_1: 1.1543 (1.0582)  loss_vfl_aux_2: 1.1985 (1.0804)  loss_vfl_aux_3: 1.1870 (1.0919)  loss_vfl_aux_4: 1.1899 (1.1005)  loss_vfl_dn_0: 0.5057 (0.4898)  loss_vfl_dn_1: 0.5370 (0.5109)  loss_vfl_dn_2: 0.5415 (0.5203)  loss_vfl_dn_3: 0.5579 (0.5306)  loss_vfl_dn_4: 0.5776 (0.5439)  loss_vfl_dn_5: 0.5884 (0.5531)  loss_vfl_enc_0: 1.0142 (0.9415)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.1637  data: 1.1635  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0666  data: 0.2038  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0815 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.026\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.036\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.028\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.051\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.034\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.128\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.186\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.198\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.048\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.305\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.264\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.278\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.210\r\n",
      "best_stat: {'epoch': 18, 'coco_eval_bbox': 0.025914604708733916}\r\n",
      "Epoch: [19]  [ 0/79]  eta: 0:05:23  lr: 0.000010  loss: 28.5466 (28.5466)  loss_bbox: 0.3514 (0.3514)  loss_bbox_aux_0: 0.3364 (0.3364)  loss_bbox_aux_1: 0.3247 (0.3247)  loss_bbox_aux_2: 0.3453 (0.3453)  loss_bbox_aux_3: 0.3455 (0.3455)  loss_bbox_aux_4: 0.3430 (0.3430)  loss_bbox_dn_0: 0.1984 (0.1984)  loss_bbox_dn_1: 0.1875 (0.1875)  loss_bbox_dn_2: 0.1903 (0.1903)  loss_bbox_dn_3: 0.1929 (0.1929)  loss_bbox_dn_4: 0.1938 (0.1938)  loss_bbox_dn_5: 0.1940 (0.1940)  loss_bbox_enc_0: 0.3829 (0.3829)  loss_giou: 1.3716 (1.3716)  loss_giou_aux_0: 1.4319 (1.4319)  loss_giou_aux_1: 1.4242 (1.4242)  loss_giou_aux_2: 1.4179 (1.4179)  loss_giou_aux_3: 1.4056 (1.4056)  loss_giou_aux_4: 1.4007 (1.4007)  loss_giou_dn_0: 1.2119 (1.2119)  loss_giou_dn_1: 1.1424 (1.1424)  loss_giou_dn_2: 1.1331 (1.1331)  loss_giou_dn_3: 1.1358 (1.1358)  loss_giou_dn_4: 1.1339 (1.1339)  loss_giou_dn_5: 1.1330 (1.1330)  loss_giou_enc_0: 1.4709 (1.4709)  loss_vfl: 0.8213 (0.8213)  loss_vfl_aux_0: 0.7068 (0.7068)  loss_vfl_aux_1: 0.7402 (0.7402)  loss_vfl_aux_2: 0.7319 (0.7319)  loss_vfl_aux_3: 0.7793 (0.7793)  loss_vfl_aux_4: 0.7778 (0.7778)  loss_vfl_dn_0: 0.4513 (0.4513)  loss_vfl_dn_1: 0.4747 (0.4747)  loss_vfl_dn_2: 0.4795 (0.4795)  loss_vfl_dn_3: 0.4924 (0.4924)  loss_vfl_dn_4: 0.5045 (0.5045)  loss_vfl_dn_5: 0.5242 (0.5242)  loss_vfl_enc_0: 0.6638 (0.6638)  time: 4.0908  data: 2.8762  max mem: 10356\r\n",
      "Epoch: [19]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 29.1904 (29.6456)  loss_bbox: 0.3165 (0.3426)  loss_bbox_aux_0: 0.3814 (0.3890)  loss_bbox_aux_1: 0.3393 (0.3652)  loss_bbox_aux_2: 0.3311 (0.3552)  loss_bbox_aux_3: 0.3173 (0.3501)  loss_bbox_aux_4: 0.3190 (0.3473)  loss_bbox_dn_0: 0.3917 (0.4089)  loss_bbox_dn_1: 0.3430 (0.3713)  loss_bbox_dn_2: 0.3318 (0.3586)  loss_bbox_dn_3: 0.3298 (0.3530)  loss_bbox_dn_4: 0.3287 (0.3506)  loss_bbox_dn_5: 0.3288 (0.3506)  loss_bbox_enc_0: 0.4286 (0.4495)  loss_giou: 0.9048 (1.1169)  loss_giou_aux_0: 0.9972 (1.1748)  loss_giou_aux_1: 0.9407 (1.1471)  loss_giou_aux_2: 0.9168 (1.1327)  loss_giou_aux_3: 0.9105 (1.1263)  loss_giou_aux_4: 0.9261 (1.1178)  loss_giou_dn_0: 1.0859 (1.1231)  loss_giou_dn_1: 0.9946 (1.0414)  loss_giou_dn_2: 0.9509 (1.0116)  loss_giou_dn_3: 0.9344 (0.9993)  loss_giou_dn_4: 0.9210 (0.9925)  loss_giou_dn_5: 0.9208 (0.9929)  loss_giou_enc_0: 1.1208 (1.2650)  loss_vfl: 1.1914 (1.0954)  loss_vfl_aux_0: 1.1260 (1.0467)  loss_vfl_aux_1: 1.1736 (1.0720)  loss_vfl_aux_2: 1.1975 (1.0734)  loss_vfl_aux_3: 1.1692 (1.0799)  loss_vfl_aux_4: 1.1736 (1.0893)  loss_vfl_dn_0: 0.5153 (0.5018)  loss_vfl_dn_1: 0.5393 (0.5176)  loss_vfl_dn_2: 0.5503 (0.5297)  loss_vfl_dn_3: 0.5615 (0.5395)  loss_vfl_dn_4: 0.5715 (0.5533)  loss_vfl_dn_5: 0.5842 (0.5622)  loss_vfl_enc_0: 1.0479 (0.9511)  time: 1.0033  data: 0.0305  max mem: 10356\r\n",
      "Epoch: [19] Total time: 0:01:23 (1.0519 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 29.1904 (29.6456)  loss_bbox: 0.3165 (0.3426)  loss_bbox_aux_0: 0.3814 (0.3890)  loss_bbox_aux_1: 0.3393 (0.3652)  loss_bbox_aux_2: 0.3311 (0.3552)  loss_bbox_aux_3: 0.3173 (0.3501)  loss_bbox_aux_4: 0.3190 (0.3473)  loss_bbox_dn_0: 0.3917 (0.4089)  loss_bbox_dn_1: 0.3430 (0.3713)  loss_bbox_dn_2: 0.3318 (0.3586)  loss_bbox_dn_3: 0.3298 (0.3530)  loss_bbox_dn_4: 0.3287 (0.3506)  loss_bbox_dn_5: 0.3288 (0.3506)  loss_bbox_enc_0: 0.4286 (0.4495)  loss_giou: 0.9048 (1.1169)  loss_giou_aux_0: 0.9972 (1.1748)  loss_giou_aux_1: 0.9407 (1.1471)  loss_giou_aux_2: 0.9168 (1.1327)  loss_giou_aux_3: 0.9105 (1.1263)  loss_giou_aux_4: 0.9261 (1.1178)  loss_giou_dn_0: 1.0859 (1.1231)  loss_giou_dn_1: 0.9946 (1.0414)  loss_giou_dn_2: 0.9509 (1.0116)  loss_giou_dn_3: 0.9344 (0.9993)  loss_giou_dn_4: 0.9210 (0.9925)  loss_giou_dn_5: 0.9208 (0.9929)  loss_giou_enc_0: 1.1208 (1.2650)  loss_vfl: 1.1914 (1.0954)  loss_vfl_aux_0: 1.1260 (1.0467)  loss_vfl_aux_1: 1.1736 (1.0720)  loss_vfl_aux_2: 1.1975 (1.0734)  loss_vfl_aux_3: 1.1692 (1.0799)  loss_vfl_aux_4: 1.1736 (1.0893)  loss_vfl_dn_0: 0.5153 (0.5018)  loss_vfl_dn_1: 0.5393 (0.5176)  loss_vfl_dn_2: 0.5503 (0.5297)  loss_vfl_dn_3: 0.5615 (0.5395)  loss_vfl_dn_4: 0.5715 (0.5533)  loss_vfl_dn_5: 0.5842 (0.5622)  loss_vfl_enc_0: 1.0479 (0.9511)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.4543  data: 1.5018  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0869  data: 0.2336  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1037 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.023\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.036\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.025\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.038\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.050\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.134\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.201\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.211\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.054\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.279\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.269\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.311\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.231\r\n",
      "best_stat: {'epoch': 18, 'coco_eval_bbox': 0.025914604708733916}\r\n",
      "Epoch: [20]  [ 0/79]  eta: 0:06:05  lr: 0.000010  loss: 29.6451 (29.6451)  loss_bbox: 0.3519 (0.3519)  loss_bbox_aux_0: 0.4038 (0.4038)  loss_bbox_aux_1: 0.4071 (0.4071)  loss_bbox_aux_2: 0.3954 (0.3954)  loss_bbox_aux_3: 0.3733 (0.3733)  loss_bbox_aux_4: 0.4083 (0.4083)  loss_bbox_dn_0: 0.2832 (0.2832)  loss_bbox_dn_1: 0.2895 (0.2895)  loss_bbox_dn_2: 0.2948 (0.2948)  loss_bbox_dn_3: 0.3035 (0.3035)  loss_bbox_dn_4: 0.3090 (0.3090)  loss_bbox_dn_5: 0.3101 (0.3101)  loss_bbox_enc_0: 0.4312 (0.4312)  loss_giou: 1.2470 (1.2470)  loss_giou_aux_0: 1.2917 (1.2917)  loss_giou_aux_1: 1.2596 (1.2596)  loss_giou_aux_2: 1.2179 (1.2179)  loss_giou_aux_3: 1.2436 (1.2436)  loss_giou_aux_4: 1.2255 (1.2255)  loss_giou_dn_0: 1.1090 (1.1090)  loss_giou_dn_1: 1.0416 (1.0416)  loss_giou_dn_2: 1.0085 (1.0085)  loss_giou_dn_3: 1.0055 (1.0055)  loss_giou_dn_4: 1.0019 (1.0019)  loss_giou_dn_5: 1.0025 (1.0025)  loss_giou_enc_0: 1.3461 (1.3461)  loss_vfl: 1.0339 (1.0339)  loss_vfl_aux_0: 0.9572 (0.9572)  loss_vfl_aux_1: 0.9810 (0.9810)  loss_vfl_aux_2: 1.0833 (1.0833)  loss_vfl_aux_3: 1.0251 (1.0251)  loss_vfl_aux_4: 1.0195 (1.0195)  loss_vfl_dn_0: 0.4971 (0.4971)  loss_vfl_dn_1: 0.5228 (0.5228)  loss_vfl_dn_2: 0.5266 (0.5266)  loss_vfl_dn_3: 0.5256 (0.5256)  loss_vfl_dn_4: 0.5326 (0.5326)  loss_vfl_dn_5: 0.5370 (0.5370)  loss_vfl_enc_0: 0.8420 (0.8420)  time: 4.6318  data: 2.9443  max mem: 10356\r\n",
      "Epoch: [20]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 29.9734 (29.5868)  loss_bbox: 0.3642 (0.3526)  loss_bbox_aux_0: 0.4088 (0.3916)  loss_bbox_aux_1: 0.3737 (0.3710)  loss_bbox_aux_2: 0.3743 (0.3666)  loss_bbox_aux_3: 0.3624 (0.3585)  loss_bbox_aux_4: 0.3703 (0.3571)  loss_bbox_dn_0: 0.3697 (0.4072)  loss_bbox_dn_1: 0.3437 (0.3716)  loss_bbox_dn_2: 0.3235 (0.3595)  loss_bbox_dn_3: 0.3211 (0.3544)  loss_bbox_dn_4: 0.3243 (0.3519)  loss_bbox_dn_5: 0.3243 (0.3519)  loss_bbox_enc_0: 0.4634 (0.4365)  loss_giou: 1.1754 (1.1002)  loss_giou_aux_0: 1.2010 (1.1529)  loss_giou_aux_1: 1.2149 (1.1271)  loss_giou_aux_2: 1.1885 (1.1136)  loss_giou_aux_3: 1.1811 (1.1082)  loss_giou_aux_4: 1.1780 (1.1056)  loss_giou_dn_0: 1.1117 (1.1153)  loss_giou_dn_1: 1.0296 (1.0302)  loss_giou_dn_2: 1.0040 (0.9985)  loss_giou_dn_3: 0.9907 (0.9869)  loss_giou_dn_4: 0.9826 (0.9800)  loss_giou_dn_5: 0.9827 (0.9802)  loss_giou_enc_0: 1.2669 (1.2497)  loss_vfl: 0.9697 (1.1094)  loss_vfl_aux_0: 0.9568 (1.0653)  loss_vfl_aux_1: 0.9456 (1.0844)  loss_vfl_aux_2: 0.9338 (1.0932)  loss_vfl_aux_3: 0.9983 (1.1077)  loss_vfl_aux_4: 0.9668 (1.1015)  loss_vfl_dn_0: 0.5012 (0.5000)  loss_vfl_dn_1: 0.5181 (0.5175)  loss_vfl_dn_2: 0.5298 (0.5285)  loss_vfl_dn_3: 0.5465 (0.5372)  loss_vfl_dn_4: 0.5516 (0.5501)  loss_vfl_dn_5: 0.5566 (0.5591)  loss_vfl_enc_0: 0.8804 (0.9542)  time: 0.9807  data: 0.0319  max mem: 10356\r\n",
      "Epoch: [20] Total time: 0:01:25 (1.0820 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 29.9734 (29.5868)  loss_bbox: 0.3642 (0.3526)  loss_bbox_aux_0: 0.4088 (0.3916)  loss_bbox_aux_1: 0.3737 (0.3710)  loss_bbox_aux_2: 0.3743 (0.3666)  loss_bbox_aux_3: 0.3624 (0.3585)  loss_bbox_aux_4: 0.3703 (0.3571)  loss_bbox_dn_0: 0.3697 (0.4072)  loss_bbox_dn_1: 0.3437 (0.3716)  loss_bbox_dn_2: 0.3235 (0.3595)  loss_bbox_dn_3: 0.3211 (0.3544)  loss_bbox_dn_4: 0.3243 (0.3519)  loss_bbox_dn_5: 0.3243 (0.3519)  loss_bbox_enc_0: 0.4634 (0.4365)  loss_giou: 1.1754 (1.1002)  loss_giou_aux_0: 1.2010 (1.1529)  loss_giou_aux_1: 1.2149 (1.1271)  loss_giou_aux_2: 1.1885 (1.1136)  loss_giou_aux_3: 1.1811 (1.1082)  loss_giou_aux_4: 1.1780 (1.1056)  loss_giou_dn_0: 1.1117 (1.1153)  loss_giou_dn_1: 1.0296 (1.0302)  loss_giou_dn_2: 1.0040 (0.9985)  loss_giou_dn_3: 0.9907 (0.9869)  loss_giou_dn_4: 0.9826 (0.9800)  loss_giou_dn_5: 0.9827 (0.9802)  loss_giou_enc_0: 1.2669 (1.2497)  loss_vfl: 0.9697 (1.1094)  loss_vfl_aux_0: 0.9568 (1.0653)  loss_vfl_aux_1: 0.9456 (1.0844)  loss_vfl_aux_2: 0.9338 (1.0932)  loss_vfl_aux_3: 0.9983 (1.1077)  loss_vfl_aux_4: 0.9668 (1.1015)  loss_vfl_dn_0: 0.5012 (0.5000)  loss_vfl_dn_1: 0.5181 (0.5175)  loss_vfl_dn_2: 0.5298 (0.5285)  loss_vfl_dn_3: 0.5465 (0.5372)  loss_vfl_dn_4: 0.5516 (0.5501)  loss_vfl_dn_5: 0.5566 (0.5591)  loss_vfl_enc_0: 0.8804 (0.9542)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3001  data: 1.3250  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0830  data: 0.2180  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0998 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.17s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.025\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.036\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.027\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.044\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.043\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.136\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.203\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.215\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.060\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.279\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.299\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.306\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.231\r\n",
      "best_stat: {'epoch': 18, 'coco_eval_bbox': 0.025914604708733916}\r\n",
      "Epoch: [21]  [ 0/79]  eta: 0:06:07  lr: 0.000010  loss: 28.9230 (28.9230)  loss_bbox: 0.2625 (0.2625)  loss_bbox_aux_0: 0.3448 (0.3448)  loss_bbox_aux_1: 0.2706 (0.2706)  loss_bbox_aux_2: 0.3033 (0.3033)  loss_bbox_aux_3: 0.2705 (0.2705)  loss_bbox_aux_4: 0.2757 (0.2757)  loss_bbox_dn_0: 0.4371 (0.4371)  loss_bbox_dn_1: 0.3790 (0.3790)  loss_bbox_dn_2: 0.3596 (0.3596)  loss_bbox_dn_3: 0.3528 (0.3528)  loss_bbox_dn_4: 0.3493 (0.3493)  loss_bbox_dn_5: 0.3495 (0.3495)  loss_bbox_enc_0: 0.4046 (0.4046)  loss_giou: 0.7665 (0.7665)  loss_giou_aux_0: 0.8398 (0.8398)  loss_giou_aux_1: 0.8376 (0.8376)  loss_giou_aux_2: 0.7783 (0.7783)  loss_giou_aux_3: 0.8198 (0.8198)  loss_giou_aux_4: 0.7936 (0.7936)  loss_giou_dn_0: 1.0365 (1.0365)  loss_giou_dn_1: 0.9052 (0.9052)  loss_giou_dn_2: 0.8669 (0.8669)  loss_giou_dn_3: 0.8454 (0.8454)  loss_giou_dn_4: 0.8254 (0.8254)  loss_giou_dn_5: 0.8253 (0.8253)  loss_giou_enc_0: 0.9319 (0.9319)  loss_vfl: 1.4702 (1.4702)  loss_vfl_aux_0: 1.3887 (1.3887)  loss_vfl_aux_1: 1.4141 (1.4141)  loss_vfl_aux_2: 1.4785 (1.4785)  loss_vfl_aux_3: 1.4517 (1.4517)  loss_vfl_aux_4: 1.4121 (1.4121)  loss_vfl_dn_0: 0.5413 (0.5413)  loss_vfl_dn_1: 0.5715 (0.5715)  loss_vfl_dn_2: 0.5854 (0.5854)  loss_vfl_dn_3: 0.5823 (0.5823)  loss_vfl_dn_4: 0.5894 (0.5894)  loss_vfl_dn_5: 0.5908 (0.5908)  loss_vfl_enc_0: 1.4155 (1.4155)  time: 4.6571  data: 2.2753  max mem: 10356\r\n",
      "Epoch: [21]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 29.2174 (29.2430)  loss_bbox: 0.3215 (0.3372)  loss_bbox_aux_0: 0.3696 (0.3743)  loss_bbox_aux_1: 0.3289 (0.3519)  loss_bbox_aux_2: 0.3401 (0.3463)  loss_bbox_aux_3: 0.3269 (0.3440)  loss_bbox_aux_4: 0.3278 (0.3416)  loss_bbox_dn_0: 0.3541 (0.3882)  loss_bbox_dn_1: 0.3126 (0.3509)  loss_bbox_dn_2: 0.3024 (0.3386)  loss_bbox_dn_3: 0.3020 (0.3331)  loss_bbox_dn_4: 0.2970 (0.3311)  loss_bbox_dn_5: 0.2965 (0.3311)  loss_bbox_enc_0: 0.4213 (0.4262)  loss_giou: 1.1527 (1.1015)  loss_giou_aux_0: 1.1848 (1.1580)  loss_giou_aux_1: 1.1377 (1.1353)  loss_giou_aux_2: 1.1387 (1.1154)  loss_giou_aux_3: 1.1459 (1.1091)  loss_giou_aux_4: 1.1462 (1.1035)  loss_giou_dn_0: 1.1414 (1.1136)  loss_giou_dn_1: 1.0596 (1.0279)  loss_giou_dn_2: 1.0324 (0.9968)  loss_giou_dn_3: 1.0255 (0.9848)  loss_giou_dn_4: 1.0129 (0.9783)  loss_giou_dn_5: 1.0124 (0.9789)  loss_giou_enc_0: 1.2407 (1.2414)  loss_vfl: 0.9880 (1.0861)  loss_vfl_aux_0: 0.9871 (1.0517)  loss_vfl_aux_1: 0.9971 (1.0733)  loss_vfl_aux_2: 1.0024 (1.0763)  loss_vfl_aux_3: 1.0159 (1.0827)  loss_vfl_aux_4: 1.0190 (1.0831)  loss_vfl_dn_0: 0.4854 (0.5018)  loss_vfl_dn_1: 0.4961 (0.5162)  loss_vfl_dn_2: 0.5074 (0.5249)  loss_vfl_dn_3: 0.5181 (0.5316)  loss_vfl_dn_4: 0.5189 (0.5437)  loss_vfl_dn_5: 0.5330 (0.5523)  loss_vfl_enc_0: 0.9050 (0.9804)  time: 0.9768  data: 0.0325  max mem: 10356\r\n",
      "Epoch: [21] Total time: 0:01:25 (1.0885 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 29.2174 (29.2430)  loss_bbox: 0.3215 (0.3372)  loss_bbox_aux_0: 0.3696 (0.3743)  loss_bbox_aux_1: 0.3289 (0.3519)  loss_bbox_aux_2: 0.3401 (0.3463)  loss_bbox_aux_3: 0.3269 (0.3440)  loss_bbox_aux_4: 0.3278 (0.3416)  loss_bbox_dn_0: 0.3541 (0.3882)  loss_bbox_dn_1: 0.3126 (0.3509)  loss_bbox_dn_2: 0.3024 (0.3386)  loss_bbox_dn_3: 0.3020 (0.3331)  loss_bbox_dn_4: 0.2970 (0.3311)  loss_bbox_dn_5: 0.2965 (0.3311)  loss_bbox_enc_0: 0.4213 (0.4262)  loss_giou: 1.1527 (1.1015)  loss_giou_aux_0: 1.1848 (1.1580)  loss_giou_aux_1: 1.1377 (1.1353)  loss_giou_aux_2: 1.1387 (1.1154)  loss_giou_aux_3: 1.1459 (1.1091)  loss_giou_aux_4: 1.1462 (1.1035)  loss_giou_dn_0: 1.1414 (1.1136)  loss_giou_dn_1: 1.0596 (1.0279)  loss_giou_dn_2: 1.0324 (0.9968)  loss_giou_dn_3: 1.0255 (0.9848)  loss_giou_dn_4: 1.0129 (0.9783)  loss_giou_dn_5: 1.0124 (0.9789)  loss_giou_enc_0: 1.2407 (1.2414)  loss_vfl: 0.9880 (1.0861)  loss_vfl_aux_0: 0.9871 (1.0517)  loss_vfl_aux_1: 0.9971 (1.0733)  loss_vfl_aux_2: 1.0024 (1.0763)  loss_vfl_aux_3: 1.0159 (1.0827)  loss_vfl_aux_4: 1.0190 (1.0831)  loss_vfl_dn_0: 0.4854 (0.5018)  loss_vfl_dn_1: 0.4961 (0.5162)  loss_vfl_dn_2: 0.5074 (0.5249)  loss_vfl_dn_3: 0.5181 (0.5316)  loss_vfl_dn_4: 0.5189 (0.5437)  loss_vfl_dn_5: 0.5330 (0.5523)  loss_vfl_enc_0: 0.9050 (0.9804)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.1438  data: 1.2004  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0762  data: 0.2141  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0938 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.021\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.028\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.022\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.033\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.044\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.136\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.193\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.205\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.276\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.279\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.289\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.223\r\n",
      "best_stat: {'epoch': 18, 'coco_eval_bbox': 0.025914604708733916}\r\n",
      "Epoch: [22]  [ 0/79]  eta: 0:05:58  lr: 0.000010  loss: 30.2759 (30.2759)  loss_bbox: 0.3737 (0.3737)  loss_bbox_aux_0: 0.4424 (0.4424)  loss_bbox_aux_1: 0.3707 (0.3707)  loss_bbox_aux_2: 0.4170 (0.4170)  loss_bbox_aux_3: 0.3990 (0.3990)  loss_bbox_aux_4: 0.3993 (0.3993)  loss_bbox_dn_0: 0.5202 (0.5202)  loss_bbox_dn_1: 0.5023 (0.5023)  loss_bbox_dn_2: 0.5035 (0.5035)  loss_bbox_dn_3: 0.4981 (0.4981)  loss_bbox_dn_4: 0.4976 (0.4976)  loss_bbox_dn_5: 0.4976 (0.4976)  loss_bbox_enc_0: 0.4790 (0.4790)  loss_giou: 1.0769 (1.0769)  loss_giou_aux_0: 1.1038 (1.1038)  loss_giou_aux_1: 1.0922 (1.0922)  loss_giou_aux_2: 1.0807 (1.0807)  loss_giou_aux_3: 1.0780 (1.0780)  loss_giou_aux_4: 1.0747 (1.0747)  loss_giou_dn_0: 1.1348 (1.1348)  loss_giou_dn_1: 1.0711 (1.0711)  loss_giou_dn_2: 1.0513 (1.0513)  loss_giou_dn_3: 1.0458 (1.0458)  loss_giou_dn_4: 1.0420 (1.0420)  loss_giou_dn_5: 1.0417 (1.0417)  loss_giou_enc_0: 1.1879 (1.1879)  loss_vfl: 1.0764 (1.0764)  loss_vfl_aux_0: 1.0034 (1.0034)  loss_vfl_aux_1: 1.0378 (1.0378)  loss_vfl_aux_2: 1.0645 (1.0645)  loss_vfl_aux_3: 1.0737 (1.0737)  loss_vfl_aux_4: 1.0769 (1.0769)  loss_vfl_dn_0: 0.5004 (0.5004)  loss_vfl_dn_1: 0.4996 (0.4996)  loss_vfl_dn_2: 0.4960 (0.4960)  loss_vfl_dn_3: 0.4960 (0.4960)  loss_vfl_dn_4: 0.4978 (0.4978)  loss_vfl_dn_5: 0.5046 (0.5046)  loss_vfl_enc_0: 0.9673 (0.9673)  time: 4.5374  data: 2.8267  max mem: 10356\r\n",
      "Epoch: [22]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 29.1134 (29.1043)  loss_bbox: 0.3199 (0.3293)  loss_bbox_aux_0: 0.3681 (0.3648)  loss_bbox_aux_1: 0.3384 (0.3460)  loss_bbox_aux_2: 0.3443 (0.3390)  loss_bbox_aux_3: 0.3260 (0.3323)  loss_bbox_aux_4: 0.3225 (0.3296)  loss_bbox_dn_0: 0.3770 (0.3974)  loss_bbox_dn_1: 0.3418 (0.3565)  loss_bbox_dn_2: 0.3301 (0.3426)  loss_bbox_dn_3: 0.3281 (0.3364)  loss_bbox_dn_4: 0.3252 (0.3336)  loss_bbox_dn_5: 0.3247 (0.3336)  loss_bbox_enc_0: 0.4271 (0.4172)  loss_giou: 1.1320 (1.0847)  loss_giou_aux_0: 1.1896 (1.1403)  loss_giou_aux_1: 1.1820 (1.1165)  loss_giou_aux_2: 1.1713 (1.1003)  loss_giou_aux_3: 1.1470 (1.0967)  loss_giou_aux_4: 1.1425 (1.0894)  loss_giou_dn_0: 1.1098 (1.1063)  loss_giou_dn_1: 1.0222 (1.0203)  loss_giou_dn_2: 0.9936 (0.9889)  loss_giou_dn_3: 0.9834 (0.9775)  loss_giou_dn_4: 0.9782 (0.9705)  loss_giou_dn_5: 0.9772 (0.9708)  loss_giou_enc_0: 1.2708 (1.2252)  loss_vfl: 1.0164 (1.0975)  loss_vfl_aux_0: 0.9495 (1.0750)  loss_vfl_aux_1: 0.9758 (1.0824)  loss_vfl_aux_2: 0.9968 (1.0884)  loss_vfl_aux_3: 0.9983 (1.0877)  loss_vfl_aux_4: 1.0083 (1.0924)  loss_vfl_dn_0: 0.4952 (0.5038)  loss_vfl_dn_1: 0.4926 (0.5136)  loss_vfl_dn_2: 0.5027 (0.5221)  loss_vfl_dn_3: 0.4987 (0.5266)  loss_vfl_dn_4: 0.5039 (0.5346)  loss_vfl_dn_5: 0.5072 (0.5429)  loss_vfl_enc_0: 0.9055 (0.9915)  time: 0.9861  data: 0.0316  max mem: 10356\r\n",
      "Epoch: [22] Total time: 0:01:25 (1.0805 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 29.1134 (29.1043)  loss_bbox: 0.3199 (0.3293)  loss_bbox_aux_0: 0.3681 (0.3648)  loss_bbox_aux_1: 0.3384 (0.3460)  loss_bbox_aux_2: 0.3443 (0.3390)  loss_bbox_aux_3: 0.3260 (0.3323)  loss_bbox_aux_4: 0.3225 (0.3296)  loss_bbox_dn_0: 0.3770 (0.3974)  loss_bbox_dn_1: 0.3418 (0.3565)  loss_bbox_dn_2: 0.3301 (0.3426)  loss_bbox_dn_3: 0.3281 (0.3364)  loss_bbox_dn_4: 0.3252 (0.3336)  loss_bbox_dn_5: 0.3247 (0.3336)  loss_bbox_enc_0: 0.4271 (0.4172)  loss_giou: 1.1320 (1.0847)  loss_giou_aux_0: 1.1896 (1.1403)  loss_giou_aux_1: 1.1820 (1.1165)  loss_giou_aux_2: 1.1713 (1.1003)  loss_giou_aux_3: 1.1470 (1.0967)  loss_giou_aux_4: 1.1425 (1.0894)  loss_giou_dn_0: 1.1098 (1.1063)  loss_giou_dn_1: 1.0222 (1.0203)  loss_giou_dn_2: 0.9936 (0.9889)  loss_giou_dn_3: 0.9834 (0.9775)  loss_giou_dn_4: 0.9782 (0.9705)  loss_giou_dn_5: 0.9772 (0.9708)  loss_giou_enc_0: 1.2708 (1.2252)  loss_vfl: 1.0164 (1.0975)  loss_vfl_aux_0: 0.9495 (1.0750)  loss_vfl_aux_1: 0.9758 (1.0824)  loss_vfl_aux_2: 0.9968 (1.0884)  loss_vfl_aux_3: 0.9983 (1.0877)  loss_vfl_aux_4: 1.0083 (1.0924)  loss_vfl_dn_0: 0.4952 (0.5038)  loss_vfl_dn_1: 0.4926 (0.5136)  loss_vfl_dn_2: 0.5027 (0.5221)  loss_vfl_dn_3: 0.4987 (0.5266)  loss_vfl_dn_4: 0.5039 (0.5346)  loss_vfl_dn_5: 0.5072 (0.5429)  loss_vfl_enc_0: 0.9055 (0.9915)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.4349  data: 1.4261  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0862  data: 0.2248  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1016 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.031\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.053\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.034\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.042\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.065\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.125\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.210\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.222\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.070\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.282\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.291\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.332\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.230\r\n",
      "best_stat: {'epoch': 22, 'coco_eval_bbox': 0.03089111775811811}\r\n",
      "Epoch: [23]  [ 0/79]  eta: 0:05:37  lr: 0.000010  loss: 30.5865 (30.5865)  loss_bbox: 0.3848 (0.3848)  loss_bbox_aux_0: 0.3613 (0.3613)  loss_bbox_aux_1: 0.4015 (0.4015)  loss_bbox_aux_2: 0.3814 (0.3814)  loss_bbox_aux_3: 0.3862 (0.3862)  loss_bbox_aux_4: 0.3991 (0.3991)  loss_bbox_dn_0: 0.4918 (0.4918)  loss_bbox_dn_1: 0.4435 (0.4435)  loss_bbox_dn_2: 0.4291 (0.4291)  loss_bbox_dn_3: 0.4202 (0.4202)  loss_bbox_dn_4: 0.4169 (0.4169)  loss_bbox_dn_5: 0.4170 (0.4170)  loss_bbox_enc_0: 0.4256 (0.4256)  loss_giou: 1.2595 (1.2595)  loss_giou_aux_0: 1.2614 (1.2614)  loss_giou_aux_1: 1.2695 (1.2695)  loss_giou_aux_2: 1.2777 (1.2777)  loss_giou_aux_3: 1.2421 (1.2421)  loss_giou_aux_4: 1.2742 (1.2742)  loss_giou_dn_0: 1.1865 (1.1865)  loss_giou_dn_1: 1.1005 (1.1005)  loss_giou_dn_2: 1.0602 (1.0602)  loss_giou_dn_3: 1.0410 (1.0410)  loss_giou_dn_4: 1.0368 (1.0368)  loss_giou_dn_5: 1.0377 (1.0377)  loss_giou_enc_0: 1.3386 (1.3386)  loss_vfl: 0.9583 (0.9583)  loss_vfl_aux_0: 1.0613 (1.0613)  loss_vfl_aux_1: 1.0007 (1.0007)  loss_vfl_aux_2: 1.0037 (1.0037)  loss_vfl_aux_3: 1.0015 (1.0015)  loss_vfl_aux_4: 0.9546 (0.9546)  loss_vfl_dn_0: 0.4739 (0.4739)  loss_vfl_dn_1: 0.4869 (0.4869)  loss_vfl_dn_2: 0.4917 (0.4917)  loss_vfl_dn_3: 0.4983 (0.4983)  loss_vfl_dn_4: 0.5028 (0.5028)  loss_vfl_dn_5: 0.5024 (0.5024)  loss_vfl_enc_0: 0.9065 (0.9065)  time: 4.2687  data: 2.7907  max mem: 10356\r\n",
      "Epoch: [23]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 28.4388 (28.9970)  loss_bbox: 0.3105 (0.3308)  loss_bbox_aux_0: 0.3743 (0.3639)  loss_bbox_aux_1: 0.3564 (0.3465)  loss_bbox_aux_2: 0.3320 (0.3428)  loss_bbox_aux_3: 0.3206 (0.3360)  loss_bbox_aux_4: 0.3044 (0.3316)  loss_bbox_dn_0: 0.3807 (0.3871)  loss_bbox_dn_1: 0.3455 (0.3454)  loss_bbox_dn_2: 0.3371 (0.3326)  loss_bbox_dn_3: 0.3330 (0.3270)  loss_bbox_dn_4: 0.3340 (0.3250)  loss_bbox_dn_5: 0.3339 (0.3250)  loss_bbox_enc_0: 0.4263 (0.4183)  loss_giou: 0.9744 (1.0939)  loss_giou_aux_0: 1.0447 (1.1548)  loss_giou_aux_1: 1.0107 (1.1246)  loss_giou_aux_2: 0.9640 (1.1086)  loss_giou_aux_3: 0.9530 (1.1070)  loss_giou_aux_4: 0.9594 (1.0982)  loss_giou_dn_0: 1.0895 (1.1043)  loss_giou_dn_1: 0.9800 (1.0149)  loss_giou_dn_2: 0.9404 (0.9835)  loss_giou_dn_3: 0.9227 (0.9718)  loss_giou_dn_4: 0.9255 (0.9652)  loss_giou_dn_5: 0.9247 (0.9657)  loss_giou_enc_0: 1.1484 (1.2383)  loss_vfl: 1.1284 (1.0803)  loss_vfl_aux_0: 1.1016 (1.0580)  loss_vfl_aux_1: 1.1331 (1.0715)  loss_vfl_aux_2: 1.1670 (1.0779)  loss_vfl_aux_3: 1.0923 (1.0717)  loss_vfl_aux_4: 1.1257 (1.0835)  loss_vfl_dn_0: 0.5067 (0.5016)  loss_vfl_dn_1: 0.5120 (0.5144)  loss_vfl_dn_2: 0.5276 (0.5229)  loss_vfl_dn_3: 0.5294 (0.5266)  loss_vfl_dn_4: 0.5411 (0.5362)  loss_vfl_dn_5: 0.5505 (0.5416)  loss_vfl_enc_0: 0.9741 (0.9680)  time: 0.9494  data: 0.0322  max mem: 10356\r\n",
      "Epoch: [23] Total time: 0:01:25 (1.0796 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 28.4388 (28.9970)  loss_bbox: 0.3105 (0.3308)  loss_bbox_aux_0: 0.3743 (0.3639)  loss_bbox_aux_1: 0.3564 (0.3465)  loss_bbox_aux_2: 0.3320 (0.3428)  loss_bbox_aux_3: 0.3206 (0.3360)  loss_bbox_aux_4: 0.3044 (0.3316)  loss_bbox_dn_0: 0.3807 (0.3871)  loss_bbox_dn_1: 0.3455 (0.3454)  loss_bbox_dn_2: 0.3371 (0.3326)  loss_bbox_dn_3: 0.3330 (0.3270)  loss_bbox_dn_4: 0.3340 (0.3250)  loss_bbox_dn_5: 0.3339 (0.3250)  loss_bbox_enc_0: 0.4263 (0.4183)  loss_giou: 0.9744 (1.0939)  loss_giou_aux_0: 1.0447 (1.1548)  loss_giou_aux_1: 1.0107 (1.1246)  loss_giou_aux_2: 0.9640 (1.1086)  loss_giou_aux_3: 0.9530 (1.1070)  loss_giou_aux_4: 0.9594 (1.0982)  loss_giou_dn_0: 1.0895 (1.1043)  loss_giou_dn_1: 0.9800 (1.0149)  loss_giou_dn_2: 0.9404 (0.9835)  loss_giou_dn_3: 0.9227 (0.9718)  loss_giou_dn_4: 0.9255 (0.9652)  loss_giou_dn_5: 0.9247 (0.9657)  loss_giou_enc_0: 1.1484 (1.2383)  loss_vfl: 1.1284 (1.0803)  loss_vfl_aux_0: 1.1016 (1.0580)  loss_vfl_aux_1: 1.1331 (1.0715)  loss_vfl_aux_2: 1.1670 (1.0779)  loss_vfl_aux_3: 1.0923 (1.0717)  loss_vfl_aux_4: 1.1257 (1.0835)  loss_vfl_dn_0: 0.5067 (0.5016)  loss_vfl_dn_1: 0.5120 (0.5144)  loss_vfl_dn_2: 0.5276 (0.5229)  loss_vfl_dn_3: 0.5294 (0.5266)  loss_vfl_dn_4: 0.5411 (0.5362)  loss_vfl_dn_5: 0.5505 (0.5416)  loss_vfl_enc_0: 0.9741 (0.9680)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3578  data: 1.4108  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0854  data: 0.2291  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1036 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.025\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.038\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.023\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.033\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.060\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.135\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.222\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.233\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.069\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.344\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.301\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.339\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.239\r\n",
      "best_stat: {'epoch': 22, 'coco_eval_bbox': 0.03089111775811811}\r\n",
      "Epoch: [24]  [ 0/79]  eta: 0:05:40  lr: 0.000010  loss: 31.6772 (31.6772)  loss_bbox: 0.4451 (0.4451)  loss_bbox_aux_0: 0.5083 (0.5083)  loss_bbox_aux_1: 0.4757 (0.4757)  loss_bbox_aux_2: 0.4483 (0.4483)  loss_bbox_aux_3: 0.4591 (0.4591)  loss_bbox_aux_4: 0.4806 (0.4806)  loss_bbox_dn_0: 0.5040 (0.5040)  loss_bbox_dn_1: 0.4675 (0.4675)  loss_bbox_dn_2: 0.4563 (0.4563)  loss_bbox_dn_3: 0.4483 (0.4483)  loss_bbox_dn_4: 0.4410 (0.4410)  loss_bbox_dn_5: 0.4406 (0.4406)  loss_bbox_enc_0: 0.5661 (0.5661)  loss_giou: 1.3995 (1.3995)  loss_giou_aux_0: 1.3773 (1.3773)  loss_giou_aux_1: 1.3990 (1.3990)  loss_giou_aux_2: 1.3974 (1.3974)  loss_giou_aux_3: 1.3762 (1.3762)  loss_giou_aux_4: 1.3676 (1.3676)  loss_giou_dn_0: 1.1946 (1.1946)  loss_giou_dn_1: 1.1342 (1.1342)  loss_giou_dn_2: 1.1139 (1.1139)  loss_giou_dn_3: 1.1058 (1.1058)  loss_giou_dn_4: 1.0980 (1.0980)  loss_giou_dn_5: 1.0990 (1.0990)  loss_giou_enc_0: 1.4532 (1.4532)  loss_vfl: 0.8911 (0.8911)  loss_vfl_aux_0: 0.8772 (0.8772)  loss_vfl_aux_1: 0.8882 (0.8882)  loss_vfl_aux_2: 0.9067 (0.9067)  loss_vfl_aux_3: 0.9131 (0.9131)  loss_vfl_aux_4: 0.8843 (0.8843)  loss_vfl_dn_0: 0.4674 (0.4674)  loss_vfl_dn_1: 0.4734 (0.4734)  loss_vfl_dn_2: 0.4735 (0.4735)  loss_vfl_dn_3: 0.4698 (0.4698)  loss_vfl_dn_4: 0.4800 (0.4800)  loss_vfl_dn_5: 0.4905 (0.4905)  loss_vfl_enc_0: 0.8054 (0.8054)  time: 4.3044  data: 2.2090  max mem: 10356\r\n",
      "Epoch: [24]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 28.3372 (28.9523)  loss_bbox: 0.2812 (0.3236)  loss_bbox_aux_0: 0.3303 (0.3651)  loss_bbox_aux_1: 0.3195 (0.3430)  loss_bbox_aux_2: 0.3108 (0.3353)  loss_bbox_aux_3: 0.2856 (0.3303)  loss_bbox_aux_4: 0.2911 (0.3259)  loss_bbox_dn_0: 0.3305 (0.3892)  loss_bbox_dn_1: 0.2723 (0.3464)  loss_bbox_dn_2: 0.2593 (0.3317)  loss_bbox_dn_3: 0.2517 (0.3259)  loss_bbox_dn_4: 0.2517 (0.3235)  loss_bbox_dn_5: 0.2514 (0.3234)  loss_bbox_enc_0: 0.3450 (0.4171)  loss_giou: 1.0102 (1.0865)  loss_giou_aux_0: 1.1006 (1.1406)  loss_giou_aux_1: 1.0709 (1.1100)  loss_giou_aux_2: 1.0516 (1.0936)  loss_giou_aux_3: 1.0474 (1.0920)  loss_giou_aux_4: 1.0348 (1.0858)  loss_giou_dn_0: 1.0823 (1.0923)  loss_giou_dn_1: 1.0046 (1.0027)  loss_giou_dn_2: 0.9568 (0.9701)  loss_giou_dn_3: 0.9416 (0.9577)  loss_giou_dn_4: 0.9279 (0.9510)  loss_giou_dn_5: 0.9286 (0.9513)  loss_giou_enc_0: 1.2221 (1.2421)  loss_vfl: 1.1748 (1.0987)  loss_vfl_aux_0: 1.1147 (1.0628)  loss_vfl_aux_1: 1.1904 (1.0951)  loss_vfl_aux_2: 1.1465 (1.0994)  loss_vfl_aux_3: 1.1895 (1.1010)  loss_vfl_aux_4: 1.2190 (1.1015)  loss_vfl_dn_0: 0.5151 (0.5091)  loss_vfl_dn_1: 0.5165 (0.5186)  loss_vfl_dn_2: 0.5251 (0.5249)  loss_vfl_dn_3: 0.5334 (0.5296)  loss_vfl_dn_4: 0.5447 (0.5394)  loss_vfl_dn_5: 0.5551 (0.5443)  loss_vfl_enc_0: 1.0347 (0.9714)  time: 1.0060  data: 0.0307  max mem: 10356\r\n",
      "Epoch: [24] Total time: 0:01:27 (1.1111 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 28.3372 (28.9523)  loss_bbox: 0.2812 (0.3236)  loss_bbox_aux_0: 0.3303 (0.3651)  loss_bbox_aux_1: 0.3195 (0.3430)  loss_bbox_aux_2: 0.3108 (0.3353)  loss_bbox_aux_3: 0.2856 (0.3303)  loss_bbox_aux_4: 0.2911 (0.3259)  loss_bbox_dn_0: 0.3305 (0.3892)  loss_bbox_dn_1: 0.2723 (0.3464)  loss_bbox_dn_2: 0.2593 (0.3317)  loss_bbox_dn_3: 0.2517 (0.3259)  loss_bbox_dn_4: 0.2517 (0.3235)  loss_bbox_dn_5: 0.2514 (0.3234)  loss_bbox_enc_0: 0.3450 (0.4171)  loss_giou: 1.0102 (1.0865)  loss_giou_aux_0: 1.1006 (1.1406)  loss_giou_aux_1: 1.0709 (1.1100)  loss_giou_aux_2: 1.0516 (1.0936)  loss_giou_aux_3: 1.0474 (1.0920)  loss_giou_aux_4: 1.0348 (1.0858)  loss_giou_dn_0: 1.0823 (1.0923)  loss_giou_dn_1: 1.0046 (1.0027)  loss_giou_dn_2: 0.9568 (0.9701)  loss_giou_dn_3: 0.9416 (0.9577)  loss_giou_dn_4: 0.9279 (0.9510)  loss_giou_dn_5: 0.9286 (0.9513)  loss_giou_enc_0: 1.2221 (1.2421)  loss_vfl: 1.1748 (1.0987)  loss_vfl_aux_0: 1.1147 (1.0628)  loss_vfl_aux_1: 1.1904 (1.0951)  loss_vfl_aux_2: 1.1465 (1.0994)  loss_vfl_aux_3: 1.1895 (1.1010)  loss_vfl_aux_4: 1.2190 (1.1015)  loss_vfl_dn_0: 0.5151 (0.5091)  loss_vfl_dn_1: 0.5165 (0.5186)  loss_vfl_dn_2: 0.5251 (0.5249)  loss_vfl_dn_3: 0.5334 (0.5296)  loss_vfl_dn_4: 0.5447 (0.5394)  loss_vfl_dn_5: 0.5551 (0.5443)  loss_vfl_enc_0: 1.0347 (0.9714)\r\n",
      "Test:  [0/8]  eta: 0:00:16    time: 2.1158  data: 1.1854  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0680  data: 0.2090  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0859 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.039\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.056\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.046\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.054\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.071\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.158\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.212\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.223\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.054\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.309\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.315\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.319\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.242\r\n",
      "best_stat: {'epoch': 24, 'coco_eval_bbox': 0.039259803584229806}\r\n",
      "Epoch: [25]  [ 0/79]  eta: 0:05:13  lr: 0.000010  loss: 27.7060 (27.7060)  loss_bbox: 0.3009 (0.3009)  loss_bbox_aux_0: 0.2873 (0.2873)  loss_bbox_aux_1: 0.2894 (0.2894)  loss_bbox_aux_2: 0.2897 (0.2897)  loss_bbox_aux_3: 0.2907 (0.2907)  loss_bbox_aux_4: 0.2910 (0.2910)  loss_bbox_dn_0: 0.1976 (0.1976)  loss_bbox_dn_1: 0.1800 (0.1800)  loss_bbox_dn_2: 0.1743 (0.1743)  loss_bbox_dn_3: 0.1725 (0.1725)  loss_bbox_dn_4: 0.1708 (0.1708)  loss_bbox_dn_5: 0.1708 (0.1708)  loss_bbox_enc_0: 0.2897 (0.2897)  loss_giou: 1.2802 (1.2802)  loss_giou_aux_0: 1.3413 (1.3413)  loss_giou_aux_1: 1.3342 (1.3342)  loss_giou_aux_2: 1.2837 (1.2837)  loss_giou_aux_3: 1.2796 (1.2796)  loss_giou_aux_4: 1.2777 (1.2777)  loss_giou_dn_0: 1.1149 (1.1149)  loss_giou_dn_1: 1.0409 (1.0409)  loss_giou_dn_2: 1.0134 (1.0134)  loss_giou_dn_3: 1.0080 (1.0080)  loss_giou_dn_4: 0.9988 (0.9988)  loss_giou_dn_5: 0.9985 (0.9985)  loss_giou_enc_0: 1.3917 (1.3917)  loss_vfl: 0.8738 (0.8738)  loss_vfl_aux_0: 0.8655 (0.8655)  loss_vfl_aux_1: 0.8503 (0.8503)  loss_vfl_aux_2: 0.9199 (0.9199)  loss_vfl_aux_3: 0.9109 (0.9109)  loss_vfl_aux_4: 0.8958 (0.8958)  loss_vfl_dn_0: 0.5018 (0.5018)  loss_vfl_dn_1: 0.4962 (0.4962)  loss_vfl_dn_2: 0.5148 (0.5148)  loss_vfl_dn_3: 0.5234 (0.5234)  loss_vfl_dn_4: 0.5238 (0.5238)  loss_vfl_dn_5: 0.5345 (0.5345)  loss_vfl_enc_0: 0.8276 (0.8276)  time: 3.9688  data: 2.6908  max mem: 10356\r\n",
      "Epoch: [25]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 28.9086 (28.7711)  loss_bbox: 0.2978 (0.3251)  loss_bbox_aux_0: 0.3314 (0.3623)  loss_bbox_aux_1: 0.3212 (0.3393)  loss_bbox_aux_2: 0.3135 (0.3318)  loss_bbox_aux_3: 0.3022 (0.3310)  loss_bbox_aux_4: 0.3010 (0.3293)  loss_bbox_dn_0: 0.3932 (0.3864)  loss_bbox_dn_1: 0.3385 (0.3440)  loss_bbox_dn_2: 0.3243 (0.3292)  loss_bbox_dn_3: 0.3073 (0.3236)  loss_bbox_dn_4: 0.2992 (0.3212)  loss_bbox_dn_5: 0.2990 (0.3212)  loss_bbox_enc_0: 0.4234 (0.4160)  loss_giou: 1.0480 (1.0804)  loss_giou_aux_0: 1.0711 (1.1292)  loss_giou_aux_1: 1.0584 (1.1046)  loss_giou_aux_2: 1.0630 (1.0944)  loss_giou_aux_3: 1.0699 (1.0893)  loss_giou_aux_4: 1.0588 (1.0833)  loss_giou_dn_0: 1.0709 (1.0908)  loss_giou_dn_1: 0.9922 (0.9995)  loss_giou_dn_2: 0.9554 (0.9666)  loss_giou_dn_3: 0.9411 (0.9550)  loss_giou_dn_4: 0.9336 (0.9481)  loss_giou_dn_5: 0.9339 (0.9485)  loss_giou_enc_0: 1.1814 (1.2236)  loss_vfl: 1.0381 (1.0777)  loss_vfl_aux_0: 1.0496 (1.0657)  loss_vfl_aux_1: 1.0706 (1.0851)  loss_vfl_aux_2: 1.0442 (1.0759)  loss_vfl_aux_3: 1.0720 (1.0793)  loss_vfl_aux_4: 1.0615 (1.0753)  loss_vfl_dn_0: 0.5001 (0.5088)  loss_vfl_dn_1: 0.5146 (0.5201)  loss_vfl_dn_2: 0.5216 (0.5259)  loss_vfl_dn_3: 0.5227 (0.5282)  loss_vfl_dn_4: 0.5403 (0.5375)  loss_vfl_dn_5: 0.5464 (0.5409)  loss_vfl_enc_0: 0.9741 (0.9770)  time: 0.9654  data: 0.0327  max mem: 10356\r\n",
      "Epoch: [25] Total time: 0:01:22 (1.0468 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 28.9086 (28.7711)  loss_bbox: 0.2978 (0.3251)  loss_bbox_aux_0: 0.3314 (0.3623)  loss_bbox_aux_1: 0.3212 (0.3393)  loss_bbox_aux_2: 0.3135 (0.3318)  loss_bbox_aux_3: 0.3022 (0.3310)  loss_bbox_aux_4: 0.3010 (0.3293)  loss_bbox_dn_0: 0.3932 (0.3864)  loss_bbox_dn_1: 0.3385 (0.3440)  loss_bbox_dn_2: 0.3243 (0.3292)  loss_bbox_dn_3: 0.3073 (0.3236)  loss_bbox_dn_4: 0.2992 (0.3212)  loss_bbox_dn_5: 0.2990 (0.3212)  loss_bbox_enc_0: 0.4234 (0.4160)  loss_giou: 1.0480 (1.0804)  loss_giou_aux_0: 1.0711 (1.1292)  loss_giou_aux_1: 1.0584 (1.1046)  loss_giou_aux_2: 1.0630 (1.0944)  loss_giou_aux_3: 1.0699 (1.0893)  loss_giou_aux_4: 1.0588 (1.0833)  loss_giou_dn_0: 1.0709 (1.0908)  loss_giou_dn_1: 0.9922 (0.9995)  loss_giou_dn_2: 0.9554 (0.9666)  loss_giou_dn_3: 0.9411 (0.9550)  loss_giou_dn_4: 0.9336 (0.9481)  loss_giou_dn_5: 0.9339 (0.9485)  loss_giou_enc_0: 1.1814 (1.2236)  loss_vfl: 1.0381 (1.0777)  loss_vfl_aux_0: 1.0496 (1.0657)  loss_vfl_aux_1: 1.0706 (1.0851)  loss_vfl_aux_2: 1.0442 (1.0759)  loss_vfl_aux_3: 1.0720 (1.0793)  loss_vfl_aux_4: 1.0615 (1.0753)  loss_vfl_dn_0: 0.5001 (0.5088)  loss_vfl_dn_1: 0.5146 (0.5201)  loss_vfl_dn_2: 0.5216 (0.5259)  loss_vfl_dn_3: 0.5227 (0.5282)  loss_vfl_dn_4: 0.5403 (0.5375)  loss_vfl_dn_5: 0.5464 (0.5409)  loss_vfl_enc_0: 0.9741 (0.9770)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.2713  data: 1.3473  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0754  data: 0.2201  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0920 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.033\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.046\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.033\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.050\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.062\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.161\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.223\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.237\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.080\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.317\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.306\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.350\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.251\r\n",
      "best_stat: {'epoch': 24, 'coco_eval_bbox': 0.039259803584229806}\r\n",
      "Epoch: [26]  [ 0/79]  eta: 0:06:34  lr: 0.000010  loss: 27.8128 (27.8128)  loss_bbox: 0.2172 (0.2172)  loss_bbox_aux_0: 0.2783 (0.2783)  loss_bbox_aux_1: 0.2394 (0.2394)  loss_bbox_aux_2: 0.2220 (0.2220)  loss_bbox_aux_3: 0.2137 (0.2137)  loss_bbox_aux_4: 0.2228 (0.2228)  loss_bbox_dn_0: 0.4670 (0.4670)  loss_bbox_dn_1: 0.3751 (0.3751)  loss_bbox_dn_2: 0.3485 (0.3485)  loss_bbox_dn_3: 0.3397 (0.3397)  loss_bbox_dn_4: 0.3335 (0.3335)  loss_bbox_dn_5: 0.3331 (0.3331)  loss_bbox_enc_0: 0.3943 (0.3943)  loss_giou: 0.7952 (0.7952)  loss_giou_aux_0: 0.9065 (0.9065)  loss_giou_aux_1: 0.8429 (0.8429)  loss_giou_aux_2: 0.8126 (0.8126)  loss_giou_aux_3: 0.7996 (0.7996)  loss_giou_aux_4: 0.8008 (0.8008)  loss_giou_dn_0: 0.9853 (0.9853)  loss_giou_dn_1: 0.8525 (0.8525)  loss_giou_dn_2: 0.8072 (0.8072)  loss_giou_dn_3: 0.7953 (0.7953)  loss_giou_dn_4: 0.7907 (0.7907)  loss_giou_dn_5: 0.7900 (0.7900)  loss_giou_enc_0: 1.0727 (1.0727)  loss_vfl: 1.3313 (1.3313)  loss_vfl_aux_0: 1.3628 (1.3628)  loss_vfl_aux_1: 1.3872 (1.3872)  loss_vfl_aux_2: 1.3953 (1.3953)  loss_vfl_aux_3: 1.3669 (1.3669)  loss_vfl_aux_4: 1.3315 (1.3315)  loss_vfl_dn_0: 0.5739 (0.5739)  loss_vfl_dn_1: 0.5756 (0.5756)  loss_vfl_dn_2: 0.5699 (0.5699)  loss_vfl_dn_3: 0.5497 (0.5497)  loss_vfl_dn_4: 0.5656 (0.5656)  loss_vfl_dn_5: 0.5555 (0.5555)  loss_vfl_enc_0: 1.2117 (1.2117)  time: 4.9879  data: 3.2964  max mem: 10356\r\n",
      "Epoch: [26]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 28.6814 (28.7087)  loss_bbox: 0.3324 (0.3271)  loss_bbox_aux_0: 0.3414 (0.3614)  loss_bbox_aux_1: 0.3314 (0.3430)  loss_bbox_aux_2: 0.3423 (0.3366)  loss_bbox_aux_3: 0.3327 (0.3330)  loss_bbox_aux_4: 0.3240 (0.3299)  loss_bbox_dn_0: 0.4017 (0.3772)  loss_bbox_dn_1: 0.3621 (0.3334)  loss_bbox_dn_2: 0.3508 (0.3195)  loss_bbox_dn_3: 0.3525 (0.3142)  loss_bbox_dn_4: 0.3530 (0.3118)  loss_bbox_dn_5: 0.3529 (0.3117)  loss_bbox_enc_0: 0.4506 (0.4153)  loss_giou: 1.0836 (1.0830)  loss_giou_aux_0: 1.1606 (1.1394)  loss_giou_aux_1: 1.1324 (1.1135)  loss_giou_aux_2: 1.1141 (1.0979)  loss_giou_aux_3: 1.0859 (1.0913)  loss_giou_aux_4: 1.0857 (1.0873)  loss_giou_dn_0: 1.0856 (1.0847)  loss_giou_dn_1: 0.9937 (0.9926)  loss_giou_dn_2: 0.9547 (0.9584)  loss_giou_dn_3: 0.9414 (0.9467)  loss_giou_dn_4: 0.9398 (0.9393)  loss_giou_dn_5: 0.9396 (0.9396)  loss_giou_enc_0: 1.2179 (1.2312)  loss_vfl: 1.0632 (1.0786)  loss_vfl_aux_0: 1.0298 (1.0688)  loss_vfl_aux_1: 1.0562 (1.0781)  loss_vfl_aux_2: 1.0432 (1.0730)  loss_vfl_aux_3: 1.0415 (1.0757)  loss_vfl_aux_4: 1.0283 (1.0782)  loss_vfl_dn_0: 0.5081 (0.5102)  loss_vfl_dn_1: 0.5198 (0.5174)  loss_vfl_dn_2: 0.5256 (0.5251)  loss_vfl_dn_3: 0.5396 (0.5284)  loss_vfl_dn_4: 0.5459 (0.5375)  loss_vfl_dn_5: 0.5430 (0.5407)  loss_vfl_enc_0: 0.9540 (0.9782)  time: 0.9963  data: 0.0315  max mem: 10356\r\n",
      "Epoch: [26] Total time: 0:01:26 (1.0902 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 28.6814 (28.7087)  loss_bbox: 0.3324 (0.3271)  loss_bbox_aux_0: 0.3414 (0.3614)  loss_bbox_aux_1: 0.3314 (0.3430)  loss_bbox_aux_2: 0.3423 (0.3366)  loss_bbox_aux_3: 0.3327 (0.3330)  loss_bbox_aux_4: 0.3240 (0.3299)  loss_bbox_dn_0: 0.4017 (0.3772)  loss_bbox_dn_1: 0.3621 (0.3334)  loss_bbox_dn_2: 0.3508 (0.3195)  loss_bbox_dn_3: 0.3525 (0.3142)  loss_bbox_dn_4: 0.3530 (0.3118)  loss_bbox_dn_5: 0.3529 (0.3117)  loss_bbox_enc_0: 0.4506 (0.4153)  loss_giou: 1.0836 (1.0830)  loss_giou_aux_0: 1.1606 (1.1394)  loss_giou_aux_1: 1.1324 (1.1135)  loss_giou_aux_2: 1.1141 (1.0979)  loss_giou_aux_3: 1.0859 (1.0913)  loss_giou_aux_4: 1.0857 (1.0873)  loss_giou_dn_0: 1.0856 (1.0847)  loss_giou_dn_1: 0.9937 (0.9926)  loss_giou_dn_2: 0.9547 (0.9584)  loss_giou_dn_3: 0.9414 (0.9467)  loss_giou_dn_4: 0.9398 (0.9393)  loss_giou_dn_5: 0.9396 (0.9396)  loss_giou_enc_0: 1.2179 (1.2312)  loss_vfl: 1.0632 (1.0786)  loss_vfl_aux_0: 1.0298 (1.0688)  loss_vfl_aux_1: 1.0562 (1.0781)  loss_vfl_aux_2: 1.0432 (1.0730)  loss_vfl_aux_3: 1.0415 (1.0757)  loss_vfl_aux_4: 1.0283 (1.0782)  loss_vfl_dn_0: 0.5081 (0.5102)  loss_vfl_dn_1: 0.5198 (0.5174)  loss_vfl_dn_2: 0.5256 (0.5251)  loss_vfl_dn_3: 0.5396 (0.5284)  loss_vfl_dn_4: 0.5459 (0.5375)  loss_vfl_dn_5: 0.5430 (0.5407)  loss_vfl_enc_0: 0.9540 (0.9782)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.2139  data: 1.1958  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0806  data: 0.2092  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0988 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.27s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.040\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.050\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.043\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.064\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.054\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.233\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.248\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.052\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.315\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.342\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.274\r\n",
      "best_stat: {'epoch': 26, 'coco_eval_bbox': 0.040015483905037535}\r\n",
      "Epoch: [27]  [ 0/79]  eta: 0:04:50  lr: 0.000010  loss: 31.6402 (31.6402)  loss_bbox: 0.4219 (0.4219)  loss_bbox_aux_0: 0.4475 (0.4475)  loss_bbox_aux_1: 0.4200 (0.4200)  loss_bbox_aux_2: 0.4292 (0.4292)  loss_bbox_aux_3: 0.4375 (0.4375)  loss_bbox_aux_4: 0.4217 (0.4217)  loss_bbox_dn_0: 0.6212 (0.6212)  loss_bbox_dn_1: 0.5601 (0.5601)  loss_bbox_dn_2: 0.5341 (0.5341)  loss_bbox_dn_3: 0.5238 (0.5238)  loss_bbox_dn_4: 0.5231 (0.5231)  loss_bbox_dn_5: 0.5227 (0.5227)  loss_bbox_enc_0: 0.5239 (0.5239)  loss_giou: 0.8468 (0.8468)  loss_giou_aux_0: 0.9387 (0.9387)  loss_giou_aux_1: 0.8828 (0.8828)  loss_giou_aux_2: 0.8819 (0.8819)  loss_giou_aux_3: 0.8542 (0.8542)  loss_giou_aux_4: 0.8454 (0.8454)  loss_giou_dn_0: 1.0690 (1.0690)  loss_giou_dn_1: 0.9868 (0.9868)  loss_giou_dn_2: 0.9570 (0.9570)  loss_giou_dn_3: 0.9496 (0.9496)  loss_giou_dn_4: 0.9432 (0.9432)  loss_giou_dn_5: 0.9424 (0.9424)  loss_giou_enc_0: 1.0421 (1.0421)  loss_vfl: 1.3696 (1.3696)  loss_vfl_aux_0: 1.4277 (1.4277)  loss_vfl_aux_1: 1.3784 (1.3784)  loss_vfl_aux_2: 1.3706 (1.3706)  loss_vfl_aux_3: 1.3345 (1.3345)  loss_vfl_aux_4: 1.3784 (1.3784)  loss_vfl_dn_0: 0.5452 (0.5452)  loss_vfl_dn_1: 0.5792 (0.5792)  loss_vfl_dn_2: 0.6147 (0.6147)  loss_vfl_dn_3: 0.6106 (0.6106)  loss_vfl_dn_4: 0.6240 (0.6240)  loss_vfl_dn_5: 0.6184 (0.6184)  loss_vfl_enc_0: 1.2622 (1.2622)  time: 3.6722  data: 2.2647  max mem: 10356\r\n",
      "Epoch: [27]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 28.3596 (28.4840)  loss_bbox: 0.3026 (0.3140)  loss_bbox_aux_0: 0.3222 (0.3445)  loss_bbox_aux_1: 0.3039 (0.3247)  loss_bbox_aux_2: 0.2919 (0.3194)  loss_bbox_aux_3: 0.2829 (0.3169)  loss_bbox_aux_4: 0.2985 (0.3156)  loss_bbox_dn_0: 0.4160 (0.3644)  loss_bbox_dn_1: 0.3656 (0.3221)  loss_bbox_dn_2: 0.3359 (0.3072)  loss_bbox_dn_3: 0.3341 (0.3012)  loss_bbox_dn_4: 0.3256 (0.2984)  loss_bbox_dn_5: 0.3248 (0.2983)  loss_bbox_enc_0: 0.3985 (0.3983)  loss_giou: 0.9729 (1.0747)  loss_giou_aux_0: 1.0369 (1.1253)  loss_giou_aux_1: 1.0240 (1.0981)  loss_giou_aux_2: 0.9762 (1.0876)  loss_giou_aux_3: 0.9810 (1.0799)  loss_giou_aux_4: 0.9777 (1.0759)  loss_giou_dn_0: 1.0579 (1.0817)  loss_giou_dn_1: 0.9594 (0.9873)  loss_giou_dn_2: 0.9298 (0.9528)  loss_giou_dn_3: 0.9229 (0.9405)  loss_giou_dn_4: 0.9138 (0.9336)  loss_giou_dn_5: 0.9136 (0.9340)  loss_giou_enc_0: 1.1598 (1.2158)  loss_vfl: 1.0547 (1.0781)  loss_vfl_aux_0: 1.1597 (1.0831)  loss_vfl_aux_1: 1.1392 (1.0914)  loss_vfl_aux_2: 1.1189 (1.0894)  loss_vfl_aux_3: 1.0605 (1.0848)  loss_vfl_aux_4: 1.0479 (1.0815)  loss_vfl_dn_0: 0.5272 (0.5139)  loss_vfl_dn_1: 0.5261 (0.5229)  loss_vfl_dn_2: 0.5400 (0.5281)  loss_vfl_dn_3: 0.5410 (0.5282)  loss_vfl_dn_4: 0.5491 (0.5391)  loss_vfl_dn_5: 0.5474 (0.5424)  loss_vfl_enc_0: 1.0554 (0.9888)  time: 0.9889  data: 0.0306  max mem: 10356\r\n",
      "Epoch: [27] Total time: 0:01:24 (1.0759 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 28.3596 (28.4840)  loss_bbox: 0.3026 (0.3140)  loss_bbox_aux_0: 0.3222 (0.3445)  loss_bbox_aux_1: 0.3039 (0.3247)  loss_bbox_aux_2: 0.2919 (0.3194)  loss_bbox_aux_3: 0.2829 (0.3169)  loss_bbox_aux_4: 0.2985 (0.3156)  loss_bbox_dn_0: 0.4160 (0.3644)  loss_bbox_dn_1: 0.3656 (0.3221)  loss_bbox_dn_2: 0.3359 (0.3072)  loss_bbox_dn_3: 0.3341 (0.3012)  loss_bbox_dn_4: 0.3256 (0.2984)  loss_bbox_dn_5: 0.3248 (0.2983)  loss_bbox_enc_0: 0.3985 (0.3983)  loss_giou: 0.9729 (1.0747)  loss_giou_aux_0: 1.0369 (1.1253)  loss_giou_aux_1: 1.0240 (1.0981)  loss_giou_aux_2: 0.9762 (1.0876)  loss_giou_aux_3: 0.9810 (1.0799)  loss_giou_aux_4: 0.9777 (1.0759)  loss_giou_dn_0: 1.0579 (1.0817)  loss_giou_dn_1: 0.9594 (0.9873)  loss_giou_dn_2: 0.9298 (0.9528)  loss_giou_dn_3: 0.9229 (0.9405)  loss_giou_dn_4: 0.9138 (0.9336)  loss_giou_dn_5: 0.9136 (0.9340)  loss_giou_enc_0: 1.1598 (1.2158)  loss_vfl: 1.0547 (1.0781)  loss_vfl_aux_0: 1.1597 (1.0831)  loss_vfl_aux_1: 1.1392 (1.0914)  loss_vfl_aux_2: 1.1189 (1.0894)  loss_vfl_aux_3: 1.0605 (1.0848)  loss_vfl_aux_4: 1.0479 (1.0815)  loss_vfl_dn_0: 0.5272 (0.5139)  loss_vfl_dn_1: 0.5261 (0.5229)  loss_vfl_dn_2: 0.5400 (0.5281)  loss_vfl_dn_3: 0.5410 (0.5282)  loss_vfl_dn_4: 0.5491 (0.5391)  loss_vfl_dn_5: 0.5474 (0.5424)  loss_vfl_enc_0: 1.0554 (0.9888)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3455  data: 1.4168  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0752  data: 0.2228  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0920 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.17s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.043\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.057\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.045\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.056\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.073\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.165\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.242\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.258\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.067\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.338\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.368\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.369\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.281\r\n",
      "best_stat: {'epoch': 27, 'coco_eval_bbox': 0.04273355443776344}\r\n",
      "Epoch: [28]  [ 0/79]  eta: 0:04:35  lr: 0.000010  loss: 30.3336 (30.3336)  loss_bbox: 0.4665 (0.4665)  loss_bbox_aux_0: 0.5344 (0.5344)  loss_bbox_aux_1: 0.5053 (0.5053)  loss_bbox_aux_2: 0.4611 (0.4611)  loss_bbox_aux_3: 0.4654 (0.4654)  loss_bbox_aux_4: 0.4603 (0.4603)  loss_bbox_dn_0: 0.2919 (0.2919)  loss_bbox_dn_1: 0.2592 (0.2592)  loss_bbox_dn_2: 0.2508 (0.2508)  loss_bbox_dn_3: 0.2494 (0.2494)  loss_bbox_dn_4: 0.2515 (0.2515)  loss_bbox_dn_5: 0.2517 (0.2517)  loss_bbox_enc_0: 0.5752 (0.5752)  loss_giou: 1.6350 (1.6350)  loss_giou_aux_0: 1.6717 (1.6717)  loss_giou_aux_1: 1.6532 (1.6532)  loss_giou_aux_2: 1.6422 (1.6422)  loss_giou_aux_3: 1.6437 (1.6437)  loss_giou_aux_4: 1.6470 (1.6470)  loss_giou_dn_0: 1.2556 (1.2556)  loss_giou_dn_1: 1.2170 (1.2170)  loss_giou_dn_2: 1.2083 (1.2083)  loss_giou_dn_3: 1.2023 (1.2023)  loss_giou_dn_4: 1.2036 (1.2036)  loss_giou_dn_5: 1.2032 (1.2032)  loss_giou_enc_0: 1.6691 (1.6691)  loss_vfl: 0.5957 (0.5957)  loss_vfl_aux_0: 0.5225 (0.5225)  loss_vfl_aux_1: 0.5416 (0.5416)  loss_vfl_aux_2: 0.5867 (0.5867)  loss_vfl_aux_3: 0.6028 (0.6028)  loss_vfl_aux_4: 0.5928 (0.5928)  loss_vfl_dn_0: 0.4124 (0.4124)  loss_vfl_dn_1: 0.4108 (0.4108)  loss_vfl_dn_2: 0.4143 (0.4143)  loss_vfl_dn_3: 0.4200 (0.4200)  loss_vfl_dn_4: 0.4241 (0.4241)  loss_vfl_dn_5: 0.4330 (0.4330)  loss_vfl_enc_0: 0.5024 (0.5024)  time: 3.4826  data: 2.2832  max mem: 10356\r\n",
      "Epoch: [28]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 28.4272 (28.5514)  loss_bbox: 0.2895 (0.3157)  loss_bbox_aux_0: 0.3427 (0.3536)  loss_bbox_aux_1: 0.3257 (0.3323)  loss_bbox_aux_2: 0.3045 (0.3283)  loss_bbox_aux_3: 0.2974 (0.3222)  loss_bbox_aux_4: 0.2996 (0.3182)  loss_bbox_dn_0: 0.3781 (0.3878)  loss_bbox_dn_1: 0.3056 (0.3425)  loss_bbox_dn_2: 0.2872 (0.3267)  loss_bbox_dn_3: 0.2749 (0.3205)  loss_bbox_dn_4: 0.2709 (0.3175)  loss_bbox_dn_5: 0.2709 (0.3175)  loss_bbox_enc_0: 0.3889 (0.4115)  loss_giou: 1.0183 (1.0423)  loss_giou_aux_0: 1.1379 (1.0924)  loss_giou_aux_1: 1.0615 (1.0707)  loss_giou_aux_2: 1.0576 (1.0578)  loss_giou_aux_3: 1.0415 (1.0538)  loss_giou_aux_4: 1.0257 (1.0458)  loss_giou_dn_0: 1.0730 (1.0724)  loss_giou_dn_1: 0.9756 (0.9808)  loss_giou_dn_2: 0.9219 (0.9455)  loss_giou_dn_3: 0.9056 (0.9336)  loss_giou_dn_4: 0.8989 (0.9263)  loss_giou_dn_5: 0.8990 (0.9267)  loss_giou_enc_0: 1.1789 (1.1883)  loss_vfl: 1.0989 (1.1075)  loss_vfl_aux_0: 1.0444 (1.1061)  loss_vfl_aux_1: 1.0767 (1.1092)  loss_vfl_aux_2: 1.0508 (1.1022)  loss_vfl_aux_3: 1.0320 (1.0980)  loss_vfl_aux_4: 1.0737 (1.1024)  loss_vfl_dn_0: 0.5203 (0.5180)  loss_vfl_dn_1: 0.5291 (0.5224)  loss_vfl_dn_2: 0.5403 (0.5302)  loss_vfl_dn_3: 0.5449 (0.5325)  loss_vfl_dn_4: 0.5469 (0.5421)  loss_vfl_dn_5: 0.5560 (0.5453)  loss_vfl_enc_0: 0.9436 (1.0048)  time: 0.9914  data: 0.0302  max mem: 10356\r\n",
      "Epoch: [28] Total time: 0:01:23 (1.0580 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 28.4272 (28.5514)  loss_bbox: 0.2895 (0.3157)  loss_bbox_aux_0: 0.3427 (0.3536)  loss_bbox_aux_1: 0.3257 (0.3323)  loss_bbox_aux_2: 0.3045 (0.3283)  loss_bbox_aux_3: 0.2974 (0.3222)  loss_bbox_aux_4: 0.2996 (0.3182)  loss_bbox_dn_0: 0.3781 (0.3878)  loss_bbox_dn_1: 0.3056 (0.3425)  loss_bbox_dn_2: 0.2872 (0.3267)  loss_bbox_dn_3: 0.2749 (0.3205)  loss_bbox_dn_4: 0.2709 (0.3175)  loss_bbox_dn_5: 0.2709 (0.3175)  loss_bbox_enc_0: 0.3889 (0.4115)  loss_giou: 1.0183 (1.0423)  loss_giou_aux_0: 1.1379 (1.0924)  loss_giou_aux_1: 1.0615 (1.0707)  loss_giou_aux_2: 1.0576 (1.0578)  loss_giou_aux_3: 1.0415 (1.0538)  loss_giou_aux_4: 1.0257 (1.0458)  loss_giou_dn_0: 1.0730 (1.0724)  loss_giou_dn_1: 0.9756 (0.9808)  loss_giou_dn_2: 0.9219 (0.9455)  loss_giou_dn_3: 0.9056 (0.9336)  loss_giou_dn_4: 0.8989 (0.9263)  loss_giou_dn_5: 0.8990 (0.9267)  loss_giou_enc_0: 1.1789 (1.1883)  loss_vfl: 1.0989 (1.1075)  loss_vfl_aux_0: 1.0444 (1.1061)  loss_vfl_aux_1: 1.0767 (1.1092)  loss_vfl_aux_2: 1.0508 (1.1022)  loss_vfl_aux_3: 1.0320 (1.0980)  loss_vfl_aux_4: 1.0737 (1.1024)  loss_vfl_dn_0: 0.5203 (0.5180)  loss_vfl_dn_1: 0.5291 (0.5224)  loss_vfl_dn_2: 0.5403 (0.5302)  loss_vfl_dn_3: 0.5449 (0.5325)  loss_vfl_dn_4: 0.5469 (0.5421)  loss_vfl_dn_5: 0.5560 (0.5453)  loss_vfl_enc_0: 0.9436 (1.0048)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.1284  data: 1.1881  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0591  data: 0.2757  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0757 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.17s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.034\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.060\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.029\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.050\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.070\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.159\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.226\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.239\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.075\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.284\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.325\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.352\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.247\r\n",
      "best_stat: {'epoch': 27, 'coco_eval_bbox': 0.04273355443776344}\r\n",
      "Epoch: [29]  [ 0/79]  eta: 0:07:00  lr: 0.000010  loss: 27.2544 (27.2544)  loss_bbox: 0.2884 (0.2884)  loss_bbox_aux_0: 0.3155 (0.3155)  loss_bbox_aux_1: 0.3006 (0.3006)  loss_bbox_aux_2: 0.2574 (0.2574)  loss_bbox_aux_3: 0.2934 (0.2934)  loss_bbox_aux_4: 0.2843 (0.2843)  loss_bbox_dn_0: 0.1839 (0.1839)  loss_bbox_dn_1: 0.1433 (0.1433)  loss_bbox_dn_2: 0.1323 (0.1323)  loss_bbox_dn_3: 0.1233 (0.1233)  loss_bbox_dn_4: 0.1204 (0.1204)  loss_bbox_dn_5: 0.1203 (0.1203)  loss_bbox_enc_0: 0.3685 (0.3685)  loss_giou: 1.4177 (1.4177)  loss_giou_aux_0: 1.4499 (1.4499)  loss_giou_aux_1: 1.4508 (1.4508)  loss_giou_aux_2: 1.4712 (1.4712)  loss_giou_aux_3: 1.4066 (1.4066)  loss_giou_aux_4: 1.4098 (1.4098)  loss_giou_dn_0: 1.2106 (1.2106)  loss_giou_dn_1: 1.1377 (1.1377)  loss_giou_dn_2: 1.1166 (1.1166)  loss_giou_dn_3: 1.1028 (1.1028)  loss_giou_dn_4: 1.0943 (1.0943)  loss_giou_dn_5: 1.0964 (1.0964)  loss_giou_enc_0: 1.5277 (1.5277)  loss_vfl: 0.6484 (0.6484)  loss_vfl_aux_0: 0.7349 (0.7349)  loss_vfl_aux_1: 0.7021 (0.7021)  loss_vfl_aux_2: 0.6672 (0.6672)  loss_vfl_aux_3: 0.6765 (0.6765)  loss_vfl_aux_4: 0.7124 (0.7124)  loss_vfl_dn_0: 0.4420 (0.4420)  loss_vfl_dn_1: 0.4246 (0.4246)  loss_vfl_dn_2: 0.4293 (0.4293)  loss_vfl_dn_3: 0.4267 (0.4267)  loss_vfl_dn_4: 0.4400 (0.4400)  loss_vfl_dn_5: 0.4365 (0.4365)  loss_vfl_enc_0: 0.6899 (0.6899)  time: 5.3214  data: 3.7059  max mem: 10356\r\n",
      "Epoch: [29]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 28.7198 (28.6548)  loss_bbox: 0.3037 (0.3258)  loss_bbox_aux_0: 0.3480 (0.3642)  loss_bbox_aux_1: 0.3218 (0.3446)  loss_bbox_aux_2: 0.3234 (0.3362)  loss_bbox_aux_3: 0.3050 (0.3298)  loss_bbox_aux_4: 0.3074 (0.3258)  loss_bbox_dn_0: 0.3661 (0.3787)  loss_bbox_dn_1: 0.3253 (0.3317)  loss_bbox_dn_2: 0.3028 (0.3164)  loss_bbox_dn_3: 0.2900 (0.3104)  loss_bbox_dn_4: 0.2834 (0.3078)  loss_bbox_dn_5: 0.2836 (0.3078)  loss_bbox_enc_0: 0.4149 (0.4179)  loss_giou: 1.0013 (1.0827)  loss_giou_aux_0: 1.0670 (1.1338)  loss_giou_aux_1: 1.0272 (1.1117)  loss_giou_aux_2: 1.0118 (1.0910)  loss_giou_aux_3: 1.0092 (1.0850)  loss_giou_aux_4: 0.9976 (1.0819)  loss_giou_dn_0: 1.0464 (1.0764)  loss_giou_dn_1: 0.9351 (0.9775)  loss_giou_dn_2: 0.9013 (0.9435)  loss_giou_dn_3: 0.8913 (0.9306)  loss_giou_dn_4: 0.8927 (0.9231)  loss_giou_dn_5: 0.8922 (0.9233)  loss_giou_enc_0: 1.1521 (1.2232)  loss_vfl: 1.1240 (1.0741)  loss_vfl_aux_0: 1.0674 (1.0999)  loss_vfl_aux_1: 1.1118 (1.0816)  loss_vfl_aux_2: 1.0737 (1.0816)  loss_vfl_aux_3: 1.0781 (1.0837)  loss_vfl_aux_4: 1.1060 (1.0832)  loss_vfl_dn_0: 0.5338 (0.5189)  loss_vfl_dn_1: 0.5411 (0.5225)  loss_vfl_dn_2: 0.5377 (0.5275)  loss_vfl_dn_3: 0.5319 (0.5269)  loss_vfl_dn_4: 0.5410 (0.5336)  loss_vfl_dn_5: 0.5415 (0.5368)  loss_vfl_enc_0: 0.9744 (1.0036)  time: 1.0719  data: 0.0332  max mem: 10356\r\n",
      "Epoch: [29] Total time: 0:01:26 (1.1009 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 28.7198 (28.6548)  loss_bbox: 0.3037 (0.3258)  loss_bbox_aux_0: 0.3480 (0.3642)  loss_bbox_aux_1: 0.3218 (0.3446)  loss_bbox_aux_2: 0.3234 (0.3362)  loss_bbox_aux_3: 0.3050 (0.3298)  loss_bbox_aux_4: 0.3074 (0.3258)  loss_bbox_dn_0: 0.3661 (0.3787)  loss_bbox_dn_1: 0.3253 (0.3317)  loss_bbox_dn_2: 0.3028 (0.3164)  loss_bbox_dn_3: 0.2900 (0.3104)  loss_bbox_dn_4: 0.2834 (0.3078)  loss_bbox_dn_5: 0.2836 (0.3078)  loss_bbox_enc_0: 0.4149 (0.4179)  loss_giou: 1.0013 (1.0827)  loss_giou_aux_0: 1.0670 (1.1338)  loss_giou_aux_1: 1.0272 (1.1117)  loss_giou_aux_2: 1.0118 (1.0910)  loss_giou_aux_3: 1.0092 (1.0850)  loss_giou_aux_4: 0.9976 (1.0819)  loss_giou_dn_0: 1.0464 (1.0764)  loss_giou_dn_1: 0.9351 (0.9775)  loss_giou_dn_2: 0.9013 (0.9435)  loss_giou_dn_3: 0.8913 (0.9306)  loss_giou_dn_4: 0.8927 (0.9231)  loss_giou_dn_5: 0.8922 (0.9233)  loss_giou_enc_0: 1.1521 (1.2232)  loss_vfl: 1.1240 (1.0741)  loss_vfl_aux_0: 1.0674 (1.0999)  loss_vfl_aux_1: 1.1118 (1.0816)  loss_vfl_aux_2: 1.0737 (1.0816)  loss_vfl_aux_3: 1.0781 (1.0837)  loss_vfl_aux_4: 1.1060 (1.0832)  loss_vfl_dn_0: 0.5338 (0.5189)  loss_vfl_dn_1: 0.5411 (0.5225)  loss_vfl_dn_2: 0.5377 (0.5275)  loss_vfl_dn_3: 0.5319 (0.5269)  loss_vfl_dn_4: 0.5410 (0.5336)  loss_vfl_dn_5: 0.5415 (0.5368)  loss_vfl_enc_0: 0.9744 (1.0036)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.4446  data: 1.4186  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.1008  data: 0.2262  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1186 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.043\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.060\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.044\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.024\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.048\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.078\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.209\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.297\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.103\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.351\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.420\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.426\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.308\r\n",
      "best_stat: {'epoch': 27, 'coco_eval_bbox': 0.04273355443776344}\r\n",
      "Epoch: [30]  [ 0/79]  eta: 0:07:03  lr: 0.000010  loss: 29.2549 (29.2549)  loss_bbox: 0.3786 (0.3786)  loss_bbox_aux_0: 0.4078 (0.4078)  loss_bbox_aux_1: 0.3862 (0.3862)  loss_bbox_aux_2: 0.3799 (0.3799)  loss_bbox_aux_3: 0.3813 (0.3813)  loss_bbox_aux_4: 0.3788 (0.3788)  loss_bbox_dn_0: 0.2078 (0.2078)  loss_bbox_dn_1: 0.1737 (0.1737)  loss_bbox_dn_2: 0.1618 (0.1618)  loss_bbox_dn_3: 0.1563 (0.1563)  loss_bbox_dn_4: 0.1543 (0.1543)  loss_bbox_dn_5: 0.1544 (0.1544)  loss_bbox_enc_0: 0.4604 (0.4604)  loss_giou: 1.6713 (1.6713)  loss_giou_aux_0: 1.6704 (1.6704)  loss_giou_aux_1: 1.6615 (1.6615)  loss_giou_aux_2: 1.6681 (1.6681)  loss_giou_aux_3: 1.6682 (1.6682)  loss_giou_aux_4: 1.6708 (1.6708)  loss_giou_dn_0: 1.2001 (1.2001)  loss_giou_dn_1: 1.1206 (1.1206)  loss_giou_dn_2: 1.1065 (1.1065)  loss_giou_dn_3: 1.0968 (1.0968)  loss_giou_dn_4: 1.0952 (1.0952)  loss_giou_dn_5: 1.0962 (1.0962)  loss_giou_enc_0: 1.7373 (1.7373)  loss_vfl: 0.5786 (0.5786)  loss_vfl_aux_0: 0.6787 (0.6787)  loss_vfl_aux_1: 0.7029 (0.7029)  loss_vfl_aux_2: 0.6235 (0.6235)  loss_vfl_aux_3: 0.5771 (0.5771)  loss_vfl_aux_4: 0.5850 (0.5850)  loss_vfl_dn_0: 0.4366 (0.4366)  loss_vfl_dn_1: 0.4423 (0.4423)  loss_vfl_dn_2: 0.4305 (0.4305)  loss_vfl_dn_3: 0.4454 (0.4454)  loss_vfl_dn_4: 0.4484 (0.4484)  loss_vfl_dn_5: 0.4645 (0.4645)  loss_vfl_enc_0: 0.5972 (0.5972)  time: 5.3598  data: 3.5894  max mem: 10356\r\n",
      "Epoch: [30]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 27.9486 (28.2626)  loss_bbox: 0.2737 (0.3039)  loss_bbox_aux_0: 0.3155 (0.3386)  loss_bbox_aux_1: 0.3007 (0.3200)  loss_bbox_aux_2: 0.2929 (0.3126)  loss_bbox_aux_3: 0.2787 (0.3086)  loss_bbox_aux_4: 0.2856 (0.3056)  loss_bbox_dn_0: 0.3372 (0.3620)  loss_bbox_dn_1: 0.2902 (0.3143)  loss_bbox_dn_2: 0.2727 (0.2995)  loss_bbox_dn_3: 0.2615 (0.2931)  loss_bbox_dn_4: 0.2576 (0.2909)  loss_bbox_dn_5: 0.2575 (0.2909)  loss_bbox_enc_0: 0.3619 (0.3929)  loss_giou: 1.0450 (1.0669)  loss_giou_aux_0: 1.1267 (1.1265)  loss_giou_aux_1: 1.1022 (1.0980)  loss_giou_aux_2: 1.0751 (1.0783)  loss_giou_aux_3: 1.0577 (1.0780)  loss_giou_aux_4: 1.0568 (1.0743)  loss_giou_dn_0: 1.0710 (1.0744)  loss_giou_dn_1: 0.9927 (0.9790)  loss_giou_dn_2: 0.9557 (0.9460)  loss_giou_dn_3: 0.9393 (0.9341)  loss_giou_dn_4: 0.9254 (0.9279)  loss_giou_dn_5: 0.9249 (0.9283)  loss_giou_enc_0: 1.2149 (1.2123)  loss_vfl: 1.0933 (1.0765)  loss_vfl_aux_0: 0.9951 (1.0643)  loss_vfl_aux_1: 1.0811 (1.0883)  loss_vfl_aux_2: 1.0913 (1.0849)  loss_vfl_aux_3: 1.0942 (1.0750)  loss_vfl_aux_4: 1.0474 (1.0737)  loss_vfl_dn_0: 0.5343 (0.5191)  loss_vfl_dn_1: 0.5278 (0.5211)  loss_vfl_dn_2: 0.5127 (0.5249)  loss_vfl_dn_3: 0.5137 (0.5234)  loss_vfl_dn_4: 0.5200 (0.5312)  loss_vfl_dn_5: 0.5287 (0.5363)  loss_vfl_enc_0: 0.9207 (0.9869)  time: 0.9998  data: 0.0304  max mem: 10356\r\n",
      "Epoch: [30] Total time: 0:01:25 (1.0865 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 27.9486 (28.2626)  loss_bbox: 0.2737 (0.3039)  loss_bbox_aux_0: 0.3155 (0.3386)  loss_bbox_aux_1: 0.3007 (0.3200)  loss_bbox_aux_2: 0.2929 (0.3126)  loss_bbox_aux_3: 0.2787 (0.3086)  loss_bbox_aux_4: 0.2856 (0.3056)  loss_bbox_dn_0: 0.3372 (0.3620)  loss_bbox_dn_1: 0.2902 (0.3143)  loss_bbox_dn_2: 0.2727 (0.2995)  loss_bbox_dn_3: 0.2615 (0.2931)  loss_bbox_dn_4: 0.2576 (0.2909)  loss_bbox_dn_5: 0.2575 (0.2909)  loss_bbox_enc_0: 0.3619 (0.3929)  loss_giou: 1.0450 (1.0669)  loss_giou_aux_0: 1.1267 (1.1265)  loss_giou_aux_1: 1.1022 (1.0980)  loss_giou_aux_2: 1.0751 (1.0783)  loss_giou_aux_3: 1.0577 (1.0780)  loss_giou_aux_4: 1.0568 (1.0743)  loss_giou_dn_0: 1.0710 (1.0744)  loss_giou_dn_1: 0.9927 (0.9790)  loss_giou_dn_2: 0.9557 (0.9460)  loss_giou_dn_3: 0.9393 (0.9341)  loss_giou_dn_4: 0.9254 (0.9279)  loss_giou_dn_5: 0.9249 (0.9283)  loss_giou_enc_0: 1.2149 (1.2123)  loss_vfl: 1.0933 (1.0765)  loss_vfl_aux_0: 0.9951 (1.0643)  loss_vfl_aux_1: 1.0811 (1.0883)  loss_vfl_aux_2: 1.0913 (1.0849)  loss_vfl_aux_3: 1.0942 (1.0750)  loss_vfl_aux_4: 1.0474 (1.0737)  loss_vfl_dn_0: 0.5343 (0.5191)  loss_vfl_dn_1: 0.5278 (0.5211)  loss_vfl_dn_2: 0.5127 (0.5249)  loss_vfl_dn_3: 0.5137 (0.5234)  loss_vfl_dn_4: 0.5200 (0.5312)  loss_vfl_dn_5: 0.5287 (0.5363)  loss_vfl_enc_0: 0.9207 (0.9869)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.2376  data: 1.3124  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0673  data: 0.2152  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0838 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.29s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.047\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.063\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.052\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.059\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.074\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.168\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.244\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.258\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.066\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.339\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.348\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.367\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.278\r\n",
      "best_stat: {'epoch': 30, 'coco_eval_bbox': 0.04711764461710192}\r\n",
      "Epoch: [31]  [ 0/79]  eta: 0:05:02  lr: 0.000010  loss: 26.7126 (26.7126)  loss_bbox: 0.1880 (0.1880)  loss_bbox_aux_0: 0.2660 (0.2660)  loss_bbox_aux_1: 0.2409 (0.2409)  loss_bbox_aux_2: 0.2191 (0.2191)  loss_bbox_aux_3: 0.2077 (0.2077)  loss_bbox_aux_4: 0.1910 (0.1910)  loss_bbox_dn_0: 0.3473 (0.3473)  loss_bbox_dn_1: 0.2942 (0.2942)  loss_bbox_dn_2: 0.2760 (0.2760)  loss_bbox_dn_3: 0.2679 (0.2679)  loss_bbox_dn_4: 0.2649 (0.2649)  loss_bbox_dn_5: 0.2651 (0.2651)  loss_bbox_enc_0: 0.3156 (0.3156)  loss_giou: 0.9021 (0.9021)  loss_giou_aux_0: 1.0264 (1.0264)  loss_giou_aux_1: 0.9751 (0.9751)  loss_giou_aux_2: 0.9443 (0.9443)  loss_giou_aux_3: 0.9232 (0.9232)  loss_giou_aux_4: 0.9195 (0.9195)  loss_giou_dn_0: 1.0632 (1.0632)  loss_giou_dn_1: 0.9508 (0.9508)  loss_giou_dn_2: 0.8954 (0.8954)  loss_giou_dn_3: 0.8708 (0.8708)  loss_giou_dn_4: 0.8565 (0.8565)  loss_giou_dn_5: 0.8566 (0.8566)  loss_giou_enc_0: 1.1861 (1.1861)  loss_vfl: 1.1677 (1.1677)  loss_vfl_aux_0: 1.0522 (1.0522)  loss_vfl_aux_1: 1.1238 (1.1238)  loss_vfl_aux_2: 1.2095 (1.2095)  loss_vfl_aux_3: 1.1409 (1.1409)  loss_vfl_aux_4: 1.0972 (1.0972)  loss_vfl_dn_0: 0.5262 (0.5262)  loss_vfl_dn_1: 0.5244 (0.5244)  loss_vfl_dn_2: 0.5302 (0.5302)  loss_vfl_dn_3: 0.5275 (0.5275)  loss_vfl_dn_4: 0.5350 (0.5350)  loss_vfl_dn_5: 0.5452 (0.5452)  loss_vfl_enc_0: 1.0190 (1.0190)  time: 3.8270  data: 2.4348  max mem: 10356\r\n",
      "Epoch: [31]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 27.6027 (28.1474)  loss_bbox: 0.2648 (0.2941)  loss_bbox_aux_0: 0.3072 (0.3313)  loss_bbox_aux_1: 0.2928 (0.3128)  loss_bbox_aux_2: 0.2765 (0.3026)  loss_bbox_aux_3: 0.2661 (0.2992)  loss_bbox_aux_4: 0.2527 (0.2966)  loss_bbox_dn_0: 0.3815 (0.3720)  loss_bbox_dn_1: 0.3442 (0.3263)  loss_bbox_dn_2: 0.3109 (0.3116)  loss_bbox_dn_3: 0.3031 (0.3059)  loss_bbox_dn_4: 0.2930 (0.3036)  loss_bbox_dn_5: 0.2934 (0.3035)  loss_bbox_enc_0: 0.3683 (0.3833)  loss_giou: 1.0251 (1.0291)  loss_giou_aux_0: 1.0500 (1.0832)  loss_giou_aux_1: 1.0246 (1.0603)  loss_giou_aux_2: 1.0121 (1.0444)  loss_giou_aux_3: 1.0154 (1.0370)  loss_giou_aux_4: 1.0169 (1.0347)  loss_giou_dn_0: 1.0567 (1.0645)  loss_giou_dn_1: 0.9482 (0.9682)  loss_giou_dn_2: 0.9136 (0.9348)  loss_giou_dn_3: 0.8975 (0.9220)  loss_giou_dn_4: 0.8800 (0.9152)  loss_giou_dn_5: 0.8805 (0.9155)  loss_giou_enc_0: 1.1398 (1.1751)  loss_vfl: 0.9724 (1.1071)  loss_vfl_aux_0: 1.1206 (1.1077)  loss_vfl_aux_1: 1.0015 (1.1062)  loss_vfl_aux_2: 1.0134 (1.1147)  loss_vfl_aux_3: 0.9841 (1.1086)  loss_vfl_aux_4: 0.9719 (1.1030)  loss_vfl_dn_0: 0.5168 (0.5190)  loss_vfl_dn_1: 0.5139 (0.5193)  loss_vfl_dn_2: 0.5088 (0.5236)  loss_vfl_dn_3: 0.5103 (0.5247)  loss_vfl_dn_4: 0.5178 (0.5311)  loss_vfl_dn_5: 0.5148 (0.5325)  loss_vfl_enc_0: 1.0547 (1.0229)  time: 0.9671  data: 0.0315  max mem: 10356\r\n",
      "Epoch: [31] Total time: 0:01:23 (1.0611 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 27.6027 (28.1474)  loss_bbox: 0.2648 (0.2941)  loss_bbox_aux_0: 0.3072 (0.3313)  loss_bbox_aux_1: 0.2928 (0.3128)  loss_bbox_aux_2: 0.2765 (0.3026)  loss_bbox_aux_3: 0.2661 (0.2992)  loss_bbox_aux_4: 0.2527 (0.2966)  loss_bbox_dn_0: 0.3815 (0.3720)  loss_bbox_dn_1: 0.3442 (0.3263)  loss_bbox_dn_2: 0.3109 (0.3116)  loss_bbox_dn_3: 0.3031 (0.3059)  loss_bbox_dn_4: 0.2930 (0.3036)  loss_bbox_dn_5: 0.2934 (0.3035)  loss_bbox_enc_0: 0.3683 (0.3833)  loss_giou: 1.0251 (1.0291)  loss_giou_aux_0: 1.0500 (1.0832)  loss_giou_aux_1: 1.0246 (1.0603)  loss_giou_aux_2: 1.0121 (1.0444)  loss_giou_aux_3: 1.0154 (1.0370)  loss_giou_aux_4: 1.0169 (1.0347)  loss_giou_dn_0: 1.0567 (1.0645)  loss_giou_dn_1: 0.9482 (0.9682)  loss_giou_dn_2: 0.9136 (0.9348)  loss_giou_dn_3: 0.8975 (0.9220)  loss_giou_dn_4: 0.8800 (0.9152)  loss_giou_dn_5: 0.8805 (0.9155)  loss_giou_enc_0: 1.1398 (1.1751)  loss_vfl: 0.9724 (1.1071)  loss_vfl_aux_0: 1.1206 (1.1077)  loss_vfl_aux_1: 1.0015 (1.1062)  loss_vfl_aux_2: 1.0134 (1.1147)  loss_vfl_aux_3: 0.9841 (1.1086)  loss_vfl_aux_4: 0.9719 (1.1030)  loss_vfl_dn_0: 0.5168 (0.5190)  loss_vfl_dn_1: 0.5139 (0.5193)  loss_vfl_dn_2: 0.5088 (0.5236)  loss_vfl_dn_3: 0.5103 (0.5247)  loss_vfl_dn_4: 0.5178 (0.5311)  loss_vfl_dn_5: 0.5148 (0.5325)  loss_vfl_enc_0: 1.0547 (1.0229)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3508  data: 1.3774  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0826  data: 0.2266  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1008 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.046\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.066\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.049\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.059\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.065\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.177\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.246\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.261\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.061\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.315\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.387\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.380\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.277\r\n",
      "best_stat: {'epoch': 30, 'coco_eval_bbox': 0.04711764461710192}\r\n",
      "Epoch: [32]  [ 0/79]  eta: 0:06:06  lr: 0.000010  loss: 29.4839 (29.4839)  loss_bbox: 0.2679 (0.2679)  loss_bbox_aux_0: 0.3469 (0.3469)  loss_bbox_aux_1: 0.3077 (0.3077)  loss_bbox_aux_2: 0.3036 (0.3036)  loss_bbox_aux_3: 0.2832 (0.2832)  loss_bbox_aux_4: 0.2710 (0.2710)  loss_bbox_dn_0: 0.5951 (0.5951)  loss_bbox_dn_1: 0.5501 (0.5501)  loss_bbox_dn_2: 0.5319 (0.5319)  loss_bbox_dn_3: 0.5242 (0.5242)  loss_bbox_dn_4: 0.5154 (0.5154)  loss_bbox_dn_5: 0.5155 (0.5155)  loss_bbox_enc_0: 0.4053 (0.4053)  loss_giou: 0.7722 (0.7722)  loss_giou_aux_0: 0.8773 (0.8773)  loss_giou_aux_1: 0.8056 (0.8056)  loss_giou_aux_2: 0.8021 (0.8021)  loss_giou_aux_3: 0.7770 (0.7770)  loss_giou_aux_4: 0.7768 (0.7768)  loss_giou_dn_0: 1.0700 (1.0700)  loss_giou_dn_1: 0.9882 (0.9882)  loss_giou_dn_2: 0.9674 (0.9674)  loss_giou_dn_3: 0.9587 (0.9587)  loss_giou_dn_4: 0.9402 (0.9402)  loss_giou_dn_5: 0.9409 (0.9409)  loss_giou_enc_0: 0.9362 (0.9362)  loss_vfl: 1.4346 (1.4346)  loss_vfl_aux_0: 1.2734 (1.2734)  loss_vfl_aux_1: 1.3093 (1.3093)  loss_vfl_aux_2: 1.3120 (1.3120)  loss_vfl_aux_3: 1.3877 (1.3877)  loss_vfl_aux_4: 1.3906 (1.3906)  loss_vfl_dn_0: 0.4979 (0.4979)  loss_vfl_dn_1: 0.5016 (0.5016)  loss_vfl_dn_2: 0.5093 (0.5093)  loss_vfl_dn_3: 0.5133 (0.5133)  loss_vfl_dn_4: 0.5176 (0.5176)  loss_vfl_dn_5: 0.5277 (0.5277)  loss_vfl_enc_0: 1.2783 (1.2783)  time: 4.6438  data: 2.7447  max mem: 10356\r\n",
      "Epoch: [32]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 28.2015 (28.2030)  loss_bbox: 0.3130 (0.3046)  loss_bbox_aux_0: 0.3369 (0.3394)  loss_bbox_aux_1: 0.3285 (0.3158)  loss_bbox_aux_2: 0.3206 (0.3105)  loss_bbox_aux_3: 0.3158 (0.3080)  loss_bbox_aux_4: 0.3147 (0.3056)  loss_bbox_dn_0: 0.3571 (0.3734)  loss_bbox_dn_1: 0.3136 (0.3253)  loss_bbox_dn_2: 0.2929 (0.3094)  loss_bbox_dn_3: 0.2796 (0.3031)  loss_bbox_dn_4: 0.2761 (0.3007)  loss_bbox_dn_5: 0.2764 (0.3006)  loss_bbox_enc_0: 0.3838 (0.3938)  loss_giou: 0.9876 (1.0480)  loss_giou_aux_0: 1.0391 (1.1093)  loss_giou_aux_1: 1.0210 (1.0797)  loss_giou_aux_2: 1.0071 (1.0621)  loss_giou_aux_3: 0.9931 (1.0573)  loss_giou_aux_4: 0.9883 (1.0524)  loss_giou_dn_0: 1.0312 (1.0668)  loss_giou_dn_1: 0.9369 (0.9707)  loss_giou_dn_2: 0.9052 (0.9373)  loss_giou_dn_3: 0.8937 (0.9255)  loss_giou_dn_4: 0.8889 (0.9187)  loss_giou_dn_5: 0.8921 (0.9194)  loss_giou_enc_0: 1.1201 (1.1909)  loss_vfl: 1.0728 (1.0787)  loss_vfl_aux_0: 1.0535 (1.0905)  loss_vfl_aux_1: 1.1255 (1.0979)  loss_vfl_aux_2: 1.0874 (1.0923)  loss_vfl_aux_3: 1.0952 (1.0884)  loss_vfl_aux_4: 1.1216 (1.0842)  loss_vfl_dn_0: 0.5273 (0.5181)  loss_vfl_dn_1: 0.5303 (0.5191)  loss_vfl_dn_2: 0.5321 (0.5207)  loss_vfl_dn_3: 0.5295 (0.5216)  loss_vfl_dn_4: 0.5417 (0.5273)  loss_vfl_dn_5: 0.5371 (0.5283)  loss_vfl_enc_0: 0.9382 (1.0074)  time: 1.0108  data: 0.0314  max mem: 10356\r\n",
      "Epoch: [32] Total time: 0:01:26 (1.0961 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 28.2015 (28.2030)  loss_bbox: 0.3130 (0.3046)  loss_bbox_aux_0: 0.3369 (0.3394)  loss_bbox_aux_1: 0.3285 (0.3158)  loss_bbox_aux_2: 0.3206 (0.3105)  loss_bbox_aux_3: 0.3158 (0.3080)  loss_bbox_aux_4: 0.3147 (0.3056)  loss_bbox_dn_0: 0.3571 (0.3734)  loss_bbox_dn_1: 0.3136 (0.3253)  loss_bbox_dn_2: 0.2929 (0.3094)  loss_bbox_dn_3: 0.2796 (0.3031)  loss_bbox_dn_4: 0.2761 (0.3007)  loss_bbox_dn_5: 0.2764 (0.3006)  loss_bbox_enc_0: 0.3838 (0.3938)  loss_giou: 0.9876 (1.0480)  loss_giou_aux_0: 1.0391 (1.1093)  loss_giou_aux_1: 1.0210 (1.0797)  loss_giou_aux_2: 1.0071 (1.0621)  loss_giou_aux_3: 0.9931 (1.0573)  loss_giou_aux_4: 0.9883 (1.0524)  loss_giou_dn_0: 1.0312 (1.0668)  loss_giou_dn_1: 0.9369 (0.9707)  loss_giou_dn_2: 0.9052 (0.9373)  loss_giou_dn_3: 0.8937 (0.9255)  loss_giou_dn_4: 0.8889 (0.9187)  loss_giou_dn_5: 0.8921 (0.9194)  loss_giou_enc_0: 1.1201 (1.1909)  loss_vfl: 1.0728 (1.0787)  loss_vfl_aux_0: 1.0535 (1.0905)  loss_vfl_aux_1: 1.1255 (1.0979)  loss_vfl_aux_2: 1.0874 (1.0923)  loss_vfl_aux_3: 1.0952 (1.0884)  loss_vfl_aux_4: 1.1216 (1.0842)  loss_vfl_dn_0: 0.5273 (0.5181)  loss_vfl_dn_1: 0.5303 (0.5191)  loss_vfl_dn_2: 0.5321 (0.5207)  loss_vfl_dn_3: 0.5295 (0.5216)  loss_vfl_dn_4: 0.5417 (0.5273)  loss_vfl_dn_5: 0.5371 (0.5283)  loss_vfl_enc_0: 0.9382 (1.0074)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3080  data: 1.3210  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0774  data: 0.2191  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0952 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.039\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.052\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.041\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.019\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.057\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.084\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.261\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.275\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.080\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.350\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.390\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.385\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.293\r\n",
      "best_stat: {'epoch': 30, 'coco_eval_bbox': 0.04711764461710192}\r\n",
      "Epoch: [33]  [ 0/79]  eta: 0:06:09  lr: 0.000010  loss: 27.9778 (27.9778)  loss_bbox: 0.2776 (0.2776)  loss_bbox_aux_0: 0.3318 (0.3318)  loss_bbox_aux_1: 0.2681 (0.2681)  loss_bbox_aux_2: 0.2648 (0.2648)  loss_bbox_aux_3: 0.2779 (0.2779)  loss_bbox_aux_4: 0.2582 (0.2582)  loss_bbox_dn_0: 0.4003 (0.4003)  loss_bbox_dn_1: 0.3390 (0.3390)  loss_bbox_dn_2: 0.3201 (0.3201)  loss_bbox_dn_3: 0.3156 (0.3156)  loss_bbox_dn_4: 0.3118 (0.3118)  loss_bbox_dn_5: 0.3118 (0.3118)  loss_bbox_enc_0: 0.3675 (0.3675)  loss_giou: 0.8937 (0.8937)  loss_giou_aux_0: 0.8783 (0.8783)  loss_giou_aux_1: 0.8916 (0.8916)  loss_giou_aux_2: 0.8311 (0.8311)  loss_giou_aux_3: 0.9171 (0.9171)  loss_giou_aux_4: 0.8946 (0.8946)  loss_giou_dn_0: 1.0025 (1.0025)  loss_giou_dn_1: 0.9019 (0.9019)  loss_giou_dn_2: 0.8561 (0.8561)  loss_giou_dn_3: 0.8482 (0.8482)  loss_giou_dn_4: 0.8358 (0.8358)  loss_giou_dn_5: 0.8397 (0.8397)  loss_giou_enc_0: 1.0909 (1.0909)  loss_vfl: 1.2451 (1.2451)  loss_vfl_aux_0: 1.3916 (1.3916)  loss_vfl_aux_1: 1.3743 (1.3743)  loss_vfl_aux_2: 1.3616 (1.3616)  loss_vfl_aux_3: 1.2039 (1.2039)  loss_vfl_aux_4: 1.2041 (1.2041)  loss_vfl_dn_0: 0.5295 (0.5295)  loss_vfl_dn_1: 0.5437 (0.5437)  loss_vfl_dn_2: 0.5406 (0.5406)  loss_vfl_dn_3: 0.5527 (0.5527)  loss_vfl_dn_4: 0.5593 (0.5593)  loss_vfl_dn_5: 0.5614 (0.5614)  loss_vfl_enc_0: 1.1836 (1.1836)  time: 4.6798  data: 2.7406  max mem: 10356\r\n",
      "Epoch: [33]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 27.7909 (27.9871)  loss_bbox: 0.3094 (0.2976)  loss_bbox_aux_0: 0.3477 (0.3305)  loss_bbox_aux_1: 0.3455 (0.3139)  loss_bbox_aux_2: 0.3288 (0.3057)  loss_bbox_aux_3: 0.3275 (0.3011)  loss_bbox_aux_4: 0.3129 (0.2977)  loss_bbox_dn_0: 0.3100 (0.3629)  loss_bbox_dn_1: 0.2787 (0.3182)  loss_bbox_dn_2: 0.2642 (0.3043)  loss_bbox_dn_3: 0.2517 (0.2992)  loss_bbox_dn_4: 0.2522 (0.2971)  loss_bbox_dn_5: 0.2524 (0.2971)  loss_bbox_enc_0: 0.3878 (0.3883)  loss_giou: 1.1680 (1.0522)  loss_giou_aux_0: 1.1386 (1.0982)  loss_giou_aux_1: 1.1265 (1.0745)  loss_giou_aux_2: 1.1623 (1.0612)  loss_giou_aux_3: 1.1575 (1.0576)  loss_giou_aux_4: 1.1774 (1.0521)  loss_giou_dn_0: 1.0689 (1.0628)  loss_giou_dn_1: 0.9901 (0.9669)  loss_giou_dn_2: 0.9565 (0.9332)  loss_giou_dn_3: 0.9489 (0.9213)  loss_giou_dn_4: 0.9460 (0.9146)  loss_giou_dn_5: 0.9469 (0.9152)  loss_giou_enc_0: 1.2986 (1.1940)  loss_vfl: 0.9836 (1.0619)  loss_vfl_aux_0: 0.9600 (1.0960)  loss_vfl_aux_1: 0.9731 (1.0862)  loss_vfl_aux_2: 1.0229 (1.0843)  loss_vfl_aux_3: 0.9785 (1.0719)  loss_vfl_aux_4: 0.9626 (1.0694)  loss_vfl_dn_0: 0.5085 (0.5145)  loss_vfl_dn_1: 0.5014 (0.5163)  loss_vfl_dn_2: 0.5051 (0.5182)  loss_vfl_dn_3: 0.5041 (0.5177)  loss_vfl_dn_4: 0.5134 (0.5208)  loss_vfl_dn_5: 0.5139 (0.5229)  loss_vfl_enc_0: 0.8735 (0.9897)  time: 1.0073  data: 0.0334  max mem: 10356\r\n",
      "Epoch: [33] Total time: 0:01:24 (1.0715 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 27.7909 (27.9871)  loss_bbox: 0.3094 (0.2976)  loss_bbox_aux_0: 0.3477 (0.3305)  loss_bbox_aux_1: 0.3455 (0.3139)  loss_bbox_aux_2: 0.3288 (0.3057)  loss_bbox_aux_3: 0.3275 (0.3011)  loss_bbox_aux_4: 0.3129 (0.2977)  loss_bbox_dn_0: 0.3100 (0.3629)  loss_bbox_dn_1: 0.2787 (0.3182)  loss_bbox_dn_2: 0.2642 (0.3043)  loss_bbox_dn_3: 0.2517 (0.2992)  loss_bbox_dn_4: 0.2522 (0.2971)  loss_bbox_dn_5: 0.2524 (0.2971)  loss_bbox_enc_0: 0.3878 (0.3883)  loss_giou: 1.1680 (1.0522)  loss_giou_aux_0: 1.1386 (1.0982)  loss_giou_aux_1: 1.1265 (1.0745)  loss_giou_aux_2: 1.1623 (1.0612)  loss_giou_aux_3: 1.1575 (1.0576)  loss_giou_aux_4: 1.1774 (1.0521)  loss_giou_dn_0: 1.0689 (1.0628)  loss_giou_dn_1: 0.9901 (0.9669)  loss_giou_dn_2: 0.9565 (0.9332)  loss_giou_dn_3: 0.9489 (0.9213)  loss_giou_dn_4: 0.9460 (0.9146)  loss_giou_dn_5: 0.9469 (0.9152)  loss_giou_enc_0: 1.2986 (1.1940)  loss_vfl: 0.9836 (1.0619)  loss_vfl_aux_0: 0.9600 (1.0960)  loss_vfl_aux_1: 0.9731 (1.0862)  loss_vfl_aux_2: 1.0229 (1.0843)  loss_vfl_aux_3: 0.9785 (1.0719)  loss_vfl_aux_4: 0.9626 (1.0694)  loss_vfl_dn_0: 0.5085 (0.5145)  loss_vfl_dn_1: 0.5014 (0.5163)  loss_vfl_dn_2: 0.5051 (0.5182)  loss_vfl_dn_3: 0.5041 (0.5177)  loss_vfl_dn_4: 0.5134 (0.5208)  loss_vfl_dn_5: 0.5139 (0.5229)  loss_vfl_enc_0: 0.8735 (0.9897)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.3997  data: 1.4669  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0825  data: 0.2306  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0990 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.39s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.044\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.061\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.048\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.013\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.055\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.070\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.167\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.246\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.258\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.052\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.331\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.365\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.378\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.267\r\n",
      "best_stat: {'epoch': 30, 'coco_eval_bbox': 0.04711764461710192}\r\n",
      "Epoch: [34]  [ 0/79]  eta: 0:06:01  lr: 0.000010  loss: 29.9222 (29.9222)  loss_bbox: 0.3607 (0.3607)  loss_bbox_aux_0: 0.3742 (0.3742)  loss_bbox_aux_1: 0.3690 (0.3690)  loss_bbox_aux_2: 0.3505 (0.3505)  loss_bbox_aux_3: 0.3482 (0.3482)  loss_bbox_aux_4: 0.3664 (0.3664)  loss_bbox_dn_0: 0.3191 (0.3191)  loss_bbox_dn_1: 0.2879 (0.2879)  loss_bbox_dn_2: 0.2782 (0.2782)  loss_bbox_dn_3: 0.2739 (0.2739)  loss_bbox_dn_4: 0.2709 (0.2709)  loss_bbox_dn_5: 0.2708 (0.2708)  loss_bbox_enc_0: 0.4209 (0.4209)  loss_giou: 1.3543 (1.3543)  loss_giou_aux_0: 1.3393 (1.3393)  loss_giou_aux_1: 1.3211 (1.3211)  loss_giou_aux_2: 1.3335 (1.3335)  loss_giou_aux_3: 1.3649 (1.3649)  loss_giou_aux_4: 1.3500 (1.3500)  loss_giou_dn_0: 1.1134 (1.1134)  loss_giou_dn_1: 1.0332 (1.0332)  loss_giou_dn_2: 1.0080 (1.0080)  loss_giou_dn_3: 1.0012 (1.0012)  loss_giou_dn_4: 0.9935 (0.9935)  loss_giou_dn_5: 0.9954 (0.9954)  loss_giou_enc_0: 1.3851 (1.3851)  loss_vfl: 0.9546 (0.9546)  loss_vfl_aux_0: 1.0354 (1.0354)  loss_vfl_aux_1: 1.0493 (1.0493)  loss_vfl_aux_2: 0.9949 (0.9949)  loss_vfl_aux_3: 0.9978 (0.9978)  loss_vfl_aux_4: 0.9612 (0.9612)  loss_vfl_dn_0: 0.4913 (0.4913)  loss_vfl_dn_1: 0.5094 (0.5094)  loss_vfl_dn_2: 0.5203 (0.5203)  loss_vfl_dn_3: 0.5111 (0.5111)  loss_vfl_dn_4: 0.5222 (0.5222)  loss_vfl_dn_5: 0.5297 (0.5297)  loss_vfl_enc_0: 0.9612 (0.9612)  time: 4.5726  data: 2.7921  max mem: 10356\r\n",
      "Epoch: [34]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 27.7099 (28.0651)  loss_bbox: 0.3171 (0.3087)  loss_bbox_aux_0: 0.3427 (0.3455)  loss_bbox_aux_1: 0.3257 (0.3237)  loss_bbox_aux_2: 0.3033 (0.3160)  loss_bbox_aux_3: 0.3214 (0.3127)  loss_bbox_aux_4: 0.3169 (0.3109)  loss_bbox_dn_0: 0.3052 (0.3637)  loss_bbox_dn_1: 0.2656 (0.3171)  loss_bbox_dn_2: 0.2477 (0.3019)  loss_bbox_dn_3: 0.2423 (0.2958)  loss_bbox_dn_4: 0.2372 (0.2936)  loss_bbox_dn_5: 0.2370 (0.2936)  loss_bbox_enc_0: 0.3959 (0.3965)  loss_giou: 1.1349 (1.0366)  loss_giou_aux_0: 1.1466 (1.0898)  loss_giou_aux_1: 1.1498 (1.0622)  loss_giou_aux_2: 1.1300 (1.0453)  loss_giou_aux_3: 1.1483 (1.0449)  loss_giou_aux_4: 1.1308 (1.0395)  loss_giou_dn_0: 1.0826 (1.0538)  loss_giou_dn_1: 1.0076 (0.9533)  loss_giou_dn_2: 0.9743 (0.9173)  loss_giou_dn_3: 0.9636 (0.9049)  loss_giou_dn_4: 0.9597 (0.8986)  loss_giou_dn_5: 0.9595 (0.8991)  loss_giou_enc_0: 1.2416 (1.1725)  loss_vfl: 0.9402 (1.0880)  loss_vfl_aux_0: 0.9846 (1.1073)  loss_vfl_aux_1: 0.9539 (1.1092)  loss_vfl_aux_2: 0.9202 (1.1016)  loss_vfl_aux_3: 0.9412 (1.0894)  loss_vfl_aux_4: 0.9512 (1.0880)  loss_vfl_dn_0: 0.4982 (0.5201)  loss_vfl_dn_1: 0.4999 (0.5216)  loss_vfl_dn_2: 0.4994 (0.5255)  loss_vfl_dn_3: 0.5039 (0.5240)  loss_vfl_dn_4: 0.5029 (0.5294)  loss_vfl_dn_5: 0.5109 (0.5322)  loss_vfl_enc_0: 0.9294 (1.0313)  time: 1.0536  data: 0.0303  max mem: 10356\r\n",
      "Epoch: [34] Total time: 0:01:26 (1.0975 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 27.7099 (28.0651)  loss_bbox: 0.3171 (0.3087)  loss_bbox_aux_0: 0.3427 (0.3455)  loss_bbox_aux_1: 0.3257 (0.3237)  loss_bbox_aux_2: 0.3033 (0.3160)  loss_bbox_aux_3: 0.3214 (0.3127)  loss_bbox_aux_4: 0.3169 (0.3109)  loss_bbox_dn_0: 0.3052 (0.3637)  loss_bbox_dn_1: 0.2656 (0.3171)  loss_bbox_dn_2: 0.2477 (0.3019)  loss_bbox_dn_3: 0.2423 (0.2958)  loss_bbox_dn_4: 0.2372 (0.2936)  loss_bbox_dn_5: 0.2370 (0.2936)  loss_bbox_enc_0: 0.3959 (0.3965)  loss_giou: 1.1349 (1.0366)  loss_giou_aux_0: 1.1466 (1.0898)  loss_giou_aux_1: 1.1498 (1.0622)  loss_giou_aux_2: 1.1300 (1.0453)  loss_giou_aux_3: 1.1483 (1.0449)  loss_giou_aux_4: 1.1308 (1.0395)  loss_giou_dn_0: 1.0826 (1.0538)  loss_giou_dn_1: 1.0076 (0.9533)  loss_giou_dn_2: 0.9743 (0.9173)  loss_giou_dn_3: 0.9636 (0.9049)  loss_giou_dn_4: 0.9597 (0.8986)  loss_giou_dn_5: 0.9595 (0.8991)  loss_giou_enc_0: 1.2416 (1.1725)  loss_vfl: 0.9402 (1.0880)  loss_vfl_aux_0: 0.9846 (1.1073)  loss_vfl_aux_1: 0.9539 (1.1092)  loss_vfl_aux_2: 0.9202 (1.1016)  loss_vfl_aux_3: 0.9412 (1.0894)  loss_vfl_aux_4: 0.9512 (1.0880)  loss_vfl_dn_0: 0.4982 (0.5201)  loss_vfl_dn_1: 0.4999 (0.5216)  loss_vfl_dn_2: 0.4994 (0.5255)  loss_vfl_dn_3: 0.5039 (0.5240)  loss_vfl_dn_4: 0.5029 (0.5294)  loss_vfl_dn_5: 0.5109 (0.5322)  loss_vfl_enc_0: 0.9294 (1.0313)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.1356  data: 1.1162  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0605  data: 0.1971  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0781 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.046\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.060\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.046\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.061\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.077\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.173\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.262\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.271\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.053\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.329\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.372\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.382\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.293\r\n",
      "best_stat: {'epoch': 30, 'coco_eval_bbox': 0.04711764461710192}\r\n",
      "Epoch: [35]  [ 0/79]  eta: 0:06:32  lr: 0.000010  loss: 29.2100 (29.2100)  loss_bbox: 0.2750 (0.2750)  loss_bbox_aux_0: 0.3119 (0.3119)  loss_bbox_aux_1: 0.2894 (0.2894)  loss_bbox_aux_2: 0.2623 (0.2623)  loss_bbox_aux_3: 0.2925 (0.2925)  loss_bbox_aux_4: 0.2509 (0.2509)  loss_bbox_dn_0: 0.5710 (0.5710)  loss_bbox_dn_1: 0.4783 (0.4783)  loss_bbox_dn_2: 0.4358 (0.4358)  loss_bbox_dn_3: 0.4234 (0.4234)  loss_bbox_dn_4: 0.4209 (0.4209)  loss_bbox_dn_5: 0.4205 (0.4205)  loss_bbox_enc_0: 0.4622 (0.4622)  loss_giou: 0.7018 (0.7018)  loss_giou_aux_0: 0.7629 (0.7629)  loss_giou_aux_1: 0.7277 (0.7277)  loss_giou_aux_2: 0.7552 (0.7552)  loss_giou_aux_3: 0.7429 (0.7429)  loss_giou_aux_4: 0.7107 (0.7107)  loss_giou_dn_0: 1.0171 (1.0171)  loss_giou_dn_1: 0.9113 (0.9113)  loss_giou_dn_2: 0.8794 (0.8794)  loss_giou_dn_3: 0.8620 (0.8620)  loss_giou_dn_4: 0.8602 (0.8602)  loss_giou_dn_5: 0.8602 (0.8602)  loss_giou_enc_0: 0.9414 (0.9414)  loss_vfl: 1.3887 (1.3887)  loss_vfl_aux_0: 1.4927 (1.4927)  loss_vfl_aux_1: 1.4907 (1.4907)  loss_vfl_aux_2: 1.4653 (1.4653)  loss_vfl_aux_3: 1.4136 (1.4136)  loss_vfl_aux_4: 1.5078 (1.5078)  loss_vfl_dn_0: 0.5706 (0.5706)  loss_vfl_dn_1: 0.5818 (0.5818)  loss_vfl_dn_2: 0.5820 (0.5820)  loss_vfl_dn_3: 0.5764 (0.5764)  loss_vfl_dn_4: 0.5823 (0.5823)  loss_vfl_dn_5: 0.5698 (0.5698)  loss_vfl_enc_0: 1.3613 (1.3613)  time: 4.9731  data: 3.1428  max mem: 10356\r\n",
      "Epoch: [35]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 27.9104 (28.0915)  loss_bbox: 0.2867 (0.3083)  loss_bbox_aux_0: 0.2946 (0.3449)  loss_bbox_aux_1: 0.2774 (0.3240)  loss_bbox_aux_2: 0.2796 (0.3169)  loss_bbox_aux_3: 0.2824 (0.3149)  loss_bbox_aux_4: 0.2853 (0.3099)  loss_bbox_dn_0: 0.3565 (0.3637)  loss_bbox_dn_1: 0.3049 (0.3152)  loss_bbox_dn_2: 0.2825 (0.2994)  loss_bbox_dn_3: 0.2740 (0.2937)  loss_bbox_dn_4: 0.2716 (0.2912)  loss_bbox_dn_5: 0.2715 (0.2912)  loss_bbox_enc_0: 0.3652 (0.4004)  loss_giou: 1.0047 (1.0439)  loss_giou_aux_0: 1.0513 (1.1034)  loss_giou_aux_1: 1.0398 (1.0727)  loss_giou_aux_2: 1.0222 (1.0608)  loss_giou_aux_3: 1.0222 (1.0515)  loss_giou_aux_4: 1.0074 (1.0449)  loss_giou_dn_0: 1.0307 (1.0545)  loss_giou_dn_1: 0.9397 (0.9561)  loss_giou_dn_2: 0.9224 (0.9206)  loss_giou_dn_3: 0.9111 (0.9088)  loss_giou_dn_4: 0.9051 (0.9026)  loss_giou_dn_5: 0.9066 (0.9028)  loss_giou_enc_0: 1.1588 (1.1973)  loss_vfl: 1.0615 (1.0782)  loss_vfl_aux_0: 1.1509 (1.1100)  loss_vfl_aux_1: 1.0889 (1.1005)  loss_vfl_aux_2: 1.1035 (1.0965)  loss_vfl_aux_3: 1.0571 (1.0889)  loss_vfl_aux_4: 1.0686 (1.0880)  loss_vfl_dn_0: 0.5332 (0.5188)  loss_vfl_dn_1: 0.5250 (0.5171)  loss_vfl_dn_2: 0.5204 (0.5182)  loss_vfl_dn_3: 0.5251 (0.5178)  loss_vfl_dn_4: 0.5298 (0.5209)  loss_vfl_dn_5: 0.5256 (0.5225)  loss_vfl_enc_0: 1.0706 (1.0207)  time: 0.9871  data: 0.0326  max mem: 10356\r\n",
      "Epoch: [35] Total time: 0:01:25 (1.0835 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 27.9104 (28.0915)  loss_bbox: 0.2867 (0.3083)  loss_bbox_aux_0: 0.2946 (0.3449)  loss_bbox_aux_1: 0.2774 (0.3240)  loss_bbox_aux_2: 0.2796 (0.3169)  loss_bbox_aux_3: 0.2824 (0.3149)  loss_bbox_aux_4: 0.2853 (0.3099)  loss_bbox_dn_0: 0.3565 (0.3637)  loss_bbox_dn_1: 0.3049 (0.3152)  loss_bbox_dn_2: 0.2825 (0.2994)  loss_bbox_dn_3: 0.2740 (0.2937)  loss_bbox_dn_4: 0.2716 (0.2912)  loss_bbox_dn_5: 0.2715 (0.2912)  loss_bbox_enc_0: 0.3652 (0.4004)  loss_giou: 1.0047 (1.0439)  loss_giou_aux_0: 1.0513 (1.1034)  loss_giou_aux_1: 1.0398 (1.0727)  loss_giou_aux_2: 1.0222 (1.0608)  loss_giou_aux_3: 1.0222 (1.0515)  loss_giou_aux_4: 1.0074 (1.0449)  loss_giou_dn_0: 1.0307 (1.0545)  loss_giou_dn_1: 0.9397 (0.9561)  loss_giou_dn_2: 0.9224 (0.9206)  loss_giou_dn_3: 0.9111 (0.9088)  loss_giou_dn_4: 0.9051 (0.9026)  loss_giou_dn_5: 0.9066 (0.9028)  loss_giou_enc_0: 1.1588 (1.1973)  loss_vfl: 1.0615 (1.0782)  loss_vfl_aux_0: 1.1509 (1.1100)  loss_vfl_aux_1: 1.0889 (1.1005)  loss_vfl_aux_2: 1.1035 (1.0965)  loss_vfl_aux_3: 1.0571 (1.0889)  loss_vfl_aux_4: 1.0686 (1.0880)  loss_vfl_dn_0: 0.5332 (0.5188)  loss_vfl_dn_1: 0.5250 (0.5171)  loss_vfl_dn_2: 0.5204 (0.5182)  loss_vfl_dn_3: 0.5251 (0.5178)  loss_vfl_dn_4: 0.5298 (0.5209)  loss_vfl_dn_5: 0.5256 (0.5225)  loss_vfl_enc_0: 1.0706 (1.0207)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.2739  data: 1.2540  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0748  data: 0.2055  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0922 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.30s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.050\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.069\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.052\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.053\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.089\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.174\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.261\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.272\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.079\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.310\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.415\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.378\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.295\r\n",
      "best_stat: {'epoch': 35, 'coco_eval_bbox': 0.05006041723737965}\r\n",
      "Epoch: [36]  [ 0/79]  eta: 0:04:49  lr: 0.000010  loss: 26.7994 (26.7994)  loss_bbox: 0.3190 (0.3190)  loss_bbox_aux_0: 0.3242 (0.3242)  loss_bbox_aux_1: 0.2954 (0.2954)  loss_bbox_aux_2: 0.3130 (0.3130)  loss_bbox_aux_3: 0.3219 (0.3219)  loss_bbox_aux_4: 0.3227 (0.3227)  loss_bbox_dn_0: 0.2701 (0.2701)  loss_bbox_dn_1: 0.2133 (0.2133)  loss_bbox_dn_2: 0.1969 (0.1969)  loss_bbox_dn_3: 0.1913 (0.1913)  loss_bbox_dn_4: 0.1872 (0.1872)  loss_bbox_dn_5: 0.1870 (0.1870)  loss_bbox_enc_0: 0.3454 (0.3454)  loss_giou: 1.2725 (1.2725)  loss_giou_aux_0: 1.3286 (1.3286)  loss_giou_aux_1: 1.2826 (1.2826)  loss_giou_aux_2: 1.2471 (1.2471)  loss_giou_aux_3: 1.2886 (1.2886)  loss_giou_aux_4: 1.2593 (1.2593)  loss_giou_dn_0: 1.0734 (1.0734)  loss_giou_dn_1: 0.9865 (0.9865)  loss_giou_dn_2: 0.9552 (0.9552)  loss_giou_dn_3: 0.9487 (0.9487)  loss_giou_dn_4: 0.9408 (0.9408)  loss_giou_dn_5: 0.9411 (0.9411)  loss_giou_enc_0: 1.3137 (1.3137)  loss_vfl: 0.7305 (0.7305)  loss_vfl_aux_0: 0.8118 (0.8118)  loss_vfl_aux_1: 0.8093 (0.8093)  loss_vfl_aux_2: 0.8005 (0.8005)  loss_vfl_aux_3: 0.7598 (0.7598)  loss_vfl_aux_4: 0.7551 (0.7551)  loss_vfl_dn_0: 0.4913 (0.4913)  loss_vfl_dn_1: 0.4890 (0.4890)  loss_vfl_dn_2: 0.4896 (0.4896)  loss_vfl_dn_3: 0.4865 (0.4865)  loss_vfl_dn_4: 0.4771 (0.4771)  loss_vfl_dn_5: 0.4805 (0.4805)  loss_vfl_enc_0: 0.8928 (0.8928)  time: 3.6603  data: 2.5987  max mem: 10356\r\n",
      "Epoch: [36]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 27.4694 (27.6972)  loss_bbox: 0.2597 (0.2915)  loss_bbox_aux_0: 0.2985 (0.3255)  loss_bbox_aux_1: 0.2734 (0.3076)  loss_bbox_aux_2: 0.2692 (0.2978)  loss_bbox_aux_3: 0.2739 (0.2967)  loss_bbox_aux_4: 0.2612 (0.2948)  loss_bbox_dn_0: 0.3071 (0.3464)  loss_bbox_dn_1: 0.2728 (0.2984)  loss_bbox_dn_2: 0.2656 (0.2823)  loss_bbox_dn_3: 0.2612 (0.2768)  loss_bbox_dn_4: 0.2607 (0.2740)  loss_bbox_dn_5: 0.2604 (0.2740)  loss_bbox_enc_0: 0.3441 (0.3752)  loss_giou: 1.0679 (1.0431)  loss_giou_aux_0: 1.1126 (1.0951)  loss_giou_aux_1: 1.1055 (1.0714)  loss_giou_aux_2: 1.0919 (1.0543)  loss_giou_aux_3: 1.0820 (1.0499)  loss_giou_aux_4: 1.0577 (1.0419)  loss_giou_dn_0: 1.0478 (1.0511)  loss_giou_dn_1: 0.9443 (0.9518)  loss_giou_dn_2: 0.9066 (0.9165)  loss_giou_dn_3: 0.8954 (0.9043)  loss_giou_dn_4: 0.8908 (0.8978)  loss_giou_dn_5: 0.8913 (0.8982)  loss_giou_enc_0: 1.2035 (1.1852)  loss_vfl: 1.0100 (1.0595)  loss_vfl_aux_0: 1.0195 (1.0963)  loss_vfl_aux_1: 1.0837 (1.0935)  loss_vfl_aux_2: 1.0337 (1.0808)  loss_vfl_aux_3: 1.0168 (1.0643)  loss_vfl_aux_4: 1.0317 (1.0646)  loss_vfl_dn_0: 0.5234 (0.5183)  loss_vfl_dn_1: 0.5153 (0.5172)  loss_vfl_dn_2: 0.5132 (0.5192)  loss_vfl_dn_3: 0.5103 (0.5190)  loss_vfl_dn_4: 0.5229 (0.5215)  loss_vfl_dn_5: 0.5165 (0.5222)  loss_vfl_enc_0: 0.9473 (1.0195)  time: 1.0453  data: 0.0297  max mem: 10356\r\n",
      "Epoch: [36] Total time: 0:01:23 (1.0630 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 27.4694 (27.6972)  loss_bbox: 0.2597 (0.2915)  loss_bbox_aux_0: 0.2985 (0.3255)  loss_bbox_aux_1: 0.2734 (0.3076)  loss_bbox_aux_2: 0.2692 (0.2978)  loss_bbox_aux_3: 0.2739 (0.2967)  loss_bbox_aux_4: 0.2612 (0.2948)  loss_bbox_dn_0: 0.3071 (0.3464)  loss_bbox_dn_1: 0.2728 (0.2984)  loss_bbox_dn_2: 0.2656 (0.2823)  loss_bbox_dn_3: 0.2612 (0.2768)  loss_bbox_dn_4: 0.2607 (0.2740)  loss_bbox_dn_5: 0.2604 (0.2740)  loss_bbox_enc_0: 0.3441 (0.3752)  loss_giou: 1.0679 (1.0431)  loss_giou_aux_0: 1.1126 (1.0951)  loss_giou_aux_1: 1.1055 (1.0714)  loss_giou_aux_2: 1.0919 (1.0543)  loss_giou_aux_3: 1.0820 (1.0499)  loss_giou_aux_4: 1.0577 (1.0419)  loss_giou_dn_0: 1.0478 (1.0511)  loss_giou_dn_1: 0.9443 (0.9518)  loss_giou_dn_2: 0.9066 (0.9165)  loss_giou_dn_3: 0.8954 (0.9043)  loss_giou_dn_4: 0.8908 (0.8978)  loss_giou_dn_5: 0.8913 (0.8982)  loss_giou_enc_0: 1.2035 (1.1852)  loss_vfl: 1.0100 (1.0595)  loss_vfl_aux_0: 1.0195 (1.0963)  loss_vfl_aux_1: 1.0837 (1.0935)  loss_vfl_aux_2: 1.0337 (1.0808)  loss_vfl_aux_3: 1.0168 (1.0643)  loss_vfl_aux_4: 1.0317 (1.0646)  loss_vfl_dn_0: 0.5234 (0.5183)  loss_vfl_dn_1: 0.5153 (0.5172)  loss_vfl_dn_2: 0.5132 (0.5192)  loss_vfl_dn_3: 0.5103 (0.5190)  loss_vfl_dn_4: 0.5229 (0.5215)  loss_vfl_dn_5: 0.5165 (0.5222)  loss_vfl_enc_0: 0.9473 (1.0195)\r\n",
      "Test:  [0/8]  eta: 0:00:16    time: 2.0578  data: 1.1097  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0476  data: 0.1932  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0640 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.32s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.045\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.063\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.047\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.015\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.054\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.072\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.167\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.253\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.261\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.071\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.299\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.394\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.367\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.277\r\n",
      "best_stat: {'epoch': 35, 'coco_eval_bbox': 0.05006041723737965}\r\n",
      "Epoch: [37]  [ 0/79]  eta: 0:05:33  lr: 0.000010  loss: 26.5700 (26.5700)  loss_bbox: 0.2916 (0.2916)  loss_bbox_aux_0: 0.3046 (0.3046)  loss_bbox_aux_1: 0.2748 (0.2748)  loss_bbox_aux_2: 0.2770 (0.2770)  loss_bbox_aux_3: 0.2795 (0.2795)  loss_bbox_aux_4: 0.2748 (0.2748)  loss_bbox_dn_0: 0.3001 (0.3001)  loss_bbox_dn_1: 0.2440 (0.2440)  loss_bbox_dn_2: 0.2299 (0.2299)  loss_bbox_dn_3: 0.2239 (0.2239)  loss_bbox_dn_4: 0.2204 (0.2204)  loss_bbox_dn_5: 0.2204 (0.2204)  loss_bbox_enc_0: 0.3307 (0.3307)  loss_giou: 1.1294 (1.1294)  loss_giou_aux_0: 1.1760 (1.1760)  loss_giou_aux_1: 1.1513 (1.1513)  loss_giou_aux_2: 1.1233 (1.1233)  loss_giou_aux_3: 1.1252 (1.1252)  loss_giou_aux_4: 1.1201 (1.1201)  loss_giou_dn_0: 1.0613 (1.0613)  loss_giou_dn_1: 0.9818 (0.9818)  loss_giou_dn_2: 0.9630 (0.9630)  loss_giou_dn_3: 0.9538 (0.9538)  loss_giou_dn_4: 0.9518 (0.9518)  loss_giou_dn_5: 0.9525 (0.9525)  loss_giou_enc_0: 1.2584 (1.2584)  loss_vfl: 0.8440 (0.8440)  loss_vfl_aux_0: 0.8914 (0.8914)  loss_vfl_aux_1: 0.8816 (0.8816)  loss_vfl_aux_2: 0.8970 (0.8970)  loss_vfl_aux_3: 0.8843 (0.8843)  loss_vfl_aux_4: 0.8718 (0.8718)  loss_vfl_dn_0: 0.5151 (0.5151)  loss_vfl_dn_1: 0.5135 (0.5135)  loss_vfl_dn_2: 0.5212 (0.5212)  loss_vfl_dn_3: 0.5162 (0.5162)  loss_vfl_dn_4: 0.5178 (0.5178)  loss_vfl_dn_5: 0.5166 (0.5166)  loss_vfl_enc_0: 0.7798 (0.7798)  time: 4.2228  data: 2.9835  max mem: 10356\r\n",
      "Epoch: [37]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 28.3843 (27.8439)  loss_bbox: 0.3031 (0.3025)  loss_bbox_aux_0: 0.3285 (0.3321)  loss_bbox_aux_1: 0.3125 (0.3113)  loss_bbox_aux_2: 0.3158 (0.3028)  loss_bbox_aux_3: 0.3070 (0.2997)  loss_bbox_aux_4: 0.3034 (0.3008)  loss_bbox_dn_0: 0.2814 (0.3635)  loss_bbox_dn_1: 0.2691 (0.3153)  loss_bbox_dn_2: 0.2637 (0.3000)  loss_bbox_dn_3: 0.2507 (0.2939)  loss_bbox_dn_4: 0.2465 (0.2918)  loss_bbox_dn_5: 0.2467 (0.2918)  loss_bbox_enc_0: 0.3690 (0.3866)  loss_giou: 1.1041 (1.0397)  loss_giou_aux_0: 1.1600 (1.0940)  loss_giou_aux_1: 1.1350 (1.0609)  loss_giou_aux_2: 1.1230 (1.0469)  loss_giou_aux_3: 1.1090 (1.0436)  loss_giou_aux_4: 1.1022 (1.0398)  loss_giou_dn_0: 1.0691 (1.0467)  loss_giou_dn_1: 0.9962 (0.9455)  loss_giou_dn_2: 0.9511 (0.9107)  loss_giou_dn_3: 0.9454 (0.8983)  loss_giou_dn_4: 0.9396 (0.8922)  loss_giou_dn_5: 0.9391 (0.8925)  loss_giou_enc_0: 1.2222 (1.1812)  loss_vfl: 1.0137 (1.0551)  loss_vfl_aux_0: 0.9824 (1.0970)  loss_vfl_aux_1: 1.0190 (1.1030)  loss_vfl_aux_2: 1.0029 (1.0944)  loss_vfl_aux_3: 0.9492 (1.0816)  loss_vfl_aux_4: 0.9834 (1.0659)  loss_vfl_dn_0: 0.5065 (0.5217)  loss_vfl_dn_1: 0.5155 (0.5202)  loss_vfl_dn_2: 0.5160 (0.5217)  loss_vfl_dn_3: 0.5251 (0.5203)  loss_vfl_dn_4: 0.5300 (0.5225)  loss_vfl_dn_5: 0.5284 (0.5242)  loss_vfl_enc_0: 0.9741 (1.0321)  time: 0.9696  data: 0.0306  max mem: 10356\r\n",
      "Epoch: [37] Total time: 0:01:26 (1.0898 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 28.3843 (27.8439)  loss_bbox: 0.3031 (0.3025)  loss_bbox_aux_0: 0.3285 (0.3321)  loss_bbox_aux_1: 0.3125 (0.3113)  loss_bbox_aux_2: 0.3158 (0.3028)  loss_bbox_aux_3: 0.3070 (0.2997)  loss_bbox_aux_4: 0.3034 (0.3008)  loss_bbox_dn_0: 0.2814 (0.3635)  loss_bbox_dn_1: 0.2691 (0.3153)  loss_bbox_dn_2: 0.2637 (0.3000)  loss_bbox_dn_3: 0.2507 (0.2939)  loss_bbox_dn_4: 0.2465 (0.2918)  loss_bbox_dn_5: 0.2467 (0.2918)  loss_bbox_enc_0: 0.3690 (0.3866)  loss_giou: 1.1041 (1.0397)  loss_giou_aux_0: 1.1600 (1.0940)  loss_giou_aux_1: 1.1350 (1.0609)  loss_giou_aux_2: 1.1230 (1.0469)  loss_giou_aux_3: 1.1090 (1.0436)  loss_giou_aux_4: 1.1022 (1.0398)  loss_giou_dn_0: 1.0691 (1.0467)  loss_giou_dn_1: 0.9962 (0.9455)  loss_giou_dn_2: 0.9511 (0.9107)  loss_giou_dn_3: 0.9454 (0.8983)  loss_giou_dn_4: 0.9396 (0.8922)  loss_giou_dn_5: 0.9391 (0.8925)  loss_giou_enc_0: 1.2222 (1.1812)  loss_vfl: 1.0137 (1.0551)  loss_vfl_aux_0: 0.9824 (1.0970)  loss_vfl_aux_1: 1.0190 (1.1030)  loss_vfl_aux_2: 1.0029 (1.0944)  loss_vfl_aux_3: 0.9492 (1.0816)  loss_vfl_aux_4: 0.9834 (1.0659)  loss_vfl_dn_0: 0.5065 (0.5217)  loss_vfl_dn_1: 0.5155 (0.5202)  loss_vfl_dn_2: 0.5160 (0.5217)  loss_vfl_dn_3: 0.5251 (0.5203)  loss_vfl_dn_4: 0.5300 (0.5225)  loss_vfl_dn_5: 0.5284 (0.5242)  loss_vfl_enc_0: 0.9741 (1.0321)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.1485  data: 1.1700  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0627  data: 0.2043  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0779 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.046\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.067\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.048\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.017\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.056\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.083\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.178\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.258\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.275\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.085\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.330\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.415\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.379\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.291\r\n",
      "best_stat: {'epoch': 35, 'coco_eval_bbox': 0.05006041723737965}\r\n",
      "Epoch: [38]  [ 0/79]  eta: 0:06:43  lr: 0.000010  loss: 29.2020 (29.2020)  loss_bbox: 0.3177 (0.3177)  loss_bbox_aux_0: 0.3592 (0.3592)  loss_bbox_aux_1: 0.3544 (0.3544)  loss_bbox_aux_2: 0.3446 (0.3446)  loss_bbox_aux_3: 0.3397 (0.3397)  loss_bbox_aux_4: 0.3274 (0.3274)  loss_bbox_dn_0: 0.3734 (0.3734)  loss_bbox_dn_1: 0.3432 (0.3432)  loss_bbox_dn_2: 0.3330 (0.3330)  loss_bbox_dn_3: 0.3320 (0.3320)  loss_bbox_dn_4: 0.3331 (0.3331)  loss_bbox_dn_5: 0.3333 (0.3333)  loss_bbox_enc_0: 0.4009 (0.4009)  loss_giou: 1.3086 (1.3086)  loss_giou_aux_0: 1.3347 (1.3347)  loss_giou_aux_1: 1.3004 (1.3004)  loss_giou_aux_2: 1.2952 (1.2952)  loss_giou_aux_3: 1.2939 (1.2939)  loss_giou_aux_4: 1.2936 (1.2936)  loss_giou_dn_0: 1.1041 (1.1041)  loss_giou_dn_1: 1.0276 (1.0276)  loss_giou_dn_2: 1.0057 (1.0057)  loss_giou_dn_3: 0.9968 (0.9968)  loss_giou_dn_4: 0.9972 (0.9972)  loss_giou_dn_5: 0.9978 (0.9978)  loss_giou_enc_0: 1.4447 (1.4447)  loss_vfl: 0.9275 (0.9275)  loss_vfl_aux_0: 0.9585 (0.9585)  loss_vfl_aux_1: 0.9133 (0.9133)  loss_vfl_aux_2: 0.9470 (0.9470)  loss_vfl_aux_3: 0.9231 (0.9231)  loss_vfl_aux_4: 0.9102 (0.9102)  loss_vfl_dn_0: 0.4806 (0.4806)  loss_vfl_dn_1: 0.4824 (0.4824)  loss_vfl_dn_2: 0.4825 (0.4825)  loss_vfl_dn_3: 0.4739 (0.4739)  loss_vfl_dn_4: 0.4856 (0.4856)  loss_vfl_dn_5: 0.5022 (0.5022)  loss_vfl_enc_0: 0.8230 (0.8230)  time: 5.1117  data: 1.6830  max mem: 10356\r\n",
      "Epoch: [38]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 27.6905 (27.6438)  loss_bbox: 0.2773 (0.2924)  loss_bbox_aux_0: 0.3203 (0.3281)  loss_bbox_aux_1: 0.2956 (0.3108)  loss_bbox_aux_2: 0.2825 (0.3018)  loss_bbox_aux_3: 0.2837 (0.2970)  loss_bbox_aux_4: 0.3021 (0.2941)  loss_bbox_dn_0: 0.3187 (0.3499)  loss_bbox_dn_1: 0.2694 (0.3005)  loss_bbox_dn_2: 0.2552 (0.2838)  loss_bbox_dn_3: 0.2477 (0.2781)  loss_bbox_dn_4: 0.2411 (0.2760)  loss_bbox_dn_5: 0.2407 (0.2760)  loss_bbox_enc_0: 0.3748 (0.3820)  loss_giou: 0.8735 (1.0438)  loss_giou_aux_0: 0.9544 (1.0990)  loss_giou_aux_1: 0.8776 (1.0653)  loss_giou_aux_2: 0.8475 (1.0559)  loss_giou_aux_3: 0.8719 (1.0486)  loss_giou_aux_4: 0.8440 (1.0450)  loss_giou_dn_0: 1.0143 (1.0482)  loss_giou_dn_1: 0.8987 (0.9502)  loss_giou_dn_2: 0.8597 (0.9146)  loss_giou_dn_3: 0.8586 (0.9026)  loss_giou_dn_4: 0.8574 (0.8963)  loss_giou_dn_5: 0.8565 (0.8966)  loss_giou_enc_0: 1.0573 (1.1801)  loss_vfl: 1.0908 (1.0426)  loss_vfl_aux_0: 1.1553 (1.0912)  loss_vfl_aux_1: 1.1750 (1.0867)  loss_vfl_aux_2: 1.1748 (1.0745)  loss_vfl_aux_3: 1.1223 (1.0600)  loss_vfl_aux_4: 1.0840 (1.0495)  loss_vfl_dn_0: 0.5247 (0.5216)  loss_vfl_dn_1: 0.5145 (0.5142)  loss_vfl_dn_2: 0.5199 (0.5174)  loss_vfl_dn_3: 0.5103 (0.5146)  loss_vfl_dn_4: 0.5171 (0.5183)  loss_vfl_dn_5: 0.5112 (0.5216)  loss_vfl_enc_0: 1.1196 (1.0146)  time: 0.9732  data: 0.0323  max mem: 10356\r\n",
      "Epoch: [38] Total time: 0:01:25 (1.0810 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 27.6905 (27.6438)  loss_bbox: 0.2773 (0.2924)  loss_bbox_aux_0: 0.3203 (0.3281)  loss_bbox_aux_1: 0.2956 (0.3108)  loss_bbox_aux_2: 0.2825 (0.3018)  loss_bbox_aux_3: 0.2837 (0.2970)  loss_bbox_aux_4: 0.3021 (0.2941)  loss_bbox_dn_0: 0.3187 (0.3499)  loss_bbox_dn_1: 0.2694 (0.3005)  loss_bbox_dn_2: 0.2552 (0.2838)  loss_bbox_dn_3: 0.2477 (0.2781)  loss_bbox_dn_4: 0.2411 (0.2760)  loss_bbox_dn_5: 0.2407 (0.2760)  loss_bbox_enc_0: 0.3748 (0.3820)  loss_giou: 0.8735 (1.0438)  loss_giou_aux_0: 0.9544 (1.0990)  loss_giou_aux_1: 0.8776 (1.0653)  loss_giou_aux_2: 0.8475 (1.0559)  loss_giou_aux_3: 0.8719 (1.0486)  loss_giou_aux_4: 0.8440 (1.0450)  loss_giou_dn_0: 1.0143 (1.0482)  loss_giou_dn_1: 0.8987 (0.9502)  loss_giou_dn_2: 0.8597 (0.9146)  loss_giou_dn_3: 0.8586 (0.9026)  loss_giou_dn_4: 0.8574 (0.8963)  loss_giou_dn_5: 0.8565 (0.8966)  loss_giou_enc_0: 1.0573 (1.1801)  loss_vfl: 1.0908 (1.0426)  loss_vfl_aux_0: 1.1553 (1.0912)  loss_vfl_aux_1: 1.1750 (1.0867)  loss_vfl_aux_2: 1.1748 (1.0745)  loss_vfl_aux_3: 1.1223 (1.0600)  loss_vfl_aux_4: 1.0840 (1.0495)  loss_vfl_dn_0: 0.5247 (0.5216)  loss_vfl_dn_1: 0.5145 (0.5142)  loss_vfl_dn_2: 0.5199 (0.5174)  loss_vfl_dn_3: 0.5103 (0.5146)  loss_vfl_dn_4: 0.5171 (0.5183)  loss_vfl_dn_5: 0.5112 (0.5216)  loss_vfl_enc_0: 1.1196 (1.0146)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3110  data: 1.3963  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0690  data: 0.2159  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0854 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.050\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.067\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.058\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.018\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.062\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.099\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.197\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.323\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.113\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.377\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.454\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.444\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.346\r\n",
      "best_stat: {'epoch': 38, 'coco_eval_bbox': 0.050397999148989514}\r\n",
      "Epoch: [39]  [ 0/79]  eta: 0:05:54  lr: 0.000010  loss: 25.8109 (25.8109)  loss_bbox: 0.2220 (0.2220)  loss_bbox_aux_0: 0.2468 (0.2468)  loss_bbox_aux_1: 0.2420 (0.2420)  loss_bbox_aux_2: 0.2311 (0.2311)  loss_bbox_aux_3: 0.2248 (0.2248)  loss_bbox_aux_4: 0.2226 (0.2226)  loss_bbox_dn_0: 0.3176 (0.3176)  loss_bbox_dn_1: 0.2615 (0.2615)  loss_bbox_dn_2: 0.2470 (0.2470)  loss_bbox_dn_3: 0.2343 (0.2343)  loss_bbox_dn_4: 0.2333 (0.2333)  loss_bbox_dn_5: 0.2332 (0.2332)  loss_bbox_enc_0: 0.2901 (0.2901)  loss_giou: 0.9154 (0.9154)  loss_giou_aux_0: 0.9817 (0.9817)  loss_giou_aux_1: 0.9468 (0.9468)  loss_giou_aux_2: 0.9318 (0.9318)  loss_giou_aux_3: 0.9157 (0.9157)  loss_giou_aux_4: 0.9128 (0.9128)  loss_giou_dn_0: 0.9876 (0.9876)  loss_giou_dn_1: 0.8718 (0.8718)  loss_giou_dn_2: 0.8226 (0.8226)  loss_giou_dn_3: 0.8012 (0.8012)  loss_giou_dn_4: 0.7930 (0.7930)  loss_giou_dn_5: 0.7937 (0.7937)  loss_giou_enc_0: 1.1087 (1.1087)  loss_vfl: 1.0974 (1.0974)  loss_vfl_aux_0: 1.1338 (1.1338)  loss_vfl_aux_1: 1.0969 (1.0969)  loss_vfl_aux_2: 1.1543 (1.1543)  loss_vfl_aux_3: 1.1455 (1.1455)  loss_vfl_aux_4: 1.1304 (1.1304)  loss_vfl_dn_0: 0.5093 (0.5093)  loss_vfl_dn_1: 0.5018 (0.5018)  loss_vfl_dn_2: 0.5007 (0.5007)  loss_vfl_dn_3: 0.4924 (0.4924)  loss_vfl_dn_4: 0.4954 (0.4954)  loss_vfl_dn_5: 0.4886 (0.4886)  loss_vfl_enc_0: 1.0752 (1.0752)  time: 4.4877  data: 2.9329  max mem: 10356\r\n",
      "Epoch: [39]  [78/79]  eta: 0:00:01  lr: 0.000010  loss: 27.8806 (27.3491)  loss_bbox: 0.2835 (0.2764)  loss_bbox_aux_0: 0.3346 (0.3110)  loss_bbox_aux_1: 0.3089 (0.2895)  loss_bbox_aux_2: 0.2940 (0.2832)  loss_bbox_aux_3: 0.2960 (0.2812)  loss_bbox_aux_4: 0.2770 (0.2772)  loss_bbox_dn_0: 0.3686 (0.3532)  loss_bbox_dn_1: 0.3151 (0.3033)  loss_bbox_dn_2: 0.3047 (0.2870)  loss_bbox_dn_3: 0.3010 (0.2811)  loss_bbox_dn_4: 0.3002 (0.2785)  loss_bbox_dn_5: 0.2997 (0.2785)  loss_bbox_enc_0: 0.3824 (0.3637)  loss_giou: 0.9627 (1.0000)  loss_giou_aux_0: 1.0085 (1.0513)  loss_giou_aux_1: 0.9681 (1.0270)  loss_giou_aux_2: 0.9671 (1.0095)  loss_giou_aux_3: 0.9652 (1.0060)  loss_giou_aux_4: 0.9562 (1.0043)  loss_giou_dn_0: 1.0421 (1.0361)  loss_giou_dn_1: 0.9348 (0.9336)  loss_giou_dn_2: 0.8824 (0.8968)  loss_giou_dn_3: 0.8689 (0.8840)  loss_giou_dn_4: 0.8605 (0.8775)  loss_giou_dn_5: 0.8608 (0.8778)  loss_giou_enc_0: 1.0907 (1.1492)  loss_vfl: 1.1292 (1.0659)  loss_vfl_aux_0: 1.2090 (1.1242)  loss_vfl_aux_1: 1.2046 (1.1181)  loss_vfl_aux_2: 1.2266 (1.1020)  loss_vfl_aux_3: 1.1597 (1.0872)  loss_vfl_aux_4: 1.1177 (1.0715)  loss_vfl_dn_0: 0.5350 (0.5258)  loss_vfl_dn_1: 0.5419 (0.5204)  loss_vfl_dn_2: 0.5514 (0.5214)  loss_vfl_dn_3: 0.5442 (0.5197)  loss_vfl_dn_4: 0.5420 (0.5206)  loss_vfl_dn_5: 0.5336 (0.5206)  loss_vfl_enc_0: 1.1113 (1.0348)  time: 1.0352  data: 0.0318  max mem: 10356\r\n",
      "Epoch: [39] Total time: 0:01:26 (1.0891 s / it)\r\n",
      "Averaged stats: lr: 0.000010  loss: 27.8806 (27.3491)  loss_bbox: 0.2835 (0.2764)  loss_bbox_aux_0: 0.3346 (0.3110)  loss_bbox_aux_1: 0.3089 (0.2895)  loss_bbox_aux_2: 0.2940 (0.2832)  loss_bbox_aux_3: 0.2960 (0.2812)  loss_bbox_aux_4: 0.2770 (0.2772)  loss_bbox_dn_0: 0.3686 (0.3532)  loss_bbox_dn_1: 0.3151 (0.3033)  loss_bbox_dn_2: 0.3047 (0.2870)  loss_bbox_dn_3: 0.3010 (0.2811)  loss_bbox_dn_4: 0.3002 (0.2785)  loss_bbox_dn_5: 0.2997 (0.2785)  loss_bbox_enc_0: 0.3824 (0.3637)  loss_giou: 0.9627 (1.0000)  loss_giou_aux_0: 1.0085 (1.0513)  loss_giou_aux_1: 0.9681 (1.0270)  loss_giou_aux_2: 0.9671 (1.0095)  loss_giou_aux_3: 0.9652 (1.0060)  loss_giou_aux_4: 0.9562 (1.0043)  loss_giou_dn_0: 1.0421 (1.0361)  loss_giou_dn_1: 0.9348 (0.9336)  loss_giou_dn_2: 0.8824 (0.8968)  loss_giou_dn_3: 0.8689 (0.8840)  loss_giou_dn_4: 0.8605 (0.8775)  loss_giou_dn_5: 0.8608 (0.8778)  loss_giou_enc_0: 1.0907 (1.1492)  loss_vfl: 1.1292 (1.0659)  loss_vfl_aux_0: 1.2090 (1.1242)  loss_vfl_aux_1: 1.2046 (1.1181)  loss_vfl_aux_2: 1.2266 (1.1020)  loss_vfl_aux_3: 1.1597 (1.0872)  loss_vfl_aux_4: 1.1177 (1.0715)  loss_vfl_dn_0: 0.5350 (0.5258)  loss_vfl_dn_1: 0.5419 (0.5204)  loss_vfl_dn_2: 0.5514 (0.5214)  loss_vfl_dn_3: 0.5442 (0.5197)  loss_vfl_dn_4: 0.5420 (0.5206)  loss_vfl_dn_5: 0.5336 (0.5206)  loss_vfl_enc_0: 1.1113 (1.0348)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.4389  data: 1.5033  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0844  data: 0.2311  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1003 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.051\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.073\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.052\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.054\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.101\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.285\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.299\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.063\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.340\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.463\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.417\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.317\r\n",
      "best_stat: {'epoch': 39, 'coco_eval_bbox': 0.05056122114529817}\r\n",
      "Epoch: [40]  [ 0/79]  eta: 0:04:54  lr: 0.000001  loss: 27.6905 (27.6905)  loss_bbox: 0.2987 (0.2987)  loss_bbox_aux_0: 0.3698 (0.3698)  loss_bbox_aux_1: 0.2881 (0.2881)  loss_bbox_aux_2: 0.2906 (0.2906)  loss_bbox_aux_3: 0.2927 (0.2927)  loss_bbox_aux_4: 0.2858 (0.2858)  loss_bbox_dn_0: 0.6417 (0.6417)  loss_bbox_dn_1: 0.5007 (0.5007)  loss_bbox_dn_2: 0.4549 (0.4549)  loss_bbox_dn_3: 0.4402 (0.4402)  loss_bbox_dn_4: 0.4323 (0.4323)  loss_bbox_dn_5: 0.4319 (0.4319)  loss_bbox_enc_0: 0.5298 (0.5298)  loss_giou: 0.7155 (0.7155)  loss_giou_aux_0: 0.8201 (0.8201)  loss_giou_aux_1: 0.7309 (0.7309)  loss_giou_aux_2: 0.7293 (0.7293)  loss_giou_aux_3: 0.7251 (0.7251)  loss_giou_aux_4: 0.7132 (0.7132)  loss_giou_dn_0: 0.8732 (0.8732)  loss_giou_dn_1: 0.6901 (0.6901)  loss_giou_dn_2: 0.6410 (0.6410)  loss_giou_dn_3: 0.6191 (0.6191)  loss_giou_dn_4: 0.6031 (0.6031)  loss_giou_dn_5: 0.6038 (0.6038)  loss_giou_enc_0: 0.9341 (0.9341)  loss_vfl: 1.3262 (1.3262)  loss_vfl_aux_0: 1.4570 (1.4570)  loss_vfl_aux_1: 1.4585 (1.4585)  loss_vfl_aux_2: 1.4790 (1.4790)  loss_vfl_aux_3: 1.3477 (1.3477)  loss_vfl_aux_4: 1.3223 (1.3223)  loss_vfl_dn_0: 0.5974 (0.5974)  loss_vfl_dn_1: 0.5657 (0.5657)  loss_vfl_dn_2: 0.5668 (0.5668)  loss_vfl_dn_3: 0.5541 (0.5541)  loss_vfl_dn_4: 0.5599 (0.5599)  loss_vfl_dn_5: 0.5435 (0.5435)  loss_vfl_enc_0: 1.2568 (1.2568)  time: 3.7269  data: 2.4501  max mem: 10356\r\n",
      "Epoch: [40]  [78/79]  eta: 0:00:01  lr: 0.000001  loss: 26.6578 (27.1874)  loss_bbox: 0.2483 (0.2853)  loss_bbox_aux_0: 0.2781 (0.3217)  loss_bbox_aux_1: 0.2554 (0.2995)  loss_bbox_aux_2: 0.2450 (0.2924)  loss_bbox_aux_3: 0.2381 (0.2876)  loss_bbox_aux_4: 0.2411 (0.2875)  loss_bbox_dn_0: 0.2873 (0.3525)  loss_bbox_dn_1: 0.2458 (0.3012)  loss_bbox_dn_2: 0.2329 (0.2857)  loss_bbox_dn_3: 0.2272 (0.2801)  loss_bbox_dn_4: 0.2240 (0.2781)  loss_bbox_dn_5: 0.2237 (0.2780)  loss_bbox_enc_0: 0.3467 (0.3684)  loss_giou: 1.0162 (1.0061)  loss_giou_aux_0: 1.0648 (1.0627)  loss_giou_aux_1: 1.0465 (1.0359)  loss_giou_aux_2: 1.0396 (1.0208)  loss_giou_aux_3: 1.0163 (1.0164)  loss_giou_aux_4: 1.0164 (1.0095)  loss_giou_dn_0: 1.0197 (1.0191)  loss_giou_dn_1: 0.9131 (0.9125)  loss_giou_dn_2: 0.8771 (0.8794)  loss_giou_dn_3: 0.8589 (0.8670)  loss_giou_dn_4: 0.8554 (0.8615)  loss_giou_dn_5: 0.8556 (0.8618)  loss_giou_enc_0: 1.1282 (1.1555)  loss_vfl: 0.9368 (1.0308)  loss_vfl_aux_0: 1.0630 (1.1205)  loss_vfl_aux_1: 1.0269 (1.0888)  loss_vfl_aux_2: 0.9541 (1.0753)  loss_vfl_aux_3: 0.9417 (1.0510)  loss_vfl_aux_4: 0.9683 (1.0414)  loss_vfl_dn_0: 0.5300 (0.5309)  loss_vfl_dn_1: 0.5201 (0.5268)  loss_vfl_dn_2: 0.5166 (0.5225)  loss_vfl_dn_3: 0.5068 (0.5160)  loss_vfl_dn_4: 0.5073 (0.5155)  loss_vfl_dn_5: 0.4971 (0.5085)  loss_vfl_enc_0: 1.0115 (1.0332)  time: 0.9983  data: 0.0311  max mem: 10356\r\n",
      "Epoch: [40] Total time: 0:01:25 (1.0849 s / it)\r\n",
      "Averaged stats: lr: 0.000001  loss: 26.6578 (27.1874)  loss_bbox: 0.2483 (0.2853)  loss_bbox_aux_0: 0.2781 (0.3217)  loss_bbox_aux_1: 0.2554 (0.2995)  loss_bbox_aux_2: 0.2450 (0.2924)  loss_bbox_aux_3: 0.2381 (0.2876)  loss_bbox_aux_4: 0.2411 (0.2875)  loss_bbox_dn_0: 0.2873 (0.3525)  loss_bbox_dn_1: 0.2458 (0.3012)  loss_bbox_dn_2: 0.2329 (0.2857)  loss_bbox_dn_3: 0.2272 (0.2801)  loss_bbox_dn_4: 0.2240 (0.2781)  loss_bbox_dn_5: 0.2237 (0.2780)  loss_bbox_enc_0: 0.3467 (0.3684)  loss_giou: 1.0162 (1.0061)  loss_giou_aux_0: 1.0648 (1.0627)  loss_giou_aux_1: 1.0465 (1.0359)  loss_giou_aux_2: 1.0396 (1.0208)  loss_giou_aux_3: 1.0163 (1.0164)  loss_giou_aux_4: 1.0164 (1.0095)  loss_giou_dn_0: 1.0197 (1.0191)  loss_giou_dn_1: 0.9131 (0.9125)  loss_giou_dn_2: 0.8771 (0.8794)  loss_giou_dn_3: 0.8589 (0.8670)  loss_giou_dn_4: 0.8554 (0.8615)  loss_giou_dn_5: 0.8556 (0.8618)  loss_giou_enc_0: 1.1282 (1.1555)  loss_vfl: 0.9368 (1.0308)  loss_vfl_aux_0: 1.0630 (1.1205)  loss_vfl_aux_1: 1.0269 (1.0888)  loss_vfl_aux_2: 0.9541 (1.0753)  loss_vfl_aux_3: 0.9417 (1.0510)  loss_vfl_aux_4: 0.9683 (1.0414)  loss_vfl_dn_0: 0.5300 (0.5309)  loss_vfl_dn_1: 0.5201 (0.5268)  loss_vfl_dn_2: 0.5166 (0.5225)  loss_vfl_dn_3: 0.5068 (0.5160)  loss_vfl_dn_4: 0.5073 (0.5155)  loss_vfl_dn_5: 0.4971 (0.5085)  loss_vfl_enc_0: 1.0115 (1.0332)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.2239  data: 1.2709  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0673  data: 0.2157  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0829 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.057\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.078\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.060\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.067\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.101\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.212\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.304\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.318\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.075\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.350\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.475\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.431\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.344\r\n",
      "best_stat: {'epoch': 40, 'coco_eval_bbox': 0.05731697525042689}\r\n",
      "Epoch: [41]  [ 0/79]  eta: 0:06:51  lr: 0.000001  loss: 27.1811 (27.1811)  loss_bbox: 0.2837 (0.2837)  loss_bbox_aux_0: 0.2724 (0.2724)  loss_bbox_aux_1: 0.2741 (0.2741)  loss_bbox_aux_2: 0.2742 (0.2742)  loss_bbox_aux_3: 0.2974 (0.2974)  loss_bbox_aux_4: 0.2889 (0.2889)  loss_bbox_dn_0: 0.2801 (0.2801)  loss_bbox_dn_1: 0.2509 (0.2509)  loss_bbox_dn_2: 0.2368 (0.2368)  loss_bbox_dn_3: 0.2324 (0.2324)  loss_bbox_dn_4: 0.2299 (0.2299)  loss_bbox_dn_5: 0.2299 (0.2299)  loss_bbox_enc_0: 0.3356 (0.3356)  loss_giou: 1.0875 (1.0875)  loss_giou_aux_0: 1.1032 (1.1032)  loss_giou_aux_1: 1.0867 (1.0867)  loss_giou_aux_2: 1.1022 (1.1022)  loss_giou_aux_3: 1.0689 (1.0689)  loss_giou_aux_4: 1.0551 (1.0551)  loss_giou_dn_0: 1.0243 (1.0243)  loss_giou_dn_1: 0.9274 (0.9274)  loss_giou_dn_2: 0.8855 (0.8855)  loss_giou_dn_3: 0.8676 (0.8676)  loss_giou_dn_4: 0.8641 (0.8641)  loss_giou_dn_5: 0.8650 (0.8650)  loss_giou_enc_0: 1.1739 (1.1739)  loss_vfl: 0.9817 (0.9817)  loss_vfl_aux_0: 1.1538 (1.1538)  loss_vfl_aux_1: 1.0532 (1.0532)  loss_vfl_aux_2: 1.0154 (1.0154)  loss_vfl_aux_3: 1.0000 (1.0000)  loss_vfl_aux_4: 1.0217 (1.0217)  loss_vfl_dn_0: 0.5398 (0.5398)  loss_vfl_dn_1: 0.5649 (0.5649)  loss_vfl_dn_2: 0.5396 (0.5396)  loss_vfl_dn_3: 0.5356 (0.5356)  loss_vfl_dn_4: 0.5308 (0.5308)  loss_vfl_dn_5: 0.5117 (0.5117)  loss_vfl_enc_0: 1.1353 (1.1353)  time: 5.2033  data: 3.8074  max mem: 10356\r\n",
      "Epoch: [41]  [78/79]  eta: 0:00:01  lr: 0.000001  loss: 26.5588 (26.9827)  loss_bbox: 0.2597 (0.2771)  loss_bbox_aux_0: 0.3000 (0.3109)  loss_bbox_aux_1: 0.2775 (0.2942)  loss_bbox_aux_2: 0.2664 (0.2847)  loss_bbox_aux_3: 0.2703 (0.2796)  loss_bbox_aux_4: 0.2562 (0.2764)  loss_bbox_dn_0: 0.3228 (0.3384)  loss_bbox_dn_1: 0.2850 (0.2871)  loss_bbox_dn_2: 0.2583 (0.2713)  loss_bbox_dn_3: 0.2514 (0.2649)  loss_bbox_dn_4: 0.2532 (0.2625)  loss_bbox_dn_5: 0.2531 (0.2624)  loss_bbox_enc_0: 0.3224 (0.3617)  loss_giou: 1.0040 (1.0060)  loss_giou_aux_0: 1.0529 (1.0573)  loss_giou_aux_1: 1.0336 (1.0358)  loss_giou_aux_2: 1.0119 (1.0200)  loss_giou_aux_3: 1.0021 (1.0158)  loss_giou_aux_4: 1.0025 (1.0079)  loss_giou_dn_0: 0.9976 (1.0184)  loss_giou_dn_1: 0.8788 (0.9125)  loss_giou_dn_2: 0.8453 (0.8782)  loss_giou_dn_3: 0.8377 (0.8654)  loss_giou_dn_4: 0.8316 (0.8596)  loss_giou_dn_5: 0.8316 (0.8596)  loss_giou_enc_0: 1.0991 (1.1507)  loss_vfl: 0.9905 (1.0190)  loss_vfl_aux_0: 1.1182 (1.1180)  loss_vfl_aux_1: 1.0654 (1.0879)  loss_vfl_aux_2: 1.0374 (1.0695)  loss_vfl_aux_3: 1.0195 (1.0511)  loss_vfl_aux_4: 0.9951 (1.0353)  loss_vfl_dn_0: 0.5334 (0.5338)  loss_vfl_dn_1: 0.5276 (0.5256)  loss_vfl_dn_2: 0.5221 (0.5192)  loss_vfl_dn_3: 0.5135 (0.5114)  loss_vfl_dn_4: 0.5128 (0.5085)  loss_vfl_dn_5: 0.5098 (0.5036)  loss_vfl_enc_0: 1.0330 (1.0414)  time: 0.9873  data: 0.0316  max mem: 10356\r\n",
      "Epoch: [41] Total time: 0:01:25 (1.0844 s / it)\r\n",
      "Averaged stats: lr: 0.000001  loss: 26.5588 (26.9827)  loss_bbox: 0.2597 (0.2771)  loss_bbox_aux_0: 0.3000 (0.3109)  loss_bbox_aux_1: 0.2775 (0.2942)  loss_bbox_aux_2: 0.2664 (0.2847)  loss_bbox_aux_3: 0.2703 (0.2796)  loss_bbox_aux_4: 0.2562 (0.2764)  loss_bbox_dn_0: 0.3228 (0.3384)  loss_bbox_dn_1: 0.2850 (0.2871)  loss_bbox_dn_2: 0.2583 (0.2713)  loss_bbox_dn_3: 0.2514 (0.2649)  loss_bbox_dn_4: 0.2532 (0.2625)  loss_bbox_dn_5: 0.2531 (0.2624)  loss_bbox_enc_0: 0.3224 (0.3617)  loss_giou: 1.0040 (1.0060)  loss_giou_aux_0: 1.0529 (1.0573)  loss_giou_aux_1: 1.0336 (1.0358)  loss_giou_aux_2: 1.0119 (1.0200)  loss_giou_aux_3: 1.0021 (1.0158)  loss_giou_aux_4: 1.0025 (1.0079)  loss_giou_dn_0: 0.9976 (1.0184)  loss_giou_dn_1: 0.8788 (0.9125)  loss_giou_dn_2: 0.8453 (0.8782)  loss_giou_dn_3: 0.8377 (0.8654)  loss_giou_dn_4: 0.8316 (0.8596)  loss_giou_dn_5: 0.8316 (0.8596)  loss_giou_enc_0: 1.0991 (1.1507)  loss_vfl: 0.9905 (1.0190)  loss_vfl_aux_0: 1.1182 (1.1180)  loss_vfl_aux_1: 1.0654 (1.0879)  loss_vfl_aux_2: 1.0374 (1.0695)  loss_vfl_aux_3: 1.0195 (1.0511)  loss_vfl_aux_4: 0.9951 (1.0353)  loss_vfl_dn_0: 0.5334 (0.5338)  loss_vfl_dn_1: 0.5276 (0.5256)  loss_vfl_dn_2: 0.5221 (0.5192)  loss_vfl_dn_3: 0.5135 (0.5114)  loss_vfl_dn_4: 0.5128 (0.5085)  loss_vfl_dn_5: 0.5098 (0.5036)  loss_vfl_enc_0: 1.0330 (1.0414)\r\n",
      "Test:  [0/8]  eta: 0:00:16    time: 2.0732  data: 1.0946  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0492  data: 0.1959  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0667 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.060\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.082\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.062\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.018\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.070\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.112\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.212\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.295\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.308\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.080\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.345\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.452\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.429\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.320\r\n",
      "best_stat: {'epoch': 41, 'coco_eval_bbox': 0.05973043702235794}\r\n",
      "Epoch: [42]  [ 0/79]  eta: 0:05:10  lr: 0.000001  loss: 26.5814 (26.5814)  loss_bbox: 0.3055 (0.3055)  loss_bbox_aux_0: 0.3545 (0.3545)  loss_bbox_aux_1: 0.3224 (0.3224)  loss_bbox_aux_2: 0.3110 (0.3110)  loss_bbox_aux_3: 0.3072 (0.3072)  loss_bbox_aux_4: 0.2868 (0.2868)  loss_bbox_dn_0: 0.3539 (0.3539)  loss_bbox_dn_1: 0.2903 (0.2903)  loss_bbox_dn_2: 0.2697 (0.2697)  loss_bbox_dn_3: 0.2631 (0.2631)  loss_bbox_dn_4: 0.2615 (0.2615)  loss_bbox_dn_5: 0.2618 (0.2618)  loss_bbox_enc_0: 0.3759 (0.3759)  loss_giou: 0.8459 (0.8459)  loss_giou_aux_0: 0.9164 (0.9164)  loss_giou_aux_1: 0.8469 (0.8469)  loss_giou_aux_2: 0.8509 (0.8509)  loss_giou_aux_3: 0.8320 (0.8320)  loss_giou_aux_4: 0.8193 (0.8193)  loss_giou_dn_0: 0.9208 (0.9208)  loss_giou_dn_1: 0.7842 (0.7842)  loss_giou_dn_2: 0.7476 (0.7476)  loss_giou_dn_3: 0.7397 (0.7397)  loss_giou_dn_4: 0.7358 (0.7358)  loss_giou_dn_5: 0.7362 (0.7362)  loss_giou_enc_0: 1.0046 (1.0046)  loss_vfl: 1.1943 (1.1943)  loss_vfl_aux_0: 1.2563 (1.2563)  loss_vfl_aux_1: 1.2744 (1.2744)  loss_vfl_aux_2: 1.2168 (1.2168)  loss_vfl_aux_3: 1.2271 (1.2271)  loss_vfl_aux_4: 1.2144 (1.2144)  loss_vfl_dn_0: 0.5820 (0.5820)  loss_vfl_dn_1: 0.5614 (0.5614)  loss_vfl_dn_2: 0.5518 (0.5518)  loss_vfl_dn_3: 0.5278 (0.5278)  loss_vfl_dn_4: 0.5251 (0.5251)  loss_vfl_dn_5: 0.5251 (0.5251)  loss_vfl_enc_0: 1.1809 (1.1809)  time: 3.9351  data: 2.6951  max mem: 10356\r\n",
      "Epoch: [42]  [78/79]  eta: 0:00:01  lr: 0.000001  loss: 26.4259 (26.9428)  loss_bbox: 0.2289 (0.2776)  loss_bbox_aux_0: 0.2612 (0.3082)  loss_bbox_aux_1: 0.2607 (0.2901)  loss_bbox_aux_2: 0.2524 (0.2805)  loss_bbox_aux_3: 0.2341 (0.2783)  loss_bbox_aux_4: 0.2294 (0.2766)  loss_bbox_dn_0: 0.3084 (0.3363)  loss_bbox_dn_1: 0.2373 (0.2827)  loss_bbox_dn_2: 0.2307 (0.2665)  loss_bbox_dn_3: 0.2301 (0.2610)  loss_bbox_dn_4: 0.2295 (0.2586)  loss_bbox_dn_5: 0.2296 (0.2585)  loss_bbox_enc_0: 0.3410 (0.3594)  loss_giou: 1.0687 (1.0198)  loss_giou_aux_0: 1.0368 (1.0673)  loss_giou_aux_1: 1.0396 (1.0469)  loss_giou_aux_2: 1.0631 (1.0311)  loss_giou_aux_3: 1.0740 (1.0294)  loss_giou_aux_4: 1.0667 (1.0224)  loss_giou_dn_0: 1.0159 (1.0158)  loss_giou_dn_1: 0.9184 (0.9127)  loss_giou_dn_2: 0.8690 (0.8790)  loss_giou_dn_3: 0.8491 (0.8668)  loss_giou_dn_4: 0.8375 (0.8606)  loss_giou_dn_5: 0.8382 (0.8606)  loss_giou_enc_0: 1.1515 (1.1557)  loss_vfl: 0.9814 (1.0055)  loss_vfl_aux_0: 1.1416 (1.1136)  loss_vfl_aux_1: 1.0994 (1.0758)  loss_vfl_aux_2: 1.0444 (1.0504)  loss_vfl_aux_3: 1.0112 (1.0350)  loss_vfl_aux_4: 0.9890 (1.0181)  loss_vfl_dn_0: 0.5325 (0.5338)  loss_vfl_dn_1: 0.5132 (0.5232)  loss_vfl_dn_2: 0.5098 (0.5168)  loss_vfl_dn_3: 0.4982 (0.5092)  loss_vfl_dn_4: 0.5018 (0.5064)  loss_vfl_dn_5: 0.4984 (0.5020)  loss_vfl_enc_0: 1.0776 (1.0507)  time: 1.0409  data: 0.0315  max mem: 10356\r\n",
      "Epoch: [42] Total time: 0:01:24 (1.0706 s / it)\r\n",
      "Averaged stats: lr: 0.000001  loss: 26.4259 (26.9428)  loss_bbox: 0.2289 (0.2776)  loss_bbox_aux_0: 0.2612 (0.3082)  loss_bbox_aux_1: 0.2607 (0.2901)  loss_bbox_aux_2: 0.2524 (0.2805)  loss_bbox_aux_3: 0.2341 (0.2783)  loss_bbox_aux_4: 0.2294 (0.2766)  loss_bbox_dn_0: 0.3084 (0.3363)  loss_bbox_dn_1: 0.2373 (0.2827)  loss_bbox_dn_2: 0.2307 (0.2665)  loss_bbox_dn_3: 0.2301 (0.2610)  loss_bbox_dn_4: 0.2295 (0.2586)  loss_bbox_dn_5: 0.2296 (0.2585)  loss_bbox_enc_0: 0.3410 (0.3594)  loss_giou: 1.0687 (1.0198)  loss_giou_aux_0: 1.0368 (1.0673)  loss_giou_aux_1: 1.0396 (1.0469)  loss_giou_aux_2: 1.0631 (1.0311)  loss_giou_aux_3: 1.0740 (1.0294)  loss_giou_aux_4: 1.0667 (1.0224)  loss_giou_dn_0: 1.0159 (1.0158)  loss_giou_dn_1: 0.9184 (0.9127)  loss_giou_dn_2: 0.8690 (0.8790)  loss_giou_dn_3: 0.8491 (0.8668)  loss_giou_dn_4: 0.8375 (0.8606)  loss_giou_dn_5: 0.8382 (0.8606)  loss_giou_enc_0: 1.1515 (1.1557)  loss_vfl: 0.9814 (1.0055)  loss_vfl_aux_0: 1.1416 (1.1136)  loss_vfl_aux_1: 1.0994 (1.0758)  loss_vfl_aux_2: 1.0444 (1.0504)  loss_vfl_aux_3: 1.0112 (1.0350)  loss_vfl_aux_4: 0.9890 (1.0181)  loss_vfl_dn_0: 0.5325 (0.5338)  loss_vfl_dn_1: 0.5132 (0.5232)  loss_vfl_dn_2: 0.5098 (0.5168)  loss_vfl_dn_3: 0.4982 (0.5092)  loss_vfl_dn_4: 0.5018 (0.5064)  loss_vfl_dn_5: 0.4984 (0.5020)  loss_vfl_enc_0: 1.0776 (1.0507)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3161  data: 1.3587  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0803  data: 0.2240  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0966 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.059\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.081\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.059\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.018\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.071\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.107\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.198\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.304\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.076\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.354\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.453\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.427\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.317\r\n",
      "best_stat: {'epoch': 41, 'coco_eval_bbox': 0.05973043702235794}\r\n",
      "Epoch: [43]  [ 0/79]  eta: 0:07:11  lr: 0.000001  loss: 27.4388 (27.4388)  loss_bbox: 0.3478 (0.3478)  loss_bbox_aux_0: 0.3901 (0.3901)  loss_bbox_aux_1: 0.3591 (0.3591)  loss_bbox_aux_2: 0.3565 (0.3565)  loss_bbox_aux_3: 0.3385 (0.3385)  loss_bbox_aux_4: 0.3330 (0.3330)  loss_bbox_dn_0: 0.5447 (0.5447)  loss_bbox_dn_1: 0.4523 (0.4523)  loss_bbox_dn_2: 0.4226 (0.4226)  loss_bbox_dn_3: 0.4091 (0.4091)  loss_bbox_dn_4: 0.4000 (0.4000)  loss_bbox_dn_5: 0.3999 (0.3999)  loss_bbox_enc_0: 0.5098 (0.5098)  loss_giou: 0.6558 (0.6558)  loss_giou_aux_0: 0.7434 (0.7434)  loss_giou_aux_1: 0.6828 (0.6828)  loss_giou_aux_2: 0.6820 (0.6820)  loss_giou_aux_3: 0.6555 (0.6555)  loss_giou_aux_4: 0.6674 (0.6674)  loss_giou_dn_0: 0.9255 (0.9255)  loss_giou_dn_1: 0.7541 (0.7541)  loss_giou_dn_2: 0.7000 (0.7000)  loss_giou_dn_3: 0.6694 (0.6694)  loss_giou_dn_4: 0.6549 (0.6549)  loss_giou_dn_5: 0.6561 (0.6561)  loss_giou_enc_0: 0.9043 (0.9043)  loss_vfl: 1.3364 (1.3364)  loss_vfl_aux_0: 1.4038 (1.4038)  loss_vfl_aux_1: 1.4429 (1.4429)  loss_vfl_aux_2: 1.3745 (1.3745)  loss_vfl_aux_3: 1.3755 (1.3755)  loss_vfl_aux_4: 1.3276 (1.3276)  loss_vfl_dn_0: 0.5537 (0.5537)  loss_vfl_dn_1: 0.5344 (0.5344)  loss_vfl_dn_2: 0.5293 (0.5293)  loss_vfl_dn_3: 0.5220 (0.5220)  loss_vfl_dn_4: 0.5151 (0.5151)  loss_vfl_dn_5: 0.5164 (0.5164)  loss_vfl_enc_0: 1.3926 (1.3926)  time: 5.4673  data: 1.8212  max mem: 10356\r\n",
      "Epoch: [43]  [78/79]  eta: 0:00:01  lr: 0.000001  loss: 26.9702 (27.0054)  loss_bbox: 0.2871 (0.2840)  loss_bbox_aux_0: 0.2836 (0.3144)  loss_bbox_aux_1: 0.2730 (0.2977)  loss_bbox_aux_2: 0.2718 (0.2920)  loss_bbox_aux_3: 0.2735 (0.2869)  loss_bbox_aux_4: 0.2885 (0.2842)  loss_bbox_dn_0: 0.2830 (0.3491)  loss_bbox_dn_1: 0.2302 (0.2951)  loss_bbox_dn_2: 0.2270 (0.2793)  loss_bbox_dn_3: 0.2257 (0.2727)  loss_bbox_dn_4: 0.2234 (0.2700)  loss_bbox_dn_5: 0.2234 (0.2698)  loss_bbox_enc_0: 0.3398 (0.3693)  loss_giou: 0.9915 (1.0184)  loss_giou_aux_0: 1.0469 (1.0710)  loss_giou_aux_1: 1.0295 (1.0482)  loss_giou_aux_2: 1.0022 (1.0297)  loss_giou_aux_3: 0.9924 (1.0264)  loss_giou_aux_4: 0.9887 (1.0229)  loss_giou_dn_0: 1.0383 (1.0199)  loss_giou_dn_1: 0.9478 (0.9167)  loss_giou_dn_2: 0.9236 (0.8840)  loss_giou_dn_3: 0.9076 (0.8718)  loss_giou_dn_4: 0.9041 (0.8654)  loss_giou_dn_5: 0.9041 (0.8654)  loss_giou_enc_0: 1.0959 (1.1611)  loss_vfl: 0.8889 (0.9921)  loss_vfl_aux_0: 1.0188 (1.1045)  loss_vfl_aux_1: 0.9312 (1.0639)  loss_vfl_aux_2: 0.9238 (1.0420)  loss_vfl_aux_3: 0.8811 (1.0199)  loss_vfl_aux_4: 0.9194 (1.0065)  loss_vfl_dn_0: 0.5206 (0.5325)  loss_vfl_dn_1: 0.5072 (0.5211)  loss_vfl_dn_2: 0.5056 (0.5152)  loss_vfl_dn_3: 0.5000 (0.5085)  loss_vfl_dn_4: 0.4944 (0.5047)  loss_vfl_dn_5: 0.4879 (0.4989)  loss_vfl_enc_0: 0.8706 (1.0304)  time: 0.9985  data: 0.0337  max mem: 10356\r\n",
      "Epoch: [43] Total time: 0:01:26 (1.0954 s / it)\r\n",
      "Averaged stats: lr: 0.000001  loss: 26.9702 (27.0054)  loss_bbox: 0.2871 (0.2840)  loss_bbox_aux_0: 0.2836 (0.3144)  loss_bbox_aux_1: 0.2730 (0.2977)  loss_bbox_aux_2: 0.2718 (0.2920)  loss_bbox_aux_3: 0.2735 (0.2869)  loss_bbox_aux_4: 0.2885 (0.2842)  loss_bbox_dn_0: 0.2830 (0.3491)  loss_bbox_dn_1: 0.2302 (0.2951)  loss_bbox_dn_2: 0.2270 (0.2793)  loss_bbox_dn_3: 0.2257 (0.2727)  loss_bbox_dn_4: 0.2234 (0.2700)  loss_bbox_dn_5: 0.2234 (0.2698)  loss_bbox_enc_0: 0.3398 (0.3693)  loss_giou: 0.9915 (1.0184)  loss_giou_aux_0: 1.0469 (1.0710)  loss_giou_aux_1: 1.0295 (1.0482)  loss_giou_aux_2: 1.0022 (1.0297)  loss_giou_aux_3: 0.9924 (1.0264)  loss_giou_aux_4: 0.9887 (1.0229)  loss_giou_dn_0: 1.0383 (1.0199)  loss_giou_dn_1: 0.9478 (0.9167)  loss_giou_dn_2: 0.9236 (0.8840)  loss_giou_dn_3: 0.9076 (0.8718)  loss_giou_dn_4: 0.9041 (0.8654)  loss_giou_dn_5: 0.9041 (0.8654)  loss_giou_enc_0: 1.0959 (1.1611)  loss_vfl: 0.8889 (0.9921)  loss_vfl_aux_0: 1.0188 (1.1045)  loss_vfl_aux_1: 0.9312 (1.0639)  loss_vfl_aux_2: 0.9238 (1.0420)  loss_vfl_aux_3: 0.8811 (1.0199)  loss_vfl_aux_4: 0.9194 (1.0065)  loss_vfl_dn_0: 0.5206 (0.5325)  loss_vfl_dn_1: 0.5072 (0.5211)  loss_vfl_dn_2: 0.5056 (0.5152)  loss_vfl_dn_3: 0.5000 (0.5085)  loss_vfl_dn_4: 0.4944 (0.5047)  loss_vfl_dn_5: 0.4879 (0.4989)  loss_vfl_enc_0: 0.8706 (1.0304)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3580  data: 1.4117  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0753  data: 0.2190  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0934 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.059\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.081\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.062\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.069\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.110\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.212\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.309\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.318\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.080\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.357\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.459\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.456\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.332\r\n",
      "best_stat: {'epoch': 41, 'coco_eval_bbox': 0.05973043702235794}\r\n",
      "Epoch: [44]  [ 0/79]  eta: 0:06:20  lr: 0.000001  loss: 28.2933 (28.2933)  loss_bbox: 0.2539 (0.2539)  loss_bbox_aux_0: 0.3410 (0.3410)  loss_bbox_aux_1: 0.2910 (0.2910)  loss_bbox_aux_2: 0.2839 (0.2839)  loss_bbox_aux_3: 0.2748 (0.2748)  loss_bbox_aux_4: 0.2657 (0.2657)  loss_bbox_dn_0: 0.3229 (0.3229)  loss_bbox_dn_1: 0.2772 (0.2772)  loss_bbox_dn_2: 0.2719 (0.2719)  loss_bbox_dn_3: 0.2713 (0.2713)  loss_bbox_dn_4: 0.2702 (0.2702)  loss_bbox_dn_5: 0.2699 (0.2699)  loss_bbox_enc_0: 0.3770 (0.3770)  loss_giou: 1.3089 (1.3089)  loss_giou_aux_0: 1.2924 (1.2924)  loss_giou_aux_1: 1.3160 (1.3160)  loss_giou_aux_2: 1.3195 (1.3195)  loss_giou_aux_3: 1.3234 (1.3234)  loss_giou_aux_4: 1.3164 (1.3164)  loss_giou_dn_0: 1.1343 (1.1343)  loss_giou_dn_1: 1.0556 (1.0556)  loss_giou_dn_2: 1.0316 (1.0316)  loss_giou_dn_3: 1.0283 (1.0283)  loss_giou_dn_4: 1.0241 (1.0241)  loss_giou_dn_5: 1.0241 (1.0241)  loss_giou_enc_0: 1.3861 (1.3861)  loss_vfl: 0.8552 (0.8552)  loss_vfl_aux_0: 0.9126 (0.9126)  loss_vfl_aux_1: 0.9138 (0.9138)  loss_vfl_aux_2: 0.9248 (0.9248)  loss_vfl_aux_3: 0.8997 (0.8997)  loss_vfl_aux_4: 0.8513 (0.8513)  loss_vfl_dn_0: 0.4540 (0.4540)  loss_vfl_dn_1: 0.4535 (0.4535)  loss_vfl_dn_2: 0.4589 (0.4589)  loss_vfl_dn_3: 0.4539 (0.4539)  loss_vfl_dn_4: 0.4551 (0.4551)  loss_vfl_dn_5: 0.4542 (0.4542)  loss_vfl_enc_0: 0.8750 (0.8750)  time: 4.8207  data: 2.9080  max mem: 10356\r\n",
      "Epoch: [44]  [78/79]  eta: 0:00:01  lr: 0.000001  loss: 26.1291 (26.8326)  loss_bbox: 0.2459 (0.2755)  loss_bbox_aux_0: 0.2755 (0.3072)  loss_bbox_aux_1: 0.2617 (0.2906)  loss_bbox_aux_2: 0.2526 (0.2825)  loss_bbox_aux_3: 0.2570 (0.2801)  loss_bbox_aux_4: 0.2471 (0.2766)  loss_bbox_dn_0: 0.2550 (0.3336)  loss_bbox_dn_1: 0.2070 (0.2801)  loss_bbox_dn_2: 0.1951 (0.2632)  loss_bbox_dn_3: 0.1894 (0.2573)  loss_bbox_dn_4: 0.1865 (0.2547)  loss_bbox_dn_5: 0.1865 (0.2546)  loss_bbox_enc_0: 0.3366 (0.3599)  loss_giou: 1.0916 (1.0115)  loss_giou_aux_0: 1.1036 (1.0603)  loss_giou_aux_1: 1.1012 (1.0350)  loss_giou_aux_2: 1.0841 (1.0187)  loss_giou_aux_3: 1.0970 (1.0141)  loss_giou_aux_4: 1.0881 (1.0107)  loss_giou_dn_0: 1.0022 (1.0140)  loss_giou_dn_1: 0.8982 (0.9081)  loss_giou_dn_2: 0.8736 (0.8727)  loss_giou_dn_3: 0.8644 (0.8605)  loss_giou_dn_4: 0.8574 (0.8544)  loss_giou_dn_5: 0.8572 (0.8542)  loss_giou_enc_0: 1.2055 (1.1430)  loss_vfl: 0.9014 (1.0019)  loss_vfl_aux_0: 1.0044 (1.1160)  loss_vfl_aux_1: 0.9617 (1.0791)  loss_vfl_aux_2: 0.9246 (1.0622)  loss_vfl_aux_3: 0.9185 (1.0336)  loss_vfl_aux_4: 0.9326 (1.0168)  loss_vfl_dn_0: 0.5336 (0.5348)  loss_vfl_dn_1: 0.5247 (0.5244)  loss_vfl_dn_2: 0.5194 (0.5178)  loss_vfl_dn_3: 0.5095 (0.5094)  loss_vfl_dn_4: 0.5043 (0.5053)  loss_vfl_dn_5: 0.5001 (0.4992)  loss_vfl_enc_0: 0.9556 (1.0590)  time: 0.9574  data: 0.0324  max mem: 10356\r\n",
      "Epoch: [44] Total time: 0:01:26 (1.0982 s / it)\r\n",
      "Averaged stats: lr: 0.000001  loss: 26.1291 (26.8326)  loss_bbox: 0.2459 (0.2755)  loss_bbox_aux_0: 0.2755 (0.3072)  loss_bbox_aux_1: 0.2617 (0.2906)  loss_bbox_aux_2: 0.2526 (0.2825)  loss_bbox_aux_3: 0.2570 (0.2801)  loss_bbox_aux_4: 0.2471 (0.2766)  loss_bbox_dn_0: 0.2550 (0.3336)  loss_bbox_dn_1: 0.2070 (0.2801)  loss_bbox_dn_2: 0.1951 (0.2632)  loss_bbox_dn_3: 0.1894 (0.2573)  loss_bbox_dn_4: 0.1865 (0.2547)  loss_bbox_dn_5: 0.1865 (0.2546)  loss_bbox_enc_0: 0.3366 (0.3599)  loss_giou: 1.0916 (1.0115)  loss_giou_aux_0: 1.1036 (1.0603)  loss_giou_aux_1: 1.1012 (1.0350)  loss_giou_aux_2: 1.0841 (1.0187)  loss_giou_aux_3: 1.0970 (1.0141)  loss_giou_aux_4: 1.0881 (1.0107)  loss_giou_dn_0: 1.0022 (1.0140)  loss_giou_dn_1: 0.8982 (0.9081)  loss_giou_dn_2: 0.8736 (0.8727)  loss_giou_dn_3: 0.8644 (0.8605)  loss_giou_dn_4: 0.8574 (0.8544)  loss_giou_dn_5: 0.8572 (0.8542)  loss_giou_enc_0: 1.2055 (1.1430)  loss_vfl: 0.9014 (1.0019)  loss_vfl_aux_0: 1.0044 (1.1160)  loss_vfl_aux_1: 0.9617 (1.0791)  loss_vfl_aux_2: 0.9246 (1.0622)  loss_vfl_aux_3: 0.9185 (1.0336)  loss_vfl_aux_4: 0.9326 (1.0168)  loss_vfl_dn_0: 0.5336 (0.5348)  loss_vfl_dn_1: 0.5247 (0.5244)  loss_vfl_dn_2: 0.5194 (0.5178)  loss_vfl_dn_3: 0.5095 (0.5094)  loss_vfl_dn_4: 0.5043 (0.5053)  loss_vfl_dn_5: 0.5001 (0.4992)  loss_vfl_enc_0: 0.9556 (1.0590)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3132  data: 1.3599  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0777  data: 0.2170  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0940 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.28s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.056\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.077\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.058\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.022\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.070\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.104\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.214\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.294\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.308\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.083\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.367\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.447\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.438\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.316\r\n",
      "best_stat: {'epoch': 41, 'coco_eval_bbox': 0.05973043702235794}\r\n",
      "Epoch: [45]  [ 0/79]  eta: 0:05:49  lr: 0.000001  loss: 26.2203 (26.2203)  loss_bbox: 0.2367 (0.2367)  loss_bbox_aux_0: 0.2565 (0.2565)  loss_bbox_aux_1: 0.2508 (0.2508)  loss_bbox_aux_2: 0.2447 (0.2447)  loss_bbox_aux_3: 0.2397 (0.2397)  loss_bbox_aux_4: 0.2431 (0.2431)  loss_bbox_dn_0: 0.2696 (0.2696)  loss_bbox_dn_1: 0.2208 (0.2208)  loss_bbox_dn_2: 0.2107 (0.2107)  loss_bbox_dn_3: 0.2095 (0.2095)  loss_bbox_dn_4: 0.2110 (0.2110)  loss_bbox_dn_5: 0.2110 (0.2110)  loss_bbox_enc_0: 0.3023 (0.3023)  loss_giou: 1.1182 (1.1182)  loss_giou_aux_0: 1.1993 (1.1993)  loss_giou_aux_1: 1.1392 (1.1392)  loss_giou_aux_2: 1.1345 (1.1345)  loss_giou_aux_3: 1.1309 (1.1309)  loss_giou_aux_4: 1.1223 (1.1223)  loss_giou_dn_0: 1.0550 (1.0550)  loss_giou_dn_1: 0.9475 (0.9475)  loss_giou_dn_2: 0.9204 (0.9204)  loss_giou_dn_3: 0.9123 (0.9123)  loss_giou_dn_4: 0.9120 (0.9120)  loss_giou_dn_5: 0.9128 (0.9128)  loss_giou_enc_0: 1.2405 (1.2405)  loss_vfl: 0.8679 (0.8679)  loss_vfl_aux_0: 0.9277 (0.9277)  loss_vfl_aux_1: 0.9343 (0.9343)  loss_vfl_aux_2: 0.8989 (0.8989)  loss_vfl_aux_3: 0.9021 (0.9021)  loss_vfl_aux_4: 0.8698 (0.8698)  loss_vfl_dn_0: 0.4931 (0.4931)  loss_vfl_dn_1: 0.5219 (0.5219)  loss_vfl_dn_2: 0.5048 (0.5048)  loss_vfl_dn_3: 0.5115 (0.5115)  loss_vfl_dn_4: 0.5076 (0.5076)  loss_vfl_dn_5: 0.5065 (0.5065)  loss_vfl_enc_0: 0.9229 (0.9229)  time: 4.4295  data: 2.4486  max mem: 10356\r\n",
      "Epoch: [45]  [78/79]  eta: 0:00:01  lr: 0.000001  loss: 26.3332 (26.9507)  loss_bbox: 0.2435 (0.2802)  loss_bbox_aux_0: 0.2944 (0.3108)  loss_bbox_aux_1: 0.2623 (0.2925)  loss_bbox_aux_2: 0.2382 (0.2845)  loss_bbox_aux_3: 0.2530 (0.2806)  loss_bbox_aux_4: 0.2365 (0.2803)  loss_bbox_dn_0: 0.2762 (0.3428)  loss_bbox_dn_1: 0.2528 (0.2900)  loss_bbox_dn_2: 0.2376 (0.2760)  loss_bbox_dn_3: 0.2339 (0.2706)  loss_bbox_dn_4: 0.2340 (0.2683)  loss_bbox_dn_5: 0.2341 (0.2682)  loss_bbox_enc_0: 0.3465 (0.3594)  loss_giou: 1.0207 (1.0058)  loss_giou_aux_0: 1.0878 (1.0604)  loss_giou_aux_1: 1.0671 (1.0342)  loss_giou_aux_2: 1.0446 (1.0186)  loss_giou_aux_3: 1.0268 (1.0162)  loss_giou_aux_4: 1.0244 (1.0104)  loss_giou_dn_0: 1.0125 (1.0117)  loss_giou_dn_1: 0.8985 (0.9086)  loss_giou_dn_2: 0.8712 (0.8765)  loss_giou_dn_3: 0.8601 (0.8657)  loss_giou_dn_4: 0.8633 (0.8597)  loss_giou_dn_5: 0.8640 (0.8597)  loss_giou_enc_0: 1.2039 (1.1464)  loss_vfl: 0.9067 (1.0070)  loss_vfl_aux_0: 1.0151 (1.1236)  loss_vfl_aux_1: 0.9697 (1.0908)  loss_vfl_aux_2: 0.9548 (1.0622)  loss_vfl_aux_3: 0.9534 (1.0401)  loss_vfl_aux_4: 0.9241 (1.0184)  loss_vfl_dn_0: 0.5148 (0.5360)  loss_vfl_dn_1: 0.5087 (0.5226)  loss_vfl_dn_2: 0.4996 (0.5140)  loss_vfl_dn_3: 0.4956 (0.5065)  loss_vfl_dn_4: 0.4915 (0.5015)  loss_vfl_dn_5: 0.4840 (0.4963)  loss_vfl_enc_0: 0.9121 (1.0535)  time: 0.9414  data: 0.0320  max mem: 10356\r\n",
      "Epoch: [45] Total time: 0:01:23 (1.0532 s / it)\r\n",
      "Averaged stats: lr: 0.000001  loss: 26.3332 (26.9507)  loss_bbox: 0.2435 (0.2802)  loss_bbox_aux_0: 0.2944 (0.3108)  loss_bbox_aux_1: 0.2623 (0.2925)  loss_bbox_aux_2: 0.2382 (0.2845)  loss_bbox_aux_3: 0.2530 (0.2806)  loss_bbox_aux_4: 0.2365 (0.2803)  loss_bbox_dn_0: 0.2762 (0.3428)  loss_bbox_dn_1: 0.2528 (0.2900)  loss_bbox_dn_2: 0.2376 (0.2760)  loss_bbox_dn_3: 0.2339 (0.2706)  loss_bbox_dn_4: 0.2340 (0.2683)  loss_bbox_dn_5: 0.2341 (0.2682)  loss_bbox_enc_0: 0.3465 (0.3594)  loss_giou: 1.0207 (1.0058)  loss_giou_aux_0: 1.0878 (1.0604)  loss_giou_aux_1: 1.0671 (1.0342)  loss_giou_aux_2: 1.0446 (1.0186)  loss_giou_aux_3: 1.0268 (1.0162)  loss_giou_aux_4: 1.0244 (1.0104)  loss_giou_dn_0: 1.0125 (1.0117)  loss_giou_dn_1: 0.8985 (0.9086)  loss_giou_dn_2: 0.8712 (0.8765)  loss_giou_dn_3: 0.8601 (0.8657)  loss_giou_dn_4: 0.8633 (0.8597)  loss_giou_dn_5: 0.8640 (0.8597)  loss_giou_enc_0: 1.2039 (1.1464)  loss_vfl: 0.9067 (1.0070)  loss_vfl_aux_0: 1.0151 (1.1236)  loss_vfl_aux_1: 0.9697 (1.0908)  loss_vfl_aux_2: 0.9548 (1.0622)  loss_vfl_aux_3: 0.9534 (1.0401)  loss_vfl_aux_4: 0.9241 (1.0184)  loss_vfl_dn_0: 0.5148 (0.5360)  loss_vfl_dn_1: 0.5087 (0.5226)  loss_vfl_dn_2: 0.4996 (0.5140)  loss_vfl_dn_3: 0.4956 (0.5065)  loss_vfl_dn_4: 0.4915 (0.5015)  loss_vfl_dn_5: 0.4840 (0.4963)  loss_vfl_enc_0: 0.9121 (1.0535)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.2916  data: 1.2771  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0773  data: 0.2176  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0950 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.057\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.076\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.057\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.023\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.073\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.105\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.294\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.307\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.080\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.366\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.435\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.423\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.326\r\n",
      "best_stat: {'epoch': 41, 'coco_eval_bbox': 0.05973043702235794}\r\n",
      "Epoch: [46]  [ 0/79]  eta: 0:06:17  lr: 0.000001  loss: 24.9933 (24.9933)  loss_bbox: 0.1807 (0.1807)  loss_bbox_aux_0: 0.2311 (0.2311)  loss_bbox_aux_1: 0.1781 (0.1781)  loss_bbox_aux_2: 0.2002 (0.2002)  loss_bbox_aux_3: 0.2014 (0.2014)  loss_bbox_aux_4: 0.1833 (0.1833)  loss_bbox_dn_0: 0.3238 (0.3238)  loss_bbox_dn_1: 0.2758 (0.2758)  loss_bbox_dn_2: 0.2551 (0.2551)  loss_bbox_dn_3: 0.2477 (0.2477)  loss_bbox_dn_4: 0.2432 (0.2432)  loss_bbox_dn_5: 0.2432 (0.2432)  loss_bbox_enc_0: 0.3516 (0.3516)  loss_giou: 0.6317 (0.6317)  loss_giou_aux_0: 0.6956 (0.6956)  loss_giou_aux_1: 0.6468 (0.6468)  loss_giou_aux_2: 0.6380 (0.6380)  loss_giou_aux_3: 0.6291 (0.6291)  loss_giou_aux_4: 0.6355 (0.6355)  loss_giou_dn_0: 0.8453 (0.8453)  loss_giou_dn_1: 0.6994 (0.6994)  loss_giou_dn_2: 0.6563 (0.6563)  loss_giou_dn_3: 0.6439 (0.6439)  loss_giou_dn_4: 0.6309 (0.6309)  loss_giou_dn_5: 0.6306 (0.6306)  loss_giou_enc_0: 0.9306 (0.9306)  loss_vfl: 1.3716 (1.3716)  loss_vfl_aux_0: 1.4292 (1.4292)  loss_vfl_aux_1: 1.4482 (1.4482)  loss_vfl_aux_2: 1.4370 (1.4370)  loss_vfl_aux_3: 1.4048 (1.4048)  loss_vfl_aux_4: 1.3843 (1.3843)  loss_vfl_dn_0: 0.5813 (0.5813)  loss_vfl_dn_1: 0.5546 (0.5546)  loss_vfl_dn_2: 0.5264 (0.5264)  loss_vfl_dn_3: 0.5161 (0.5161)  loss_vfl_dn_4: 0.5095 (0.5095)  loss_vfl_dn_5: 0.4998 (0.4998)  loss_vfl_enc_0: 1.3018 (1.3018)  time: 4.7841  data: 2.9038  max mem: 10356\r\n",
      "Epoch: [46]  [78/79]  eta: 0:00:01  lr: 0.000001  loss: 26.9403 (26.5544)  loss_bbox: 0.2586 (0.2604)  loss_bbox_aux_0: 0.2642 (0.2964)  loss_bbox_aux_1: 0.2761 (0.2767)  loss_bbox_aux_2: 0.2715 (0.2701)  loss_bbox_aux_3: 0.2640 (0.2644)  loss_bbox_aux_4: 0.2777 (0.2605)  loss_bbox_dn_0: 0.3461 (0.3306)  loss_bbox_dn_1: 0.2799 (0.2776)  loss_bbox_dn_2: 0.2599 (0.2621)  loss_bbox_dn_3: 0.2491 (0.2558)  loss_bbox_dn_4: 0.2489 (0.2532)  loss_bbox_dn_5: 0.2489 (0.2531)  loss_bbox_enc_0: 0.3335 (0.3454)  loss_giou: 0.9365 (0.9758)  loss_giou_aux_0: 0.9809 (1.0263)  loss_giou_aux_1: 0.9446 (1.0022)  loss_giou_aux_2: 0.9470 (0.9858)  loss_giou_aux_3: 0.9365 (0.9824)  loss_giou_aux_4: 0.9396 (0.9797)  loss_giou_dn_0: 1.0194 (1.0059)  loss_giou_dn_1: 0.9256 (0.9000)  loss_giou_dn_2: 0.9039 (0.8663)  loss_giou_dn_3: 0.8977 (0.8539)  loss_giou_dn_4: 0.8910 (0.8474)  loss_giou_dn_5: 0.8916 (0.8472)  loss_giou_enc_0: 1.0797 (1.1221)  loss_vfl: 1.0769 (1.0107)  loss_vfl_aux_0: 1.1306 (1.1277)  loss_vfl_aux_1: 1.1655 (1.0980)  loss_vfl_aux_2: 1.1143 (1.0755)  loss_vfl_aux_3: 1.0664 (1.0523)  loss_vfl_aux_4: 1.0544 (1.0351)  loss_vfl_dn_0: 0.5383 (0.5381)  loss_vfl_dn_1: 0.5205 (0.5269)  loss_vfl_dn_2: 0.5167 (0.5181)  loss_vfl_dn_3: 0.4967 (0.5098)  loss_vfl_dn_4: 0.4935 (0.5050)  loss_vfl_dn_5: 0.4916 (0.4989)  loss_vfl_enc_0: 1.0676 (1.0568)  time: 0.9658  data: 0.0307  max mem: 10356\r\n",
      "Epoch: [46] Total time: 0:01:26 (1.0898 s / it)\r\n",
      "Averaged stats: lr: 0.000001  loss: 26.9403 (26.5544)  loss_bbox: 0.2586 (0.2604)  loss_bbox_aux_0: 0.2642 (0.2964)  loss_bbox_aux_1: 0.2761 (0.2767)  loss_bbox_aux_2: 0.2715 (0.2701)  loss_bbox_aux_3: 0.2640 (0.2644)  loss_bbox_aux_4: 0.2777 (0.2605)  loss_bbox_dn_0: 0.3461 (0.3306)  loss_bbox_dn_1: 0.2799 (0.2776)  loss_bbox_dn_2: 0.2599 (0.2621)  loss_bbox_dn_3: 0.2491 (0.2558)  loss_bbox_dn_4: 0.2489 (0.2532)  loss_bbox_dn_5: 0.2489 (0.2531)  loss_bbox_enc_0: 0.3335 (0.3454)  loss_giou: 0.9365 (0.9758)  loss_giou_aux_0: 0.9809 (1.0263)  loss_giou_aux_1: 0.9446 (1.0022)  loss_giou_aux_2: 0.9470 (0.9858)  loss_giou_aux_3: 0.9365 (0.9824)  loss_giou_aux_4: 0.9396 (0.9797)  loss_giou_dn_0: 1.0194 (1.0059)  loss_giou_dn_1: 0.9256 (0.9000)  loss_giou_dn_2: 0.9039 (0.8663)  loss_giou_dn_3: 0.8977 (0.8539)  loss_giou_dn_4: 0.8910 (0.8474)  loss_giou_dn_5: 0.8916 (0.8472)  loss_giou_enc_0: 1.0797 (1.1221)  loss_vfl: 1.0769 (1.0107)  loss_vfl_aux_0: 1.1306 (1.1277)  loss_vfl_aux_1: 1.1655 (1.0980)  loss_vfl_aux_2: 1.1143 (1.0755)  loss_vfl_aux_3: 1.0664 (1.0523)  loss_vfl_aux_4: 1.0544 (1.0351)  loss_vfl_dn_0: 0.5383 (0.5381)  loss_vfl_dn_1: 0.5205 (0.5269)  loss_vfl_dn_2: 0.5167 (0.5181)  loss_vfl_dn_3: 0.4967 (0.5098)  loss_vfl_dn_4: 0.4935 (0.5050)  loss_vfl_dn_5: 0.4916 (0.4989)  loss_vfl_enc_0: 1.0676 (1.0568)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.4204  data: 1.4559  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0769  data: 0.2200  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0934 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.26s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.053\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.071\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.054\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.020\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.067\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.095\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.210\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.304\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.316\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.082\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.356\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.468\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.438\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.331\r\n",
      "best_stat: {'epoch': 41, 'coco_eval_bbox': 0.05973043702235794}\r\n",
      "Epoch: [47]  [ 0/79]  eta: 0:06:10  lr: 0.000001  loss: 28.1907 (28.1907)  loss_bbox: 0.3210 (0.3210)  loss_bbox_aux_0: 0.3666 (0.3666)  loss_bbox_aux_1: 0.3461 (0.3461)  loss_bbox_aux_2: 0.3404 (0.3404)  loss_bbox_aux_3: 0.3359 (0.3359)  loss_bbox_aux_4: 0.3290 (0.3290)  loss_bbox_dn_0: 0.4137 (0.4137)  loss_bbox_dn_1: 0.3719 (0.3719)  loss_bbox_dn_2: 0.3579 (0.3579)  loss_bbox_dn_3: 0.3523 (0.3523)  loss_bbox_dn_4: 0.3494 (0.3494)  loss_bbox_dn_5: 0.3495 (0.3495)  loss_bbox_enc_0: 0.4079 (0.4079)  loss_giou: 1.2007 (1.2007)  loss_giou_aux_0: 1.2269 (1.2269)  loss_giou_aux_1: 1.2012 (1.2012)  loss_giou_aux_2: 1.1973 (1.1973)  loss_giou_aux_3: 1.1773 (1.1773)  loss_giou_aux_4: 1.1792 (1.1792)  loss_giou_dn_0: 1.1175 (1.1175)  loss_giou_dn_1: 1.0449 (1.0449)  loss_giou_dn_2: 1.0183 (1.0183)  loss_giou_dn_3: 1.0056 (1.0056)  loss_giou_dn_4: 1.0038 (1.0038)  loss_giou_dn_5: 1.0036 (1.0036)  loss_giou_enc_0: 1.2909 (1.2909)  loss_vfl: 0.8906 (0.8906)  loss_vfl_aux_0: 0.8660 (0.8660)  loss_vfl_aux_1: 0.8733 (0.8733)  loss_vfl_aux_2: 0.8628 (0.8628)  loss_vfl_aux_3: 0.8833 (0.8833)  loss_vfl_aux_4: 0.8691 (0.8691)  loss_vfl_dn_0: 0.4753 (0.4753)  loss_vfl_dn_1: 0.4644 (0.4644)  loss_vfl_dn_2: 0.4626 (0.4626)  loss_vfl_dn_3: 0.4587 (0.4587)  loss_vfl_dn_4: 0.4579 (0.4579)  loss_vfl_dn_5: 0.4630 (0.4630)  loss_vfl_enc_0: 0.8547 (0.8547)  time: 4.6848  data: 3.1761  max mem: 10356\r\n",
      "Epoch: [47]  [78/79]  eta: 0:00:01  lr: 0.000001  loss: 27.1246 (26.7601)  loss_bbox: 0.2522 (0.2689)  loss_bbox_aux_0: 0.2719 (0.2968)  loss_bbox_aux_1: 0.2730 (0.2848)  loss_bbox_aux_2: 0.2612 (0.2772)  loss_bbox_aux_3: 0.2547 (0.2713)  loss_bbox_aux_4: 0.2483 (0.2718)  loss_bbox_dn_0: 0.3179 (0.3470)  loss_bbox_dn_1: 0.2572 (0.2921)  loss_bbox_dn_2: 0.2385 (0.2763)  loss_bbox_dn_3: 0.2399 (0.2705)  loss_bbox_dn_4: 0.2418 (0.2678)  loss_bbox_dn_5: 0.2417 (0.2677)  loss_bbox_enc_0: 0.3320 (0.3476)  loss_giou: 1.0575 (0.9844)  loss_giou_aux_0: 1.1204 (1.0307)  loss_giou_aux_1: 1.0609 (1.0060)  loss_giou_aux_2: 1.0643 (0.9898)  loss_giou_aux_3: 1.0750 (0.9901)  loss_giou_aux_4: 1.0654 (0.9854)  loss_giou_dn_0: 1.0222 (1.0057)  loss_giou_dn_1: 0.9207 (0.8994)  loss_giou_dn_2: 0.8902 (0.8667)  loss_giou_dn_3: 0.8787 (0.8546)  loss_giou_dn_4: 0.8668 (0.8483)  loss_giou_dn_5: 0.8661 (0.8481)  loss_giou_enc_0: 1.1721 (1.1217)  loss_vfl: 1.0215 (1.0161)  loss_vfl_aux_0: 1.0581 (1.1391)  loss_vfl_aux_1: 1.0942 (1.0943)  loss_vfl_aux_2: 1.0532 (1.0718)  loss_vfl_aux_3: 1.0540 (1.0525)  loss_vfl_aux_4: 1.0605 (1.0356)  loss_vfl_dn_0: 0.5321 (0.5409)  loss_vfl_dn_1: 0.5281 (0.5274)  loss_vfl_dn_2: 0.5204 (0.5195)  loss_vfl_dn_3: 0.5272 (0.5104)  loss_vfl_dn_4: 0.5151 (0.5065)  loss_vfl_dn_5: 0.5122 (0.5008)  loss_vfl_enc_0: 0.9983 (1.0744)  time: 0.9456  data: 0.0333  max mem: 10356\r\n",
      "Epoch: [47] Total time: 0:01:24 (1.0710 s / it)\r\n",
      "Averaged stats: lr: 0.000001  loss: 27.1246 (26.7601)  loss_bbox: 0.2522 (0.2689)  loss_bbox_aux_0: 0.2719 (0.2968)  loss_bbox_aux_1: 0.2730 (0.2848)  loss_bbox_aux_2: 0.2612 (0.2772)  loss_bbox_aux_3: 0.2547 (0.2713)  loss_bbox_aux_4: 0.2483 (0.2718)  loss_bbox_dn_0: 0.3179 (0.3470)  loss_bbox_dn_1: 0.2572 (0.2921)  loss_bbox_dn_2: 0.2385 (0.2763)  loss_bbox_dn_3: 0.2399 (0.2705)  loss_bbox_dn_4: 0.2418 (0.2678)  loss_bbox_dn_5: 0.2417 (0.2677)  loss_bbox_enc_0: 0.3320 (0.3476)  loss_giou: 1.0575 (0.9844)  loss_giou_aux_0: 1.1204 (1.0307)  loss_giou_aux_1: 1.0609 (1.0060)  loss_giou_aux_2: 1.0643 (0.9898)  loss_giou_aux_3: 1.0750 (0.9901)  loss_giou_aux_4: 1.0654 (0.9854)  loss_giou_dn_0: 1.0222 (1.0057)  loss_giou_dn_1: 0.9207 (0.8994)  loss_giou_dn_2: 0.8902 (0.8667)  loss_giou_dn_3: 0.8787 (0.8546)  loss_giou_dn_4: 0.8668 (0.8483)  loss_giou_dn_5: 0.8661 (0.8481)  loss_giou_enc_0: 1.1721 (1.1217)  loss_vfl: 1.0215 (1.0161)  loss_vfl_aux_0: 1.0581 (1.1391)  loss_vfl_aux_1: 1.0942 (1.0943)  loss_vfl_aux_2: 1.0532 (1.0718)  loss_vfl_aux_3: 1.0540 (1.0525)  loss_vfl_aux_4: 1.0605 (1.0356)  loss_vfl_dn_0: 0.5321 (0.5409)  loss_vfl_dn_1: 0.5281 (0.5274)  loss_vfl_dn_2: 0.5204 (0.5195)  loss_vfl_dn_3: 0.5272 (0.5104)  loss_vfl_dn_4: 0.5151 (0.5065)  loss_vfl_dn_5: 0.5122 (0.5008)  loss_vfl_enc_0: 0.9983 (1.0744)\r\n",
      "Test:  [0/8]  eta: 0:00:16    time: 2.0836  data: 1.1604  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0523  data: 0.2014  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0696 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.17s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.058\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.080\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.058\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.072\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.101\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.198\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.300\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.311\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.081\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.350\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.458\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.434\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.320\r\n",
      "best_stat: {'epoch': 41, 'coco_eval_bbox': 0.05973043702235794}\r\n",
      "Epoch: [48]  [ 0/79]  eta: 0:06:00  lr: 0.000001  loss: 29.9731 (29.9731)  loss_bbox: 0.4627 (0.4627)  loss_bbox_aux_0: 0.5081 (0.5081)  loss_bbox_aux_1: 0.4637 (0.4637)  loss_bbox_aux_2: 0.4820 (0.4820)  loss_bbox_aux_3: 0.4963 (0.4963)  loss_bbox_aux_4: 0.4897 (0.4897)  loss_bbox_dn_0: 0.1879 (0.1879)  loss_bbox_dn_1: 0.1533 (0.1533)  loss_bbox_dn_2: 0.1403 (0.1403)  loss_bbox_dn_3: 0.1344 (0.1344)  loss_bbox_dn_4: 0.1321 (0.1321)  loss_bbox_dn_5: 0.1322 (0.1322)  loss_bbox_enc_0: 0.5131 (0.5131)  loss_giou: 1.7184 (1.7184)  loss_giou_aux_0: 1.7316 (1.7316)  loss_giou_aux_1: 1.7585 (1.7585)  loss_giou_aux_2: 1.6991 (1.6991)  loss_giou_aux_3: 1.6632 (1.6632)  loss_giou_aux_4: 1.6836 (1.6836)  loss_giou_dn_0: 1.1119 (1.1119)  loss_giou_dn_1: 1.0563 (1.0563)  loss_giou_dn_2: 1.0308 (1.0308)  loss_giou_dn_3: 1.0225 (1.0225)  loss_giou_dn_4: 1.0188 (1.0188)  loss_giou_dn_5: 1.0187 (1.0187)  loss_giou_enc_0: 1.8570 (1.8570)  loss_vfl: 0.6150 (0.6150)  loss_vfl_aux_0: 0.6768 (0.6768)  loss_vfl_aux_1: 0.6599 (0.6599)  loss_vfl_aux_2: 0.6404 (0.6404)  loss_vfl_aux_3: 0.6260 (0.6260)  loss_vfl_aux_4: 0.5984 (0.5984)  loss_vfl_dn_0: 0.4973 (0.4973)  loss_vfl_dn_1: 0.4832 (0.4832)  loss_vfl_dn_2: 0.4774 (0.4774)  loss_vfl_dn_3: 0.4720 (0.4720)  loss_vfl_dn_4: 0.4656 (0.4656)  loss_vfl_dn_5: 0.4666 (0.4666)  loss_vfl_enc_0: 0.6287 (0.6287)  time: 4.5597  data: 2.9476  max mem: 10356\r\n",
      "Epoch: [48]  [78/79]  eta: 0:00:01  lr: 0.000001  loss: 26.4079 (26.7202)  loss_bbox: 0.2348 (0.2688)  loss_bbox_aux_0: 0.2728 (0.3028)  loss_bbox_aux_1: 0.2486 (0.2837)  loss_bbox_aux_2: 0.2425 (0.2778)  loss_bbox_aux_3: 0.2414 (0.2736)  loss_bbox_aux_4: 0.2396 (0.2702)  loss_bbox_dn_0: 0.3043 (0.3461)  loss_bbox_dn_1: 0.2546 (0.2913)  loss_bbox_dn_2: 0.2307 (0.2754)  loss_bbox_dn_3: 0.2249 (0.2691)  loss_bbox_dn_4: 0.2242 (0.2660)  loss_bbox_dn_5: 0.2240 (0.2659)  loss_bbox_enc_0: 0.3075 (0.3508)  loss_giou: 0.8676 (0.9877)  loss_giou_aux_0: 0.9294 (1.0397)  loss_giou_aux_1: 0.9225 (1.0141)  loss_giou_aux_2: 0.9152 (0.9968)  loss_giou_aux_3: 0.8914 (0.9946)  loss_giou_aux_4: 0.8860 (0.9905)  loss_giou_dn_0: 0.9635 (1.0036)  loss_giou_dn_1: 0.8506 (0.8977)  loss_giou_dn_2: 0.8107 (0.8625)  loss_giou_dn_3: 0.7964 (0.8500)  loss_giou_dn_4: 0.7888 (0.8430)  loss_giou_dn_5: 0.7883 (0.8429)  loss_giou_enc_0: 1.0065 (1.1294)  loss_vfl: 1.0776 (1.0049)  loss_vfl_aux_0: 1.2280 (1.1362)  loss_vfl_aux_1: 1.1704 (1.1004)  loss_vfl_aux_2: 1.1309 (1.0633)  loss_vfl_aux_3: 1.1113 (1.0380)  loss_vfl_aux_4: 1.0762 (1.0186)  loss_vfl_dn_0: 0.5580 (0.5389)  loss_vfl_dn_1: 0.5488 (0.5259)  loss_vfl_dn_2: 0.5394 (0.5186)  loss_vfl_dn_3: 0.5317 (0.5101)  loss_vfl_dn_4: 0.5316 (0.5054)  loss_vfl_dn_5: 0.5304 (0.5005)  loss_vfl_enc_0: 1.1550 (1.0654)  time: 1.0185  data: 0.0317  max mem: 10356\r\n",
      "Epoch: [48] Total time: 0:01:25 (1.0875 s / it)\r\n",
      "Averaged stats: lr: 0.000001  loss: 26.4079 (26.7202)  loss_bbox: 0.2348 (0.2688)  loss_bbox_aux_0: 0.2728 (0.3028)  loss_bbox_aux_1: 0.2486 (0.2837)  loss_bbox_aux_2: 0.2425 (0.2778)  loss_bbox_aux_3: 0.2414 (0.2736)  loss_bbox_aux_4: 0.2396 (0.2702)  loss_bbox_dn_0: 0.3043 (0.3461)  loss_bbox_dn_1: 0.2546 (0.2913)  loss_bbox_dn_2: 0.2307 (0.2754)  loss_bbox_dn_3: 0.2249 (0.2691)  loss_bbox_dn_4: 0.2242 (0.2660)  loss_bbox_dn_5: 0.2240 (0.2659)  loss_bbox_enc_0: 0.3075 (0.3508)  loss_giou: 0.8676 (0.9877)  loss_giou_aux_0: 0.9294 (1.0397)  loss_giou_aux_1: 0.9225 (1.0141)  loss_giou_aux_2: 0.9152 (0.9968)  loss_giou_aux_3: 0.8914 (0.9946)  loss_giou_aux_4: 0.8860 (0.9905)  loss_giou_dn_0: 0.9635 (1.0036)  loss_giou_dn_1: 0.8506 (0.8977)  loss_giou_dn_2: 0.8107 (0.8625)  loss_giou_dn_3: 0.7964 (0.8500)  loss_giou_dn_4: 0.7888 (0.8430)  loss_giou_dn_5: 0.7883 (0.8429)  loss_giou_enc_0: 1.0065 (1.1294)  loss_vfl: 1.0776 (1.0049)  loss_vfl_aux_0: 1.2280 (1.1362)  loss_vfl_aux_1: 1.1704 (1.1004)  loss_vfl_aux_2: 1.1309 (1.0633)  loss_vfl_aux_3: 1.1113 (1.0380)  loss_vfl_aux_4: 1.0762 (1.0186)  loss_vfl_dn_0: 0.5580 (0.5389)  loss_vfl_dn_1: 0.5488 (0.5259)  loss_vfl_dn_2: 0.5394 (0.5186)  loss_vfl_dn_3: 0.5317 (0.5101)  loss_vfl_dn_4: 0.5316 (0.5054)  loss_vfl_dn_5: 0.5304 (0.5005)  loss_vfl_enc_0: 1.1550 (1.0654)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.2918  data: 1.3070  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0753  data: 0.2144  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0909 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.055\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.080\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.055\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.020\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.070\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.097\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.196\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.300\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.082\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.357\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.463\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.440\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.318\r\n",
      "best_stat: {'epoch': 41, 'coco_eval_bbox': 0.05973043702235794}\r\n",
      "Epoch: [49]  [ 0/79]  eta: 0:05:16  lr: 0.000001  loss: 25.7825 (25.7825)  loss_bbox: 0.2460 (0.2460)  loss_bbox_aux_0: 0.2469 (0.2469)  loss_bbox_aux_1: 0.2402 (0.2402)  loss_bbox_aux_2: 0.2554 (0.2554)  loss_bbox_aux_3: 0.2327 (0.2327)  loss_bbox_aux_4: 0.2450 (0.2450)  loss_bbox_dn_0: 0.2325 (0.2325)  loss_bbox_dn_1: 0.1760 (0.1760)  loss_bbox_dn_2: 0.1597 (0.1597)  loss_bbox_dn_3: 0.1561 (0.1561)  loss_bbox_dn_4: 0.1564 (0.1564)  loss_bbox_dn_5: 0.1561 (0.1561)  loss_bbox_enc_0: 0.3032 (0.3032)  loss_giou: 1.0244 (1.0244)  loss_giou_aux_0: 1.0363 (1.0363)  loss_giou_aux_1: 1.0270 (1.0270)  loss_giou_aux_2: 1.0389 (1.0389)  loss_giou_aux_3: 1.0279 (1.0279)  loss_giou_aux_4: 1.0348 (1.0348)  loss_giou_dn_0: 1.0019 (1.0019)  loss_giou_dn_1: 0.9043 (0.9043)  loss_giou_dn_2: 0.8786 (0.8786)  loss_giou_dn_3: 0.8708 (0.8708)  loss_giou_dn_4: 0.8713 (0.8713)  loss_giou_dn_5: 0.8710 (0.8710)  loss_giou_enc_0: 1.1083 (1.1083)  loss_vfl: 0.9788 (0.9788)  loss_vfl_aux_0: 1.1685 (1.1685)  loss_vfl_aux_1: 1.1072 (1.1072)  loss_vfl_aux_2: 1.0388 (1.0388)  loss_vfl_aux_3: 0.9961 (0.9961)  loss_vfl_aux_4: 0.9675 (0.9675)  loss_vfl_dn_0: 0.5270 (0.5270)  loss_vfl_dn_1: 0.5159 (0.5159)  loss_vfl_dn_2: 0.4993 (0.4993)  loss_vfl_dn_3: 0.4816 (0.4816)  loss_vfl_dn_4: 0.4821 (0.4821)  loss_vfl_dn_5: 0.4755 (0.4755)  loss_vfl_enc_0: 1.0427 (1.0427)  time: 4.0007  data: 2.3176  max mem: 10356\r\n",
      "Epoch: [49]  [78/79]  eta: 0:00:01  lr: 0.000001  loss: 26.3015 (26.6138)  loss_bbox: 0.2505 (0.2607)  loss_bbox_aux_0: 0.2737 (0.2917)  loss_bbox_aux_1: 0.2633 (0.2741)  loss_bbox_aux_2: 0.2521 (0.2663)  loss_bbox_aux_3: 0.2510 (0.2648)  loss_bbox_aux_4: 0.2434 (0.2629)  loss_bbox_dn_0: 0.3398 (0.3421)  loss_bbox_dn_1: 0.2636 (0.2854)  loss_bbox_dn_2: 0.2412 (0.2678)  loss_bbox_dn_3: 0.2339 (0.2611)  loss_bbox_dn_4: 0.2290 (0.2583)  loss_bbox_dn_5: 0.2289 (0.2581)  loss_bbox_enc_0: 0.3438 (0.3438)  loss_giou: 0.9191 (0.9744)  loss_giou_aux_0: 0.9374 (1.0213)  loss_giou_aux_1: 0.9103 (1.0001)  loss_giou_aux_2: 0.9041 (0.9867)  loss_giou_aux_3: 0.8954 (0.9811)  loss_giou_aux_4: 0.8878 (0.9771)  loss_giou_dn_0: 0.9732 (1.0039)  loss_giou_dn_1: 0.8521 (0.8937)  loss_giou_dn_2: 0.8198 (0.8591)  loss_giou_dn_3: 0.8034 (0.8464)  loss_giou_dn_4: 0.8016 (0.8403)  loss_giou_dn_5: 0.8021 (0.8402)  loss_giou_enc_0: 1.0221 (1.1111)  loss_vfl: 1.0452 (1.0223)  loss_vfl_aux_0: 1.1836 (1.1432)  loss_vfl_aux_1: 1.0962 (1.1080)  loss_vfl_aux_2: 1.0967 (1.0829)  loss_vfl_aux_3: 1.0947 (1.0614)  loss_vfl_aux_4: 1.0637 (1.0443)  loss_vfl_dn_0: 0.5479 (0.5392)  loss_vfl_dn_1: 0.5326 (0.5259)  loss_vfl_dn_2: 0.5199 (0.5176)  loss_vfl_dn_3: 0.5115 (0.5092)  loss_vfl_dn_4: 0.5057 (0.5046)  loss_vfl_dn_5: 0.4943 (0.4978)  loss_vfl_enc_0: 1.1223 (1.0854)  time: 1.0011  data: 0.0320  max mem: 10356\r\n",
      "Epoch: [49] Total time: 0:01:25 (1.0881 s / it)\r\n",
      "Averaged stats: lr: 0.000001  loss: 26.3015 (26.6138)  loss_bbox: 0.2505 (0.2607)  loss_bbox_aux_0: 0.2737 (0.2917)  loss_bbox_aux_1: 0.2633 (0.2741)  loss_bbox_aux_2: 0.2521 (0.2663)  loss_bbox_aux_3: 0.2510 (0.2648)  loss_bbox_aux_4: 0.2434 (0.2629)  loss_bbox_dn_0: 0.3398 (0.3421)  loss_bbox_dn_1: 0.2636 (0.2854)  loss_bbox_dn_2: 0.2412 (0.2678)  loss_bbox_dn_3: 0.2339 (0.2611)  loss_bbox_dn_4: 0.2290 (0.2583)  loss_bbox_dn_5: 0.2289 (0.2581)  loss_bbox_enc_0: 0.3438 (0.3438)  loss_giou: 0.9191 (0.9744)  loss_giou_aux_0: 0.9374 (1.0213)  loss_giou_aux_1: 0.9103 (1.0001)  loss_giou_aux_2: 0.9041 (0.9867)  loss_giou_aux_3: 0.8954 (0.9811)  loss_giou_aux_4: 0.8878 (0.9771)  loss_giou_dn_0: 0.9732 (1.0039)  loss_giou_dn_1: 0.8521 (0.8937)  loss_giou_dn_2: 0.8198 (0.8591)  loss_giou_dn_3: 0.8034 (0.8464)  loss_giou_dn_4: 0.8016 (0.8403)  loss_giou_dn_5: 0.8021 (0.8402)  loss_giou_enc_0: 1.0221 (1.1111)  loss_vfl: 1.0452 (1.0223)  loss_vfl_aux_0: 1.1836 (1.1432)  loss_vfl_aux_1: 1.0962 (1.1080)  loss_vfl_aux_2: 1.0967 (1.0829)  loss_vfl_aux_3: 1.0947 (1.0614)  loss_vfl_aux_4: 1.0637 (1.0443)  loss_vfl_dn_0: 0.5479 (0.5392)  loss_vfl_dn_1: 0.5326 (0.5259)  loss_vfl_dn_2: 0.5199 (0.5176)  loss_vfl_dn_3: 0.5115 (0.5092)  loss_vfl_dn_4: 0.5057 (0.5046)  loss_vfl_dn_5: 0.4943 (0.4978)  loss_vfl_enc_0: 1.1223 (1.0854)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.1386  data: 1.2164  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0609  data: 0.2062  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0766 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.058\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.081\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.060\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.075\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.100\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.196\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.296\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.306\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.071\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.358\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.446\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.431\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.322\r\n",
      "best_stat: {'epoch': 41, 'coco_eval_bbox': 0.05973043702235794}\r\n",
      "Training time 1:22:54\r\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/RT-DETR/rtdetrv2_pytorch/\n",
    "\n",
    "!torchrun --nproc_per_node=2 tools/train.py \\\n",
    "    -c configs/rtdetrv2/rtdetrv2_taco_finetune_convnext.yml \\\n",
    "    --use-amp \\\n",
    "    --seed=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "854cae41",
   "metadata": {
    "_cell_guid": "0fb01b42-24cd-4d5c-9116-e8cf752cc8b9",
    "_uuid": "07f73175-fea4-4d6f-b4d7-1aa994068d55",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-30T21:33:59.045343Z",
     "iopub.status.busy": "2025-10-30T21:33:59.045033Z",
     "iopub.status.idle": "2025-10-30T21:33:59.051168Z",
     "shell.execute_reply": "2025-10-30T21:33:59.050491Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.242056,
     "end_time": "2025-10-30T21:33:59.052252",
     "exception": false,
     "start_time": "2025-10-30T21:33:58.810196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/RT-DETR/rtdetrv2_pytorch/configs/rtdetrv2/rtdetrv2_taco_finetune_vit.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/RT-DETR/rtdetrv2_pytorch/configs/rtdetrv2/rtdetrv2_taco_finetune_vit.yml\n",
    "__include__: [\n",
    "  '../dataset/coco_detection.yml',\n",
    "  '../runtime.yml',\n",
    "  './include/dataloader.yml',\n",
    "  './include/rtdetrv2_r50vd.yml',\n",
    "]\n",
    "\n",
    "output_dir: /kaggle/working/FINAL/FINETUNE_DISTILLED/rtdetrv2_finetune_taco_vit_teacher\n",
    "\n",
    "RTDETR:\n",
    "  backbone: PResNet\n",
    "\n",
    "PResNet:\n",
    "  depth: 50\n",
    "  variant: d\n",
    "  freeze_at: 0\n",
    "  return_idx: [1, 2, 3]\n",
    "  num_stages: 4\n",
    "  freeze_norm: True\n",
    "  pretrained: False\n",
    "\n",
    "task: detection\n",
    "remap_mscoco_category: false\n",
    "tuning: '/kaggle/working/FINAL/DISTILL-VIT/distilled_rtdetr_vit_teacher_BEST.pth'\n",
    "compile: true\n",
    "epoches: 50\n",
    "\n",
    "num_classes: 60\n",
    "\n",
    "train_dataloader:\n",
    "  num_workers: 4\n",
    "  dataset:\n",
    "    type: CocoDetection\n",
    "    img_folder: /kaggle/input/dsp-pre-final/processed_taco_coco/train2017\n",
    "    ann_file: /kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_train2017.json\n",
    "\n",
    "val_dataloader:\n",
    "  num_workers: 4\n",
    "  dataset:\n",
    "    type: CocoDetection\n",
    "    img_folder: /kaggle/input/dsp-pre-final/processed_taco_coco/val2017\n",
    "    ann_file: /kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_val2017.json\n",
    "\n",
    "batch_size: 16\n",
    "\n",
    "optimizer:\n",
    "  type: AdamW\n",
    "  params:\n",
    "    - params: '^(?=.*backbone)'\n",
    "      lr: 0.00002   \n",
    "  lr: 0.00002   \n",
    "  weight_decay: 0.0001\n",
    "  betas: [0.9, 0.999]\n",
    "\n",
    "lr_scheduler:\n",
    "  type: MultiStepLR\n",
    "  milestones: [40]\n",
    "  gamma: 0.1\n",
    "\n",
    "checkpoint_freq: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e919ed5",
   "metadata": {
    "_cell_guid": "3b0c0c33-d8fd-413f-a2c3-9f69606cb06e",
    "_uuid": "6a4678e7-7327-419a-b7ff-a59772ba9bf6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-30T21:33:59.520045Z",
     "iopub.status.busy": "2025-10-30T21:33:59.519769Z",
     "iopub.status.idle": "2025-10-30T22:57:25.108387Z",
     "shell.execute_reply": "2025-10-30T22:57:25.107567Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 5005.82417,
     "end_time": "2025-10-30T22:57:25.110466",
     "exception": false,
     "start_time": "2025-10-30T21:33:59.286296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/RT-DETR/rtdetrv2_pytorch\n",
      "W1030 21:34:01.734000 10042 torch/distributed/run.py:793] \r\n",
      "W1030 21:34:01.734000 10042 torch/distributed/run.py:793] *****************************************\r\n",
      "W1030 21:34:01.734000 10042 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \r\n",
      "W1030 21:34:01.734000 10042 torch/distributed/run.py:793] *****************************************\r\n",
      "2025-10-30 21:34:04.167425: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2025-10-30 21:34:04.167448: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1761860044.189074   10047 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1761860044.189074   10048 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1761860044.195550   10047 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "E0000 00:00:1761860044.195550   10048 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Initialized distributed mode...\r\n",
      "cfg:  {'task': 'detection', '_model': None, '_postprocessor': None, '_criterion': None, '_optimizer': None, '_lr_scheduler': None, '_lr_warmup_scheduler': None, '_train_dataloader': None, '_val_dataloader': None, '_ema': None, '_scaler': None, '_train_dataset': None, '_val_dataset': None, '_collate_fn': None, '_evaluator': None, '_writer': None, 'num_workers': 0, 'batch_size': 16, '_train_batch_size': None, '_val_batch_size': None, '_train_shuffle': None, '_val_shuffle': None, 'resume': None, 'tuning': '/kaggle/working/FINAL/DISTILL-VIT/distilled_rtdetr_vit_teacher_BEST.pth', 'epoches': 50, 'last_epoch': -1, 'use_amp': True, 'use_ema': False, 'ema_decay': 0.9999, 'ema_warmups': 2000, 'sync_bn': True, 'clip_max_norm': 0.0, 'find_unused_parameters': False, 'seed': 0, 'print_freq': 100, 'checkpoint_freq': 10, 'output_dir': '/kaggle/working/FINAL/FINETUNE_DISTILLED/rtdetrv2_finetune_taco_vit_teacher', 'summary_dir': None, 'device': '', 'yaml_cfg': {'task': 'detection', 'evaluator': {'type': 'CocoEvaluator', 'iou_types': ['bbox']}, 'num_classes': 60, 'remap_mscoco_category': False, 'train_dataloader': {'type': 'DataLoader', 'dataset': {'type': 'CocoDetection', 'img_folder': '/kaggle/input/dsp-pre-final/processed_taco_coco/train2017', 'ann_file': '/kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_train2017.json', 'return_masks': False, 'transforms': {'type': 'Compose', 'ops': [{'type': 'RandomPhotometricDistort', 'p': 0.5}, {'type': 'RandomZoomOut', 'fill': 0}, {'type': 'RandomIoUCrop', 'p': 0.8}, {'type': 'SanitizeBoundingBoxes', 'min_size': 1}, {'type': 'RandomHorizontalFlip'}, {'type': 'Resize', 'size': [640, 640]}, {'type': 'SanitizeBoundingBoxes', 'min_size': 1}, {'type': 'ConvertPILImage', 'dtype': 'float32', 'scale': True}, {'type': 'ConvertBoxes', 'fmt': 'cxcywh', 'normalize': True}], 'policy': {'name': 'stop_epoch', 'epoch': 71, 'ops': ['RandomPhotometricDistort', 'RandomZoomOut', 'RandomIoUCrop']}}}, 'shuffle': True, 'num_workers': 4, 'drop_last': True, 'collate_fn': {'type': 'BatchImageCollateFuncion', 'scales': [480, 512, 544, 576, 608, 640, 640, 640, 672, 704, 736, 768, 800], 'stop_epoch': 71}, 'total_batch_size': 16}, 'val_dataloader': {'type': 'DataLoader', 'dataset': {'type': 'CocoDetection', 'img_folder': '/kaggle/input/dsp-pre-final/processed_taco_coco/val2017', 'ann_file': '/kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_val2017.json', 'return_masks': False, 'transforms': {'type': 'Compose', 'ops': [{'type': 'Resize', 'size': [640, 640]}, {'type': 'ConvertPILImage', 'dtype': 'float32', 'scale': True}]}}, 'shuffle': False, 'num_workers': 4, 'drop_last': False, 'collate_fn': {'type': 'BatchImageCollateFuncion'}, 'total_batch_size': 32}, 'print_freq': 100, 'output_dir': '/kaggle/working/FINAL/FINETUNE_DISTILLED/rtdetrv2_finetune_taco_vit_teacher', 'checkpoint_freq': 10, 'sync_bn': True, 'find_unused_parameters': False, 'use_amp': True, 'scaler': {'type': 'GradScaler', 'enabled': True}, 'use_ema': False, 'ema': {'type': 'ModelEMA', 'decay': 0.9999, 'warmups': 2000}, 'model': 'RTDETR', 'criterion': 'RTDETRCriterionv2', 'postprocessor': 'RTDETRPostProcessor', 'use_focal_loss': True, 'eval_spatial_size': [640, 640], 'RTDETR': {'backbone': 'PResNet', 'encoder': 'HybridEncoder', 'decoder': 'RTDETRTransformerv2'}, 'PResNet': {'depth': 50, 'variant': 'd', 'freeze_at': 0, 'return_idx': [1, 2, 3], 'num_stages': 4, 'freeze_norm': True, 'pretrained': False}, 'HybridEncoder': {'in_channels': [512, 1024, 2048], 'feat_strides': [8, 16, 32], 'hidden_dim': 256, 'use_encoder_idx': [2], 'num_encoder_layers': 1, 'nhead': 8, 'dim_feedforward': 1024, 'dropout': 0.0, 'enc_act': 'gelu', 'expansion': 1.0, 'depth_mult': 1, 'act': 'silu'}, 'RTDETRTransformerv2': {'feat_channels': [256, 256, 256], 'feat_strides': [8, 16, 32], 'hidden_dim': 256, 'num_levels': 3, 'num_layers': 6, 'num_queries': 300, 'num_denoising': 100, 'label_noise_ratio': 0.5, 'box_noise_scale': 1.0, 'eval_idx': -1, 'num_points': [4, 4, 4], 'cross_attn_method': 'default', 'query_select_method': 'default'}, 'RTDETRPostProcessor': {'num_top_queries': 300}, 'RTDETRCriterionv2': {'weight_dict': {'loss_vfl': 1, 'loss_bbox': 5, 'loss_giou': 2}, 'losses': ['vfl', 'boxes'], 'alpha': 0.75, 'gamma': 2.0, 'matcher': {'type': 'HungarianMatcher', 'weight_dict': {'cost_class': 2, 'cost_bbox': 5, 'cost_giou': 2}, 'alpha': 0.25, 'gamma': 2.0}}, '__include__': ['../dataset/coco_detection.yml', '../runtime.yml', './include/dataloader.yml', './include/rtdetrv2_r50vd.yml'], 'tuning': '/kaggle/working/FINAL/DISTILL-VIT/distilled_rtdetr_vit_teacher_BEST.pth', 'compile': True, 'epoches': 50, 'batch_size': 16, 'optimizer': {'type': 'AdamW', 'params': [{'params': '^(?=.*backbone)', 'lr': 2e-05}], 'lr': 2e-05, 'weight_decay': 0.0001, 'betas': [0.9, 0.999]}, 'lr_scheduler': {'type': 'MultiStepLR', 'milestones': [40], 'gamma': 0.1}, 'config': 'configs/rtdetrv2/rtdetrv2_taco_finetune_vit.yml', 'seed': 0, 'test_only': False, 'print_method': 'builtin', 'print_rank': 0}}\r\n",
      "Start training\r\n",
      "Initialized distributed mode...\r\n",
      "tuning checkpoint from /kaggle/working/FINAL/DISTILL-VIT/distilled_rtdetr_vit_teacher_BEST.pth\r\n",
      "/kaggle/working/RT-DETR/rtdetrv2_pytorch/tools/../src/solver/_solver.py:155: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  state = torch.load(path, map_location='cpu')\r\n",
      "/kaggle/working/RT-DETR/rtdetrv2_pytorch/tools/../src/solver/_solver.py:155: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  state = torch.load(path, map_location='cpu')\r\n",
      "Load model.state_dict, {'missed': ['backbone.conv1.conv1_1.conv.weight', 'backbone.conv1.conv1_1.norm.weight', 'backbone.conv1.conv1_1.norm.bias', 'backbone.conv1.conv1_1.norm.running_mean', 'backbone.conv1.conv1_1.norm.running_var', 'backbone.conv1.conv1_2.conv.weight', 'backbone.conv1.conv1_2.norm.weight', 'backbone.conv1.conv1_2.norm.bias', 'backbone.conv1.conv1_2.norm.running_mean', 'backbone.conv1.conv1_2.norm.running_var', 'backbone.conv1.conv1_3.conv.weight', 'backbone.conv1.conv1_3.norm.weight', 'backbone.conv1.conv1_3.norm.bias', 'backbone.conv1.conv1_3.norm.running_mean', 'backbone.conv1.conv1_3.norm.running_var', 'backbone.res_layers.0.blocks.0.branch2a.conv.weight', 'backbone.res_layers.0.blocks.0.branch2a.norm.weight', 'backbone.res_layers.0.blocks.0.branch2a.norm.bias', 'backbone.res_layers.0.blocks.0.branch2a.norm.running_mean', 'backbone.res_layers.0.blocks.0.branch2a.norm.running_var', 'backbone.res_layers.0.blocks.0.branch2b.conv.weight', 'backbone.res_layers.0.blocks.0.branch2b.norm.weight', 'backbone.res_layers.0.blocks.0.branch2b.norm.bias', 'backbone.res_layers.0.blocks.0.branch2b.norm.running_mean', 'backbone.res_layers.0.blocks.0.branch2b.norm.running_var', 'backbone.res_layers.0.blocks.0.branch2c.conv.weight', 'backbone.res_layers.0.blocks.0.branch2c.norm.weight', 'backbone.res_layers.0.blocks.0.branch2c.norm.bias', 'backbone.res_layers.0.blocks.0.branch2c.norm.running_mean', 'backbone.res_layers.0.blocks.0.branch2c.norm.running_var', 'backbone.res_layers.0.blocks.0.short.conv.weight', 'backbone.res_layers.0.blocks.0.short.norm.weight', 'backbone.res_layers.0.blocks.0.short.norm.bias', 'backbone.res_layers.0.blocks.0.short.norm.running_mean', 'backbone.res_layers.0.blocks.0.short.norm.running_var', 'backbone.res_layers.0.blocks.1.branch2a.conv.weight', 'backbone.res_layers.0.blocks.1.branch2a.norm.weight', 'backbone.res_layers.0.blocks.1.branch2a.norm.bias', 'backbone.res_layers.0.blocks.1.branch2a.norm.running_mean', 'backbone.res_layers.0.blocks.1.branch2a.norm.running_var', 'backbone.res_layers.0.blocks.1.branch2b.conv.weight', 'backbone.res_layers.0.blocks.1.branch2b.norm.weight', 'backbone.res_layers.0.blocks.1.branch2b.norm.bias', 'backbone.res_layers.0.blocks.1.branch2b.norm.running_mean', 'backbone.res_layers.0.blocks.1.branch2b.norm.running_var', 'backbone.res_layers.0.blocks.1.branch2c.conv.weight', 'backbone.res_layers.0.blocks.1.branch2c.norm.weight', 'backbone.res_layers.0.blocks.1.branch2c.norm.bias', 'backbone.res_layers.0.blocks.1.branch2c.norm.running_mean', 'backbone.res_layers.0.blocks.1.branch2c.norm.running_var', 'backbone.res_layers.0.blocks.2.branch2a.conv.weight', 'backbone.res_layers.0.blocks.2.branch2a.norm.weight', 'backbone.res_layers.0.blocks.2.branch2a.norm.bias', 'backbone.res_layers.0.blocks.2.branch2a.norm.running_mean', 'backbone.res_layers.0.blocks.2.branch2a.norm.running_var', 'backbone.res_layers.0.blocks.2.branch2b.conv.weight', 'backbone.res_layers.0.blocks.2.branch2b.norm.weight', 'backbone.res_layers.0.blocks.2.branch2b.norm.bias', 'backbone.res_layers.0.blocks.2.branch2b.norm.running_mean', 'backbone.res_layers.0.blocks.2.branch2b.norm.running_var', 'backbone.res_layers.0.blocks.2.branch2c.conv.weight', 'backbone.res_layers.0.blocks.2.branch2c.norm.weight', 'backbone.res_layers.0.blocks.2.branch2c.norm.bias', 'backbone.res_layers.0.blocks.2.branch2c.norm.running_mean', 'backbone.res_layers.0.blocks.2.branch2c.norm.running_var', 'backbone.res_layers.1.blocks.0.branch2a.conv.weight', 'backbone.res_layers.1.blocks.0.branch2a.norm.weight', 'backbone.res_layers.1.blocks.0.branch2a.norm.bias', 'backbone.res_layers.1.blocks.0.branch2a.norm.running_mean', 'backbone.res_layers.1.blocks.0.branch2a.norm.running_var', 'backbone.res_layers.1.blocks.0.branch2b.conv.weight', 'backbone.res_layers.1.blocks.0.branch2b.norm.weight', 'backbone.res_layers.1.blocks.0.branch2b.norm.bias', 'backbone.res_layers.1.blocks.0.branch2b.norm.running_mean', 'backbone.res_layers.1.blocks.0.branch2b.norm.running_var', 'backbone.res_layers.1.blocks.0.branch2c.conv.weight', 'backbone.res_layers.1.blocks.0.branch2c.norm.weight', 'backbone.res_layers.1.blocks.0.branch2c.norm.bias', 'backbone.res_layers.1.blocks.0.branch2c.norm.running_mean', 'backbone.res_layers.1.blocks.0.branch2c.norm.running_var', 'backbone.res_layers.1.blocks.0.short.conv.conv.weight', 'backbone.res_layers.1.blocks.0.short.conv.norm.weight', 'backbone.res_layers.1.blocks.0.short.conv.norm.bias', 'backbone.res_layers.1.blocks.0.short.conv.norm.running_mean', 'backbone.res_layers.1.blocks.0.short.conv.norm.running_var', 'backbone.res_layers.1.blocks.1.branch2a.conv.weight', 'backbone.res_layers.1.blocks.1.branch2a.norm.weight', 'backbone.res_layers.1.blocks.1.branch2a.norm.bias', 'backbone.res_layers.1.blocks.1.branch2a.norm.running_mean', 'backbone.res_layers.1.blocks.1.branch2a.norm.running_var', 'backbone.res_layers.1.blocks.1.branch2b.conv.weight', 'backbone.res_layers.1.blocks.1.branch2b.norm.weight', 'backbone.res_layers.1.blocks.1.branch2b.norm.bias', 'backbone.res_layers.1.blocks.1.branch2b.norm.running_mean', 'backbone.res_layers.1.blocks.1.branch2b.norm.running_var', 'backbone.res_layers.1.blocks.1.branch2c.conv.weight', 'backbone.res_layers.1.blocks.1.branch2c.norm.weight', 'backbone.res_layers.1.blocks.1.branch2c.norm.bias', 'backbone.res_layers.1.blocks.1.branch2c.norm.running_mean', 'backbone.res_layers.1.blocks.1.branch2c.norm.running_var', 'backbone.res_layers.1.blocks.2.branch2a.conv.weight', 'backbone.res_layers.1.blocks.2.branch2a.norm.weight', 'backbone.res_layers.1.blocks.2.branch2a.norm.bias', 'backbone.res_layers.1.blocks.2.branch2a.norm.running_mean', 'backbone.res_layers.1.blocks.2.branch2a.norm.running_var', 'backbone.res_layers.1.blocks.2.branch2b.conv.weight', 'backbone.res_layers.1.blocks.2.branch2b.norm.weight', 'backbone.res_layers.1.blocks.2.branch2b.norm.bias', 'backbone.res_layers.1.blocks.2.branch2b.norm.running_mean', 'backbone.res_layers.1.blocks.2.branch2b.norm.running_var', 'backbone.res_layers.1.blocks.2.branch2c.conv.weight', 'backbone.res_layers.1.blocks.2.branch2c.norm.weight', 'backbone.res_layers.1.blocks.2.branch2c.norm.bias', 'backbone.res_layers.1.blocks.2.branch2c.norm.running_mean', 'backbone.res_layers.1.blocks.2.branch2c.norm.running_var', 'backbone.res_layers.1.blocks.3.branch2a.conv.weight', 'backbone.res_layers.1.blocks.3.branch2a.norm.weight', 'backbone.res_layers.1.blocks.3.branch2a.norm.bias', 'backbone.res_layers.1.blocks.3.branch2a.norm.running_mean', 'backbone.res_layers.1.blocks.3.branch2a.norm.running_var', 'backbone.res_layers.1.blocks.3.branch2b.conv.weight', 'backbone.res_layers.1.blocks.3.branch2b.norm.weight', 'backbone.res_layers.1.blocks.3.branch2b.norm.bias', 'backbone.res_layers.1.blocks.3.branch2b.norm.running_mean', 'backbone.res_layers.1.blocks.3.branch2b.norm.running_var', 'backbone.res_layers.1.blocks.3.branch2c.conv.weight', 'backbone.res_layers.1.blocks.3.branch2c.norm.weight', 'backbone.res_layers.1.blocks.3.branch2c.norm.bias', 'backbone.res_layers.1.blocks.3.branch2c.norm.running_mean', 'backbone.res_layers.1.blocks.3.branch2c.norm.running_var', 'backbone.res_layers.2.blocks.0.branch2a.conv.weight', 'backbone.res_layers.2.blocks.0.branch2a.norm.weight', 'backbone.res_layers.2.blocks.0.branch2a.norm.bias', 'backbone.res_layers.2.blocks.0.branch2a.norm.running_mean', 'backbone.res_layers.2.blocks.0.branch2a.norm.running_var', 'backbone.res_layers.2.blocks.0.branch2b.conv.weight', 'backbone.res_layers.2.blocks.0.branch2b.norm.weight', 'backbone.res_layers.2.blocks.0.branch2b.norm.bias', 'backbone.res_layers.2.blocks.0.branch2b.norm.running_mean', 'backbone.res_layers.2.blocks.0.branch2b.norm.running_var', 'backbone.res_layers.2.blocks.0.branch2c.conv.weight', 'backbone.res_layers.2.blocks.0.branch2c.norm.weight', 'backbone.res_layers.2.blocks.0.branch2c.norm.bias', 'backbone.res_layers.2.blocks.0.branch2c.norm.running_mean', 'backbone.res_layers.2.blocks.0.branch2c.norm.running_var', 'backbone.res_layers.2.blocks.0.short.conv.conv.weight', 'backbone.res_layers.2.blocks.0.short.conv.norm.weight', 'backbone.res_layers.2.blocks.0.short.conv.norm.bias', 'backbone.res_layers.2.blocks.0.short.conv.norm.running_mean', 'backbone.res_layers.2.blocks.0.short.conv.norm.running_var', 'backbone.res_layers.2.blocks.1.branch2a.conv.weight', 'backbone.res_layers.2.blocks.1.branch2a.norm.weight', 'backbone.res_layers.2.blocks.1.branch2a.norm.bias', 'backbone.res_layers.2.blocks.1.branch2a.norm.running_mean', 'backbone.res_layers.2.blocks.1.branch2a.norm.running_var', 'backbone.res_layers.2.blocks.1.branch2b.conv.weight', 'backbone.res_layers.2.blocks.1.branch2b.norm.weight', 'backbone.res_layers.2.blocks.1.branch2b.norm.bias', 'backbone.res_layers.2.blocks.1.branch2b.norm.running_mean', 'backbone.res_layers.2.blocks.1.branch2b.norm.running_var', 'backbone.res_layers.2.blocks.1.branch2c.conv.weight', 'backbone.res_layers.2.blocks.1.branch2c.norm.weight', 'backbone.res_layers.2.blocks.1.branch2c.norm.bias', 'backbone.res_layers.2.blocks.1.branch2c.norm.running_mean', 'backbone.res_layers.2.blocks.1.branch2c.norm.running_var', 'backbone.res_layers.2.blocks.2.branch2a.conv.weight', 'backbone.res_layers.2.blocks.2.branch2a.norm.weight', 'backbone.res_layers.2.blocks.2.branch2a.norm.bias', 'backbone.res_layers.2.blocks.2.branch2a.norm.running_mean', 'backbone.res_layers.2.blocks.2.branch2a.norm.running_var', 'backbone.res_layers.2.blocks.2.branch2b.conv.weight', 'backbone.res_layers.2.blocks.2.branch2b.norm.weight', 'backbone.res_layers.2.blocks.2.branch2b.norm.bias', 'backbone.res_layers.2.blocks.2.branch2b.norm.running_mean', 'backbone.res_layers.2.blocks.2.branch2b.norm.running_var', 'backbone.res_layers.2.blocks.2.branch2c.conv.weight', 'backbone.res_layers.2.blocks.2.branch2c.norm.weight', 'backbone.res_layers.2.blocks.2.branch2c.norm.bias', 'backbone.res_layers.2.blocks.2.branch2c.norm.running_mean', 'backbone.res_layers.2.blocks.2.branch2c.norm.running_var', 'backbone.res_layers.2.blocks.3.branch2a.conv.weight', 'backbone.res_layers.2.blocks.3.branch2a.norm.weight', 'backbone.res_layers.2.blocks.3.branch2a.norm.bias', 'backbone.res_layers.2.blocks.3.branch2a.norm.running_mean', 'backbone.res_layers.2.blocks.3.branch2a.norm.running_var', 'backbone.res_layers.2.blocks.3.branch2b.conv.weight', 'backbone.res_layers.2.blocks.3.branch2b.norm.weight', 'backbone.res_layers.2.blocks.3.branch2b.norm.bias', 'backbone.res_layers.2.blocks.3.branch2b.norm.running_mean', 'backbone.res_layers.2.blocks.3.branch2b.norm.running_var', 'backbone.res_layers.2.blocks.3.branch2c.conv.weight', 'backbone.res_layers.2.blocks.3.branch2c.norm.weight', 'backbone.res_layers.2.blocks.3.branch2c.norm.bias', 'backbone.res_layers.2.blocks.3.branch2c.norm.running_mean', 'backbone.res_layers.2.blocks.3.branch2c.norm.running_var', 'backbone.res_layers.2.blocks.4.branch2a.conv.weight', 'backbone.res_layers.2.blocks.4.branch2a.norm.weight', 'backbone.res_layers.2.blocks.4.branch2a.norm.bias', 'backbone.res_layers.2.blocks.4.branch2a.norm.running_mean', 'backbone.res_layers.2.blocks.4.branch2a.norm.running_var', 'backbone.res_layers.2.blocks.4.branch2b.conv.weight', 'backbone.res_layers.2.blocks.4.branch2b.norm.weight', 'backbone.res_layers.2.blocks.4.branch2b.norm.bias', 'backbone.res_layers.2.blocks.4.branch2b.norm.running_mean', 'backbone.res_layers.2.blocks.4.branch2b.norm.running_var', 'backbone.res_layers.2.blocks.4.branch2c.conv.weight', 'backbone.res_layers.2.blocks.4.branch2c.norm.weight', 'backbone.res_layers.2.blocks.4.branch2c.norm.bias', 'backbone.res_layers.2.blocks.4.branch2c.norm.running_mean', 'backbone.res_layers.2.blocks.4.branch2c.norm.running_var', 'backbone.res_layers.2.blocks.5.branch2a.conv.weight', 'backbone.res_layers.2.blocks.5.branch2a.norm.weight', 'backbone.res_layers.2.blocks.5.branch2a.norm.bias', 'backbone.res_layers.2.blocks.5.branch2a.norm.running_mean', 'backbone.res_layers.2.blocks.5.branch2a.norm.running_var', 'backbone.res_layers.2.blocks.5.branch2b.conv.weight', 'backbone.res_layers.2.blocks.5.branch2b.norm.weight', 'backbone.res_layers.2.blocks.5.branch2b.norm.bias', 'backbone.res_layers.2.blocks.5.branch2b.norm.running_mean', 'backbone.res_layers.2.blocks.5.branch2b.norm.running_var', 'backbone.res_layers.2.blocks.5.branch2c.conv.weight', 'backbone.res_layers.2.blocks.5.branch2c.norm.weight', 'backbone.res_layers.2.blocks.5.branch2c.norm.bias', 'backbone.res_layers.2.blocks.5.branch2c.norm.running_mean', 'backbone.res_layers.2.blocks.5.branch2c.norm.running_var', 'backbone.res_layers.3.blocks.0.branch2a.conv.weight', 'backbone.res_layers.3.blocks.0.branch2a.norm.weight', 'backbone.res_layers.3.blocks.0.branch2a.norm.bias', 'backbone.res_layers.3.blocks.0.branch2a.norm.running_mean', 'backbone.res_layers.3.blocks.0.branch2a.norm.running_var', 'backbone.res_layers.3.blocks.0.branch2b.conv.weight', 'backbone.res_layers.3.blocks.0.branch2b.norm.weight', 'backbone.res_layers.3.blocks.0.branch2b.norm.bias', 'backbone.res_layers.3.blocks.0.branch2b.norm.running_mean', 'backbone.res_layers.3.blocks.0.branch2b.norm.running_var', 'backbone.res_layers.3.blocks.0.branch2c.conv.weight', 'backbone.res_layers.3.blocks.0.branch2c.norm.weight', 'backbone.res_layers.3.blocks.0.branch2c.norm.bias', 'backbone.res_layers.3.blocks.0.branch2c.norm.running_mean', 'backbone.res_layers.3.blocks.0.branch2c.norm.running_var', 'backbone.res_layers.3.blocks.0.short.conv.conv.weight', 'backbone.res_layers.3.blocks.0.short.conv.norm.weight', 'backbone.res_layers.3.blocks.0.short.conv.norm.bias', 'backbone.res_layers.3.blocks.0.short.conv.norm.running_mean', 'backbone.res_layers.3.blocks.0.short.conv.norm.running_var', 'backbone.res_layers.3.blocks.1.branch2a.conv.weight', 'backbone.res_layers.3.blocks.1.branch2a.norm.weight', 'backbone.res_layers.3.blocks.1.branch2a.norm.bias', 'backbone.res_layers.3.blocks.1.branch2a.norm.running_mean', 'backbone.res_layers.3.blocks.1.branch2a.norm.running_var', 'backbone.res_layers.3.blocks.1.branch2b.conv.weight', 'backbone.res_layers.3.blocks.1.branch2b.norm.weight', 'backbone.res_layers.3.blocks.1.branch2b.norm.bias', 'backbone.res_layers.3.blocks.1.branch2b.norm.running_mean', 'backbone.res_layers.3.blocks.1.branch2b.norm.running_var', 'backbone.res_layers.3.blocks.1.branch2c.conv.weight', 'backbone.res_layers.3.blocks.1.branch2c.norm.weight', 'backbone.res_layers.3.blocks.1.branch2c.norm.bias', 'backbone.res_layers.3.blocks.1.branch2c.norm.running_mean', 'backbone.res_layers.3.blocks.1.branch2c.norm.running_var', 'backbone.res_layers.3.blocks.2.branch2a.conv.weight', 'backbone.res_layers.3.blocks.2.branch2a.norm.weight', 'backbone.res_layers.3.blocks.2.branch2a.norm.bias', 'backbone.res_layers.3.blocks.2.branch2a.norm.running_mean', 'backbone.res_layers.3.blocks.2.branch2a.norm.running_var', 'backbone.res_layers.3.blocks.2.branch2b.conv.weight', 'backbone.res_layers.3.blocks.2.branch2b.norm.weight', 'backbone.res_layers.3.blocks.2.branch2b.norm.bias', 'backbone.res_layers.3.blocks.2.branch2b.norm.running_mean', 'backbone.res_layers.3.blocks.2.branch2b.norm.running_var', 'backbone.res_layers.3.blocks.2.branch2c.conv.weight', 'backbone.res_layers.3.blocks.2.branch2c.norm.weight', 'backbone.res_layers.3.blocks.2.branch2c.norm.bias', 'backbone.res_layers.3.blocks.2.branch2c.norm.running_mean', 'backbone.res_layers.3.blocks.2.branch2c.norm.running_var', 'decoder.anchors', 'decoder.valid_mask', 'decoder.input_proj.0.conv.weight', 'decoder.input_proj.0.norm.weight', 'decoder.input_proj.0.norm.bias', 'decoder.input_proj.0.norm.running_mean', 'decoder.input_proj.0.norm.running_var', 'decoder.input_proj.0.norm.num_batches_tracked', 'decoder.input_proj.1.conv.weight', 'decoder.input_proj.1.norm.weight', 'decoder.input_proj.1.norm.bias', 'decoder.input_proj.1.norm.running_mean', 'decoder.input_proj.1.norm.running_var', 'decoder.input_proj.1.norm.num_batches_tracked', 'decoder.input_proj.2.conv.weight', 'decoder.input_proj.2.norm.weight', 'decoder.input_proj.2.norm.bias', 'decoder.input_proj.2.norm.running_mean', 'decoder.input_proj.2.norm.running_var', 'decoder.input_proj.2.norm.num_batches_tracked', 'decoder.decoder.layers.0.self_attn.in_proj_weight', 'decoder.decoder.layers.0.self_attn.in_proj_bias', 'decoder.decoder.layers.0.self_attn.out_proj.weight', 'decoder.decoder.layers.0.self_attn.out_proj.bias', 'decoder.decoder.layers.0.norm1.weight', 'decoder.decoder.layers.0.norm1.bias', 'decoder.decoder.layers.0.cross_attn.num_points_scale', 'decoder.decoder.layers.0.cross_attn.sampling_offsets.weight', 'decoder.decoder.layers.0.cross_attn.sampling_offsets.bias', 'decoder.decoder.layers.0.cross_attn.attention_weights.weight', 'decoder.decoder.layers.0.cross_attn.attention_weights.bias', 'decoder.decoder.layers.0.cross_attn.value_proj.weight', 'decoder.decoder.layers.0.cross_attn.value_proj.bias', 'decoder.decoder.layers.0.cross_attn.output_proj.weight', 'decoder.decoder.layers.0.cross_attn.output_proj.bias', 'decoder.decoder.layers.0.norm2.weight', 'decoder.decoder.layers.0.norm2.bias', 'decoder.decoder.layers.0.linear1.weight', 'decoder.decoder.layers.0.linear1.bias', 'decoder.decoder.layers.0.linear2.weight', 'decoder.decoder.layers.0.linear2.bias', 'decoder.decoder.layers.0.norm3.weight', 'decoder.decoder.layers.0.norm3.bias', 'decoder.decoder.layers.1.self_attn.in_proj_weight', 'decoder.decoder.layers.1.self_attn.in_proj_bias', 'decoder.decoder.layers.1.self_attn.out_proj.weight', 'decoder.decoder.layers.1.self_attn.out_proj.bias', 'decoder.decoder.layers.1.norm1.weight', 'decoder.decoder.layers.1.norm1.bias', 'decoder.decoder.layers.1.cross_attn.num_points_scale', 'decoder.decoder.layers.1.cross_attn.sampling_offsets.weight', 'decoder.decoder.layers.1.cross_attn.sampling_offsets.bias', 'decoder.decoder.layers.1.cross_attn.attention_weights.weight', 'decoder.decoder.layers.1.cross_attn.attention_weights.bias', 'decoder.decoder.layers.1.cross_attn.value_proj.weight', 'decoder.decoder.layers.1.cross_attn.value_proj.bias', 'decoder.decoder.layers.1.cross_attn.output_proj.weight', 'decoder.decoder.layers.1.cross_attn.output_proj.bias', 'decoder.decoder.layers.1.norm2.weight', 'decoder.decoder.layers.1.norm2.bias', 'decoder.decoder.layers.1.linear1.weight', 'decoder.decoder.layers.1.linear1.bias', 'decoder.decoder.layers.1.linear2.weight', 'decoder.decoder.layers.1.linear2.bias', 'decoder.decoder.layers.1.norm3.weight', 'decoder.decoder.layers.1.norm3.bias', 'decoder.decoder.layers.2.self_attn.in_proj_weight', 'decoder.decoder.layers.2.self_attn.in_proj_bias', 'decoder.decoder.layers.2.self_attn.out_proj.weight', 'decoder.decoder.layers.2.self_attn.out_proj.bias', 'decoder.decoder.layers.2.norm1.weight', 'decoder.decoder.layers.2.norm1.bias', 'decoder.decoder.layers.2.cross_attn.num_points_scale', 'decoder.decoder.layers.2.cross_attn.sampling_offsets.weight', 'decoder.decoder.layers.2.cross_attn.sampling_offsets.bias', 'decoder.decoder.layers.2.cross_attn.attention_weights.weight', 'decoder.decoder.layers.2.cross_attn.attention_weights.bias', 'decoder.decoder.layers.2.cross_attn.value_proj.weight', 'decoder.decoder.layers.2.cross_attn.value_proj.bias', 'decoder.decoder.layers.2.cross_attn.output_proj.weight', 'decoder.decoder.layers.2.cross_attn.output_proj.bias', 'decoder.decoder.layers.2.norm2.weight', 'decoder.decoder.layers.2.norm2.bias', 'decoder.decoder.layers.2.linear1.weight', 'decoder.decoder.layers.2.linear1.bias', 'decoder.decoder.layers.2.linear2.weight', 'decoder.decoder.layers.2.linear2.bias', 'decoder.decoder.layers.2.norm3.weight', 'decoder.decoder.layers.2.norm3.bias', 'decoder.decoder.layers.3.self_attn.in_proj_weight', 'decoder.decoder.layers.3.self_attn.in_proj_bias', 'decoder.decoder.layers.3.self_attn.out_proj.weight', 'decoder.decoder.layers.3.self_attn.out_proj.bias', 'decoder.decoder.layers.3.norm1.weight', 'decoder.decoder.layers.3.norm1.bias', 'decoder.decoder.layers.3.cross_attn.num_points_scale', 'decoder.decoder.layers.3.cross_attn.sampling_offsets.weight', 'decoder.decoder.layers.3.cross_attn.sampling_offsets.bias', 'decoder.decoder.layers.3.cross_attn.attention_weights.weight', 'decoder.decoder.layers.3.cross_attn.attention_weights.bias', 'decoder.decoder.layers.3.cross_attn.value_proj.weight', 'decoder.decoder.layers.3.cross_attn.value_proj.bias', 'decoder.decoder.layers.3.cross_attn.output_proj.weight', 'decoder.decoder.layers.3.cross_attn.output_proj.bias', 'decoder.decoder.layers.3.norm2.weight', 'decoder.decoder.layers.3.norm2.bias', 'decoder.decoder.layers.3.linear1.weight', 'decoder.decoder.layers.3.linear1.bias', 'decoder.decoder.layers.3.linear2.weight', 'decoder.decoder.layers.3.linear2.bias', 'decoder.decoder.layers.3.norm3.weight', 'decoder.decoder.layers.3.norm3.bias', 'decoder.decoder.layers.4.self_attn.in_proj_weight', 'decoder.decoder.layers.4.self_attn.in_proj_bias', 'decoder.decoder.layers.4.self_attn.out_proj.weight', 'decoder.decoder.layers.4.self_attn.out_proj.bias', 'decoder.decoder.layers.4.norm1.weight', 'decoder.decoder.layers.4.norm1.bias', 'decoder.decoder.layers.4.cross_attn.num_points_scale', 'decoder.decoder.layers.4.cross_attn.sampling_offsets.weight', 'decoder.decoder.layers.4.cross_attn.sampling_offsets.bias', 'decoder.decoder.layers.4.cross_attn.attention_weights.weight', 'decoder.decoder.layers.4.cross_attn.attention_weights.bias', 'decoder.decoder.layers.4.cross_attn.value_proj.weight', 'decoder.decoder.layers.4.cross_attn.value_proj.bias', 'decoder.decoder.layers.4.cross_attn.output_proj.weight', 'decoder.decoder.layers.4.cross_attn.output_proj.bias', 'decoder.decoder.layers.4.norm2.weight', 'decoder.decoder.layers.4.norm2.bias', 'decoder.decoder.layers.4.linear1.weight', 'decoder.decoder.layers.4.linear1.bias', 'decoder.decoder.layers.4.linear2.weight', 'decoder.decoder.layers.4.linear2.bias', 'decoder.decoder.layers.4.norm3.weight', 'decoder.decoder.layers.4.norm3.bias', 'decoder.decoder.layers.5.self_attn.in_proj_weight', 'decoder.decoder.layers.5.self_attn.in_proj_bias', 'decoder.decoder.layers.5.self_attn.out_proj.weight', 'decoder.decoder.layers.5.self_attn.out_proj.bias', 'decoder.decoder.layers.5.norm1.weight', 'decoder.decoder.layers.5.norm1.bias', 'decoder.decoder.layers.5.cross_attn.num_points_scale', 'decoder.decoder.layers.5.cross_attn.sampling_offsets.weight', 'decoder.decoder.layers.5.cross_attn.sampling_offsets.bias', 'decoder.decoder.layers.5.cross_attn.attention_weights.weight', 'decoder.decoder.layers.5.cross_attn.attention_weights.bias', 'decoder.decoder.layers.5.cross_attn.value_proj.weight', 'decoder.decoder.layers.5.cross_attn.value_proj.bias', 'decoder.decoder.layers.5.cross_attn.output_proj.weight', 'decoder.decoder.layers.5.cross_attn.output_proj.bias', 'decoder.decoder.layers.5.norm2.weight', 'decoder.decoder.layers.5.norm2.bias', 'decoder.decoder.layers.5.linear1.weight', 'decoder.decoder.layers.5.linear1.bias', 'decoder.decoder.layers.5.linear2.weight', 'decoder.decoder.layers.5.linear2.bias', 'decoder.decoder.layers.5.norm3.weight', 'decoder.decoder.layers.5.norm3.bias', 'decoder.denoising_class_embed.weight', 'decoder.query_pos_head.layers.0.weight', 'decoder.query_pos_head.layers.0.bias', 'decoder.query_pos_head.layers.1.weight', 'decoder.query_pos_head.layers.1.bias', 'decoder.enc_output.proj.weight', 'decoder.enc_output.proj.bias', 'decoder.enc_output.norm.weight', 'decoder.enc_output.norm.bias', 'decoder.enc_score_head.weight', 'decoder.enc_score_head.bias', 'decoder.enc_bbox_head.layers.0.weight', 'decoder.enc_bbox_head.layers.0.bias', 'decoder.enc_bbox_head.layers.1.weight', 'decoder.enc_bbox_head.layers.1.bias', 'decoder.enc_bbox_head.layers.2.weight', 'decoder.enc_bbox_head.layers.2.bias', 'decoder.dec_score_head.0.weight', 'decoder.dec_score_head.0.bias', 'decoder.dec_score_head.1.weight', 'decoder.dec_score_head.1.bias', 'decoder.dec_score_head.2.weight', 'decoder.dec_score_head.2.bias', 'decoder.dec_score_head.3.weight', 'decoder.dec_score_head.3.bias', 'decoder.dec_score_head.4.weight', 'decoder.dec_score_head.4.bias', 'decoder.dec_score_head.5.weight', 'decoder.dec_score_head.5.bias', 'decoder.dec_bbox_head.0.layers.0.weight', 'decoder.dec_bbox_head.0.layers.0.bias', 'decoder.dec_bbox_head.0.layers.1.weight', 'decoder.dec_bbox_head.0.layers.1.bias', 'decoder.dec_bbox_head.0.layers.2.weight', 'decoder.dec_bbox_head.0.layers.2.bias', 'decoder.dec_bbox_head.1.layers.0.weight', 'decoder.dec_bbox_head.1.layers.0.bias', 'decoder.dec_bbox_head.1.layers.1.weight', 'decoder.dec_bbox_head.1.layers.1.bias', 'decoder.dec_bbox_head.1.layers.2.weight', 'decoder.dec_bbox_head.1.layers.2.bias', 'decoder.dec_bbox_head.2.layers.0.weight', 'decoder.dec_bbox_head.2.layers.0.bias', 'decoder.dec_bbox_head.2.layers.1.weight', 'decoder.dec_bbox_head.2.layers.1.bias', 'decoder.dec_bbox_head.2.layers.2.weight', 'decoder.dec_bbox_head.2.layers.2.bias', 'decoder.dec_bbox_head.3.layers.0.weight', 'decoder.dec_bbox_head.3.layers.0.bias', 'decoder.dec_bbox_head.3.layers.1.weight', 'decoder.dec_bbox_head.3.layers.1.bias', 'decoder.dec_bbox_head.3.layers.2.weight', 'decoder.dec_bbox_head.3.layers.2.bias', 'decoder.dec_bbox_head.4.layers.0.weight', 'decoder.dec_bbox_head.4.layers.0.bias', 'decoder.dec_bbox_head.4.layers.1.weight', 'decoder.dec_bbox_head.4.layers.1.bias', 'decoder.dec_bbox_head.4.layers.2.weight', 'decoder.dec_bbox_head.4.layers.2.bias', 'decoder.dec_bbox_head.5.layers.0.weight', 'decoder.dec_bbox_head.5.layers.0.bias', 'decoder.dec_bbox_head.5.layers.1.weight', 'decoder.dec_bbox_head.5.layers.1.bias', 'decoder.dec_bbox_head.5.layers.2.weight', 'decoder.dec_bbox_head.5.layers.2.bias', 'encoder.input_proj.0.conv.weight', 'encoder.input_proj.0.norm.weight', 'encoder.input_proj.0.norm.bias', 'encoder.input_proj.0.norm.running_mean', 'encoder.input_proj.0.norm.running_var', 'encoder.input_proj.0.norm.num_batches_tracked', 'encoder.input_proj.1.conv.weight', 'encoder.input_proj.1.norm.weight', 'encoder.input_proj.1.norm.bias', 'encoder.input_proj.1.norm.running_mean', 'encoder.input_proj.1.norm.running_var', 'encoder.input_proj.1.norm.num_batches_tracked', 'encoder.input_proj.2.conv.weight', 'encoder.input_proj.2.norm.weight', 'encoder.input_proj.2.norm.bias', 'encoder.input_proj.2.norm.running_mean', 'encoder.input_proj.2.norm.running_var', 'encoder.input_proj.2.norm.num_batches_tracked', 'encoder.encoder.0.layers.0.self_attn.in_proj_weight', 'encoder.encoder.0.layers.0.self_attn.in_proj_bias', 'encoder.encoder.0.layers.0.self_attn.out_proj.weight', 'encoder.encoder.0.layers.0.self_attn.out_proj.bias', 'encoder.encoder.0.layers.0.linear1.weight', 'encoder.encoder.0.layers.0.linear1.bias', 'encoder.encoder.0.layers.0.linear2.weight', 'encoder.encoder.0.layers.0.linear2.bias', 'encoder.encoder.0.layers.0.norm1.weight', 'encoder.encoder.0.layers.0.norm1.bias', 'encoder.encoder.0.layers.0.norm2.weight', 'encoder.encoder.0.layers.0.norm2.bias', 'encoder.lateral_convs.0.conv.weight', 'encoder.lateral_convs.0.norm.weight', 'encoder.lateral_convs.0.norm.bias', 'encoder.lateral_convs.0.norm.running_mean', 'encoder.lateral_convs.0.norm.running_var', 'encoder.lateral_convs.0.norm.num_batches_tracked', 'encoder.lateral_convs.1.conv.weight', 'encoder.lateral_convs.1.norm.weight', 'encoder.lateral_convs.1.norm.bias', 'encoder.lateral_convs.1.norm.running_mean', 'encoder.lateral_convs.1.norm.running_var', 'encoder.lateral_convs.1.norm.num_batches_tracked', 'encoder.fpn_blocks.0.conv1.conv.weight', 'encoder.fpn_blocks.0.conv1.norm.weight', 'encoder.fpn_blocks.0.conv1.norm.bias', 'encoder.fpn_blocks.0.conv1.norm.running_mean', 'encoder.fpn_blocks.0.conv1.norm.running_var', 'encoder.fpn_blocks.0.conv1.norm.num_batches_tracked', 'encoder.fpn_blocks.0.conv2.conv.weight', 'encoder.fpn_blocks.0.conv2.norm.weight', 'encoder.fpn_blocks.0.conv2.norm.bias', 'encoder.fpn_blocks.0.conv2.norm.running_mean', 'encoder.fpn_blocks.0.conv2.norm.running_var', 'encoder.fpn_blocks.0.conv2.norm.num_batches_tracked', 'encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight', 'encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight', 'encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias', 'encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.running_mean', 'encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.running_var', 'encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.num_batches_tracked', 'encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight', 'encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight', 'encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias', 'encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.running_mean', 'encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.running_var', 'encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.num_batches_tracked', 'encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight', 'encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight', 'encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias', 'encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.running_mean', 'encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.running_var', 'encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.num_batches_tracked', 'encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight', 'encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight', 'encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias', 'encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.running_mean', 'encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.running_var', 'encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.num_batches_tracked', 'encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight', 'encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight', 'encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias', 'encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.running_mean', 'encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.running_var', 'encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.num_batches_tracked', 'encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight', 'encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight', 'encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias', 'encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.running_mean', 'encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.running_var', 'encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.num_batches_tracked', 'encoder.fpn_blocks.1.conv1.conv.weight', 'encoder.fpn_blocks.1.conv1.norm.weight', 'encoder.fpn_blocks.1.conv1.norm.bias', 'encoder.fpn_blocks.1.conv1.norm.running_mean', 'encoder.fpn_blocks.1.conv1.norm.running_var', 'encoder.fpn_blocks.1.conv1.norm.num_batches_tracked', 'encoder.fpn_blocks.1.conv2.conv.weight', 'encoder.fpn_blocks.1.conv2.norm.weight', 'encoder.fpn_blocks.1.conv2.norm.bias', 'encoder.fpn_blocks.1.conv2.norm.running_mean', 'encoder.fpn_blocks.1.conv2.norm.running_var', 'encoder.fpn_blocks.1.conv2.norm.num_batches_tracked', 'encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight', 'encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight', 'encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias', 'encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.running_mean', 'encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.running_var', 'encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.num_batches_tracked', 'encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight', 'encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight', 'encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias', 'encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.running_mean', 'encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.running_var', 'encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.num_batches_tracked', 'encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight', 'encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight', 'encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias', 'encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.running_mean', 'encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.running_var', 'encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.num_batches_tracked', 'encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight', 'encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight', 'encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias', 'encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.running_mean', 'encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.running_var', 'encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.num_batches_tracked', 'encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight', 'encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight', 'encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias', 'encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.running_mean', 'encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.running_var', 'encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.num_batches_tracked', 'encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight', 'encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight', 'encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias', 'encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.running_mean', 'encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.running_var', 'encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.num_batches_tracked', 'encoder.downsample_convs.0.conv.weight', 'encoder.downsample_convs.0.norm.weight', 'encoder.downsample_convs.0.norm.bias', 'encoder.downsample_convs.0.norm.running_mean', 'encoder.downsample_convs.0.norm.running_var', 'encoder.downsample_convs.0.norm.num_batches_tracked', 'encoder.downsample_convs.1.conv.weight', 'encoder.downsample_convs.1.norm.weight', 'encoder.downsample_convs.1.norm.bias', 'encoder.downsample_convs.1.norm.running_mean', 'encoder.downsample_convs.1.norm.running_var', 'encoder.downsample_convs.1.norm.num_batches_tracked', 'encoder.pan_blocks.0.conv1.conv.weight', 'encoder.pan_blocks.0.conv1.norm.weight', 'encoder.pan_blocks.0.conv1.norm.bias', 'encoder.pan_blocks.0.conv1.norm.running_mean', 'encoder.pan_blocks.0.conv1.norm.running_var', 'encoder.pan_blocks.0.conv1.norm.num_batches_tracked', 'encoder.pan_blocks.0.conv2.conv.weight', 'encoder.pan_blocks.0.conv2.norm.weight', 'encoder.pan_blocks.0.conv2.norm.bias', 'encoder.pan_blocks.0.conv2.norm.running_mean', 'encoder.pan_blocks.0.conv2.norm.running_var', 'encoder.pan_blocks.0.conv2.norm.num_batches_tracked', 'encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight', 'encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight', 'encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias', 'encoder.pan_blocks.0.bottlenecks.0.conv1.norm.running_mean', 'encoder.pan_blocks.0.bottlenecks.0.conv1.norm.running_var', 'encoder.pan_blocks.0.bottlenecks.0.conv1.norm.num_batches_tracked', 'encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight', 'encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight', 'encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias', 'encoder.pan_blocks.0.bottlenecks.0.conv2.norm.running_mean', 'encoder.pan_blocks.0.bottlenecks.0.conv2.norm.running_var', 'encoder.pan_blocks.0.bottlenecks.0.conv2.norm.num_batches_tracked', 'encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight', 'encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight', 'encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias', 'encoder.pan_blocks.0.bottlenecks.1.conv1.norm.running_mean', 'encoder.pan_blocks.0.bottlenecks.1.conv1.norm.running_var', 'encoder.pan_blocks.0.bottlenecks.1.conv1.norm.num_batches_tracked', 'encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight', 'encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight', 'encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias', 'encoder.pan_blocks.0.bottlenecks.1.conv2.norm.running_mean', 'encoder.pan_blocks.0.bottlenecks.1.conv2.norm.running_var', 'encoder.pan_blocks.0.bottlenecks.1.conv2.norm.num_batches_tracked', 'encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight', 'encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight', 'encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias', 'encoder.pan_blocks.0.bottlenecks.2.conv1.norm.running_mean', 'encoder.pan_blocks.0.bottlenecks.2.conv1.norm.running_var', 'encoder.pan_blocks.0.bottlenecks.2.conv1.norm.num_batches_tracked', 'encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight', 'encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight', 'encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias', 'encoder.pan_blocks.0.bottlenecks.2.conv2.norm.running_mean', 'encoder.pan_blocks.0.bottlenecks.2.conv2.norm.running_var', 'encoder.pan_blocks.0.bottlenecks.2.conv2.norm.num_batches_tracked', 'encoder.pan_blocks.1.conv1.conv.weight', 'encoder.pan_blocks.1.conv1.norm.weight', 'encoder.pan_blocks.1.conv1.norm.bias', 'encoder.pan_blocks.1.conv1.norm.running_mean', 'encoder.pan_blocks.1.conv1.norm.running_var', 'encoder.pan_blocks.1.conv1.norm.num_batches_tracked', 'encoder.pan_blocks.1.conv2.conv.weight', 'encoder.pan_blocks.1.conv2.norm.weight', 'encoder.pan_blocks.1.conv2.norm.bias', 'encoder.pan_blocks.1.conv2.norm.running_mean', 'encoder.pan_blocks.1.conv2.norm.running_var', 'encoder.pan_blocks.1.conv2.norm.num_batches_tracked', 'encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight', 'encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight', 'encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias', 'encoder.pan_blocks.1.bottlenecks.0.conv1.norm.running_mean', 'encoder.pan_blocks.1.bottlenecks.0.conv1.norm.running_var', 'encoder.pan_blocks.1.bottlenecks.0.conv1.norm.num_batches_tracked', 'encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight', 'encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight', 'encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias', 'encoder.pan_blocks.1.bottlenecks.0.conv2.norm.running_mean', 'encoder.pan_blocks.1.bottlenecks.0.conv2.norm.running_var', 'encoder.pan_blocks.1.bottlenecks.0.conv2.norm.num_batches_tracked', 'encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight', 'encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight', 'encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias', 'encoder.pan_blocks.1.bottlenecks.1.conv1.norm.running_mean', 'encoder.pan_blocks.1.bottlenecks.1.conv1.norm.running_var', 'encoder.pan_blocks.1.bottlenecks.1.conv1.norm.num_batches_tracked', 'encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight', 'encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight', 'encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias', 'encoder.pan_blocks.1.bottlenecks.1.conv2.norm.running_mean', 'encoder.pan_blocks.1.bottlenecks.1.conv2.norm.running_var', 'encoder.pan_blocks.1.bottlenecks.1.conv2.norm.num_batches_tracked', 'encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight', 'encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight', 'encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias', 'encoder.pan_blocks.1.bottlenecks.2.conv1.norm.running_mean', 'encoder.pan_blocks.1.bottlenecks.2.conv1.norm.running_var', 'encoder.pan_blocks.1.bottlenecks.2.conv1.norm.num_batches_tracked', 'encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight', 'encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight', 'encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias', 'encoder.pan_blocks.1.bottlenecks.2.conv2.norm.running_mean', 'encoder.pan_blocks.1.bottlenecks.2.conv2.norm.running_var', 'encoder.pan_blocks.1.bottlenecks.2.conv2.norm.num_batches_tracked'], 'unmatched': []}\r\n",
      "/kaggle/working/RT-DETR/rtdetrv2_pytorch/tools/../src/core/workspace.py:179: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\r\n",
      "  return module(**module_kwargs)\r\n",
      "/kaggle/working/RT-DETR/rtdetrv2_pytorch/tools/../src/core/workspace.py:179: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\r\n",
      "  return module(**module_kwargs)\r\n",
      "Initial lr: [2e-05, 2e-05]\r\n",
      "building train_dataloader with batch_size=8...\r\n",
      "building val_dataloader with batch_size=16...\r\n",
      "number of trainable parameters: 42821760\r\n",
      "Epoch: [0]  [ 0/79]  eta: 0:08:50  lr: 0.000020  loss: 36.6440 (36.6440)  loss_bbox: 0.7998 (0.7998)  loss_bbox_aux_0: 0.8393 (0.8393)  loss_bbox_aux_1: 0.8246 (0.8246)  loss_bbox_aux_2: 0.7953 (0.7953)  loss_bbox_aux_3: 0.8299 (0.8299)  loss_bbox_aux_4: 0.8143 (0.8143)  loss_bbox_dn_0: 0.4249 (0.4249)  loss_bbox_dn_1: 0.4249 (0.4249)  loss_bbox_dn_2: 0.4249 (0.4249)  loss_bbox_dn_3: 0.4249 (0.4249)  loss_bbox_dn_4: 0.4249 (0.4249)  loss_bbox_dn_5: 0.4249 (0.4249)  loss_bbox_enc_0: 0.8313 (0.8313)  loss_giou: 1.8573 (1.8573)  loss_giou_aux_0: 1.8459 (1.8459)  loss_giou_aux_1: 1.8473 (1.8473)  loss_giou_aux_2: 1.8874 (1.8874)  loss_giou_aux_3: 1.8201 (1.8201)  loss_giou_aux_4: 1.8360 (1.8360)  loss_giou_dn_0: 1.3827 (1.3827)  loss_giou_dn_1: 1.3827 (1.3827)  loss_giou_dn_2: 1.3827 (1.3827)  loss_giou_dn_3: 1.3827 (1.3827)  loss_giou_dn_4: 1.3827 (1.3827)  loss_giou_dn_5: 1.3827 (1.3827)  loss_giou_enc_0: 1.8677 (1.8677)  loss_vfl: 0.3421 (0.3421)  loss_vfl_aux_0: 0.3530 (0.3530)  loss_vfl_aux_1: 0.3052 (0.3052)  loss_vfl_aux_2: 0.3124 (0.3124)  loss_vfl_aux_3: 0.3624 (0.3624)  loss_vfl_aux_4: 0.3417 (0.3417)  loss_vfl_dn_0: 0.8298 (0.8298)  loss_vfl_dn_1: 0.7654 (0.7654)  loss_vfl_dn_2: 0.7646 (0.7646)  loss_vfl_dn_3: 0.8049 (0.8049)  loss_vfl_dn_4: 0.7761 (0.7761)  loss_vfl_dn_5: 0.8066 (0.8066)  loss_vfl_enc_0: 0.3377 (0.3377)  time: 6.7169  data: 2.9149  max mem: 7012\r\n",
      "Epoch: [0]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 37.0613 (37.7031)  loss_bbox: 0.9359 (1.0163)  loss_bbox_aux_0: 0.9799 (1.0359)  loss_bbox_aux_1: 0.9470 (1.0267)  loss_bbox_aux_2: 0.9470 (1.0202)  loss_bbox_aux_3: 0.9181 (1.0205)  loss_bbox_aux_4: 0.9455 (1.0198)  loss_bbox_dn_0: 0.5002 (0.4982)  loss_bbox_dn_1: 0.5015 (0.4988)  loss_bbox_dn_2: 0.5029 (0.4995)  loss_bbox_dn_3: 0.5039 (0.5001)  loss_bbox_dn_4: 0.5047 (0.5006)  loss_bbox_dn_5: 0.5057 (0.5011)  loss_bbox_enc_0: 1.0034 (1.0588)  loss_giou: 1.7659 (1.8354)  loss_giou_aux_0: 1.7973 (1.8556)  loss_giou_aux_1: 1.7796 (1.8449)  loss_giou_aux_2: 1.7665 (1.8413)  loss_giou_aux_3: 1.7611 (1.8383)  loss_giou_aux_4: 1.7719 (1.8367)  loss_giou_dn_0: 1.3725 (1.3703)  loss_giou_dn_1: 1.3723 (1.3704)  loss_giou_dn_2: 1.3720 (1.3707)  loss_giou_dn_3: 1.3721 (1.3712)  loss_giou_dn_4: 1.3717 (1.3719)  loss_giou_dn_5: 1.3770 (1.3729)  loss_giou_enc_0: 1.7887 (1.8661)  loss_vfl: 0.3232 (0.2958)  loss_vfl_aux_0: 0.2883 (0.2773)  loss_vfl_aux_1: 0.3019 (0.2847)  loss_vfl_aux_2: 0.3125 (0.2886)  loss_vfl_aux_3: 0.3241 (0.2999)  loss_vfl_aux_4: 0.3313 (0.2971)  loss_vfl_dn_0: 0.6672 (0.7327)  loss_vfl_dn_1: 0.6589 (0.7313)  loss_vfl_dn_2: 0.6567 (0.7210)  loss_vfl_dn_3: 0.6414 (0.7208)  loss_vfl_dn_4: 0.6426 (0.7046)  loss_vfl_dn_5: 0.6384 (0.7129)  loss_vfl_enc_0: 0.3119 (0.2943)  time: 0.9636  data: 0.0300  max mem: 10338\r\n",
      "Epoch: [0] Total time: 0:01:26 (1.0979 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 37.0613 (37.7031)  loss_bbox: 0.9359 (1.0163)  loss_bbox_aux_0: 0.9799 (1.0359)  loss_bbox_aux_1: 0.9470 (1.0267)  loss_bbox_aux_2: 0.9470 (1.0202)  loss_bbox_aux_3: 0.9181 (1.0205)  loss_bbox_aux_4: 0.9455 (1.0198)  loss_bbox_dn_0: 0.5002 (0.4982)  loss_bbox_dn_1: 0.5015 (0.4988)  loss_bbox_dn_2: 0.5029 (0.4995)  loss_bbox_dn_3: 0.5039 (0.5001)  loss_bbox_dn_4: 0.5047 (0.5006)  loss_bbox_dn_5: 0.5057 (0.5011)  loss_bbox_enc_0: 1.0034 (1.0588)  loss_giou: 1.7659 (1.8354)  loss_giou_aux_0: 1.7973 (1.8556)  loss_giou_aux_1: 1.7796 (1.8449)  loss_giou_aux_2: 1.7665 (1.8413)  loss_giou_aux_3: 1.7611 (1.8383)  loss_giou_aux_4: 1.7719 (1.8367)  loss_giou_dn_0: 1.3725 (1.3703)  loss_giou_dn_1: 1.3723 (1.3704)  loss_giou_dn_2: 1.3720 (1.3707)  loss_giou_dn_3: 1.3721 (1.3712)  loss_giou_dn_4: 1.3717 (1.3719)  loss_giou_dn_5: 1.3770 (1.3729)  loss_giou_enc_0: 1.7887 (1.8661)  loss_vfl: 0.3232 (0.2958)  loss_vfl_aux_0: 0.2883 (0.2773)  loss_vfl_aux_1: 0.3019 (0.2847)  loss_vfl_aux_2: 0.3125 (0.2886)  loss_vfl_aux_3: 0.3241 (0.2999)  loss_vfl_aux_4: 0.3313 (0.2971)  loss_vfl_dn_0: 0.6672 (0.7327)  loss_vfl_dn_1: 0.6589 (0.7313)  loss_vfl_dn_2: 0.6567 (0.7210)  loss_vfl_dn_3: 0.6414 (0.7208)  loss_vfl_dn_4: 0.6426 (0.7046)  loss_vfl_dn_5: 0.6384 (0.7129)  loss_vfl_enc_0: 0.3119 (0.2943)\r\n",
      "Test:  [0/8]  eta: 0:00:20    time: 2.5514  data: 1.3266  max mem: 10338\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0907  data: 0.2191  max mem: 10338\r\n",
      "Test: Total time: 0:00:08 (1.1082 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.14s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      "best_stat: {'epoch': 0, 'coco_eval_bbox': 1.2899031697496356e-07}\r\n",
      "Epoch: [1]  [ 0/79]  eta: 0:05:20  lr: 0.000020  loss: 33.5132 (33.5132)  loss_bbox: 0.6985 (0.6985)  loss_bbox_aux_0: 0.7223 (0.7223)  loss_bbox_aux_1: 0.6883 (0.6883)  loss_bbox_aux_2: 0.6763 (0.6763)  loss_bbox_aux_3: 0.6811 (0.6811)  loss_bbox_aux_4: 0.6895 (0.6895)  loss_bbox_dn_0: 0.3485 (0.3485)  loss_bbox_dn_1: 0.3504 (0.3504)  loss_bbox_dn_2: 0.3527 (0.3527)  loss_bbox_dn_3: 0.3545 (0.3545)  loss_bbox_dn_4: 0.3561 (0.3561)  loss_bbox_dn_5: 0.3576 (0.3576)  loss_bbox_enc_0: 0.7066 (0.7066)  loss_giou: 1.7777 (1.7777)  loss_giou_aux_0: 1.7761 (1.7761)  loss_giou_aux_1: 1.7871 (1.7871)  loss_giou_aux_2: 1.7862 (1.7862)  loss_giou_aux_3: 1.7775 (1.7775)  loss_giou_aux_4: 1.7831 (1.7831)  loss_giou_dn_0: 1.4012 (1.4012)  loss_giou_dn_1: 1.4019 (1.4019)  loss_giou_dn_2: 1.4004 (1.4004)  loss_giou_dn_3: 1.3980 (1.3980)  loss_giou_dn_4: 1.3972 (1.3972)  loss_giou_dn_5: 1.4027 (1.4027)  loss_giou_enc_0: 1.8237 (1.8237)  loss_vfl: 0.3036 (0.3036)  loss_vfl_aux_0: 0.2687 (0.2687)  loss_vfl_aux_1: 0.2932 (0.2932)  loss_vfl_aux_2: 0.2839 (0.2839)  loss_vfl_aux_3: 0.2960 (0.2960)  loss_vfl_aux_4: 0.3214 (0.3214)  loss_vfl_dn_0: 0.5961 (0.5961)  loss_vfl_dn_1: 0.5850 (0.5850)  loss_vfl_dn_2: 0.6001 (0.6001)  loss_vfl_dn_3: 0.5824 (0.5824)  loss_vfl_dn_4: 0.5990 (0.5990)  loss_vfl_dn_5: 0.5834 (0.5834)  loss_vfl_enc_0: 0.3051 (0.3051)  time: 4.0568  data: 2.6105  max mem: 10338\r\n",
      "Epoch: [1]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 35.9781 (36.5715)  loss_bbox: 0.9060 (0.9525)  loss_bbox_aux_0: 0.9327 (0.9753)  loss_bbox_aux_1: 0.9069 (0.9596)  loss_bbox_aux_2: 0.9206 (0.9559)  loss_bbox_aux_3: 0.9084 (0.9530)  loss_bbox_aux_4: 0.9139 (0.9521)  loss_bbox_dn_0: 0.4083 (0.4982)  loss_bbox_dn_1: 0.4088 (0.5002)  loss_bbox_dn_2: 0.4094 (0.5024)  loss_bbox_dn_3: 0.4097 (0.5038)  loss_bbox_dn_4: 0.4104 (0.5050)  loss_bbox_dn_5: 0.4109 (0.5059)  loss_bbox_enc_0: 0.9309 (0.9872)  loss_giou: 1.8260 (1.7472)  loss_giou_aux_0: 1.8485 (1.7654)  loss_giou_aux_1: 1.8274 (1.7567)  loss_giou_aux_2: 1.7973 (1.7505)  loss_giou_aux_3: 1.8343 (1.7500)  loss_giou_aux_4: 1.8107 (1.7484)  loss_giou_dn_0: 1.3674 (1.3690)  loss_giou_dn_1: 1.3686 (1.3689)  loss_giou_dn_2: 1.3704 (1.3689)  loss_giou_dn_3: 1.3715 (1.3695)  loss_giou_dn_4: 1.3727 (1.3705)  loss_giou_dn_5: 1.3739 (1.3720)  loss_giou_enc_0: 1.8461 (1.7814)  loss_vfl: 0.4213 (0.4233)  loss_vfl_aux_0: 0.3328 (0.3621)  loss_vfl_aux_1: 0.3740 (0.3940)  loss_vfl_aux_2: 0.3580 (0.3866)  loss_vfl_aux_3: 0.3870 (0.4006)  loss_vfl_aux_4: 0.4073 (0.4152)  loss_vfl_dn_0: 0.5392 (0.5888)  loss_vfl_dn_1: 0.5576 (0.5914)  loss_vfl_dn_2: 0.5649 (0.6017)  loss_vfl_dn_3: 0.5699 (0.5997)  loss_vfl_dn_4: 0.5682 (0.5917)  loss_vfl_dn_5: 0.5633 (0.5888)  loss_vfl_enc_0: 0.3160 (0.3583)  time: 0.9650  data: 0.0319  max mem: 10356\r\n",
      "Epoch: [1] Total time: 0:01:25 (1.0774 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 35.9781 (36.5715)  loss_bbox: 0.9060 (0.9525)  loss_bbox_aux_0: 0.9327 (0.9753)  loss_bbox_aux_1: 0.9069 (0.9596)  loss_bbox_aux_2: 0.9206 (0.9559)  loss_bbox_aux_3: 0.9084 (0.9530)  loss_bbox_aux_4: 0.9139 (0.9521)  loss_bbox_dn_0: 0.4083 (0.4982)  loss_bbox_dn_1: 0.4088 (0.5002)  loss_bbox_dn_2: 0.4094 (0.5024)  loss_bbox_dn_3: 0.4097 (0.5038)  loss_bbox_dn_4: 0.4104 (0.5050)  loss_bbox_dn_5: 0.4109 (0.5059)  loss_bbox_enc_0: 0.9309 (0.9872)  loss_giou: 1.8260 (1.7472)  loss_giou_aux_0: 1.8485 (1.7654)  loss_giou_aux_1: 1.8274 (1.7567)  loss_giou_aux_2: 1.7973 (1.7505)  loss_giou_aux_3: 1.8343 (1.7500)  loss_giou_aux_4: 1.8107 (1.7484)  loss_giou_dn_0: 1.3674 (1.3690)  loss_giou_dn_1: 1.3686 (1.3689)  loss_giou_dn_2: 1.3704 (1.3689)  loss_giou_dn_3: 1.3715 (1.3695)  loss_giou_dn_4: 1.3727 (1.3705)  loss_giou_dn_5: 1.3739 (1.3720)  loss_giou_enc_0: 1.8461 (1.7814)  loss_vfl: 0.4213 (0.4233)  loss_vfl_aux_0: 0.3328 (0.3621)  loss_vfl_aux_1: 0.3740 (0.3940)  loss_vfl_aux_2: 0.3580 (0.3866)  loss_vfl_aux_3: 0.3870 (0.4006)  loss_vfl_aux_4: 0.4073 (0.4152)  loss_vfl_dn_0: 0.5392 (0.5888)  loss_vfl_dn_1: 0.5576 (0.5914)  loss_vfl_dn_2: 0.5649 (0.6017)  loss_vfl_dn_3: 0.5699 (0.5997)  loss_vfl_dn_4: 0.5682 (0.5917)  loss_vfl_dn_5: 0.5633 (0.5888)  loss_vfl_enc_0: 0.3160 (0.3583)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.2937  data: 1.3041  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0574  data: 0.2139  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0742 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.13s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      "best_stat: {'epoch': 1, 'coco_eval_bbox': 3.691768846240541e-07}\r\n",
      "Epoch: [2]  [ 0/79]  eta: 0:05:28  lr: 0.000020  loss: 34.4452 (34.4452)  loss_bbox: 0.7451 (0.7451)  loss_bbox_aux_0: 0.7492 (0.7492)  loss_bbox_aux_1: 0.7427 (0.7427)  loss_bbox_aux_2: 0.7688 (0.7688)  loss_bbox_aux_3: 0.7522 (0.7522)  loss_bbox_aux_4: 0.7561 (0.7561)  loss_bbox_dn_0: 0.3861 (0.3861)  loss_bbox_dn_1: 0.3880 (0.3880)  loss_bbox_dn_2: 0.3899 (0.3899)  loss_bbox_dn_3: 0.3909 (0.3909)  loss_bbox_dn_4: 0.3913 (0.3913)  loss_bbox_dn_5: 0.3917 (0.3917)  loss_bbox_enc_0: 0.7919 (0.7919)  loss_giou: 1.7171 (1.7171)  loss_giou_aux_0: 1.7241 (1.7241)  loss_giou_aux_1: 1.7291 (1.7291)  loss_giou_aux_2: 1.6940 (1.6940)  loss_giou_aux_3: 1.6964 (1.6964)  loss_giou_aux_4: 1.6961 (1.6961)  loss_giou_dn_0: 1.3642 (1.3642)  loss_giou_dn_1: 1.3664 (1.3664)  loss_giou_dn_2: 1.3688 (1.3688)  loss_giou_dn_3: 1.3700 (1.3700)  loss_giou_dn_4: 1.3700 (1.3700)  loss_giou_dn_5: 1.3702 (1.3702)  loss_giou_enc_0: 1.7419 (1.7419)  loss_vfl: 0.4872 (0.4872)  loss_vfl_aux_0: 0.3931 (0.3931)  loss_vfl_aux_1: 0.4491 (0.4491)  loss_vfl_aux_2: 0.4479 (0.4479)  loss_vfl_aux_3: 0.4512 (0.4512)  loss_vfl_aux_4: 0.4875 (0.4875)  loss_vfl_dn_0: 0.5624 (0.5624)  loss_vfl_dn_1: 0.5760 (0.5760)  loss_vfl_dn_2: 0.5885 (0.5885)  loss_vfl_dn_3: 0.5856 (0.5856)  loss_vfl_dn_4: 0.6031 (0.6031)  loss_vfl_dn_5: 0.6023 (0.6023)  loss_vfl_enc_0: 0.3593 (0.3593)  time: 4.1621  data: 2.8207  max mem: 10356\r\n",
      "Epoch: [2]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 35.2709 (36.2825)  loss_bbox: 0.9047 (0.9466)  loss_bbox_aux_0: 0.9219 (0.9644)  loss_bbox_aux_1: 0.9192 (0.9536)  loss_bbox_aux_2: 0.9062 (0.9491)  loss_bbox_aux_3: 0.9092 (0.9481)  loss_bbox_aux_4: 0.8981 (0.9464)  loss_bbox_dn_0: 0.4208 (0.5222)  loss_bbox_dn_1: 0.4235 (0.5238)  loss_bbox_dn_2: 0.4252 (0.5248)  loss_bbox_dn_3: 0.4254 (0.5252)  loss_bbox_dn_4: 0.4252 (0.5252)  loss_bbox_dn_5: 0.4249 (0.5251)  loss_bbox_enc_0: 0.9603 (0.9841)  loss_giou: 1.6628 (1.6385)  loss_giou_aux_0: 1.6831 (1.6532)  loss_giou_aux_1: 1.6776 (1.6469)  loss_giou_aux_2: 1.6893 (1.6421)  loss_giou_aux_3: 1.6869 (1.6396)  loss_giou_aux_4: 1.6667 (1.6389)  loss_giou_dn_0: 1.3674 (1.3668)  loss_giou_dn_1: 1.3663 (1.3663)  loss_giou_dn_2: 1.3648 (1.3660)  loss_giou_dn_3: 1.3639 (1.3660)  loss_giou_dn_4: 1.3629 (1.3661)  loss_giou_dn_5: 1.3621 (1.3663)  loss_giou_enc_0: 1.6567 (1.6654)  loss_vfl: 0.5120 (0.5345)  loss_vfl_aux_0: 0.4468 (0.4603)  loss_vfl_aux_1: 0.4652 (0.4911)  loss_vfl_aux_2: 0.4631 (0.4932)  loss_vfl_aux_3: 0.4869 (0.5126)  loss_vfl_aux_4: 0.5056 (0.5294)  loss_vfl_dn_0: 0.4777 (0.5125)  loss_vfl_dn_1: 0.5112 (0.5300)  loss_vfl_dn_2: 0.5278 (0.5451)  loss_vfl_dn_3: 0.5297 (0.5585)  loss_vfl_dn_4: 0.5500 (0.5590)  loss_vfl_dn_5: 0.5573 (0.5656)  loss_vfl_enc_0: 0.3997 (0.4299)  time: 1.0150  data: 0.0311  max mem: 10356\r\n",
      "Epoch: [2] Total time: 0:01:27 (1.1061 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 35.2709 (36.2825)  loss_bbox: 0.9047 (0.9466)  loss_bbox_aux_0: 0.9219 (0.9644)  loss_bbox_aux_1: 0.9192 (0.9536)  loss_bbox_aux_2: 0.9062 (0.9491)  loss_bbox_aux_3: 0.9092 (0.9481)  loss_bbox_aux_4: 0.8981 (0.9464)  loss_bbox_dn_0: 0.4208 (0.5222)  loss_bbox_dn_1: 0.4235 (0.5238)  loss_bbox_dn_2: 0.4252 (0.5248)  loss_bbox_dn_3: 0.4254 (0.5252)  loss_bbox_dn_4: 0.4252 (0.5252)  loss_bbox_dn_5: 0.4249 (0.5251)  loss_bbox_enc_0: 0.9603 (0.9841)  loss_giou: 1.6628 (1.6385)  loss_giou_aux_0: 1.6831 (1.6532)  loss_giou_aux_1: 1.6776 (1.6469)  loss_giou_aux_2: 1.6893 (1.6421)  loss_giou_aux_3: 1.6869 (1.6396)  loss_giou_aux_4: 1.6667 (1.6389)  loss_giou_dn_0: 1.3674 (1.3668)  loss_giou_dn_1: 1.3663 (1.3663)  loss_giou_dn_2: 1.3648 (1.3660)  loss_giou_dn_3: 1.3639 (1.3660)  loss_giou_dn_4: 1.3629 (1.3661)  loss_giou_dn_5: 1.3621 (1.3663)  loss_giou_enc_0: 1.6567 (1.6654)  loss_vfl: 0.5120 (0.5345)  loss_vfl_aux_0: 0.4468 (0.4603)  loss_vfl_aux_1: 0.4652 (0.4911)  loss_vfl_aux_2: 0.4631 (0.4932)  loss_vfl_aux_3: 0.4869 (0.5126)  loss_vfl_aux_4: 0.5056 (0.5294)  loss_vfl_dn_0: 0.4777 (0.5125)  loss_vfl_dn_1: 0.5112 (0.5300)  loss_vfl_dn_2: 0.5278 (0.5451)  loss_vfl_dn_3: 0.5297 (0.5585)  loss_vfl_dn_4: 0.5500 (0.5590)  loss_vfl_dn_5: 0.5573 (0.5656)  loss_vfl_enc_0: 0.3997 (0.4299)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.3886  data: 1.4499  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0697  data: 0.2238  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0872 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.14s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.007\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\r\n",
      "best_stat: {'epoch': 2, 'coco_eval_bbox': 5.202622027426078e-06}\r\n",
      "Epoch: [3]  [ 0/79]  eta: 0:06:45  lr: 0.000020  loss: 34.6407 (34.6407)  loss_bbox: 0.9031 (0.9031)  loss_bbox_aux_0: 0.9533 (0.9533)  loss_bbox_aux_1: 0.9060 (0.9060)  loss_bbox_aux_2: 0.8892 (0.8892)  loss_bbox_aux_3: 0.8954 (0.8954)  loss_bbox_aux_4: 0.8913 (0.8913)  loss_bbox_dn_0: 0.4262 (0.4262)  loss_bbox_dn_1: 0.4270 (0.4270)  loss_bbox_dn_2: 0.4272 (0.4272)  loss_bbox_dn_3: 0.4268 (0.4268)  loss_bbox_dn_4: 0.4262 (0.4262)  loss_bbox_dn_5: 0.4259 (0.4259)  loss_bbox_enc_0: 0.9227 (0.9227)  loss_giou: 1.6440 (1.6440)  loss_giou_aux_0: 1.6580 (1.6580)  loss_giou_aux_1: 1.6587 (1.6587)  loss_giou_aux_2: 1.6616 (1.6616)  loss_giou_aux_3: 1.6640 (1.6640)  loss_giou_aux_4: 1.6550 (1.6550)  loss_giou_dn_0: 1.3467 (1.3467)  loss_giou_dn_1: 1.3474 (1.3474)  loss_giou_dn_2: 1.3500 (1.3500)  loss_giou_dn_3: 1.3554 (1.3554)  loss_giou_dn_4: 1.3615 (1.3615)  loss_giou_dn_5: 1.3657 (1.3657)  loss_giou_enc_0: 1.6889 (1.6889)  loss_vfl: 0.4694 (0.4694)  loss_vfl_aux_0: 0.3885 (0.3885)  loss_vfl_aux_1: 0.4124 (0.4124)  loss_vfl_aux_2: 0.4167 (0.4167)  loss_vfl_aux_3: 0.4586 (0.4586)  loss_vfl_aux_4: 0.4756 (0.4756)  loss_vfl_dn_0: 0.4603 (0.4603)  loss_vfl_dn_1: 0.4651 (0.4651)  loss_vfl_dn_2: 0.4888 (0.4888)  loss_vfl_dn_3: 0.5166 (0.5166)  loss_vfl_dn_4: 0.5237 (0.5237)  loss_vfl_dn_5: 0.5308 (0.5308)  loss_vfl_enc_0: 0.3572 (0.3572)  time: 5.1308  data: 3.8024  max mem: 10356\r\n",
      "Epoch: [3]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 34.9333 (35.9145)  loss_bbox: 0.8278 (0.8987)  loss_bbox_aux_0: 0.8390 (0.9245)  loss_bbox_aux_1: 0.8488 (0.9115)  loss_bbox_aux_2: 0.8256 (0.9050)  loss_bbox_aux_3: 0.8195 (0.9002)  loss_bbox_aux_4: 0.8295 (0.9013)  loss_bbox_dn_0: 0.5056 (0.5364)  loss_bbox_dn_1: 0.5059 (0.5369)  loss_bbox_dn_2: 0.5051 (0.5365)  loss_bbox_dn_3: 0.5039 (0.5357)  loss_bbox_dn_4: 0.5022 (0.5345)  loss_bbox_dn_5: 0.5013 (0.5338)  loss_bbox_enc_0: 0.8556 (0.9339)  loss_giou: 1.5347 (1.5720)  loss_giou_aux_0: 1.5705 (1.5792)  loss_giou_aux_1: 1.5394 (1.5786)  loss_giou_aux_2: 1.5682 (1.5789)  loss_giou_aux_3: 1.5562 (1.5792)  loss_giou_aux_4: 1.5189 (1.5722)  loss_giou_dn_0: 1.3758 (1.3675)  loss_giou_dn_1: 1.3761 (1.3672)  loss_giou_dn_2: 1.3756 (1.3678)  loss_giou_dn_3: 1.3754 (1.3694)  loss_giou_dn_4: 1.3750 (1.3711)  loss_giou_dn_5: 1.3755 (1.3728)  loss_giou_enc_0: 1.5541 (1.5927)  loss_vfl: 0.6233 (0.6206)  loss_vfl_aux_0: 0.5634 (0.5446)  loss_vfl_aux_1: 0.5896 (0.5583)  loss_vfl_aux_2: 0.5562 (0.5655)  loss_vfl_aux_3: 0.6105 (0.5889)  loss_vfl_aux_4: 0.6050 (0.6078)  loss_vfl_dn_0: 0.4595 (0.4783)  loss_vfl_dn_1: 0.4618 (0.4862)  loss_vfl_dn_2: 0.4722 (0.4992)  loss_vfl_dn_3: 0.4938 (0.5241)  loss_vfl_dn_4: 0.5067 (0.5303)  loss_vfl_dn_5: 0.5261 (0.5448)  loss_vfl_enc_0: 0.5365 (0.5086)  time: 0.9455  data: 0.0315  max mem: 10356\r\n",
      "Epoch: [3] Total time: 0:01:27 (1.1125 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 34.9333 (35.9145)  loss_bbox: 0.8278 (0.8987)  loss_bbox_aux_0: 0.8390 (0.9245)  loss_bbox_aux_1: 0.8488 (0.9115)  loss_bbox_aux_2: 0.8256 (0.9050)  loss_bbox_aux_3: 0.8195 (0.9002)  loss_bbox_aux_4: 0.8295 (0.9013)  loss_bbox_dn_0: 0.5056 (0.5364)  loss_bbox_dn_1: 0.5059 (0.5369)  loss_bbox_dn_2: 0.5051 (0.5365)  loss_bbox_dn_3: 0.5039 (0.5357)  loss_bbox_dn_4: 0.5022 (0.5345)  loss_bbox_dn_5: 0.5013 (0.5338)  loss_bbox_enc_0: 0.8556 (0.9339)  loss_giou: 1.5347 (1.5720)  loss_giou_aux_0: 1.5705 (1.5792)  loss_giou_aux_1: 1.5394 (1.5786)  loss_giou_aux_2: 1.5682 (1.5789)  loss_giou_aux_3: 1.5562 (1.5792)  loss_giou_aux_4: 1.5189 (1.5722)  loss_giou_dn_0: 1.3758 (1.3675)  loss_giou_dn_1: 1.3761 (1.3672)  loss_giou_dn_2: 1.3756 (1.3678)  loss_giou_dn_3: 1.3754 (1.3694)  loss_giou_dn_4: 1.3750 (1.3711)  loss_giou_dn_5: 1.3755 (1.3728)  loss_giou_enc_0: 1.5541 (1.5927)  loss_vfl: 0.6233 (0.6206)  loss_vfl_aux_0: 0.5634 (0.5446)  loss_vfl_aux_1: 0.5896 (0.5583)  loss_vfl_aux_2: 0.5562 (0.5655)  loss_vfl_aux_3: 0.6105 (0.5889)  loss_vfl_aux_4: 0.6050 (0.6078)  loss_vfl_dn_0: 0.4595 (0.4783)  loss_vfl_dn_1: 0.4618 (0.4862)  loss_vfl_dn_2: 0.4722 (0.4992)  loss_vfl_dn_3: 0.4938 (0.5241)  loss_vfl_dn_4: 0.5067 (0.5303)  loss_vfl_dn_5: 0.5261 (0.5448)  loss_vfl_enc_0: 0.5365 (0.5086)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.2006  data: 1.2602  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0638  data: 0.2109  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0793 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.14s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.003\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.012\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.013\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\r\n",
      "best_stat: {'epoch': 3, 'coco_eval_bbox': 1.0435538561990336e-05}\r\n",
      "Epoch: [4]  [ 0/79]  eta: 0:04:59  lr: 0.000020  loss: 35.7685 (35.7685)  loss_bbox: 0.7711 (0.7711)  loss_bbox_aux_0: 0.7773 (0.7773)  loss_bbox_aux_1: 0.7594 (0.7594)  loss_bbox_aux_2: 0.7692 (0.7692)  loss_bbox_aux_3: 0.7848 (0.7848)  loss_bbox_aux_4: 0.7706 (0.7706)  loss_bbox_dn_0: 0.5734 (0.5734)  loss_bbox_dn_1: 0.5737 (0.5737)  loss_bbox_dn_2: 0.5726 (0.5726)  loss_bbox_dn_3: 0.5712 (0.5712)  loss_bbox_dn_4: 0.5693 (0.5693)  loss_bbox_dn_5: 0.5686 (0.5686)  loss_bbox_enc_0: 0.7905 (0.7905)  loss_giou: 1.2812 (1.2812)  loss_giou_aux_0: 1.2812 (1.2812)  loss_giou_aux_1: 1.2881 (1.2881)  loss_giou_aux_2: 1.2790 (1.2790)  loss_giou_aux_3: 1.2751 (1.2751)  loss_giou_aux_4: 1.2845 (1.2845)  loss_giou_dn_0: 1.3606 (1.3606)  loss_giou_dn_1: 1.3610 (1.3610)  loss_giou_dn_2: 1.3631 (1.3631)  loss_giou_dn_3: 1.3705 (1.3705)  loss_giou_dn_4: 1.3814 (1.3814)  loss_giou_dn_5: 1.3934 (1.3934)  loss_giou_enc_0: 1.2934 (1.2934)  loss_vfl: 0.9634 (0.9634)  loss_vfl_aux_0: 0.8837 (0.8837)  loss_vfl_aux_1: 0.9058 (0.9058)  loss_vfl_aux_2: 0.9086 (0.9086)  loss_vfl_aux_3: 0.9603 (0.9603)  loss_vfl_aux_4: 0.9446 (0.9446)  loss_vfl_dn_0: 0.5182 (0.5182)  loss_vfl_dn_1: 0.5239 (0.5239)  loss_vfl_dn_2: 0.5465 (0.5465)  loss_vfl_dn_3: 0.5720 (0.5720)  loss_vfl_dn_4: 0.5601 (0.5601)  loss_vfl_dn_5: 0.5713 (0.5713)  loss_vfl_enc_0: 0.8458 (0.8458)  time: 3.7886  data: 2.5208  max mem: 10356\r\n",
      "Epoch: [4]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 34.9724 (34.7871)  loss_bbox: 0.8074 (0.7800)  loss_bbox_aux_0: 0.7746 (0.8028)  loss_bbox_aux_1: 0.7808 (0.7973)  loss_bbox_aux_2: 0.7720 (0.7908)  loss_bbox_aux_3: 0.8052 (0.7877)  loss_bbox_aux_4: 0.7542 (0.7835)  loss_bbox_dn_0: 0.5214 (0.5070)  loss_bbox_dn_1: 0.5210 (0.5064)  loss_bbox_dn_2: 0.5202 (0.5051)  loss_bbox_dn_3: 0.5195 (0.5037)  loss_bbox_dn_4: 0.5187 (0.5021)  loss_bbox_dn_5: 0.5186 (0.5014)  loss_bbox_enc_0: 0.7863 (0.8145)  loss_giou: 1.5219 (1.5443)  loss_giou_aux_0: 1.5442 (1.5493)  loss_giou_aux_1: 1.5258 (1.5473)  loss_giou_aux_2: 1.5248 (1.5494)  loss_giou_aux_3: 1.5195 (1.5487)  loss_giou_aux_4: 1.5267 (1.5450)  loss_giou_dn_0: 1.3701 (1.3710)  loss_giou_dn_1: 1.3678 (1.3706)  loss_giou_dn_2: 1.3661 (1.3703)  loss_giou_dn_3: 1.3658 (1.3710)  loss_giou_dn_4: 1.3659 (1.3723)  loss_giou_dn_5: 1.3658 (1.3736)  loss_giou_enc_0: 1.5385 (1.5594)  loss_vfl: 0.6250 (0.6488)  loss_vfl_aux_0: 0.5813 (0.5986)  loss_vfl_aux_1: 0.5735 (0.6029)  loss_vfl_aux_2: 0.5863 (0.6069)  loss_vfl_aux_3: 0.5991 (0.6178)  loss_vfl_aux_4: 0.6133 (0.6355)  loss_vfl_dn_0: 0.4497 (0.4519)  loss_vfl_dn_1: 0.4448 (0.4547)  loss_vfl_dn_2: 0.4525 (0.4643)  loss_vfl_dn_3: 0.4729 (0.4869)  loss_vfl_dn_4: 0.4851 (0.4938)  loss_vfl_dn_5: 0.5049 (0.5100)  loss_vfl_enc_0: 0.5389 (0.5608)  time: 0.9923  data: 0.0314  max mem: 10356\r\n",
      "Epoch: [4] Total time: 0:01:22 (1.0460 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 34.9724 (34.7871)  loss_bbox: 0.8074 (0.7800)  loss_bbox_aux_0: 0.7746 (0.8028)  loss_bbox_aux_1: 0.7808 (0.7973)  loss_bbox_aux_2: 0.7720 (0.7908)  loss_bbox_aux_3: 0.8052 (0.7877)  loss_bbox_aux_4: 0.7542 (0.7835)  loss_bbox_dn_0: 0.5214 (0.5070)  loss_bbox_dn_1: 0.5210 (0.5064)  loss_bbox_dn_2: 0.5202 (0.5051)  loss_bbox_dn_3: 0.5195 (0.5037)  loss_bbox_dn_4: 0.5187 (0.5021)  loss_bbox_dn_5: 0.5186 (0.5014)  loss_bbox_enc_0: 0.7863 (0.8145)  loss_giou: 1.5219 (1.5443)  loss_giou_aux_0: 1.5442 (1.5493)  loss_giou_aux_1: 1.5258 (1.5473)  loss_giou_aux_2: 1.5248 (1.5494)  loss_giou_aux_3: 1.5195 (1.5487)  loss_giou_aux_4: 1.5267 (1.5450)  loss_giou_dn_0: 1.3701 (1.3710)  loss_giou_dn_1: 1.3678 (1.3706)  loss_giou_dn_2: 1.3661 (1.3703)  loss_giou_dn_3: 1.3658 (1.3710)  loss_giou_dn_4: 1.3659 (1.3723)  loss_giou_dn_5: 1.3658 (1.3736)  loss_giou_enc_0: 1.5385 (1.5594)  loss_vfl: 0.6250 (0.6488)  loss_vfl_aux_0: 0.5813 (0.5986)  loss_vfl_aux_1: 0.5735 (0.6029)  loss_vfl_aux_2: 0.5863 (0.6069)  loss_vfl_aux_3: 0.5991 (0.6178)  loss_vfl_aux_4: 0.6133 (0.6355)  loss_vfl_dn_0: 0.4497 (0.4519)  loss_vfl_dn_1: 0.4448 (0.4547)  loss_vfl_dn_2: 0.4525 (0.4643)  loss_vfl_dn_3: 0.4729 (0.4869)  loss_vfl_dn_4: 0.4851 (0.4938)  loss_vfl_dn_5: 0.5049 (0.5100)  loss_vfl_enc_0: 0.5389 (0.5608)\r\n",
      "Test:  [0/8]  eta: 0:00:24    time: 3.0789  data: 1.5701  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0888  data: 0.2356  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1055 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.14s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.004\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.019\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.005\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.022\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\r\n",
      "best_stat: {'epoch': 4, 'coco_eval_bbox': 0.00012393611313328963}\r\n",
      "Epoch: [5]  [ 0/79]  eta: 0:05:06  lr: 0.000020  loss: 39.9563 (39.9563)  loss_bbox: 1.0635 (1.0635)  loss_bbox_aux_0: 1.1122 (1.1122)  loss_bbox_aux_1: 1.0760 (1.0760)  loss_bbox_aux_2: 1.0734 (1.0734)  loss_bbox_aux_3: 1.0704 (1.0704)  loss_bbox_aux_4: 1.0633 (1.0633)  loss_bbox_dn_0: 0.8433 (0.8433)  loss_bbox_dn_1: 0.8416 (0.8416)  loss_bbox_dn_2: 0.8389 (0.8389)  loss_bbox_dn_3: 0.8361 (0.8361)  loss_bbox_dn_4: 0.8323 (0.8323)  loss_bbox_dn_5: 0.8310 (0.8310)  loss_bbox_enc_0: 1.0748 (1.0748)  loss_giou: 1.5184 (1.5184)  loss_giou_aux_0: 1.4943 (1.4943)  loss_giou_aux_1: 1.5037 (1.5037)  loss_giou_aux_2: 1.5048 (1.5048)  loss_giou_aux_3: 1.5094 (1.5094)  loss_giou_aux_4: 1.5131 (1.5131)  loss_giou_dn_0: 1.3610 (1.3610)  loss_giou_dn_1: 1.3601 (1.3601)  loss_giou_dn_2: 1.3600 (1.3600)  loss_giou_dn_3: 1.3598 (1.3598)  loss_giou_dn_4: 1.3599 (1.3599)  loss_giou_dn_5: 1.3594 (1.3594)  loss_giou_enc_0: 1.5053 (1.5053)  loss_vfl: 0.8550 (0.8550)  loss_vfl_aux_0: 0.8345 (0.8345)  loss_vfl_aux_1: 0.8403 (0.8403)  loss_vfl_aux_2: 0.8335 (0.8335)  loss_vfl_aux_3: 0.8577 (0.8577)  loss_vfl_aux_4: 0.8425 (0.8425)  loss_vfl_dn_0: 0.4407 (0.4407)  loss_vfl_dn_1: 0.4489 (0.4489)  loss_vfl_dn_2: 0.4578 (0.4578)  loss_vfl_dn_3: 0.4946 (0.4946)  loss_vfl_dn_4: 0.4971 (0.4971)  loss_vfl_dn_5: 0.4954 (0.4954)  loss_vfl_enc_0: 0.7925 (0.7925)  time: 3.8755  data: 2.5385  max mem: 10356\r\n",
      "Epoch: [5]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 33.1720 (34.6921)  loss_bbox: 0.6265 (0.7538)  loss_bbox_aux_0: 0.6714 (0.7912)  loss_bbox_aux_1: 0.6599 (0.7818)  loss_bbox_aux_2: 0.6423 (0.7750)  loss_bbox_aux_3: 0.6494 (0.7675)  loss_bbox_aux_4: 0.6297 (0.7596)  loss_bbox_dn_0: 0.4710 (0.5243)  loss_bbox_dn_1: 0.4689 (0.5226)  loss_bbox_dn_2: 0.4669 (0.5207)  loss_bbox_dn_3: 0.4662 (0.5192)  loss_bbox_dn_4: 0.4666 (0.5176)  loss_bbox_dn_5: 0.4660 (0.5173)  loss_bbox_enc_0: 0.6895 (0.8046)  loss_giou: 1.5031 (1.5265)  loss_giou_aux_0: 1.4999 (1.5381)  loss_giou_aux_1: 1.5271 (1.5336)  loss_giou_aux_2: 1.5027 (1.5318)  loss_giou_aux_3: 1.5149 (1.5334)  loss_giou_aux_4: 1.4967 (1.5244)  loss_giou_dn_0: 1.3758 (1.3711)  loss_giou_dn_1: 1.3761 (1.3704)  loss_giou_dn_2: 1.3725 (1.3695)  loss_giou_dn_3: 1.3729 (1.3693)  loss_giou_dn_4: 1.3691 (1.3695)  loss_giou_dn_5: 1.3661 (1.3706)  loss_giou_enc_0: 1.5444 (1.5526)  loss_vfl: 0.6140 (0.6628)  loss_vfl_aux_0: 0.5730 (0.6268)  loss_vfl_aux_1: 0.5873 (0.6308)  loss_vfl_aux_2: 0.5835 (0.6313)  loss_vfl_aux_3: 0.5896 (0.6395)  loss_vfl_aux_4: 0.6006 (0.6480)  loss_vfl_dn_0: 0.4279 (0.4402)  loss_vfl_dn_1: 0.4264 (0.4391)  loss_vfl_dn_2: 0.4326 (0.4471)  loss_vfl_dn_3: 0.4625 (0.4668)  loss_vfl_dn_4: 0.4590 (0.4720)  loss_vfl_dn_5: 0.4802 (0.4836)  loss_vfl_enc_0: 0.5408 (0.5881)  time: 0.9757  data: 0.0331  max mem: 10356\r\n",
      "Epoch: [5] Total time: 0:01:25 (1.0772 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 33.1720 (34.6921)  loss_bbox: 0.6265 (0.7538)  loss_bbox_aux_0: 0.6714 (0.7912)  loss_bbox_aux_1: 0.6599 (0.7818)  loss_bbox_aux_2: 0.6423 (0.7750)  loss_bbox_aux_3: 0.6494 (0.7675)  loss_bbox_aux_4: 0.6297 (0.7596)  loss_bbox_dn_0: 0.4710 (0.5243)  loss_bbox_dn_1: 0.4689 (0.5226)  loss_bbox_dn_2: 0.4669 (0.5207)  loss_bbox_dn_3: 0.4662 (0.5192)  loss_bbox_dn_4: 0.4666 (0.5176)  loss_bbox_dn_5: 0.4660 (0.5173)  loss_bbox_enc_0: 0.6895 (0.8046)  loss_giou: 1.5031 (1.5265)  loss_giou_aux_0: 1.4999 (1.5381)  loss_giou_aux_1: 1.5271 (1.5336)  loss_giou_aux_2: 1.5027 (1.5318)  loss_giou_aux_3: 1.5149 (1.5334)  loss_giou_aux_4: 1.4967 (1.5244)  loss_giou_dn_0: 1.3758 (1.3711)  loss_giou_dn_1: 1.3761 (1.3704)  loss_giou_dn_2: 1.3725 (1.3695)  loss_giou_dn_3: 1.3729 (1.3693)  loss_giou_dn_4: 1.3691 (1.3695)  loss_giou_dn_5: 1.3661 (1.3706)  loss_giou_enc_0: 1.5444 (1.5526)  loss_vfl: 0.6140 (0.6628)  loss_vfl_aux_0: 0.5730 (0.6268)  loss_vfl_aux_1: 0.5873 (0.6308)  loss_vfl_aux_2: 0.5835 (0.6313)  loss_vfl_aux_3: 0.5896 (0.6395)  loss_vfl_aux_4: 0.6006 (0.6480)  loss_vfl_dn_0: 0.4279 (0.4402)  loss_vfl_dn_1: 0.4264 (0.4391)  loss_vfl_dn_2: 0.4326 (0.4471)  loss_vfl_dn_3: 0.4625 (0.4668)  loss_vfl_dn_4: 0.4590 (0.4720)  loss_vfl_dn_5: 0.4802 (0.4836)  loss_vfl_enc_0: 0.5408 (0.5881)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.4813  data: 1.5693  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0839  data: 0.2375  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1001 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.16s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.008\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.011\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.024\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.013\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.036\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.004\r\n",
      "best_stat: {'epoch': 5, 'coco_eval_bbox': 0.00018578802221292344}\r\n",
      "Epoch: [6]  [ 0/79]  eta: 0:04:22  lr: 0.000020  loss: 36.8931 (36.8931)  loss_bbox: 0.8688 (0.8688)  loss_bbox_aux_0: 0.9500 (0.9500)  loss_bbox_aux_1: 0.9216 (0.9216)  loss_bbox_aux_2: 0.9030 (0.9030)  loss_bbox_aux_3: 0.8863 (0.8863)  loss_bbox_aux_4: 0.8897 (0.8897)  loss_bbox_dn_0: 0.6158 (0.6158)  loss_bbox_dn_1: 0.6140 (0.6140)  loss_bbox_dn_2: 0.6122 (0.6122)  loss_bbox_dn_3: 0.6107 (0.6107)  loss_bbox_dn_4: 0.6090 (0.6090)  loss_bbox_dn_5: 0.6081 (0.6081)  loss_bbox_enc_0: 0.9620 (0.9620)  loss_giou: 1.7572 (1.7572)  loss_giou_aux_0: 1.7239 (1.7239)  loss_giou_aux_1: 1.7391 (1.7391)  loss_giou_aux_2: 1.7458 (1.7458)  loss_giou_aux_3: 1.7592 (1.7592)  loss_giou_aux_4: 1.7480 (1.7480)  loss_giou_dn_0: 1.3548 (1.3548)  loss_giou_dn_1: 1.3557 (1.3557)  loss_giou_dn_2: 1.3627 (1.3627)  loss_giou_dn_3: 1.3689 (1.3689)  loss_giou_dn_4: 1.3776 (1.3776)  loss_giou_dn_5: 1.3805 (1.3805)  loss_giou_enc_0: 1.7587 (1.7587)  loss_vfl: 0.5275 (0.5275)  loss_vfl_aux_0: 0.5039 (0.5039)  loss_vfl_aux_1: 0.5192 (0.5192)  loss_vfl_aux_2: 0.5315 (0.5315)  loss_vfl_aux_3: 0.5331 (0.5331)  loss_vfl_aux_4: 0.5316 (0.5316)  loss_vfl_dn_0: 0.4603 (0.4603)  loss_vfl_dn_1: 0.4534 (0.4534)  loss_vfl_dn_2: 0.4530 (0.4530)  loss_vfl_dn_3: 0.4503 (0.4503)  loss_vfl_dn_4: 0.4767 (0.4767)  loss_vfl_dn_5: 0.4785 (0.4785)  loss_vfl_enc_0: 0.4908 (0.4908)  time: 3.3262  data: 2.0876  max mem: 10356\r\n",
      "Epoch: [6]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 33.6871 (34.0426)  loss_bbox: 0.6518 (0.6761)  loss_bbox_aux_0: 0.7152 (0.7238)  loss_bbox_aux_1: 0.6823 (0.7111)  loss_bbox_aux_2: 0.6644 (0.6967)  loss_bbox_aux_3: 0.6412 (0.6894)  loss_bbox_aux_4: 0.6467 (0.6786)  loss_bbox_dn_0: 0.4210 (0.5013)  loss_bbox_dn_1: 0.4180 (0.4982)  loss_bbox_dn_2: 0.4150 (0.4954)  loss_bbox_dn_3: 0.4128 (0.4936)  loss_bbox_dn_4: 0.4096 (0.4916)  loss_bbox_dn_5: 0.4099 (0.4916)  loss_bbox_enc_0: 0.7071 (0.7399)  loss_giou: 1.5702 (1.5256)  loss_giou_aux_0: 1.5867 (1.5393)  loss_giou_aux_1: 1.5842 (1.5377)  loss_giou_aux_2: 1.5915 (1.5391)  loss_giou_aux_3: 1.5714 (1.5367)  loss_giou_aux_4: 1.5663 (1.5304)  loss_giou_dn_0: 1.3689 (1.3742)  loss_giou_dn_1: 1.3650 (1.3728)  loss_giou_dn_2: 1.3606 (1.3704)  loss_giou_dn_3: 1.3612 (1.3686)  loss_giou_dn_4: 1.3585 (1.3660)  loss_giou_dn_5: 1.3585 (1.3658)  loss_giou_enc_0: 1.6096 (1.5502)  loss_vfl: 0.6813 (0.6793)  loss_vfl_aux_0: 0.6194 (0.6407)  loss_vfl_aux_1: 0.6311 (0.6388)  loss_vfl_aux_2: 0.6382 (0.6478)  loss_vfl_aux_3: 0.6337 (0.6521)  loss_vfl_aux_4: 0.6687 (0.6634)  loss_vfl_dn_0: 0.4105 (0.4231)  loss_vfl_dn_1: 0.4103 (0.4216)  loss_vfl_dn_2: 0.4285 (0.4298)  loss_vfl_dn_3: 0.4460 (0.4493)  loss_vfl_dn_4: 0.4553 (0.4578)  loss_vfl_dn_5: 0.4651 (0.4655)  loss_vfl_enc_0: 0.5989 (0.6094)  time: 0.9978  data: 0.0344  max mem: 10356\r\n",
      "Epoch: [6] Total time: 0:01:23 (1.0633 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 33.6871 (34.0426)  loss_bbox: 0.6518 (0.6761)  loss_bbox_aux_0: 0.7152 (0.7238)  loss_bbox_aux_1: 0.6823 (0.7111)  loss_bbox_aux_2: 0.6644 (0.6967)  loss_bbox_aux_3: 0.6412 (0.6894)  loss_bbox_aux_4: 0.6467 (0.6786)  loss_bbox_dn_0: 0.4210 (0.5013)  loss_bbox_dn_1: 0.4180 (0.4982)  loss_bbox_dn_2: 0.4150 (0.4954)  loss_bbox_dn_3: 0.4128 (0.4936)  loss_bbox_dn_4: 0.4096 (0.4916)  loss_bbox_dn_5: 0.4099 (0.4916)  loss_bbox_enc_0: 0.7071 (0.7399)  loss_giou: 1.5702 (1.5256)  loss_giou_aux_0: 1.5867 (1.5393)  loss_giou_aux_1: 1.5842 (1.5377)  loss_giou_aux_2: 1.5915 (1.5391)  loss_giou_aux_3: 1.5714 (1.5367)  loss_giou_aux_4: 1.5663 (1.5304)  loss_giou_dn_0: 1.3689 (1.3742)  loss_giou_dn_1: 1.3650 (1.3728)  loss_giou_dn_2: 1.3606 (1.3704)  loss_giou_dn_3: 1.3612 (1.3686)  loss_giou_dn_4: 1.3585 (1.3660)  loss_giou_dn_5: 1.3585 (1.3658)  loss_giou_enc_0: 1.6096 (1.5502)  loss_vfl: 0.6813 (0.6793)  loss_vfl_aux_0: 0.6194 (0.6407)  loss_vfl_aux_1: 0.6311 (0.6388)  loss_vfl_aux_2: 0.6382 (0.6478)  loss_vfl_aux_3: 0.6337 (0.6521)  loss_vfl_aux_4: 0.6687 (0.6634)  loss_vfl_dn_0: 0.4105 (0.4231)  loss_vfl_dn_1: 0.4103 (0.4216)  loss_vfl_dn_2: 0.4285 (0.4298)  loss_vfl_dn_3: 0.4460 (0.4493)  loss_vfl_dn_4: 0.4553 (0.4578)  loss_vfl_dn_5: 0.4651 (0.4655)  loss_vfl_enc_0: 0.5989 (0.6094)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.1498  data: 1.2086  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0722  data: 0.2097  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0877 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.16s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.006\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.013\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.019\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.035\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.023\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.055\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.005\r\n",
      "best_stat: {'epoch': 6, 'coco_eval_bbox': 0.00022402344534924612}\r\n",
      "Epoch: [7]  [ 0/79]  eta: 0:05:06  lr: 0.000020  loss: 31.1361 (31.1361)  loss_bbox: 0.4085 (0.4085)  loss_bbox_aux_0: 0.4632 (0.4632)  loss_bbox_aux_1: 0.4710 (0.4710)  loss_bbox_aux_2: 0.4705 (0.4705)  loss_bbox_aux_3: 0.4370 (0.4370)  loss_bbox_aux_4: 0.4257 (0.4257)  loss_bbox_dn_0: 0.4174 (0.4174)  loss_bbox_dn_1: 0.4128 (0.4128)  loss_bbox_dn_2: 0.4077 (0.4077)  loss_bbox_dn_3: 0.4035 (0.4035)  loss_bbox_dn_4: 0.3979 (0.3979)  loss_bbox_dn_5: 0.3968 (0.3968)  loss_bbox_enc_0: 0.5126 (0.5126)  loss_giou: 1.2757 (1.2757)  loss_giou_aux_0: 1.3199 (1.3199)  loss_giou_aux_1: 1.2901 (1.2901)  loss_giou_aux_2: 1.2767 (1.2767)  loss_giou_aux_3: 1.2849 (1.2849)  loss_giou_aux_4: 1.2707 (1.2707)  loss_giou_dn_0: 1.3708 (1.3708)  loss_giou_dn_1: 1.3644 (1.3644)  loss_giou_dn_2: 1.3523 (1.3523)  loss_giou_dn_3: 1.3415 (1.3415)  loss_giou_dn_4: 1.3256 (1.3256)  loss_giou_dn_5: 1.3217 (1.3217)  loss_giou_enc_0: 1.3195 (1.3195)  loss_vfl: 0.8423 (0.8423)  loss_vfl_aux_0: 0.8079 (0.8079)  loss_vfl_aux_1: 0.8191 (0.8191)  loss_vfl_aux_2: 0.8354 (0.8354)  loss_vfl_aux_3: 0.8281 (0.8281)  loss_vfl_aux_4: 0.8313 (0.8313)  loss_vfl_dn_0: 0.4198 (0.4198)  loss_vfl_dn_1: 0.4188 (0.4188)  loss_vfl_dn_2: 0.4335 (0.4335)  loss_vfl_dn_3: 0.4589 (0.4589)  loss_vfl_dn_4: 0.4644 (0.4644)  loss_vfl_dn_5: 0.4736 (0.4736)  loss_vfl_enc_0: 0.7645 (0.7645)  time: 3.8851  data: 2.6989  max mem: 10356\r\n",
      "Epoch: [7]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 32.7182 (33.7881)  loss_bbox: 0.5018 (0.6171)  loss_bbox_aux_0: 0.5972 (0.6846)  loss_bbox_aux_1: 0.5981 (0.6689)  loss_bbox_aux_2: 0.5796 (0.6600)  loss_bbox_aux_3: 0.5440 (0.6436)  loss_bbox_aux_4: 0.5185 (0.6260)  loss_bbox_dn_0: 0.4686 (0.5176)  loss_bbox_dn_1: 0.4616 (0.5130)  loss_bbox_dn_2: 0.4539 (0.5077)  loss_bbox_dn_3: 0.4484 (0.5038)  loss_bbox_dn_4: 0.4434 (0.5000)  loss_bbox_dn_5: 0.4437 (0.4998)  loss_bbox_enc_0: 0.6084 (0.7068)  loss_giou: 1.3962 (1.4279)  loss_giou_aux_0: 1.4619 (1.4816)  loss_giou_aux_1: 1.4422 (1.4732)  loss_giou_aux_2: 1.4216 (1.4571)  loss_giou_aux_3: 1.4109 (1.4476)  loss_giou_aux_4: 1.3903 (1.4291)  loss_giou_dn_0: 1.3544 (1.3656)  loss_giou_dn_1: 1.3408 (1.3601)  loss_giou_dn_2: 1.3280 (1.3524)  loss_giou_dn_3: 1.3163 (1.3455)  loss_giou_dn_4: 1.3030 (1.3379)  loss_giou_dn_5: 1.3024 (1.3376)  loss_giou_enc_0: 1.4953 (1.5082)  loss_vfl: 0.8247 (0.7935)  loss_vfl_aux_0: 0.6875 (0.7070)  loss_vfl_aux_1: 0.6932 (0.7116)  loss_vfl_aux_2: 0.7446 (0.7275)  loss_vfl_aux_3: 0.7617 (0.7448)  loss_vfl_aux_4: 0.8018 (0.7748)  loss_vfl_dn_0: 0.4205 (0.4218)  loss_vfl_dn_1: 0.4246 (0.4225)  loss_vfl_dn_2: 0.4558 (0.4376)  loss_vfl_dn_3: 0.4819 (0.4587)  loss_vfl_dn_4: 0.4944 (0.4738)  loss_vfl_dn_5: 0.5076 (0.4820)  loss_vfl_enc_0: 0.6311 (0.6599)  time: 1.0602  data: 0.0311  max mem: 10356\r\n",
      "Epoch: [7] Total time: 0:01:26 (1.0963 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 32.7182 (33.7881)  loss_bbox: 0.5018 (0.6171)  loss_bbox_aux_0: 0.5972 (0.6846)  loss_bbox_aux_1: 0.5981 (0.6689)  loss_bbox_aux_2: 0.5796 (0.6600)  loss_bbox_aux_3: 0.5440 (0.6436)  loss_bbox_aux_4: 0.5185 (0.6260)  loss_bbox_dn_0: 0.4686 (0.5176)  loss_bbox_dn_1: 0.4616 (0.5130)  loss_bbox_dn_2: 0.4539 (0.5077)  loss_bbox_dn_3: 0.4484 (0.5038)  loss_bbox_dn_4: 0.4434 (0.5000)  loss_bbox_dn_5: 0.4437 (0.4998)  loss_bbox_enc_0: 0.6084 (0.7068)  loss_giou: 1.3962 (1.4279)  loss_giou_aux_0: 1.4619 (1.4816)  loss_giou_aux_1: 1.4422 (1.4732)  loss_giou_aux_2: 1.4216 (1.4571)  loss_giou_aux_3: 1.4109 (1.4476)  loss_giou_aux_4: 1.3903 (1.4291)  loss_giou_dn_0: 1.3544 (1.3656)  loss_giou_dn_1: 1.3408 (1.3601)  loss_giou_dn_2: 1.3280 (1.3524)  loss_giou_dn_3: 1.3163 (1.3455)  loss_giou_dn_4: 1.3030 (1.3379)  loss_giou_dn_5: 1.3024 (1.3376)  loss_giou_enc_0: 1.4953 (1.5082)  loss_vfl: 0.8247 (0.7935)  loss_vfl_aux_0: 0.6875 (0.7070)  loss_vfl_aux_1: 0.6932 (0.7116)  loss_vfl_aux_2: 0.7446 (0.7275)  loss_vfl_aux_3: 0.7617 (0.7448)  loss_vfl_aux_4: 0.8018 (0.7748)  loss_vfl_dn_0: 0.4205 (0.4218)  loss_vfl_dn_1: 0.4246 (0.4225)  loss_vfl_dn_2: 0.4558 (0.4376)  loss_vfl_dn_3: 0.4819 (0.4587)  loss_vfl_dn_4: 0.4944 (0.4738)  loss_vfl_dn_5: 0.5076 (0.4820)  loss_vfl_enc_0: 0.6311 (0.6599)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.2489  data: 1.3061  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0765  data: 0.2200  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0932 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.16s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.010\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.026\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.032\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.064\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.045\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.079\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.025\r\n",
      "best_stat: {'epoch': 7, 'coco_eval_bbox': 0.0004564711822133883}\r\n",
      "Epoch: [8]  [ 0/79]  eta: 0:05:53  lr: 0.000020  loss: 34.3131 (34.3131)  loss_bbox: 0.5794 (0.5794)  loss_bbox_aux_0: 0.7014 (0.7014)  loss_bbox_aux_1: 0.6793 (0.6793)  loss_bbox_aux_2: 0.6634 (0.6634)  loss_bbox_aux_3: 0.6054 (0.6054)  loss_bbox_aux_4: 0.5953 (0.5953)  loss_bbox_dn_0: 0.5343 (0.5343)  loss_bbox_dn_1: 0.5277 (0.5277)  loss_bbox_dn_2: 0.5205 (0.5205)  loss_bbox_dn_3: 0.5137 (0.5137)  loss_bbox_dn_4: 0.5076 (0.5076)  loss_bbox_dn_5: 0.5068 (0.5068)  loss_bbox_enc_0: 0.7405 (0.7405)  loss_giou: 1.4035 (1.4035)  loss_giou_aux_0: 1.5481 (1.5481)  loss_giou_aux_1: 1.5279 (1.5279)  loss_giou_aux_2: 1.4921 (1.4921)  loss_giou_aux_3: 1.4898 (1.4898)  loss_giou_aux_4: 1.4229 (1.4229)  loss_giou_dn_0: 1.3966 (1.3966)  loss_giou_dn_1: 1.3876 (1.3876)  loss_giou_dn_2: 1.3732 (1.3732)  loss_giou_dn_3: 1.3630 (1.3630)  loss_giou_dn_4: 1.3568 (1.3568)  loss_giou_dn_5: 1.3539 (1.3539)  loss_giou_enc_0: 1.5568 (1.5568)  loss_vfl: 0.8752 (0.8752)  loss_vfl_aux_0: 0.6672 (0.6672)  loss_vfl_aux_1: 0.6802 (0.6802)  loss_vfl_aux_2: 0.7258 (0.7258)  loss_vfl_aux_3: 0.7710 (0.7710)  loss_vfl_aux_4: 0.8550 (0.8550)  loss_vfl_dn_0: 0.4119 (0.4119)  loss_vfl_dn_1: 0.4316 (0.4316)  loss_vfl_dn_2: 0.4636 (0.4636)  loss_vfl_dn_3: 0.5024 (0.5024)  loss_vfl_dn_4: 0.5055 (0.5055)  loss_vfl_dn_5: 0.5011 (0.5011)  loss_vfl_enc_0: 0.5750 (0.5750)  time: 4.4748  data: 3.1929  max mem: 10356\r\n",
      "Epoch: [8]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 33.3634 (33.5486)  loss_bbox: 0.4940 (0.5862)  loss_bbox_aux_0: 0.5828 (0.6619)  loss_bbox_aux_1: 0.5540 (0.6436)  loss_bbox_aux_2: 0.5143 (0.6207)  loss_bbox_aux_3: 0.5108 (0.6054)  loss_bbox_aux_4: 0.5024 (0.5907)  loss_bbox_dn_0: 0.4793 (0.5143)  loss_bbox_dn_1: 0.4658 (0.5058)  loss_bbox_dn_2: 0.4559 (0.4959)  loss_bbox_dn_3: 0.4517 (0.4916)  loss_bbox_dn_4: 0.4526 (0.4914)  loss_bbox_dn_5: 0.4552 (0.4924)  loss_bbox_enc_0: 0.6145 (0.6888)  loss_giou: 1.3470 (1.4140)  loss_giou_aux_0: 1.4519 (1.4811)  loss_giou_aux_1: 1.4233 (1.4613)  loss_giou_aux_2: 1.3697 (1.4374)  loss_giou_aux_3: 1.3448 (1.4267)  loss_giou_aux_4: 1.3556 (1.4167)  loss_giou_dn_0: 1.3609 (1.3668)  loss_giou_dn_1: 1.3376 (1.3504)  loss_giou_dn_2: 1.3168 (1.3304)  loss_giou_dn_3: 1.3007 (1.3185)  loss_giou_dn_4: 1.2936 (1.3102)  loss_giou_dn_5: 1.2999 (1.3103)  loss_giou_enc_0: 1.5009 (1.5038)  loss_vfl: 0.8840 (0.8147)  loss_vfl_aux_0: 0.7615 (0.7139)  loss_vfl_aux_1: 0.7832 (0.7232)  loss_vfl_aux_2: 0.8311 (0.7562)  loss_vfl_aux_3: 0.8813 (0.7797)  loss_vfl_aux_4: 0.8535 (0.8015)  loss_vfl_dn_0: 0.4193 (0.4173)  loss_vfl_dn_1: 0.4268 (0.4262)  loss_vfl_dn_2: 0.4545 (0.4505)  loss_vfl_dn_3: 0.4822 (0.4775)  loss_vfl_dn_4: 0.5101 (0.4944)  loss_vfl_dn_5: 0.5088 (0.5030)  loss_vfl_enc_0: 0.6760 (0.6740)  time: 1.0155  data: 0.0341  max mem: 10356\r\n",
      "Epoch: [8] Total time: 0:01:25 (1.0860 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 33.3634 (33.5486)  loss_bbox: 0.4940 (0.5862)  loss_bbox_aux_0: 0.5828 (0.6619)  loss_bbox_aux_1: 0.5540 (0.6436)  loss_bbox_aux_2: 0.5143 (0.6207)  loss_bbox_aux_3: 0.5108 (0.6054)  loss_bbox_aux_4: 0.5024 (0.5907)  loss_bbox_dn_0: 0.4793 (0.5143)  loss_bbox_dn_1: 0.4658 (0.5058)  loss_bbox_dn_2: 0.4559 (0.4959)  loss_bbox_dn_3: 0.4517 (0.4916)  loss_bbox_dn_4: 0.4526 (0.4914)  loss_bbox_dn_5: 0.4552 (0.4924)  loss_bbox_enc_0: 0.6145 (0.6888)  loss_giou: 1.3470 (1.4140)  loss_giou_aux_0: 1.4519 (1.4811)  loss_giou_aux_1: 1.4233 (1.4613)  loss_giou_aux_2: 1.3697 (1.4374)  loss_giou_aux_3: 1.3448 (1.4267)  loss_giou_aux_4: 1.3556 (1.4167)  loss_giou_dn_0: 1.3609 (1.3668)  loss_giou_dn_1: 1.3376 (1.3504)  loss_giou_dn_2: 1.3168 (1.3304)  loss_giou_dn_3: 1.3007 (1.3185)  loss_giou_dn_4: 1.2936 (1.3102)  loss_giou_dn_5: 1.2999 (1.3103)  loss_giou_enc_0: 1.5009 (1.5038)  loss_vfl: 0.8840 (0.8147)  loss_vfl_aux_0: 0.7615 (0.7139)  loss_vfl_aux_1: 0.7832 (0.7232)  loss_vfl_aux_2: 0.8311 (0.7562)  loss_vfl_aux_3: 0.8813 (0.7797)  loss_vfl_aux_4: 0.8535 (0.8015)  loss_vfl_dn_0: 0.4193 (0.4173)  loss_vfl_dn_1: 0.4268 (0.4262)  loss_vfl_dn_2: 0.4545 (0.4505)  loss_vfl_dn_3: 0.4822 (0.4775)  loss_vfl_dn_4: 0.5101 (0.4944)  loss_vfl_dn_5: 0.5088 (0.5030)  loss_vfl_enc_0: 0.6760 (0.6740)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.1515  data: 1.2242  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0655  data: 0.2136  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0835 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.17s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.011\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.021\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.026\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.019\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.056\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.020\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.061\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.020\r\n",
      "best_stat: {'epoch': 8, 'coco_eval_bbox': 0.0011548992079778715}\r\n",
      "Epoch: [9]  [ 0/79]  eta: 0:05:21  lr: 0.000020  loss: 35.6444 (35.6444)  loss_bbox: 0.7916 (0.7916)  loss_bbox_aux_0: 0.7834 (0.7834)  loss_bbox_aux_1: 0.8170 (0.8170)  loss_bbox_aux_2: 0.7941 (0.7941)  loss_bbox_aux_3: 0.7659 (0.7659)  loss_bbox_aux_4: 0.7855 (0.7855)  loss_bbox_dn_0: 0.4547 (0.4547)  loss_bbox_dn_1: 0.4423 (0.4423)  loss_bbox_dn_2: 0.4261 (0.4261)  loss_bbox_dn_3: 0.4195 (0.4195)  loss_bbox_dn_4: 0.4169 (0.4169)  loss_bbox_dn_5: 0.4166 (0.4166)  loss_bbox_enc_0: 0.8146 (0.8146)  loss_giou: 1.7633 (1.7633)  loss_giou_aux_0: 1.8278 (1.8278)  loss_giou_aux_1: 1.8099 (1.8099)  loss_giou_aux_2: 1.8041 (1.8041)  loss_giou_aux_3: 1.8093 (1.8093)  loss_giou_aux_4: 1.7821 (1.7821)  loss_giou_dn_0: 1.3762 (1.3762)  loss_giou_dn_1: 1.3883 (1.3883)  loss_giou_dn_2: 1.3653 (1.3653)  loss_giou_dn_3: 1.3474 (1.3474)  loss_giou_dn_4: 1.3362 (1.3362)  loss_giou_dn_5: 1.3328 (1.3328)  loss_giou_enc_0: 1.8403 (1.8403)  loss_vfl: 0.6794 (0.6794)  loss_vfl_aux_0: 0.5286 (0.5286)  loss_vfl_aux_1: 0.5503 (0.5503)  loss_vfl_aux_2: 0.5964 (0.5964)  loss_vfl_aux_3: 0.6379 (0.6379)  loss_vfl_aux_4: 0.6282 (0.6282)  loss_vfl_dn_0: 0.4077 (0.4077)  loss_vfl_dn_1: 0.4028 (0.4028)  loss_vfl_dn_2: 0.4259 (0.4259)  loss_vfl_dn_3: 0.4517 (0.4517)  loss_vfl_dn_4: 0.4594 (0.4594)  loss_vfl_dn_5: 0.4851 (0.4851)  loss_vfl_enc_0: 0.4796 (0.4796)  time: 4.0654  data: 2.5943  max mem: 10356\r\n",
      "Epoch: [9]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 32.6301 (33.1755)  loss_bbox: 0.4894 (0.5408)  loss_bbox_aux_0: 0.5135 (0.6063)  loss_bbox_aux_1: 0.5037 (0.5878)  loss_bbox_aux_2: 0.5113 (0.5625)  loss_bbox_aux_3: 0.4991 (0.5512)  loss_bbox_aux_4: 0.4955 (0.5441)  loss_bbox_dn_0: 0.4966 (0.5069)  loss_bbox_dn_1: 0.4792 (0.4948)  loss_bbox_dn_2: 0.4658 (0.4826)  loss_bbox_dn_3: 0.4649 (0.4799)  loss_bbox_dn_4: 0.4766 (0.4799)  loss_bbox_dn_5: 0.4815 (0.4805)  loss_bbox_enc_0: 0.5566 (0.6374)  loss_giou: 1.4010 (1.3885)  loss_giou_aux_0: 1.4419 (1.4572)  loss_giou_aux_1: 1.4468 (1.4320)  loss_giou_aux_2: 1.4183 (1.4053)  loss_giou_aux_3: 1.4242 (1.4001)  loss_giou_aux_4: 1.4179 (1.3937)  loss_giou_dn_0: 1.3496 (1.3590)  loss_giou_dn_1: 1.3158 (1.3269)  loss_giou_dn_2: 1.2748 (1.3001)  loss_giou_dn_3: 1.2576 (1.2883)  loss_giou_dn_4: 1.2604 (1.2821)  loss_giou_dn_5: 1.2590 (1.2819)  loss_giou_enc_0: 1.4521 (1.4866)  loss_vfl: 0.8254 (0.8594)  loss_vfl_aux_0: 0.7959 (0.7433)  loss_vfl_aux_1: 0.7876 (0.7765)  loss_vfl_aux_2: 0.8154 (0.8156)  loss_vfl_aux_3: 0.8169 (0.8379)  loss_vfl_aux_4: 0.8269 (0.8448)  loss_vfl_dn_0: 0.4207 (0.4166)  loss_vfl_dn_1: 0.4414 (0.4352)  loss_vfl_dn_2: 0.4652 (0.4665)  loss_vfl_dn_3: 0.4977 (0.4920)  loss_vfl_dn_4: 0.5177 (0.5085)  loss_vfl_dn_5: 0.5228 (0.5193)  loss_vfl_enc_0: 0.7563 (0.7035)  time: 1.0400  data: 0.0308  max mem: 10356\r\n",
      "Epoch: [9] Total time: 0:01:25 (1.0774 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 32.6301 (33.1755)  loss_bbox: 0.4894 (0.5408)  loss_bbox_aux_0: 0.5135 (0.6063)  loss_bbox_aux_1: 0.5037 (0.5878)  loss_bbox_aux_2: 0.5113 (0.5625)  loss_bbox_aux_3: 0.4991 (0.5512)  loss_bbox_aux_4: 0.4955 (0.5441)  loss_bbox_dn_0: 0.4966 (0.5069)  loss_bbox_dn_1: 0.4792 (0.4948)  loss_bbox_dn_2: 0.4658 (0.4826)  loss_bbox_dn_3: 0.4649 (0.4799)  loss_bbox_dn_4: 0.4766 (0.4799)  loss_bbox_dn_5: 0.4815 (0.4805)  loss_bbox_enc_0: 0.5566 (0.6374)  loss_giou: 1.4010 (1.3885)  loss_giou_aux_0: 1.4419 (1.4572)  loss_giou_aux_1: 1.4468 (1.4320)  loss_giou_aux_2: 1.4183 (1.4053)  loss_giou_aux_3: 1.4242 (1.4001)  loss_giou_aux_4: 1.4179 (1.3937)  loss_giou_dn_0: 1.3496 (1.3590)  loss_giou_dn_1: 1.3158 (1.3269)  loss_giou_dn_2: 1.2748 (1.3001)  loss_giou_dn_3: 1.2576 (1.2883)  loss_giou_dn_4: 1.2604 (1.2821)  loss_giou_dn_5: 1.2590 (1.2819)  loss_giou_enc_0: 1.4521 (1.4866)  loss_vfl: 0.8254 (0.8594)  loss_vfl_aux_0: 0.7959 (0.7433)  loss_vfl_aux_1: 0.7876 (0.7765)  loss_vfl_aux_2: 0.8154 (0.8156)  loss_vfl_aux_3: 0.8169 (0.8379)  loss_vfl_aux_4: 0.8269 (0.8448)  loss_vfl_dn_0: 0.4207 (0.4166)  loss_vfl_dn_1: 0.4414 (0.4352)  loss_vfl_dn_2: 0.4652 (0.4665)  loss_vfl_dn_3: 0.4977 (0.4920)  loss_vfl_dn_4: 0.5177 (0.5085)  loss_vfl_dn_5: 0.5228 (0.5193)  loss_vfl_enc_0: 0.7563 (0.7035)\r\n",
      "Test:  [0/8]  eta: 0:00:16    time: 2.0787  data: 1.0887  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0547  data: 0.1969  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0718 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.016\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.037\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.043\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.020\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.087\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.056\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.104\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.025\r\n",
      "best_stat: {'epoch': 8, 'coco_eval_bbox': 0.0011548992079778715}\r\n",
      "Epoch: [10]  [ 0/79]  eta: 0:06:40  lr: 0.000020  loss: 30.4759 (30.4759)  loss_bbox: 0.4006 (0.4006)  loss_bbox_aux_0: 0.4380 (0.4380)  loss_bbox_aux_1: 0.4040 (0.4040)  loss_bbox_aux_2: 0.3742 (0.3742)  loss_bbox_aux_3: 0.3740 (0.3740)  loss_bbox_aux_4: 0.3904 (0.3904)  loss_bbox_dn_0: 0.3113 (0.3113)  loss_bbox_dn_1: 0.2943 (0.2943)  loss_bbox_dn_2: 0.2774 (0.2774)  loss_bbox_dn_3: 0.2772 (0.2772)  loss_bbox_dn_4: 0.2775 (0.2775)  loss_bbox_dn_5: 0.2790 (0.2790)  loss_bbox_enc_0: 0.4465 (0.4465)  loss_giou: 1.3168 (1.3168)  loss_giou_aux_0: 1.4174 (1.4174)  loss_giou_aux_1: 1.3664 (1.3664)  loss_giou_aux_2: 1.3457 (1.3457)  loss_giou_aux_3: 1.3515 (1.3515)  loss_giou_aux_4: 1.3081 (1.3081)  loss_giou_dn_0: 1.3529 (1.3529)  loss_giou_dn_1: 1.2970 (1.2970)  loss_giou_dn_2: 1.2496 (1.2496)  loss_giou_dn_3: 1.2277 (1.2277)  loss_giou_dn_4: 1.2157 (1.2157)  loss_giou_dn_5: 1.2127 (1.2127)  loss_giou_enc_0: 1.4595 (1.4595)  loss_vfl: 0.9304 (0.9304)  loss_vfl_aux_0: 0.7302 (0.7302)  loss_vfl_aux_1: 0.8323 (0.8323)  loss_vfl_aux_2: 0.8723 (0.8723)  loss_vfl_aux_3: 0.9109 (0.9109)  loss_vfl_aux_4: 0.9280 (0.9280)  loss_vfl_dn_0: 0.4098 (0.4098)  loss_vfl_dn_1: 0.4536 (0.4536)  loss_vfl_dn_2: 0.4850 (0.4850)  loss_vfl_dn_3: 0.5155 (0.5155)  loss_vfl_dn_4: 0.5514 (0.5514)  loss_vfl_dn_5: 0.5533 (0.5533)  loss_vfl_enc_0: 0.6379 (0.6379)  time: 5.0645  data: 2.9846  max mem: 10356\r\n",
      "Epoch: [10]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 32.7755 (33.0313)  loss_bbox: 0.5513 (0.5383)  loss_bbox_aux_0: 0.6256 (0.6008)  loss_bbox_aux_1: 0.5792 (0.5808)  loss_bbox_aux_2: 0.5725 (0.5557)  loss_bbox_aux_3: 0.5505 (0.5500)  loss_bbox_aux_4: 0.5588 (0.5426)  loss_bbox_dn_0: 0.4831 (0.5118)  loss_bbox_dn_1: 0.4668 (0.4951)  loss_bbox_dn_2: 0.4584 (0.4845)  loss_bbox_dn_3: 0.4560 (0.4833)  loss_bbox_dn_4: 0.4547 (0.4829)  loss_bbox_dn_5: 0.4541 (0.4834)  loss_bbox_enc_0: 0.6475 (0.6370)  loss_giou: 1.3660 (1.3455)  loss_giou_aux_0: 1.4035 (1.4306)  loss_giou_aux_1: 1.3770 (1.3846)  loss_giou_aux_2: 1.3349 (1.3637)  loss_giou_aux_3: 1.3665 (1.3573)  loss_giou_aux_4: 1.3544 (1.3490)  loss_giou_dn_0: 1.3330 (1.3472)  loss_giou_dn_1: 1.2900 (1.3049)  loss_giou_dn_2: 1.2566 (1.2819)  loss_giou_dn_3: 1.2439 (1.2735)  loss_giou_dn_4: 1.2344 (1.2689)  loss_giou_dn_5: 1.2311 (1.2691)  loss_giou_enc_0: 1.4026 (1.4706)  loss_vfl: 0.9053 (0.8929)  loss_vfl_aux_0: 0.7605 (0.7592)  loss_vfl_aux_1: 0.8223 (0.8120)  loss_vfl_aux_2: 0.8547 (0.8440)  loss_vfl_aux_3: 0.8569 (0.8610)  loss_vfl_aux_4: 0.8772 (0.8757)  loss_vfl_dn_0: 0.4349 (0.4209)  loss_vfl_dn_1: 0.4585 (0.4486)  loss_vfl_dn_2: 0.4690 (0.4766)  loss_vfl_dn_3: 0.5026 (0.5011)  loss_vfl_dn_4: 0.5239 (0.5187)  loss_vfl_dn_5: 0.5398 (0.5315)  loss_vfl_enc_0: 0.6943 (0.6961)  time: 0.9575  data: 0.0332  max mem: 10356\r\n",
      "Epoch: [10] Total time: 0:01:25 (1.0760 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 32.7755 (33.0313)  loss_bbox: 0.5513 (0.5383)  loss_bbox_aux_0: 0.6256 (0.6008)  loss_bbox_aux_1: 0.5792 (0.5808)  loss_bbox_aux_2: 0.5725 (0.5557)  loss_bbox_aux_3: 0.5505 (0.5500)  loss_bbox_aux_4: 0.5588 (0.5426)  loss_bbox_dn_0: 0.4831 (0.5118)  loss_bbox_dn_1: 0.4668 (0.4951)  loss_bbox_dn_2: 0.4584 (0.4845)  loss_bbox_dn_3: 0.4560 (0.4833)  loss_bbox_dn_4: 0.4547 (0.4829)  loss_bbox_dn_5: 0.4541 (0.4834)  loss_bbox_enc_0: 0.6475 (0.6370)  loss_giou: 1.3660 (1.3455)  loss_giou_aux_0: 1.4035 (1.4306)  loss_giou_aux_1: 1.3770 (1.3846)  loss_giou_aux_2: 1.3349 (1.3637)  loss_giou_aux_3: 1.3665 (1.3573)  loss_giou_aux_4: 1.3544 (1.3490)  loss_giou_dn_0: 1.3330 (1.3472)  loss_giou_dn_1: 1.2900 (1.3049)  loss_giou_dn_2: 1.2566 (1.2819)  loss_giou_dn_3: 1.2439 (1.2735)  loss_giou_dn_4: 1.2344 (1.2689)  loss_giou_dn_5: 1.2311 (1.2691)  loss_giou_enc_0: 1.4026 (1.4706)  loss_vfl: 0.9053 (0.8929)  loss_vfl_aux_0: 0.7605 (0.7592)  loss_vfl_aux_1: 0.8223 (0.8120)  loss_vfl_aux_2: 0.8547 (0.8440)  loss_vfl_aux_3: 0.8569 (0.8610)  loss_vfl_aux_4: 0.8772 (0.8757)  loss_vfl_dn_0: 0.4349 (0.4209)  loss_vfl_dn_1: 0.4585 (0.4486)  loss_vfl_dn_2: 0.4690 (0.4766)  loss_vfl_dn_3: 0.5026 (0.5011)  loss_vfl_dn_4: 0.5239 (0.5187)  loss_vfl_dn_5: 0.5398 (0.5315)  loss_vfl_enc_0: 0.6943 (0.6961)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3548  data: 1.3549  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0808  data: 0.2166  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0967 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.004\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.030\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.053\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.060\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.120\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.081\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.138\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.045\r\n",
      "best_stat: {'epoch': 10, 'coco_eval_bbox': 0.001820162097970564}\r\n",
      "Epoch: [11]  [ 0/79]  eta: 0:05:19  lr: 0.000020  loss: 33.7283 (33.7283)  loss_bbox: 0.6689 (0.6689)  loss_bbox_aux_0: 0.7200 (0.7200)  loss_bbox_aux_1: 0.6512 (0.6512)  loss_bbox_aux_2: 0.7065 (0.7065)  loss_bbox_aux_3: 0.6928 (0.6928)  loss_bbox_aux_4: 0.6378 (0.6378)  loss_bbox_dn_0: 0.4995 (0.4995)  loss_bbox_dn_1: 0.4852 (0.4852)  loss_bbox_dn_2: 0.4781 (0.4781)  loss_bbox_dn_3: 0.4765 (0.4765)  loss_bbox_dn_4: 0.4749 (0.4749)  loss_bbox_dn_5: 0.4752 (0.4752)  loss_bbox_enc_0: 0.7426 (0.7426)  loss_giou: 1.6200 (1.6200)  loss_giou_aux_0: 1.6459 (1.6459)  loss_giou_aux_1: 1.6658 (1.6658)  loss_giou_aux_2: 1.6111 (1.6111)  loss_giou_aux_3: 1.6263 (1.6263)  loss_giou_aux_4: 1.6505 (1.6505)  loss_giou_dn_0: 1.3422 (1.3422)  loss_giou_dn_1: 1.3345 (1.3345)  loss_giou_dn_2: 1.3400 (1.3400)  loss_giou_dn_3: 1.3414 (1.3414)  loss_giou_dn_4: 1.3463 (1.3463)  loss_giou_dn_5: 1.3476 (1.3476)  loss_giou_enc_0: 1.6334 (1.6334)  loss_vfl: 0.6360 (0.6360)  loss_vfl_aux_0: 0.5226 (0.5226)  loss_vfl_aux_1: 0.5621 (0.5621)  loss_vfl_aux_2: 0.5786 (0.5786)  loss_vfl_aux_3: 0.6130 (0.6130)  loss_vfl_aux_4: 0.6267 (0.6267)  loss_vfl_dn_0: 0.4000 (0.4000)  loss_vfl_dn_1: 0.3929 (0.3929)  loss_vfl_dn_2: 0.4008 (0.4008)  loss_vfl_dn_3: 0.4021 (0.4021)  loss_vfl_dn_4: 0.4135 (0.4135)  loss_vfl_dn_5: 0.4310 (0.4310)  loss_vfl_enc_0: 0.5347 (0.5347)  time: 4.0483  data: 2.9374  max mem: 10356\r\n",
      "Epoch: [11]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 32.1291 (32.6648)  loss_bbox: 0.4452 (0.5025)  loss_bbox_aux_0: 0.4960 (0.5640)  loss_bbox_aux_1: 0.4915 (0.5289)  loss_bbox_aux_2: 0.4553 (0.5158)  loss_bbox_aux_3: 0.4465 (0.5100)  loss_bbox_aux_4: 0.4285 (0.5015)  loss_bbox_dn_0: 0.4456 (0.4985)  loss_bbox_dn_1: 0.4270 (0.4777)  loss_bbox_dn_2: 0.4273 (0.4692)  loss_bbox_dn_3: 0.4348 (0.4678)  loss_bbox_dn_4: 0.4406 (0.4670)  loss_bbox_dn_5: 0.4436 (0.4672)  loss_bbox_enc_0: 0.5330 (0.6000)  loss_giou: 1.3329 (1.3228)  loss_giou_aux_0: 1.3809 (1.4002)  loss_giou_aux_1: 1.3297 (1.3543)  loss_giou_aux_2: 1.3438 (1.3409)  loss_giou_aux_3: 1.3183 (1.3330)  loss_giou_aux_4: 1.3179 (1.3278)  loss_giou_dn_0: 1.3235 (1.3308)  loss_giou_dn_1: 1.2695 (1.2790)  loss_giou_dn_2: 1.2492 (1.2598)  loss_giou_dn_3: 1.2369 (1.2496)  loss_giou_dn_4: 1.2334 (1.2441)  loss_giou_dn_5: 1.2335 (1.2440)  loss_giou_enc_0: 1.4260 (1.4531)  loss_vfl: 0.8967 (0.9294)  loss_vfl_aux_0: 0.7742 (0.7913)  loss_vfl_aux_1: 0.8467 (0.8598)  loss_vfl_aux_2: 0.8674 (0.8803)  loss_vfl_aux_3: 0.8999 (0.9023)  loss_vfl_aux_4: 0.9094 (0.9124)  loss_vfl_dn_0: 0.4214 (0.4270)  loss_vfl_dn_1: 0.4530 (0.4594)  loss_vfl_dn_2: 0.4854 (0.4840)  loss_vfl_dn_3: 0.5103 (0.5098)  loss_vfl_dn_4: 0.5311 (0.5304)  loss_vfl_dn_5: 0.5458 (0.5430)  loss_vfl_enc_0: 0.7122 (0.7262)  time: 1.0310  data: 0.0322  max mem: 10356\r\n",
      "Epoch: [11] Total time: 0:01:26 (1.0890 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 32.1291 (32.6648)  loss_bbox: 0.4452 (0.5025)  loss_bbox_aux_0: 0.4960 (0.5640)  loss_bbox_aux_1: 0.4915 (0.5289)  loss_bbox_aux_2: 0.4553 (0.5158)  loss_bbox_aux_3: 0.4465 (0.5100)  loss_bbox_aux_4: 0.4285 (0.5015)  loss_bbox_dn_0: 0.4456 (0.4985)  loss_bbox_dn_1: 0.4270 (0.4777)  loss_bbox_dn_2: 0.4273 (0.4692)  loss_bbox_dn_3: 0.4348 (0.4678)  loss_bbox_dn_4: 0.4406 (0.4670)  loss_bbox_dn_5: 0.4436 (0.4672)  loss_bbox_enc_0: 0.5330 (0.6000)  loss_giou: 1.3329 (1.3228)  loss_giou_aux_0: 1.3809 (1.4002)  loss_giou_aux_1: 1.3297 (1.3543)  loss_giou_aux_2: 1.3438 (1.3409)  loss_giou_aux_3: 1.3183 (1.3330)  loss_giou_aux_4: 1.3179 (1.3278)  loss_giou_dn_0: 1.3235 (1.3308)  loss_giou_dn_1: 1.2695 (1.2790)  loss_giou_dn_2: 1.2492 (1.2598)  loss_giou_dn_3: 1.2369 (1.2496)  loss_giou_dn_4: 1.2334 (1.2441)  loss_giou_dn_5: 1.2335 (1.2440)  loss_giou_enc_0: 1.4260 (1.4531)  loss_vfl: 0.8967 (0.9294)  loss_vfl_aux_0: 0.7742 (0.7913)  loss_vfl_aux_1: 0.8467 (0.8598)  loss_vfl_aux_2: 0.8674 (0.8803)  loss_vfl_aux_3: 0.8999 (0.9023)  loss_vfl_aux_4: 0.9094 (0.9124)  loss_vfl_dn_0: 0.4214 (0.4270)  loss_vfl_dn_1: 0.4530 (0.4594)  loss_vfl_dn_2: 0.4854 (0.4840)  loss_vfl_dn_3: 0.5103 (0.5098)  loss_vfl_dn_4: 0.5311 (0.5304)  loss_vfl_dn_5: 0.5458 (0.5430)  loss_vfl_enc_0: 0.7122 (0.7262)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3012  data: 1.2861  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0965  data: 0.2243  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1148 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.011\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.007\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.028\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.067\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.075\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.131\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.111\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.153\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.069\r\n",
      "best_stat: {'epoch': 11, 'coco_eval_bbox': 0.0032288936115117983}\r\n",
      "Epoch: [12]  [ 0/79]  eta: 0:05:18  lr: 0.000020  loss: 35.3339 (35.3339)  loss_bbox: 0.6108 (0.6108)  loss_bbox_aux_0: 0.6327 (0.6327)  loss_bbox_aux_1: 0.5948 (0.5948)  loss_bbox_aux_2: 0.5936 (0.5936)  loss_bbox_aux_3: 0.5912 (0.5912)  loss_bbox_aux_4: 0.5881 (0.5881)  loss_bbox_dn_0: 0.6307 (0.6307)  loss_bbox_dn_1: 0.6099 (0.6099)  loss_bbox_dn_2: 0.6040 (0.6040)  loss_bbox_dn_3: 0.6005 (0.6005)  loss_bbox_dn_4: 0.5950 (0.5950)  loss_bbox_dn_5: 0.5936 (0.5936)  loss_bbox_enc_0: 0.7170 (0.7170)  loss_giou: 1.1339 (1.1339)  loss_giou_aux_0: 1.2689 (1.2689)  loss_giou_aux_1: 1.2105 (1.2105)  loss_giou_aux_2: 1.1866 (1.1866)  loss_giou_aux_3: 1.1729 (1.1729)  loss_giou_aux_4: 1.2198 (1.2198)  loss_giou_dn_0: 1.3274 (1.3274)  loss_giou_dn_1: 1.2551 (1.2551)  loss_giou_dn_2: 1.2210 (1.2210)  loss_giou_dn_3: 1.1990 (1.1990)  loss_giou_dn_4: 1.1865 (1.1865)  loss_giou_dn_5: 1.1838 (1.1838)  loss_giou_enc_0: 1.3121 (1.3121)  loss_vfl: 1.3252 (1.3252)  loss_vfl_aux_0: 1.1096 (1.1096)  loss_vfl_aux_1: 1.2134 (1.2134)  loss_vfl_aux_2: 1.2231 (1.2231)  loss_vfl_aux_3: 1.2876 (1.2876)  loss_vfl_aux_4: 1.2168 (1.2168)  loss_vfl_dn_0: 0.4229 (0.4229)  loss_vfl_dn_1: 0.4761 (0.4761)  loss_vfl_dn_2: 0.5266 (0.5266)  loss_vfl_dn_3: 0.5752 (0.5752)  loss_vfl_dn_4: 0.5823 (0.5823)  loss_vfl_dn_5: 0.5981 (0.5981)  loss_vfl_enc_0: 0.9375 (0.9375)  time: 4.0272  data: 2.8171  max mem: 10356\r\n",
      "Epoch: [12]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 32.1322 (32.3058)  loss_bbox: 0.4645 (0.4669)  loss_bbox_aux_0: 0.5284 (0.5221)  loss_bbox_aux_1: 0.4995 (0.4939)  loss_bbox_aux_2: 0.4883 (0.4797)  loss_bbox_aux_3: 0.4847 (0.4739)  loss_bbox_aux_4: 0.4511 (0.4699)  loss_bbox_dn_0: 0.4418 (0.4839)  loss_bbox_dn_1: 0.4219 (0.4628)  loss_bbox_dn_2: 0.4241 (0.4554)  loss_bbox_dn_3: 0.4265 (0.4531)  loss_bbox_dn_4: 0.4287 (0.4514)  loss_bbox_dn_5: 0.4293 (0.4513)  loss_bbox_enc_0: 0.5894 (0.5752)  loss_giou: 1.1388 (1.2912)  loss_giou_aux_0: 1.2316 (1.3575)  loss_giou_aux_1: 1.1768 (1.3141)  loss_giou_aux_2: 1.1777 (1.3071)  loss_giou_aux_3: 1.1680 (1.3036)  loss_giou_aux_4: 1.1531 (1.2938)  loss_giou_dn_0: 1.2969 (1.3134)  loss_giou_dn_1: 1.2353 (1.2583)  loss_giou_dn_2: 1.2093 (1.2402)  loss_giou_dn_3: 1.1932 (1.2284)  loss_giou_dn_4: 1.1829 (1.2208)  loss_giou_dn_5: 1.1817 (1.2202)  loss_giou_enc_0: 1.3138 (1.4271)  loss_vfl: 1.0613 (0.9621)  loss_vfl_aux_0: 0.9561 (0.8525)  loss_vfl_aux_1: 0.9658 (0.9054)  loss_vfl_aux_2: 0.9990 (0.9152)  loss_vfl_aux_3: 1.0356 (0.9298)  loss_vfl_aux_4: 1.0178 (0.9468)  loss_vfl_dn_0: 0.4276 (0.4310)  loss_vfl_dn_1: 0.4690 (0.4679)  loss_vfl_dn_2: 0.4974 (0.4942)  loss_vfl_dn_3: 0.5387 (0.5223)  loss_vfl_dn_4: 0.5608 (0.5478)  loss_vfl_dn_5: 0.5740 (0.5608)  loss_vfl_enc_0: 0.7991 (0.7546)  time: 1.0297  data: 0.0327  max mem: 10356\r\n",
      "Epoch: [12] Total time: 0:01:25 (1.0833 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 32.1322 (32.3058)  loss_bbox: 0.4645 (0.4669)  loss_bbox_aux_0: 0.5284 (0.5221)  loss_bbox_aux_1: 0.4995 (0.4939)  loss_bbox_aux_2: 0.4883 (0.4797)  loss_bbox_aux_3: 0.4847 (0.4739)  loss_bbox_aux_4: 0.4511 (0.4699)  loss_bbox_dn_0: 0.4418 (0.4839)  loss_bbox_dn_1: 0.4219 (0.4628)  loss_bbox_dn_2: 0.4241 (0.4554)  loss_bbox_dn_3: 0.4265 (0.4531)  loss_bbox_dn_4: 0.4287 (0.4514)  loss_bbox_dn_5: 0.4293 (0.4513)  loss_bbox_enc_0: 0.5894 (0.5752)  loss_giou: 1.1388 (1.2912)  loss_giou_aux_0: 1.2316 (1.3575)  loss_giou_aux_1: 1.1768 (1.3141)  loss_giou_aux_2: 1.1777 (1.3071)  loss_giou_aux_3: 1.1680 (1.3036)  loss_giou_aux_4: 1.1531 (1.2938)  loss_giou_dn_0: 1.2969 (1.3134)  loss_giou_dn_1: 1.2353 (1.2583)  loss_giou_dn_2: 1.2093 (1.2402)  loss_giou_dn_3: 1.1932 (1.2284)  loss_giou_dn_4: 1.1829 (1.2208)  loss_giou_dn_5: 1.1817 (1.2202)  loss_giou_enc_0: 1.3138 (1.4271)  loss_vfl: 1.0613 (0.9621)  loss_vfl_aux_0: 0.9561 (0.8525)  loss_vfl_aux_1: 0.9658 (0.9054)  loss_vfl_aux_2: 0.9990 (0.9152)  loss_vfl_aux_3: 1.0356 (0.9298)  loss_vfl_aux_4: 1.0178 (0.9468)  loss_vfl_dn_0: 0.4276 (0.4310)  loss_vfl_dn_1: 0.4690 (0.4679)  loss_vfl_dn_2: 0.4974 (0.4942)  loss_vfl_dn_3: 0.5387 (0.5223)  loss_vfl_dn_4: 0.5608 (0.5478)  loss_vfl_dn_5: 0.5740 (0.5608)  loss_vfl_enc_0: 0.7991 (0.7546)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.2341  data: 1.3135  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0629  data: 0.2162  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0807 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.010\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.006\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.012\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.005\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.036\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.065\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.074\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.032\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.147\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.080\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.152\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.070\r\n",
      "best_stat: {'epoch': 12, 'coco_eval_bbox': 0.005033527323812633}\r\n",
      "Epoch: [13]  [ 0/79]  eta: 0:05:18  lr: 0.000020  loss: 30.2167 (30.2167)  loss_bbox: 0.3449 (0.3449)  loss_bbox_aux_0: 0.3686 (0.3686)  loss_bbox_aux_1: 0.3860 (0.3860)  loss_bbox_aux_2: 0.3364 (0.3364)  loss_bbox_aux_3: 0.3584 (0.3584)  loss_bbox_aux_4: 0.3431 (0.3431)  loss_bbox_dn_0: 0.3777 (0.3777)  loss_bbox_dn_1: 0.3559 (0.3559)  loss_bbox_dn_2: 0.3500 (0.3500)  loss_bbox_dn_3: 0.3462 (0.3462)  loss_bbox_dn_4: 0.3474 (0.3474)  loss_bbox_dn_5: 0.3483 (0.3483)  loss_bbox_enc_0: 0.4455 (0.4455)  loss_giou: 1.2436 (1.2436)  loss_giou_aux_0: 1.2894 (1.2894)  loss_giou_aux_1: 1.2725 (1.2725)  loss_giou_aux_2: 1.2495 (1.2495)  loss_giou_aux_3: 1.2335 (1.2335)  loss_giou_aux_4: 1.2211 (1.2211)  loss_giou_dn_0: 1.3182 (1.3182)  loss_giou_dn_1: 1.2628 (1.2628)  loss_giou_dn_2: 1.2401 (1.2401)  loss_giou_dn_3: 1.2228 (1.2228)  loss_giou_dn_4: 1.2215 (1.2215)  loss_giou_dn_5: 1.2240 (1.2240)  loss_giou_enc_0: 1.4047 (1.4047)  loss_vfl: 0.9495 (0.9495)  loss_vfl_aux_0: 0.8369 (0.8369)  loss_vfl_aux_1: 0.8599 (0.8599)  loss_vfl_aux_2: 0.9580 (0.9580)  loss_vfl_aux_3: 0.9648 (0.9648)  loss_vfl_aux_4: 0.9443 (0.9443)  loss_vfl_dn_0: 0.4021 (0.4021)  loss_vfl_dn_1: 0.4508 (0.4508)  loss_vfl_dn_2: 0.4818 (0.4818)  loss_vfl_dn_3: 0.5137 (0.5137)  loss_vfl_dn_4: 0.5140 (0.5140)  loss_vfl_dn_5: 0.5200 (0.5200)  loss_vfl_enc_0: 0.7087 (0.7087)  time: 4.0296  data: 2.7602  max mem: 10356\r\n",
      "Epoch: [13]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 32.4558 (32.2747)  loss_bbox: 0.4697 (0.4659)  loss_bbox_aux_0: 0.5215 (0.5052)  loss_bbox_aux_1: 0.5044 (0.4893)  loss_bbox_aux_2: 0.4774 (0.4772)  loss_bbox_aux_3: 0.5106 (0.4719)  loss_bbox_aux_4: 0.4942 (0.4666)  loss_bbox_dn_0: 0.5124 (0.4855)  loss_bbox_dn_1: 0.4941 (0.4669)  loss_bbox_dn_2: 0.4835 (0.4615)  loss_bbox_dn_3: 0.4856 (0.4602)  loss_bbox_dn_4: 0.4864 (0.4599)  loss_bbox_dn_5: 0.4881 (0.4601)  loss_bbox_enc_0: 0.5618 (0.5612)  loss_giou: 1.2354 (1.2715)  loss_giou_aux_0: 1.3221 (1.3272)  loss_giou_aux_1: 1.2602 (1.2956)  loss_giou_aux_2: 1.2604 (1.2840)  loss_giou_aux_3: 1.2371 (1.2819)  loss_giou_aux_4: 1.2227 (1.2745)  loss_giou_dn_0: 1.2761 (1.2972)  loss_giou_dn_1: 1.2224 (1.2436)  loss_giou_dn_2: 1.2077 (1.2261)  loss_giou_dn_3: 1.1970 (1.2123)  loss_giou_dn_4: 1.1925 (1.2048)  loss_giou_dn_5: 1.1928 (1.2050)  loss_giou_enc_0: 1.4307 (1.4227)  loss_vfl: 1.0015 (0.9864)  loss_vfl_aux_0: 0.9019 (0.8835)  loss_vfl_aux_1: 0.9351 (0.9227)  loss_vfl_aux_2: 0.9746 (0.9409)  loss_vfl_aux_3: 0.9873 (0.9591)  loss_vfl_aux_4: 0.9871 (0.9758)  loss_vfl_dn_0: 0.4432 (0.4382)  loss_vfl_dn_1: 0.4762 (0.4738)  loss_vfl_dn_2: 0.4995 (0.5007)  loss_vfl_dn_3: 0.5281 (0.5330)  loss_vfl_dn_4: 0.5513 (0.5558)  loss_vfl_dn_5: 0.5571 (0.5673)  loss_vfl_enc_0: 0.7385 (0.7598)  time: 1.0234  data: 0.0312  max mem: 10356\r\n",
      "Epoch: [13] Total time: 0:01:24 (1.0676 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 32.4558 (32.2747)  loss_bbox: 0.4697 (0.4659)  loss_bbox_aux_0: 0.5215 (0.5052)  loss_bbox_aux_1: 0.5044 (0.4893)  loss_bbox_aux_2: 0.4774 (0.4772)  loss_bbox_aux_3: 0.5106 (0.4719)  loss_bbox_aux_4: 0.4942 (0.4666)  loss_bbox_dn_0: 0.5124 (0.4855)  loss_bbox_dn_1: 0.4941 (0.4669)  loss_bbox_dn_2: 0.4835 (0.4615)  loss_bbox_dn_3: 0.4856 (0.4602)  loss_bbox_dn_4: 0.4864 (0.4599)  loss_bbox_dn_5: 0.4881 (0.4601)  loss_bbox_enc_0: 0.5618 (0.5612)  loss_giou: 1.2354 (1.2715)  loss_giou_aux_0: 1.3221 (1.3272)  loss_giou_aux_1: 1.2602 (1.2956)  loss_giou_aux_2: 1.2604 (1.2840)  loss_giou_aux_3: 1.2371 (1.2819)  loss_giou_aux_4: 1.2227 (1.2745)  loss_giou_dn_0: 1.2761 (1.2972)  loss_giou_dn_1: 1.2224 (1.2436)  loss_giou_dn_2: 1.2077 (1.2261)  loss_giou_dn_3: 1.1970 (1.2123)  loss_giou_dn_4: 1.1925 (1.2048)  loss_giou_dn_5: 1.1928 (1.2050)  loss_giou_enc_0: 1.4307 (1.4227)  loss_vfl: 1.0015 (0.9864)  loss_vfl_aux_0: 0.9019 (0.8835)  loss_vfl_aux_1: 0.9351 (0.9227)  loss_vfl_aux_2: 0.9746 (0.9409)  loss_vfl_aux_3: 0.9873 (0.9591)  loss_vfl_aux_4: 0.9871 (0.9758)  loss_vfl_dn_0: 0.4432 (0.4382)  loss_vfl_dn_1: 0.4762 (0.4738)  loss_vfl_dn_2: 0.4995 (0.5007)  loss_vfl_dn_3: 0.5281 (0.5330)  loss_vfl_dn_4: 0.5513 (0.5558)  loss_vfl_dn_5: 0.5571 (0.5673)  loss_vfl_enc_0: 0.7385 (0.7598)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.4333  data: 1.5319  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0784  data: 0.2315  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0957 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.004\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.010\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.007\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.079\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.087\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.035\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.171\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.100\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.163\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.088\r\n",
      "best_stat: {'epoch': 12, 'coco_eval_bbox': 0.005033527323812633}\r\n",
      "Epoch: [14]  [ 0/79]  eta: 0:06:50  lr: 0.000020  loss: 30.4800 (30.4800)  loss_bbox: 0.4118 (0.4118)  loss_bbox_aux_0: 0.4398 (0.4398)  loss_bbox_aux_1: 0.4335 (0.4335)  loss_bbox_aux_2: 0.4118 (0.4118)  loss_bbox_aux_3: 0.4008 (0.4008)  loss_bbox_aux_4: 0.4113 (0.4113)  loss_bbox_dn_0: 0.3771 (0.3771)  loss_bbox_dn_1: 0.3674 (0.3674)  loss_bbox_dn_2: 0.3628 (0.3628)  loss_bbox_dn_3: 0.3631 (0.3631)  loss_bbox_dn_4: 0.3645 (0.3645)  loss_bbox_dn_5: 0.3646 (0.3646)  loss_bbox_enc_0: 0.5307 (0.5307)  loss_giou: 1.4024 (1.4024)  loss_giou_aux_0: 1.4014 (1.4014)  loss_giou_aux_1: 1.4393 (1.4393)  loss_giou_aux_2: 1.4323 (1.4323)  loss_giou_aux_3: 1.4368 (1.4368)  loss_giou_aux_4: 1.4137 (1.4137)  loss_giou_dn_0: 1.2878 (1.2878)  loss_giou_dn_1: 1.2437 (1.2437)  loss_giou_dn_2: 1.2312 (1.2312)  loss_giou_dn_3: 1.2217 (1.2217)  loss_giou_dn_4: 1.2160 (1.2160)  loss_giou_dn_5: 1.2175 (1.2175)  loss_giou_enc_0: 1.4949 (1.4949)  loss_vfl: 0.7493 (0.7493)  loss_vfl_aux_0: 0.7229 (0.7229)  loss_vfl_aux_1: 0.6951 (0.6951)  loss_vfl_aux_2: 0.7041 (0.7041)  loss_vfl_aux_3: 0.7363 (0.7363)  loss_vfl_aux_4: 0.7300 (0.7300)  loss_vfl_dn_0: 0.4282 (0.4282)  loss_vfl_dn_1: 0.4535 (0.4535)  loss_vfl_dn_2: 0.4658 (0.4658)  loss_vfl_dn_3: 0.4913 (0.4913)  loss_vfl_dn_4: 0.5132 (0.5132)  loss_vfl_dn_5: 0.5277 (0.5277)  loss_vfl_enc_0: 0.5847 (0.5847)  time: 5.1967  data: 3.4720  max mem: 10356\r\n",
      "Epoch: [14]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 30.9058 (32.0681)  loss_bbox: 0.4181 (0.4506)  loss_bbox_aux_0: 0.4454 (0.4847)  loss_bbox_aux_1: 0.4321 (0.4724)  loss_bbox_aux_2: 0.4208 (0.4642)  loss_bbox_aux_3: 0.4288 (0.4591)  loss_bbox_aux_4: 0.4165 (0.4513)  loss_bbox_dn_0: 0.3897 (0.4627)  loss_bbox_dn_1: 0.3770 (0.4445)  loss_bbox_dn_2: 0.3770 (0.4378)  loss_bbox_dn_3: 0.3775 (0.4351)  loss_bbox_dn_4: 0.3756 (0.4337)  loss_bbox_dn_5: 0.3753 (0.4335)  loss_bbox_enc_0: 0.4705 (0.5515)  loss_giou: 1.1507 (1.2733)  loss_giou_aux_0: 1.1933 (1.3157)  loss_giou_aux_1: 1.1677 (1.2932)  loss_giou_aux_2: 1.1620 (1.2810)  loss_giou_aux_3: 1.1666 (1.2780)  loss_giou_aux_4: 1.1490 (1.2740)  loss_giou_dn_0: 1.2705 (1.2795)  loss_giou_dn_1: 1.2103 (1.2254)  loss_giou_dn_2: 1.1862 (1.2067)  loss_giou_dn_3: 1.1651 (1.1921)  loss_giou_dn_4: 1.1527 (1.1844)  loss_giou_dn_5: 1.1516 (1.1841)  loss_giou_enc_0: 1.3221 (1.4130)  loss_vfl: 1.0193 (0.9918)  loss_vfl_aux_0: 0.9902 (0.9226)  loss_vfl_aux_1: 1.0139 (0.9497)  loss_vfl_aux_2: 1.0056 (0.9582)  loss_vfl_aux_3: 1.0164 (0.9744)  loss_vfl_aux_4: 1.0061 (0.9867)  loss_vfl_dn_0: 0.4460 (0.4437)  loss_vfl_dn_1: 0.4723 (0.4791)  loss_vfl_dn_2: 0.4967 (0.5073)  loss_vfl_dn_3: 0.5371 (0.5383)  loss_vfl_dn_4: 0.5681 (0.5648)  loss_vfl_dn_5: 0.5857 (0.5792)  loss_vfl_enc_0: 0.8550 (0.7907)  time: 1.0177  data: 0.0324  max mem: 10356\r\n",
      "Epoch: [14] Total time: 0:01:25 (1.0871 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 30.9058 (32.0681)  loss_bbox: 0.4181 (0.4506)  loss_bbox_aux_0: 0.4454 (0.4847)  loss_bbox_aux_1: 0.4321 (0.4724)  loss_bbox_aux_2: 0.4208 (0.4642)  loss_bbox_aux_3: 0.4288 (0.4591)  loss_bbox_aux_4: 0.4165 (0.4513)  loss_bbox_dn_0: 0.3897 (0.4627)  loss_bbox_dn_1: 0.3770 (0.4445)  loss_bbox_dn_2: 0.3770 (0.4378)  loss_bbox_dn_3: 0.3775 (0.4351)  loss_bbox_dn_4: 0.3756 (0.4337)  loss_bbox_dn_5: 0.3753 (0.4335)  loss_bbox_enc_0: 0.4705 (0.5515)  loss_giou: 1.1507 (1.2733)  loss_giou_aux_0: 1.1933 (1.3157)  loss_giou_aux_1: 1.1677 (1.2932)  loss_giou_aux_2: 1.1620 (1.2810)  loss_giou_aux_3: 1.1666 (1.2780)  loss_giou_aux_4: 1.1490 (1.2740)  loss_giou_dn_0: 1.2705 (1.2795)  loss_giou_dn_1: 1.2103 (1.2254)  loss_giou_dn_2: 1.1862 (1.2067)  loss_giou_dn_3: 1.1651 (1.1921)  loss_giou_dn_4: 1.1527 (1.1844)  loss_giou_dn_5: 1.1516 (1.1841)  loss_giou_enc_0: 1.3221 (1.4130)  loss_vfl: 1.0193 (0.9918)  loss_vfl_aux_0: 0.9902 (0.9226)  loss_vfl_aux_1: 1.0139 (0.9497)  loss_vfl_aux_2: 1.0056 (0.9582)  loss_vfl_aux_3: 1.0164 (0.9744)  loss_vfl_aux_4: 1.0061 (0.9867)  loss_vfl_dn_0: 0.4460 (0.4437)  loss_vfl_dn_1: 0.4723 (0.4791)  loss_vfl_dn_2: 0.4967 (0.5073)  loss_vfl_dn_3: 0.5371 (0.5383)  loss_vfl_dn_4: 0.5681 (0.5648)  loss_vfl_dn_5: 0.5857 (0.5792)  loss_vfl_enc_0: 0.8550 (0.7907)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.2506  data: 1.2787  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0790  data: 0.2203  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0947 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.012\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.085\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.093\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.048\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.152\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.113\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.183\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.093\r\n",
      "best_stat: {'epoch': 12, 'coco_eval_bbox': 0.005033527323812633}\r\n",
      "Epoch: [15]  [ 0/79]  eta: 0:05:55  lr: 0.000020  loss: 34.3413 (34.3413)  loss_bbox: 0.8220 (0.8220)  loss_bbox_aux_0: 0.8021 (0.8021)  loss_bbox_aux_1: 0.7992 (0.7992)  loss_bbox_aux_2: 0.7992 (0.7992)  loss_bbox_aux_3: 0.8175 (0.8175)  loss_bbox_aux_4: 0.8470 (0.8470)  loss_bbox_dn_0: 0.2056 (0.2056)  loss_bbox_dn_1: 0.1936 (0.1936)  loss_bbox_dn_2: 0.1915 (0.1915)  loss_bbox_dn_3: 0.1918 (0.1918)  loss_bbox_dn_4: 0.1925 (0.1925)  loss_bbox_dn_5: 0.1926 (0.1926)  loss_bbox_enc_0: 0.8170 (0.8170)  loss_giou: 2.0015 (2.0015)  loss_giou_aux_0: 2.0077 (2.0077)  loss_giou_aux_1: 2.0166 (2.0166)  loss_giou_aux_2: 2.0192 (2.0192)  loss_giou_aux_3: 2.0103 (2.0103)  loss_giou_aux_4: 1.9957 (1.9957)  loss_giou_dn_0: 1.3435 (1.3435)  loss_giou_dn_1: 1.3381 (1.3381)  loss_giou_dn_2: 1.3360 (1.3360)  loss_giou_dn_3: 1.3436 (1.3436)  loss_giou_dn_4: 1.3376 (1.3376)  loss_giou_dn_5: 1.3370 (1.3370)  loss_giou_enc_0: 2.0120 (2.0120)  loss_vfl: 0.4207 (0.4207)  loss_vfl_aux_0: 0.3799 (0.3799)  loss_vfl_aux_1: 0.4059 (0.4059)  loss_vfl_aux_2: 0.3992 (0.3992)  loss_vfl_aux_3: 0.4070 (0.4070)  loss_vfl_aux_4: 0.4136 (0.4136)  loss_vfl_dn_0: 0.4132 (0.4132)  loss_vfl_dn_1: 0.4293 (0.4293)  loss_vfl_dn_2: 0.4209 (0.4209)  loss_vfl_dn_3: 0.4418 (0.4418)  loss_vfl_dn_4: 0.4434 (0.4434)  loss_vfl_dn_5: 0.4739 (0.4739)  loss_vfl_enc_0: 0.3221 (0.3221)  time: 4.4941  data: 2.8688  max mem: 10356\r\n",
      "Epoch: [15]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 31.1935 (32.1674)  loss_bbox: 0.4148 (0.4522)  loss_bbox_aux_0: 0.4392 (0.4868)  loss_bbox_aux_1: 0.4315 (0.4786)  loss_bbox_aux_2: 0.4332 (0.4685)  loss_bbox_aux_3: 0.4158 (0.4650)  loss_bbox_aux_4: 0.4183 (0.4568)  loss_bbox_dn_0: 0.4194 (0.4882)  loss_bbox_dn_1: 0.4138 (0.4707)  loss_bbox_dn_2: 0.4166 (0.4645)  loss_bbox_dn_3: 0.4193 (0.4620)  loss_bbox_dn_4: 0.4236 (0.4606)  loss_bbox_dn_5: 0.4245 (0.4604)  loss_bbox_enc_0: 0.5221 (0.5568)  loss_giou: 1.3154 (1.2451)  loss_giou_aux_0: 1.3511 (1.2882)  loss_giou_aux_1: 1.3299 (1.2692)  loss_giou_aux_2: 1.3146 (1.2567)  loss_giou_aux_3: 1.3131 (1.2532)  loss_giou_aux_4: 1.3079 (1.2456)  loss_giou_dn_0: 1.2606 (1.2586)  loss_giou_dn_1: 1.2164 (1.2070)  loss_giou_dn_2: 1.2030 (1.1861)  loss_giou_dn_3: 1.1906 (1.1728)  loss_giou_dn_4: 1.1874 (1.1650)  loss_giou_dn_5: 1.1860 (1.1651)  loss_giou_enc_0: 1.4200 (1.3888)  loss_vfl: 0.9407 (1.0261)  loss_vfl_aux_0: 0.8423 (0.9472)  loss_vfl_aux_1: 0.8657 (0.9671)  loss_vfl_aux_2: 0.8862 (0.9789)  loss_vfl_aux_3: 0.8926 (0.9962)  loss_vfl_aux_4: 0.9014 (1.0113)  loss_vfl_dn_0: 0.4495 (0.4542)  loss_vfl_dn_1: 0.4734 (0.4871)  loss_vfl_dn_2: 0.4882 (0.5158)  loss_vfl_dn_3: 0.5054 (0.5443)  loss_vfl_dn_4: 0.5262 (0.5721)  loss_vfl_dn_5: 0.5443 (0.5840)  loss_vfl_enc_0: 0.7261 (0.8107)  time: 0.9956  data: 0.0317  max mem: 10356\r\n",
      "Epoch: [15] Total time: 0:01:24 (1.0715 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 31.1935 (32.1674)  loss_bbox: 0.4148 (0.4522)  loss_bbox_aux_0: 0.4392 (0.4868)  loss_bbox_aux_1: 0.4315 (0.4786)  loss_bbox_aux_2: 0.4332 (0.4685)  loss_bbox_aux_3: 0.4158 (0.4650)  loss_bbox_aux_4: 0.4183 (0.4568)  loss_bbox_dn_0: 0.4194 (0.4882)  loss_bbox_dn_1: 0.4138 (0.4707)  loss_bbox_dn_2: 0.4166 (0.4645)  loss_bbox_dn_3: 0.4193 (0.4620)  loss_bbox_dn_4: 0.4236 (0.4606)  loss_bbox_dn_5: 0.4245 (0.4604)  loss_bbox_enc_0: 0.5221 (0.5568)  loss_giou: 1.3154 (1.2451)  loss_giou_aux_0: 1.3511 (1.2882)  loss_giou_aux_1: 1.3299 (1.2692)  loss_giou_aux_2: 1.3146 (1.2567)  loss_giou_aux_3: 1.3131 (1.2532)  loss_giou_aux_4: 1.3079 (1.2456)  loss_giou_dn_0: 1.2606 (1.2586)  loss_giou_dn_1: 1.2164 (1.2070)  loss_giou_dn_2: 1.2030 (1.1861)  loss_giou_dn_3: 1.1906 (1.1728)  loss_giou_dn_4: 1.1874 (1.1650)  loss_giou_dn_5: 1.1860 (1.1651)  loss_giou_enc_0: 1.4200 (1.3888)  loss_vfl: 0.9407 (1.0261)  loss_vfl_aux_0: 0.8423 (0.9472)  loss_vfl_aux_1: 0.8657 (0.9671)  loss_vfl_aux_2: 0.8862 (0.9789)  loss_vfl_aux_3: 0.8926 (0.9962)  loss_vfl_aux_4: 0.9014 (1.0113)  loss_vfl_dn_0: 0.4495 (0.4542)  loss_vfl_dn_1: 0.4734 (0.4871)  loss_vfl_dn_2: 0.4882 (0.5158)  loss_vfl_dn_3: 0.5054 (0.5443)  loss_vfl_dn_4: 0.5262 (0.5721)  loss_vfl_dn_5: 0.5443 (0.5840)  loss_vfl_enc_0: 0.7261 (0.8107)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.2254  data: 1.2995  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0643  data: 0.2140  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0808 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.011\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.016\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.013\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.076\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.117\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.044\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.209\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.145\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.213\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.122\r\n",
      "best_stat: {'epoch': 15, 'coco_eval_bbox': 0.0063496308404630344}\r\n",
      "Epoch: [16]  [ 0/79]  eta: 0:05:06  lr: 0.000020  loss: 31.4496 (31.4496)  loss_bbox: 0.3768 (0.3768)  loss_bbox_aux_0: 0.3916 (0.3916)  loss_bbox_aux_1: 0.3729 (0.3729)  loss_bbox_aux_2: 0.3876 (0.3876)  loss_bbox_aux_3: 0.4009 (0.4009)  loss_bbox_aux_4: 0.3928 (0.3928)  loss_bbox_dn_0: 0.5174 (0.5174)  loss_bbox_dn_1: 0.4751 (0.4751)  loss_bbox_dn_2: 0.4556 (0.4556)  loss_bbox_dn_3: 0.4467 (0.4467)  loss_bbox_dn_4: 0.4362 (0.4362)  loss_bbox_dn_5: 0.4342 (0.4342)  loss_bbox_enc_0: 0.5022 (0.5022)  loss_giou: 1.0378 (1.0378)  loss_giou_aux_0: 1.1122 (1.1122)  loss_giou_aux_1: 1.0370 (1.0370)  loss_giou_aux_2: 1.0410 (1.0410)  loss_giou_aux_3: 1.0509 (1.0509)  loss_giou_aux_4: 1.0450 (1.0450)  loss_giou_dn_0: 1.2066 (1.2066)  loss_giou_dn_1: 1.1240 (1.1240)  loss_giou_dn_2: 1.0789 (1.0789)  loss_giou_dn_3: 1.0575 (1.0575)  loss_giou_dn_4: 1.0401 (1.0401)  loss_giou_dn_5: 1.0360 (1.0360)  loss_giou_enc_0: 1.1684 (1.1684)  loss_vfl: 1.2305 (1.2305)  loss_vfl_aux_0: 1.1558 (1.1558)  loss_vfl_aux_1: 1.2866 (1.2866)  loss_vfl_aux_2: 1.2793 (1.2793)  loss_vfl_aux_3: 1.2280 (1.2280)  loss_vfl_aux_4: 1.2280 (1.2280)  loss_vfl_dn_0: 0.4752 (0.4752)  loss_vfl_dn_1: 0.5114 (0.5114)  loss_vfl_dn_2: 0.5490 (0.5490)  loss_vfl_dn_3: 0.5792 (0.5792)  loss_vfl_dn_4: 0.6064 (0.6064)  loss_vfl_dn_5: 0.6176 (0.6176)  loss_vfl_enc_0: 1.0774 (1.0774)  time: 3.8848  data: 2.5927  max mem: 10356\r\n",
      "Epoch: [16]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 31.4303 (31.9274)  loss_bbox: 0.4439 (0.4395)  loss_bbox_aux_0: 0.4649 (0.4714)  loss_bbox_aux_1: 0.4728 (0.4629)  loss_bbox_aux_2: 0.4722 (0.4519)  loss_bbox_aux_3: 0.4607 (0.4488)  loss_bbox_aux_4: 0.4507 (0.4416)  loss_bbox_dn_0: 0.3940 (0.4710)  loss_bbox_dn_1: 0.3866 (0.4520)  loss_bbox_dn_2: 0.3791 (0.4442)  loss_bbox_dn_3: 0.3739 (0.4399)  loss_bbox_dn_4: 0.3697 (0.4374)  loss_bbox_dn_5: 0.3686 (0.4370)  loss_bbox_enc_0: 0.5271 (0.5291)  loss_giou: 1.2219 (1.2218)  loss_giou_aux_0: 1.2327 (1.2614)  loss_giou_aux_1: 1.2427 (1.2458)  loss_giou_aux_2: 1.2307 (1.2352)  loss_giou_aux_3: 1.2320 (1.2318)  loss_giou_aux_4: 1.2157 (1.2271)  loss_giou_dn_0: 1.2469 (1.2527)  loss_giou_dn_1: 1.1884 (1.1979)  loss_giou_dn_2: 1.1702 (1.1760)  loss_giou_dn_3: 1.1580 (1.1615)  loss_giou_dn_4: 1.1537 (1.1532)  loss_giou_dn_5: 1.1527 (1.1527)  loss_giou_enc_0: 1.3424 (1.3635)  loss_vfl: 0.9556 (1.0439)  loss_vfl_aux_0: 0.9368 (0.9742)  loss_vfl_aux_1: 0.9419 (0.9947)  loss_vfl_aux_2: 0.9600 (1.0093)  loss_vfl_aux_3: 0.9468 (1.0242)  loss_vfl_aux_4: 0.9399 (1.0318)  loss_vfl_dn_0: 0.4468 (0.4565)  loss_vfl_dn_1: 0.4857 (0.4921)  loss_vfl_dn_2: 0.5109 (0.5220)  loss_vfl_dn_3: 0.5394 (0.5539)  loss_vfl_dn_4: 0.5627 (0.5795)  loss_vfl_dn_5: 0.5713 (0.5941)  loss_vfl_enc_0: 0.8086 (0.8439)  time: 1.0201  data: 0.0323  max mem: 10356\r\n",
      "Epoch: [16] Total time: 0:01:26 (1.0914 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 31.4303 (31.9274)  loss_bbox: 0.4439 (0.4395)  loss_bbox_aux_0: 0.4649 (0.4714)  loss_bbox_aux_1: 0.4728 (0.4629)  loss_bbox_aux_2: 0.4722 (0.4519)  loss_bbox_aux_3: 0.4607 (0.4488)  loss_bbox_aux_4: 0.4507 (0.4416)  loss_bbox_dn_0: 0.3940 (0.4710)  loss_bbox_dn_1: 0.3866 (0.4520)  loss_bbox_dn_2: 0.3791 (0.4442)  loss_bbox_dn_3: 0.3739 (0.4399)  loss_bbox_dn_4: 0.3697 (0.4374)  loss_bbox_dn_5: 0.3686 (0.4370)  loss_bbox_enc_0: 0.5271 (0.5291)  loss_giou: 1.2219 (1.2218)  loss_giou_aux_0: 1.2327 (1.2614)  loss_giou_aux_1: 1.2427 (1.2458)  loss_giou_aux_2: 1.2307 (1.2352)  loss_giou_aux_3: 1.2320 (1.2318)  loss_giou_aux_4: 1.2157 (1.2271)  loss_giou_dn_0: 1.2469 (1.2527)  loss_giou_dn_1: 1.1884 (1.1979)  loss_giou_dn_2: 1.1702 (1.1760)  loss_giou_dn_3: 1.1580 (1.1615)  loss_giou_dn_4: 1.1537 (1.1532)  loss_giou_dn_5: 1.1527 (1.1527)  loss_giou_enc_0: 1.3424 (1.3635)  loss_vfl: 0.9556 (1.0439)  loss_vfl_aux_0: 0.9368 (0.9742)  loss_vfl_aux_1: 0.9419 (0.9947)  loss_vfl_aux_2: 0.9600 (1.0093)  loss_vfl_aux_3: 0.9468 (1.0242)  loss_vfl_aux_4: 0.9399 (1.0318)  loss_vfl_dn_0: 0.4468 (0.4565)  loss_vfl_dn_1: 0.4857 (0.4921)  loss_vfl_dn_2: 0.5109 (0.5220)  loss_vfl_dn_3: 0.5394 (0.5539)  loss_vfl_dn_4: 0.5627 (0.5795)  loss_vfl_dn_5: 0.5713 (0.5941)  loss_vfl_enc_0: 0.8086 (0.8439)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.2113  data: 1.2877  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0701  data: 0.2181  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0883 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.005\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.022\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.004\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.059\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.092\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.100\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.030\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.146\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.149\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.170\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.105\r\n",
      "best_stat: {'epoch': 15, 'coco_eval_bbox': 0.0063496308404630344}\r\n",
      "Epoch: [17]  [ 0/79]  eta: 0:06:36  lr: 0.000020  loss: 30.7506 (30.7506)  loss_bbox: 0.3198 (0.3198)  loss_bbox_aux_0: 0.3758 (0.3758)  loss_bbox_aux_1: 0.3808 (0.3808)  loss_bbox_aux_2: 0.3304 (0.3304)  loss_bbox_aux_3: 0.3240 (0.3240)  loss_bbox_aux_4: 0.3417 (0.3417)  loss_bbox_dn_0: 0.4212 (0.4212)  loss_bbox_dn_1: 0.4147 (0.4147)  loss_bbox_dn_2: 0.4106 (0.4106)  loss_bbox_dn_3: 0.4072 (0.4072)  loss_bbox_dn_4: 0.4056 (0.4056)  loss_bbox_dn_5: 0.4048 (0.4048)  loss_bbox_enc_0: 0.5117 (0.5117)  loss_giou: 1.2561 (1.2561)  loss_giou_aux_0: 1.3129 (1.3129)  loss_giou_aux_1: 1.2647 (1.2647)  loss_giou_aux_2: 1.2733 (1.2733)  loss_giou_aux_3: 1.2631 (1.2631)  loss_giou_aux_4: 1.2430 (1.2430)  loss_giou_dn_0: 1.2826 (1.2826)  loss_giou_dn_1: 1.2392 (1.2392)  loss_giou_dn_2: 1.2201 (1.2201)  loss_giou_dn_3: 1.2066 (1.2066)  loss_giou_dn_4: 1.1975 (1.1975)  loss_giou_dn_5: 1.1955 (1.1955)  loss_giou_enc_0: 1.3649 (1.3649)  loss_vfl: 0.9546 (0.9546)  loss_vfl_aux_0: 0.9500 (0.9500)  loss_vfl_aux_1: 0.9626 (0.9626)  loss_vfl_aux_2: 0.9573 (0.9573)  loss_vfl_aux_3: 0.9668 (0.9668)  loss_vfl_aux_4: 0.9724 (0.9724)  loss_vfl_dn_0: 0.4219 (0.4219)  loss_vfl_dn_1: 0.4443 (0.4443)  loss_vfl_dn_2: 0.4678 (0.4678)  loss_vfl_dn_3: 0.4882 (0.4882)  loss_vfl_dn_4: 0.5132 (0.5132)  loss_vfl_dn_5: 0.5264 (0.5264)  loss_vfl_enc_0: 0.7573 (0.7573)  time: 5.0190  data: 3.7149  max mem: 10356\r\n",
      "Epoch: [17]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 32.1005 (31.5730)  loss_bbox: 0.4271 (0.4180)  loss_bbox_aux_0: 0.4572 (0.4488)  loss_bbox_aux_1: 0.4613 (0.4382)  loss_bbox_aux_2: 0.4306 (0.4309)  loss_bbox_aux_3: 0.4317 (0.4233)  loss_bbox_aux_4: 0.4408 (0.4198)  loss_bbox_dn_0: 0.4159 (0.4592)  loss_bbox_dn_1: 0.3960 (0.4409)  loss_bbox_dn_2: 0.3845 (0.4332)  loss_bbox_dn_3: 0.3801 (0.4292)  loss_bbox_dn_4: 0.3806 (0.4270)  loss_bbox_dn_5: 0.3799 (0.4266)  loss_bbox_enc_0: 0.5189 (0.5088)  loss_giou: 1.2047 (1.2067)  loss_giou_aux_0: 1.2287 (1.2470)  loss_giou_aux_1: 1.2180 (1.2343)  loss_giou_aux_2: 1.2184 (1.2212)  loss_giou_aux_3: 1.1995 (1.2165)  loss_giou_aux_4: 1.1970 (1.2050)  loss_giou_dn_0: 1.2336 (1.2427)  loss_giou_dn_1: 1.1651 (1.1892)  loss_giou_dn_2: 1.1343 (1.1659)  loss_giou_dn_3: 1.1225 (1.1515)  loss_giou_dn_4: 1.1126 (1.1438)  loss_giou_dn_5: 1.1110 (1.1432)  loss_giou_enc_0: 1.3184 (1.3537)  loss_vfl: 0.9771 (1.0491)  loss_vfl_aux_0: 0.8853 (0.9862)  loss_vfl_aux_1: 0.9487 (0.9930)  loss_vfl_aux_2: 0.9834 (1.0074)  loss_vfl_aux_3: 0.9685 (1.0246)  loss_vfl_aux_4: 0.9360 (1.0396)  loss_vfl_dn_0: 0.4545 (0.4582)  loss_vfl_dn_1: 0.4761 (0.4906)  loss_vfl_dn_2: 0.5078 (0.5195)  loss_vfl_dn_3: 0.5347 (0.5505)  loss_vfl_dn_4: 0.5576 (0.5778)  loss_vfl_dn_5: 0.5725 (0.5941)  loss_vfl_enc_0: 0.8374 (0.8579)  time: 1.0390  data: 0.0307  max mem: 10356\r\n",
      "Epoch: [17] Total time: 0:01:27 (1.1018 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 32.1005 (31.5730)  loss_bbox: 0.4271 (0.4180)  loss_bbox_aux_0: 0.4572 (0.4488)  loss_bbox_aux_1: 0.4613 (0.4382)  loss_bbox_aux_2: 0.4306 (0.4309)  loss_bbox_aux_3: 0.4317 (0.4233)  loss_bbox_aux_4: 0.4408 (0.4198)  loss_bbox_dn_0: 0.4159 (0.4592)  loss_bbox_dn_1: 0.3960 (0.4409)  loss_bbox_dn_2: 0.3845 (0.4332)  loss_bbox_dn_3: 0.3801 (0.4292)  loss_bbox_dn_4: 0.3806 (0.4270)  loss_bbox_dn_5: 0.3799 (0.4266)  loss_bbox_enc_0: 0.5189 (0.5088)  loss_giou: 1.2047 (1.2067)  loss_giou_aux_0: 1.2287 (1.2470)  loss_giou_aux_1: 1.2180 (1.2343)  loss_giou_aux_2: 1.2184 (1.2212)  loss_giou_aux_3: 1.1995 (1.2165)  loss_giou_aux_4: 1.1970 (1.2050)  loss_giou_dn_0: 1.2336 (1.2427)  loss_giou_dn_1: 1.1651 (1.1892)  loss_giou_dn_2: 1.1343 (1.1659)  loss_giou_dn_3: 1.1225 (1.1515)  loss_giou_dn_4: 1.1126 (1.1438)  loss_giou_dn_5: 1.1110 (1.1432)  loss_giou_enc_0: 1.3184 (1.3537)  loss_vfl: 0.9771 (1.0491)  loss_vfl_aux_0: 0.8853 (0.9862)  loss_vfl_aux_1: 0.9487 (0.9930)  loss_vfl_aux_2: 0.9834 (1.0074)  loss_vfl_aux_3: 0.9685 (1.0246)  loss_vfl_aux_4: 0.9360 (1.0396)  loss_vfl_dn_0: 0.4545 (0.4582)  loss_vfl_dn_1: 0.4761 (0.4906)  loss_vfl_dn_2: 0.5078 (0.5195)  loss_vfl_dn_3: 0.5347 (0.5505)  loss_vfl_dn_4: 0.5576 (0.5778)  loss_vfl_dn_5: 0.5725 (0.5941)  loss_vfl_enc_0: 0.8374 (0.8579)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3250  data: 1.3532  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0694  data: 0.2142  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0859 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.20s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.013\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.010\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.016\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.019\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.085\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.136\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.143\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.229\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.191\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.230\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.141\r\n",
      "best_stat: {'epoch': 17, 'coco_eval_bbox': 0.00823832999448743}\r\n",
      "Epoch: [18]  [ 0/79]  eta: 0:04:39  lr: 0.000020  loss: 34.9037 (34.9037)  loss_bbox: 0.4206 (0.4206)  loss_bbox_aux_0: 0.5889 (0.5889)  loss_bbox_aux_1: 0.5283 (0.5283)  loss_bbox_aux_2: 0.4982 (0.4982)  loss_bbox_aux_3: 0.4470 (0.4470)  loss_bbox_aux_4: 0.4125 (0.4125)  loss_bbox_dn_0: 0.7624 (0.7624)  loss_bbox_dn_1: 0.7050 (0.7050)  loss_bbox_dn_2: 0.6812 (0.6812)  loss_bbox_dn_3: 0.6638 (0.6638)  loss_bbox_dn_4: 0.6499 (0.6499)  loss_bbox_dn_5: 0.6472 (0.6472)  loss_bbox_enc_0: 0.7232 (0.7232)  loss_giou: 0.8480 (0.8480)  loss_giou_aux_0: 0.9504 (0.9504)  loss_giou_aux_1: 0.8823 (0.8823)  loss_giou_aux_2: 0.8703 (0.8703)  loss_giou_aux_3: 0.8645 (0.8645)  loss_giou_aux_4: 0.8446 (0.8446)  loss_giou_dn_0: 1.2290 (1.2290)  loss_giou_dn_1: 1.1357 (1.1357)  loss_giou_dn_2: 1.0889 (1.0889)  loss_giou_dn_3: 1.0570 (1.0570)  loss_giou_dn_4: 1.0373 (1.0373)  loss_giou_dn_5: 1.0341 (1.0341)  loss_giou_enc_0: 1.0951 (1.0951)  loss_vfl: 1.6748 (1.6748)  loss_vfl_aux_0: 1.5200 (1.5200)  loss_vfl_aux_1: 1.5918 (1.5918)  loss_vfl_aux_2: 1.5903 (1.5903)  loss_vfl_aux_3: 1.6069 (1.6069)  loss_vfl_aux_4: 1.7061 (1.7061)  loss_vfl_dn_0: 0.4377 (0.4377)  loss_vfl_dn_1: 0.4904 (0.4904)  loss_vfl_dn_2: 0.5291 (0.5291)  loss_vfl_dn_3: 0.5896 (0.5896)  loss_vfl_dn_4: 0.6267 (0.6267)  loss_vfl_dn_5: 0.6418 (0.6418)  loss_vfl_enc_0: 1.2329 (1.2329)  time: 3.5397  data: 2.3461  max mem: 10356\r\n",
      "Epoch: [18]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 31.3716 (31.6046)  loss_bbox: 0.3949 (0.4128)  loss_bbox_aux_0: 0.4122 (0.4399)  loss_bbox_aux_1: 0.4043 (0.4323)  loss_bbox_aux_2: 0.4055 (0.4260)  loss_bbox_aux_3: 0.3953 (0.4214)  loss_bbox_aux_4: 0.3878 (0.4153)  loss_bbox_dn_0: 0.4919 (0.4720)  loss_bbox_dn_1: 0.4510 (0.4531)  loss_bbox_dn_2: 0.4312 (0.4442)  loss_bbox_dn_3: 0.4202 (0.4398)  loss_bbox_dn_4: 0.4187 (0.4366)  loss_bbox_dn_5: 0.4190 (0.4361)  loss_bbox_enc_0: 0.4787 (0.4998)  loss_giou: 1.1231 (1.2042)  loss_giou_aux_0: 1.1155 (1.2397)  loss_giou_aux_1: 1.0843 (1.2274)  loss_giou_aux_2: 1.0889 (1.2129)  loss_giou_aux_3: 1.0986 (1.2106)  loss_giou_aux_4: 1.0980 (1.2038)  loss_giou_dn_0: 1.2127 (1.2403)  loss_giou_dn_1: 1.1702 (1.1852)  loss_giou_dn_2: 1.1369 (1.1609)  loss_giou_dn_3: 1.1173 (1.1463)  loss_giou_dn_4: 1.1079 (1.1375)  loss_giou_dn_5: 1.1096 (1.1370)  loss_giou_enc_0: 1.2276 (1.3450)  loss_vfl: 1.1311 (1.0506)  loss_vfl_aux_0: 1.1162 (1.0020)  loss_vfl_aux_1: 1.0803 (1.0105)  loss_vfl_aux_2: 1.1025 (1.0216)  loss_vfl_aux_3: 1.1169 (1.0368)  loss_vfl_aux_4: 1.1382 (1.0456)  loss_vfl_dn_0: 0.4678 (0.4594)  loss_vfl_dn_1: 0.5078 (0.4921)  loss_vfl_dn_2: 0.5371 (0.5212)  loss_vfl_dn_3: 0.5784 (0.5511)  loss_vfl_dn_4: 0.6030 (0.5767)  loss_vfl_dn_5: 0.6165 (0.5926)  loss_vfl_enc_0: 0.9590 (0.8641)  time: 1.0110  data: 0.0310  max mem: 10356\r\n",
      "Epoch: [18] Total time: 0:01:25 (1.0817 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 31.3716 (31.6046)  loss_bbox: 0.3949 (0.4128)  loss_bbox_aux_0: 0.4122 (0.4399)  loss_bbox_aux_1: 0.4043 (0.4323)  loss_bbox_aux_2: 0.4055 (0.4260)  loss_bbox_aux_3: 0.3953 (0.4214)  loss_bbox_aux_4: 0.3878 (0.4153)  loss_bbox_dn_0: 0.4919 (0.4720)  loss_bbox_dn_1: 0.4510 (0.4531)  loss_bbox_dn_2: 0.4312 (0.4442)  loss_bbox_dn_3: 0.4202 (0.4398)  loss_bbox_dn_4: 0.4187 (0.4366)  loss_bbox_dn_5: 0.4190 (0.4361)  loss_bbox_enc_0: 0.4787 (0.4998)  loss_giou: 1.1231 (1.2042)  loss_giou_aux_0: 1.1155 (1.2397)  loss_giou_aux_1: 1.0843 (1.2274)  loss_giou_aux_2: 1.0889 (1.2129)  loss_giou_aux_3: 1.0986 (1.2106)  loss_giou_aux_4: 1.0980 (1.2038)  loss_giou_dn_0: 1.2127 (1.2403)  loss_giou_dn_1: 1.1702 (1.1852)  loss_giou_dn_2: 1.1369 (1.1609)  loss_giou_dn_3: 1.1173 (1.1463)  loss_giou_dn_4: 1.1079 (1.1375)  loss_giou_dn_5: 1.1096 (1.1370)  loss_giou_enc_0: 1.2276 (1.3450)  loss_vfl: 1.1311 (1.0506)  loss_vfl_aux_0: 1.1162 (1.0020)  loss_vfl_aux_1: 1.0803 (1.0105)  loss_vfl_aux_2: 1.1025 (1.0216)  loss_vfl_aux_3: 1.1169 (1.0368)  loss_vfl_aux_4: 1.1382 (1.0456)  loss_vfl_dn_0: 0.4678 (0.4594)  loss_vfl_dn_1: 0.5078 (0.4921)  loss_vfl_dn_2: 0.5371 (0.5212)  loss_vfl_dn_3: 0.5784 (0.5511)  loss_vfl_dn_4: 0.6030 (0.5767)  loss_vfl_dn_5: 0.6165 (0.5926)  loss_vfl_enc_0: 0.9590 (0.8641)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.1561  data: 1.2022  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0581  data: 0.2082  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0756 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.20s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.013\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.017\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.008\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.088\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.138\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.145\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.038\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.241\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.191\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.238\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.150\r\n",
      "best_stat: {'epoch': 17, 'coco_eval_bbox': 0.00823832999448743}\r\n",
      "Epoch: [19]  [ 0/79]  eta: 0:07:02  lr: 0.000020  loss: 28.3631 (28.3631)  loss_bbox: 0.2961 (0.2961)  loss_bbox_aux_0: 0.2940 (0.2940)  loss_bbox_aux_1: 0.2918 (0.2918)  loss_bbox_aux_2: 0.3151 (0.3151)  loss_bbox_aux_3: 0.3015 (0.3015)  loss_bbox_aux_4: 0.2896 (0.2896)  loss_bbox_dn_0: 0.2124 (0.2124)  loss_bbox_dn_1: 0.2107 (0.2107)  loss_bbox_dn_2: 0.2104 (0.2104)  loss_bbox_dn_3: 0.2103 (0.2103)  loss_bbox_dn_4: 0.2099 (0.2099)  loss_bbox_dn_5: 0.2100 (0.2100)  loss_bbox_enc_0: 0.3308 (0.3308)  loss_giou: 1.3604 (1.3604)  loss_giou_aux_0: 1.3700 (1.3700)  loss_giou_aux_1: 1.4061 (1.4061)  loss_giou_aux_2: 1.3732 (1.3732)  loss_giou_aux_3: 1.3599 (1.3599)  loss_giou_aux_4: 1.3672 (1.3672)  loss_giou_dn_0: 1.2652 (1.2652)  loss_giou_dn_1: 1.2312 (1.2312)  loss_giou_dn_2: 1.2199 (1.2199)  loss_giou_dn_3: 1.2144 (1.2144)  loss_giou_dn_4: 1.2147 (1.2147)  loss_giou_dn_5: 1.2175 (1.2175)  loss_giou_enc_0: 1.4801 (1.4801)  loss_vfl: 0.7556 (0.7556)  loss_vfl_aux_0: 0.7214 (0.7214)  loss_vfl_aux_1: 0.6787 (0.6787)  loss_vfl_aux_2: 0.6946 (0.6946)  loss_vfl_aux_3: 0.7271 (0.7271)  loss_vfl_aux_4: 0.7371 (0.7371)  loss_vfl_dn_0: 0.4514 (0.4514)  loss_vfl_dn_1: 0.4664 (0.4664)  loss_vfl_dn_2: 0.4839 (0.4839)  loss_vfl_dn_3: 0.5090 (0.5090)  loss_vfl_dn_4: 0.5312 (0.5312)  loss_vfl_dn_5: 0.5356 (0.5356)  loss_vfl_enc_0: 0.6086 (0.6086)  time: 5.3434  data: 3.9168  max mem: 10356\r\n",
      "Epoch: [19]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 31.5429 (31.6109)  loss_bbox: 0.3983 (0.4106)  loss_bbox_aux_0: 0.4365 (0.4412)  loss_bbox_aux_1: 0.4165 (0.4376)  loss_bbox_aux_2: 0.4006 (0.4263)  loss_bbox_aux_3: 0.4010 (0.4213)  loss_bbox_aux_4: 0.4024 (0.4153)  loss_bbox_dn_0: 0.4884 (0.4690)  loss_bbox_dn_1: 0.4566 (0.4488)  loss_bbox_dn_2: 0.4400 (0.4391)  loss_bbox_dn_3: 0.4321 (0.4338)  loss_bbox_dn_4: 0.4266 (0.4307)  loss_bbox_dn_5: 0.4257 (0.4302)  loss_bbox_enc_0: 0.4870 (0.4992)  loss_giou: 1.0349 (1.1946)  loss_giou_aux_0: 1.0873 (1.2293)  loss_giou_aux_1: 1.0614 (1.2098)  loss_giou_aux_2: 1.0672 (1.2021)  loss_giou_aux_3: 1.0278 (1.1977)  loss_giou_aux_4: 1.0497 (1.1926)  loss_giou_dn_0: 1.2080 (1.2300)  loss_giou_dn_1: 1.1425 (1.1746)  loss_giou_dn_2: 1.1104 (1.1498)  loss_giou_dn_3: 1.0876 (1.1342)  loss_giou_dn_4: 1.0703 (1.1250)  loss_giou_dn_5: 1.0715 (1.1249)  loss_giou_enc_0: 1.2276 (1.3325)  loss_vfl: 1.1738 (1.0718)  loss_vfl_aux_0: 1.1069 (1.0209)  loss_vfl_aux_1: 1.1360 (1.0320)  loss_vfl_aux_2: 1.1445 (1.0408)  loss_vfl_aux_3: 1.1797 (1.0561)  loss_vfl_aux_4: 1.1812 (1.0618)  loss_vfl_dn_0: 0.4761 (0.4659)  loss_vfl_dn_1: 0.5165 (0.4989)  loss_vfl_dn_2: 0.5426 (0.5283)  loss_vfl_dn_3: 0.5868 (0.5596)  loss_vfl_dn_4: 0.6172 (0.5864)  loss_vfl_dn_5: 0.6306 (0.6027)  loss_vfl_enc_0: 0.9482 (0.8855)  time: 1.0061  data: 0.0311  max mem: 10356\r\n",
      "Epoch: [19] Total time: 0:01:24 (1.0745 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 31.5429 (31.6109)  loss_bbox: 0.3983 (0.4106)  loss_bbox_aux_0: 0.4365 (0.4412)  loss_bbox_aux_1: 0.4165 (0.4376)  loss_bbox_aux_2: 0.4006 (0.4263)  loss_bbox_aux_3: 0.4010 (0.4213)  loss_bbox_aux_4: 0.4024 (0.4153)  loss_bbox_dn_0: 0.4884 (0.4690)  loss_bbox_dn_1: 0.4566 (0.4488)  loss_bbox_dn_2: 0.4400 (0.4391)  loss_bbox_dn_3: 0.4321 (0.4338)  loss_bbox_dn_4: 0.4266 (0.4307)  loss_bbox_dn_5: 0.4257 (0.4302)  loss_bbox_enc_0: 0.4870 (0.4992)  loss_giou: 1.0349 (1.1946)  loss_giou_aux_0: 1.0873 (1.2293)  loss_giou_aux_1: 1.0614 (1.2098)  loss_giou_aux_2: 1.0672 (1.2021)  loss_giou_aux_3: 1.0278 (1.1977)  loss_giou_aux_4: 1.0497 (1.1926)  loss_giou_dn_0: 1.2080 (1.2300)  loss_giou_dn_1: 1.1425 (1.1746)  loss_giou_dn_2: 1.1104 (1.1498)  loss_giou_dn_3: 1.0876 (1.1342)  loss_giou_dn_4: 1.0703 (1.1250)  loss_giou_dn_5: 1.0715 (1.1249)  loss_giou_enc_0: 1.2276 (1.3325)  loss_vfl: 1.1738 (1.0718)  loss_vfl_aux_0: 1.1069 (1.0209)  loss_vfl_aux_1: 1.1360 (1.0320)  loss_vfl_aux_2: 1.1445 (1.0408)  loss_vfl_aux_3: 1.1797 (1.0561)  loss_vfl_aux_4: 1.1812 (1.0618)  loss_vfl_dn_0: 0.4761 (0.4659)  loss_vfl_dn_1: 0.5165 (0.4989)  loss_vfl_dn_2: 0.5426 (0.5283)  loss_vfl_dn_3: 0.5868 (0.5596)  loss_vfl_dn_4: 0.6172 (0.5864)  loss_vfl_dn_5: 0.6306 (0.6027)  loss_vfl_enc_0: 0.9482 (0.8855)\r\n",
      "Test:  [0/8]  eta: 0:00:22    time: 2.7899  data: 1.8146  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.1276  data: 0.2712  max mem: 10356\r\n",
      "Test: Total time: 0:00:09 (1.1436 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.19s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.014\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.016\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.016\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.089\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.132\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.141\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.051\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.252\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.159\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.229\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.148\r\n",
      "best_stat: {'epoch': 17, 'coco_eval_bbox': 0.00823832999448743}\r\n",
      "Epoch: [20]  [ 0/79]  eta: 0:06:20  lr: 0.000020  loss: 30.3305 (30.3305)  loss_bbox: 0.4175 (0.4175)  loss_bbox_aux_0: 0.4082 (0.4082)  loss_bbox_aux_1: 0.4387 (0.4387)  loss_bbox_aux_2: 0.4195 (0.4195)  loss_bbox_aux_3: 0.3983 (0.3983)  loss_bbox_aux_4: 0.4139 (0.4139)  loss_bbox_dn_0: 0.3010 (0.3010)  loss_bbox_dn_1: 0.3089 (0.3089)  loss_bbox_dn_2: 0.3100 (0.3100)  loss_bbox_dn_3: 0.3172 (0.3172)  loss_bbox_dn_4: 0.3239 (0.3239)  loss_bbox_dn_5: 0.3254 (0.3254)  loss_bbox_enc_0: 0.4578 (0.4578)  loss_giou: 1.3226 (1.3226)  loss_giou_aux_0: 1.3216 (1.3216)  loss_giou_aux_1: 1.3290 (1.3290)  loss_giou_aux_2: 1.3536 (1.3536)  loss_giou_aux_3: 1.3475 (1.3475)  loss_giou_aux_4: 1.3201 (1.3201)  loss_giou_dn_0: 1.1588 (1.1588)  loss_giou_dn_1: 1.1053 (1.1053)  loss_giou_dn_2: 1.0777 (1.0777)  loss_giou_dn_3: 1.0748 (1.0748)  loss_giou_dn_4: 1.0786 (1.0786)  loss_giou_dn_5: 1.0810 (1.0810)  loss_giou_enc_0: 1.3573 (1.3573)  loss_vfl: 0.9260 (0.9260)  loss_vfl_aux_0: 0.8772 (0.8772)  loss_vfl_aux_1: 0.8638 (0.8638)  loss_vfl_aux_2: 0.8931 (0.8931)  loss_vfl_aux_3: 0.9353 (0.9353)  loss_vfl_aux_4: 0.9143 (0.9143)  loss_vfl_dn_0: 0.4988 (0.4988)  loss_vfl_dn_1: 0.5305 (0.5305)  loss_vfl_dn_2: 0.5648 (0.5648)  loss_vfl_dn_3: 0.5607 (0.5607)  loss_vfl_dn_4: 0.5808 (0.5808)  loss_vfl_dn_5: 0.6031 (0.6031)  loss_vfl_enc_0: 0.8137 (0.8137)  time: 4.8216  data: 3.0428  max mem: 10356\r\n",
      "Epoch: [20]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 31.4589 (31.3911)  loss_bbox: 0.4228 (0.4084)  loss_bbox_aux_0: 0.4405 (0.4342)  loss_bbox_aux_1: 0.4528 (0.4316)  loss_bbox_aux_2: 0.4437 (0.4229)  loss_bbox_aux_3: 0.4366 (0.4187)  loss_bbox_aux_4: 0.4246 (0.4134)  loss_bbox_dn_0: 0.4284 (0.4635)  loss_bbox_dn_1: 0.4168 (0.4458)  loss_bbox_dn_2: 0.4086 (0.4369)  loss_bbox_dn_3: 0.4030 (0.4324)  loss_bbox_dn_4: 0.4002 (0.4300)  loss_bbox_dn_5: 0.3996 (0.4296)  loss_bbox_enc_0: 0.5020 (0.4922)  loss_giou: 1.2280 (1.1780)  loss_giou_aux_0: 1.2640 (1.2053)  loss_giou_aux_1: 1.2578 (1.1931)  loss_giou_aux_2: 1.2354 (1.1841)  loss_giou_aux_3: 1.2267 (1.1857)  loss_giou_aux_4: 1.2197 (1.1788)  loss_giou_dn_0: 1.2163 (1.2184)  loss_giou_dn_1: 1.1718 (1.1595)  loss_giou_dn_2: 1.1529 (1.1326)  loss_giou_dn_3: 1.1379 (1.1169)  loss_giou_dn_4: 1.1285 (1.1081)  loss_giou_dn_5: 1.1280 (1.1075)  loss_giou_enc_0: 1.3629 (1.3075)  loss_vfl: 0.9631 (1.0691)  loss_vfl_aux_0: 0.9583 (1.0305)  loss_vfl_aux_1: 0.9595 (1.0323)  loss_vfl_aux_2: 0.9353 (1.0482)  loss_vfl_aux_3: 0.9543 (1.0548)  loss_vfl_aux_4: 0.9612 (1.0650)  loss_vfl_dn_0: 0.4520 (0.4669)  loss_vfl_dn_1: 0.4824 (0.5008)  loss_vfl_dn_2: 0.5148 (0.5317)  loss_vfl_dn_3: 0.5344 (0.5619)  loss_vfl_dn_4: 0.5681 (0.5900)  loss_vfl_dn_5: 0.5825 (0.6061)  loss_vfl_enc_0: 0.8250 (0.8986)  time: 0.9775  data: 0.0322  max mem: 10356\r\n",
      "Epoch: [20] Total time: 0:01:25 (1.0885 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 31.4589 (31.3911)  loss_bbox: 0.4228 (0.4084)  loss_bbox_aux_0: 0.4405 (0.4342)  loss_bbox_aux_1: 0.4528 (0.4316)  loss_bbox_aux_2: 0.4437 (0.4229)  loss_bbox_aux_3: 0.4366 (0.4187)  loss_bbox_aux_4: 0.4246 (0.4134)  loss_bbox_dn_0: 0.4284 (0.4635)  loss_bbox_dn_1: 0.4168 (0.4458)  loss_bbox_dn_2: 0.4086 (0.4369)  loss_bbox_dn_3: 0.4030 (0.4324)  loss_bbox_dn_4: 0.4002 (0.4300)  loss_bbox_dn_5: 0.3996 (0.4296)  loss_bbox_enc_0: 0.5020 (0.4922)  loss_giou: 1.2280 (1.1780)  loss_giou_aux_0: 1.2640 (1.2053)  loss_giou_aux_1: 1.2578 (1.1931)  loss_giou_aux_2: 1.2354 (1.1841)  loss_giou_aux_3: 1.2267 (1.1857)  loss_giou_aux_4: 1.2197 (1.1788)  loss_giou_dn_0: 1.2163 (1.2184)  loss_giou_dn_1: 1.1718 (1.1595)  loss_giou_dn_2: 1.1529 (1.1326)  loss_giou_dn_3: 1.1379 (1.1169)  loss_giou_dn_4: 1.1285 (1.1081)  loss_giou_dn_5: 1.1280 (1.1075)  loss_giou_enc_0: 1.3629 (1.3075)  loss_vfl: 0.9631 (1.0691)  loss_vfl_aux_0: 0.9583 (1.0305)  loss_vfl_aux_1: 0.9595 (1.0323)  loss_vfl_aux_2: 0.9353 (1.0482)  loss_vfl_aux_3: 0.9543 (1.0548)  loss_vfl_aux_4: 0.9612 (1.0650)  loss_vfl_dn_0: 0.4520 (0.4669)  loss_vfl_dn_1: 0.4824 (0.5008)  loss_vfl_dn_2: 0.5148 (0.5317)  loss_vfl_dn_3: 0.5344 (0.5619)  loss_vfl_dn_4: 0.5681 (0.5900)  loss_vfl_dn_5: 0.5825 (0.6061)  loss_vfl_enc_0: 0.8250 (0.8986)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.2113  data: 1.2501  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0752  data: 0.2165  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0932 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.19s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.011\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.027\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.087\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.142\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.149\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.046\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.231\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.249\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.147\r\n",
      "best_stat: {'epoch': 17, 'coco_eval_bbox': 0.00823832999448743}\r\n",
      "Epoch: [21]  [ 0/79]  eta: 0:05:42  lr: 0.000020  loss: 31.1289 (31.1289)  loss_bbox: 0.3040 (0.3040)  loss_bbox_aux_0: 0.3780 (0.3780)  loss_bbox_aux_1: 0.3420 (0.3420)  loss_bbox_aux_2: 0.3328 (0.3328)  loss_bbox_aux_3: 0.3077 (0.3077)  loss_bbox_aux_4: 0.3112 (0.3112)  loss_bbox_dn_0: 0.5166 (0.5166)  loss_bbox_dn_1: 0.4887 (0.4887)  loss_bbox_dn_2: 0.4750 (0.4750)  loss_bbox_dn_3: 0.4635 (0.4635)  loss_bbox_dn_4: 0.4545 (0.4545)  loss_bbox_dn_5: 0.4519 (0.4519)  loss_bbox_enc_0: 0.4117 (0.4117)  loss_giou: 0.8521 (0.8521)  loss_giou_aux_0: 0.9095 (0.9095)  loss_giou_aux_1: 0.8659 (0.8659)  loss_giou_aux_2: 0.8964 (0.8964)  loss_giou_aux_3: 0.8546 (0.8546)  loss_giou_aux_4: 0.8511 (0.8511)  loss_giou_dn_0: 1.1827 (1.1827)  loss_giou_dn_1: 1.0938 (1.0938)  loss_giou_dn_2: 1.0525 (1.0525)  loss_giou_dn_3: 1.0309 (1.0309)  loss_giou_dn_4: 1.0089 (1.0089)  loss_giou_dn_5: 1.0049 (1.0049)  loss_giou_enc_0: 1.0764 (1.0764)  loss_vfl: 1.4263 (1.4263)  loss_vfl_aux_0: 1.4004 (1.4004)  loss_vfl_aux_1: 1.4170 (1.4170)  loss_vfl_aux_2: 1.3765 (1.3765)  loss_vfl_aux_3: 1.4893 (1.4893)  loss_vfl_aux_4: 1.4463 (1.4463)  loss_vfl_dn_0: 0.4844 (0.4844)  loss_vfl_dn_1: 0.5376 (0.5376)  loss_vfl_dn_2: 0.5588 (0.5588)  loss_vfl_dn_3: 0.6182 (0.6182)  loss_vfl_dn_4: 0.6450 (0.6450)  loss_vfl_dn_5: 0.6641 (0.6641)  loss_vfl_enc_0: 1.1479 (1.1479)  time: 4.3347  data: 2.6990  max mem: 10356\r\n",
      "Epoch: [21]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 31.0355 (31.2658)  loss_bbox: 0.3765 (0.4010)  loss_bbox_aux_0: 0.4177 (0.4287)  loss_bbox_aux_1: 0.4166 (0.4222)  loss_bbox_aux_2: 0.4055 (0.4099)  loss_bbox_aux_3: 0.3924 (0.4058)  loss_bbox_aux_4: 0.3931 (0.4013)  loss_bbox_dn_0: 0.4091 (0.4465)  loss_bbox_dn_1: 0.3932 (0.4264)  loss_bbox_dn_2: 0.3865 (0.4176)  loss_bbox_dn_3: 0.3804 (0.4118)  loss_bbox_dn_4: 0.3785 (0.4088)  loss_bbox_dn_5: 0.3782 (0.4082)  loss_bbox_enc_0: 0.4509 (0.4780)  loss_giou: 1.2274 (1.1826)  loss_giou_aux_0: 1.2821 (1.2190)  loss_giou_aux_1: 1.2724 (1.2054)  loss_giou_aux_2: 1.2560 (1.1956)  loss_giou_aux_3: 1.2687 (1.1928)  loss_giou_aux_4: 1.2431 (1.1875)  loss_giou_dn_0: 1.2255 (1.2169)  loss_giou_dn_1: 1.1752 (1.1574)  loss_giou_dn_2: 1.1540 (1.1323)  loss_giou_dn_3: 1.1442 (1.1164)  loss_giou_dn_4: 1.1441 (1.1072)  loss_giou_dn_5: 1.1452 (1.1069)  loss_giou_enc_0: 1.3342 (1.3207)  loss_vfl: 1.0098 (1.0730)  loss_vfl_aux_0: 0.8999 (1.0275)  loss_vfl_aux_1: 0.9150 (1.0353)  loss_vfl_aux_2: 0.9487 (1.0423)  loss_vfl_aux_3: 0.9883 (1.0582)  loss_vfl_aux_4: 0.9775 (1.0600)  loss_vfl_dn_0: 0.4506 (0.4677)  loss_vfl_dn_1: 0.4835 (0.5025)  loss_vfl_dn_2: 0.5134 (0.5310)  loss_vfl_dn_3: 0.5446 (0.5607)  loss_vfl_dn_4: 0.5598 (0.5894)  loss_vfl_dn_5: 0.5835 (0.6076)  loss_vfl_enc_0: 0.8101 (0.9035)  time: 0.9828  data: 0.0318  max mem: 10356\r\n",
      "Epoch: [21] Total time: 0:01:25 (1.0877 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 31.0355 (31.2658)  loss_bbox: 0.3765 (0.4010)  loss_bbox_aux_0: 0.4177 (0.4287)  loss_bbox_aux_1: 0.4166 (0.4222)  loss_bbox_aux_2: 0.4055 (0.4099)  loss_bbox_aux_3: 0.3924 (0.4058)  loss_bbox_aux_4: 0.3931 (0.4013)  loss_bbox_dn_0: 0.4091 (0.4465)  loss_bbox_dn_1: 0.3932 (0.4264)  loss_bbox_dn_2: 0.3865 (0.4176)  loss_bbox_dn_3: 0.3804 (0.4118)  loss_bbox_dn_4: 0.3785 (0.4088)  loss_bbox_dn_5: 0.3782 (0.4082)  loss_bbox_enc_0: 0.4509 (0.4780)  loss_giou: 1.2274 (1.1826)  loss_giou_aux_0: 1.2821 (1.2190)  loss_giou_aux_1: 1.2724 (1.2054)  loss_giou_aux_2: 1.2560 (1.1956)  loss_giou_aux_3: 1.2687 (1.1928)  loss_giou_aux_4: 1.2431 (1.1875)  loss_giou_dn_0: 1.2255 (1.2169)  loss_giou_dn_1: 1.1752 (1.1574)  loss_giou_dn_2: 1.1540 (1.1323)  loss_giou_dn_3: 1.1442 (1.1164)  loss_giou_dn_4: 1.1441 (1.1072)  loss_giou_dn_5: 1.1452 (1.1069)  loss_giou_enc_0: 1.3342 (1.3207)  loss_vfl: 1.0098 (1.0730)  loss_vfl_aux_0: 0.8999 (1.0275)  loss_vfl_aux_1: 0.9150 (1.0353)  loss_vfl_aux_2: 0.9487 (1.0423)  loss_vfl_aux_3: 0.9883 (1.0582)  loss_vfl_aux_4: 0.9775 (1.0600)  loss_vfl_dn_0: 0.4506 (0.4677)  loss_vfl_dn_1: 0.4835 (0.5025)  loss_vfl_dn_2: 0.5134 (0.5310)  loss_vfl_dn_3: 0.5446 (0.5607)  loss_vfl_dn_4: 0.5598 (0.5894)  loss_vfl_dn_5: 0.5835 (0.6076)  loss_vfl_enc_0: 0.8101 (0.9035)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.4468  data: 1.4990  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0992  data: 0.2356  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1163 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.19s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.009\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.013\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.009\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.019\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.115\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.169\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.178\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.045\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.269\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.231\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.265\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.194\r\n",
      "best_stat: {'epoch': 21, 'coco_eval_bbox': 0.008643489902262266}\r\n",
      "Epoch: [22]  [ 0/79]  eta: 0:05:13  lr: 0.000020  loss: 32.4505 (32.4505)  loss_bbox: 0.5690 (0.5690)  loss_bbox_aux_0: 0.5855 (0.5855)  loss_bbox_aux_1: 0.5720 (0.5720)  loss_bbox_aux_2: 0.5739 (0.5739)  loss_bbox_aux_3: 0.5712 (0.5712)  loss_bbox_aux_4: 0.5685 (0.5685)  loss_bbox_dn_0: 0.5727 (0.5727)  loss_bbox_dn_1: 0.5664 (0.5664)  loss_bbox_dn_2: 0.5609 (0.5609)  loss_bbox_dn_3: 0.5595 (0.5595)  loss_bbox_dn_4: 0.5623 (0.5623)  loss_bbox_dn_5: 0.5635 (0.5635)  loss_bbox_enc_0: 0.6359 (0.6359)  loss_giou: 1.1322 (1.1322)  loss_giou_aux_0: 1.1928 (1.1928)  loss_giou_aux_1: 1.1380 (1.1380)  loss_giou_aux_2: 1.1318 (1.1318)  loss_giou_aux_3: 1.1309 (1.1309)  loss_giou_aux_4: 1.1407 (1.1407)  loss_giou_dn_0: 1.2238 (1.2238)  loss_giou_dn_1: 1.1681 (1.1681)  loss_giou_dn_2: 1.1440 (1.1440)  loss_giou_dn_3: 1.1287 (1.1287)  loss_giou_dn_4: 1.1205 (1.1205)  loss_giou_dn_5: 1.1203 (1.1203)  loss_giou_enc_0: 1.3377 (1.3377)  loss_vfl: 1.0110 (1.0110)  loss_vfl_aux_0: 0.9390 (0.9390)  loss_vfl_aux_1: 1.0439 (1.0439)  loss_vfl_aux_2: 1.0166 (1.0166)  loss_vfl_aux_3: 0.9978 (0.9978)  loss_vfl_aux_4: 0.9863 (0.9863)  loss_vfl_dn_0: 0.4537 (0.4537)  loss_vfl_dn_1: 0.4901 (0.4901)  loss_vfl_dn_2: 0.5089 (0.5089)  loss_vfl_dn_3: 0.5297 (0.5297)  loss_vfl_dn_4: 0.5411 (0.5411)  loss_vfl_dn_5: 0.5470 (0.5470)  loss_vfl_enc_0: 0.8145 (0.8145)  time: 3.9731  data: 2.5735  max mem: 10356\r\n",
      "Epoch: [22]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 31.7298 (31.1322)  loss_bbox: 0.4213 (0.3877)  loss_bbox_aux_0: 0.4503 (0.4174)  loss_bbox_aux_1: 0.4345 (0.4149)  loss_bbox_aux_2: 0.4197 (0.4041)  loss_bbox_aux_3: 0.4330 (0.3993)  loss_bbox_aux_4: 0.4067 (0.3907)  loss_bbox_dn_0: 0.4347 (0.4616)  loss_bbox_dn_1: 0.4091 (0.4396)  loss_bbox_dn_2: 0.3976 (0.4289)  loss_bbox_dn_3: 0.3905 (0.4223)  loss_bbox_dn_4: 0.3855 (0.4184)  loss_bbox_dn_5: 0.3852 (0.4179)  loss_bbox_enc_0: 0.4846 (0.4639)  loss_giou: 1.2515 (1.1742)  loss_giou_aux_0: 1.2799 (1.2112)  loss_giou_aux_1: 1.2634 (1.1964)  loss_giou_aux_2: 1.2703 (1.1855)  loss_giou_aux_3: 1.2583 (1.1835)  loss_giou_aux_4: 1.2774 (1.1765)  loss_giou_dn_0: 1.2075 (1.2112)  loss_giou_dn_1: 1.1352 (1.1481)  loss_giou_dn_2: 1.1033 (1.1198)  loss_giou_dn_3: 1.0970 (1.1037)  loss_giou_dn_4: 1.0858 (1.0931)  loss_giou_dn_5: 1.0871 (1.0923)  loss_giou_enc_0: 1.3929 (1.3038)  loss_vfl: 0.9104 (1.0637)  loss_vfl_aux_0: 0.8894 (1.0296)  loss_vfl_aux_1: 0.9236 (1.0314)  loss_vfl_aux_2: 0.9319 (1.0437)  loss_vfl_aux_3: 0.9089 (1.0542)  loss_vfl_aux_4: 0.8870 (1.0595)  loss_vfl_dn_0: 0.4596 (0.4674)  loss_vfl_dn_1: 0.4902 (0.5027)  loss_vfl_dn_2: 0.5133 (0.5307)  loss_vfl_dn_3: 0.5380 (0.5613)  loss_vfl_dn_4: 0.5592 (0.5877)  loss_vfl_dn_5: 0.5822 (0.6051)  loss_vfl_enc_0: 0.8301 (0.9292)  time: 0.9936  data: 0.0310  max mem: 10356\r\n",
      "Epoch: [22] Total time: 0:01:24 (1.0720 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 31.7298 (31.1322)  loss_bbox: 0.4213 (0.3877)  loss_bbox_aux_0: 0.4503 (0.4174)  loss_bbox_aux_1: 0.4345 (0.4149)  loss_bbox_aux_2: 0.4197 (0.4041)  loss_bbox_aux_3: 0.4330 (0.3993)  loss_bbox_aux_4: 0.4067 (0.3907)  loss_bbox_dn_0: 0.4347 (0.4616)  loss_bbox_dn_1: 0.4091 (0.4396)  loss_bbox_dn_2: 0.3976 (0.4289)  loss_bbox_dn_3: 0.3905 (0.4223)  loss_bbox_dn_4: 0.3855 (0.4184)  loss_bbox_dn_5: 0.3852 (0.4179)  loss_bbox_enc_0: 0.4846 (0.4639)  loss_giou: 1.2515 (1.1742)  loss_giou_aux_0: 1.2799 (1.2112)  loss_giou_aux_1: 1.2634 (1.1964)  loss_giou_aux_2: 1.2703 (1.1855)  loss_giou_aux_3: 1.2583 (1.1835)  loss_giou_aux_4: 1.2774 (1.1765)  loss_giou_dn_0: 1.2075 (1.2112)  loss_giou_dn_1: 1.1352 (1.1481)  loss_giou_dn_2: 1.1033 (1.1198)  loss_giou_dn_3: 1.0970 (1.1037)  loss_giou_dn_4: 1.0858 (1.0931)  loss_giou_dn_5: 1.0871 (1.0923)  loss_giou_enc_0: 1.3929 (1.3038)  loss_vfl: 0.9104 (1.0637)  loss_vfl_aux_0: 0.8894 (1.0296)  loss_vfl_aux_1: 0.9236 (1.0314)  loss_vfl_aux_2: 0.9319 (1.0437)  loss_vfl_aux_3: 0.9089 (1.0542)  loss_vfl_aux_4: 0.8870 (1.0595)  loss_vfl_dn_0: 0.4596 (0.4674)  loss_vfl_dn_1: 0.4902 (0.5027)  loss_vfl_dn_2: 0.5133 (0.5307)  loss_vfl_dn_3: 0.5380 (0.5613)  loss_vfl_dn_4: 0.5592 (0.5877)  loss_vfl_dn_5: 0.5822 (0.6051)  loss_vfl_enc_0: 0.8301 (0.9292)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3631  data: 1.3764  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0848  data: 0.2260  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1027 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.19s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.009\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.013\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.009\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.019\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.025\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.106\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.154\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.161\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.043\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.237\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.245\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.256\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.172\r\n",
      "best_stat: {'epoch': 22, 'coco_eval_bbox': 0.00870606415383243}\r\n",
      "Epoch: [23]  [ 0/79]  eta: 0:05:04  lr: 0.000020  loss: 32.3057 (32.3057)  loss_bbox: 0.4850 (0.4850)  loss_bbox_aux_0: 0.4921 (0.4921)  loss_bbox_aux_1: 0.5026 (0.5026)  loss_bbox_aux_2: 0.4916 (0.4916)  loss_bbox_aux_3: 0.4946 (0.4946)  loss_bbox_aux_4: 0.4945 (0.4945)  loss_bbox_dn_0: 0.5370 (0.5370)  loss_bbox_dn_1: 0.5096 (0.5096)  loss_bbox_dn_2: 0.4963 (0.4963)  loss_bbox_dn_3: 0.4885 (0.4885)  loss_bbox_dn_4: 0.4826 (0.4826)  loss_bbox_dn_5: 0.4824 (0.4824)  loss_bbox_enc_0: 0.5624 (0.5624)  loss_giou: 1.3246 (1.3246)  loss_giou_aux_0: 1.3179 (1.3179)  loss_giou_aux_1: 1.3483 (1.3483)  loss_giou_aux_2: 1.3428 (1.3428)  loss_giou_aux_3: 1.3431 (1.3431)  loss_giou_aux_4: 1.3126 (1.3126)  loss_giou_dn_0: 1.2814 (1.2814)  loss_giou_dn_1: 1.2292 (1.2292)  loss_giou_dn_2: 1.2076 (1.2076)  loss_giou_dn_3: 1.1934 (1.1934)  loss_giou_dn_4: 1.1824 (1.1824)  loss_giou_dn_5: 1.1826 (1.1826)  loss_giou_enc_0: 1.4128 (1.4128)  loss_vfl: 0.8801 (0.8801)  loss_vfl_aux_0: 0.9346 (0.9346)  loss_vfl_aux_1: 0.8091 (0.8091)  loss_vfl_aux_2: 0.8440 (0.8440)  loss_vfl_aux_3: 0.8589 (0.8589)  loss_vfl_aux_4: 0.8958 (0.8958)  loss_vfl_dn_0: 0.4504 (0.4504)  loss_vfl_dn_1: 0.4802 (0.4802)  loss_vfl_dn_2: 0.5029 (0.5029)  loss_vfl_dn_3: 0.5195 (0.5195)  loss_vfl_dn_4: 0.5476 (0.5476)  loss_vfl_dn_5: 0.5676 (0.5676)  loss_vfl_enc_0: 0.8169 (0.8169)  time: 3.8592  data: 2.5011  max mem: 10356\r\n",
      "Epoch: [23]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 30.6230 (31.0163)  loss_bbox: 0.3835 (0.3954)  loss_bbox_aux_0: 0.4037 (0.4213)  loss_bbox_aux_1: 0.4041 (0.4146)  loss_bbox_aux_2: 0.3842 (0.4081)  loss_bbox_aux_3: 0.4108 (0.4035)  loss_bbox_aux_4: 0.3998 (0.3983)  loss_bbox_dn_0: 0.4439 (0.4463)  loss_bbox_dn_1: 0.4216 (0.4252)  loss_bbox_dn_2: 0.4194 (0.4147)  loss_bbox_dn_3: 0.4229 (0.4087)  loss_bbox_dn_4: 0.4312 (0.4051)  loss_bbox_dn_5: 0.4329 (0.4046)  loss_bbox_enc_0: 0.4503 (0.4666)  loss_giou: 1.0797 (1.1693)  loss_giou_aux_0: 1.1114 (1.2000)  loss_giou_aux_1: 1.1045 (1.1880)  loss_giou_aux_2: 1.0863 (1.1804)  loss_giou_aux_3: 1.0627 (1.1758)  loss_giou_aux_4: 1.0575 (1.1681)  loss_giou_dn_0: 1.1865 (1.2044)  loss_giou_dn_1: 1.1084 (1.1422)  loss_giou_dn_2: 1.0785 (1.1155)  loss_giou_dn_3: 1.0549 (1.0993)  loss_giou_dn_4: 1.0450 (1.0896)  loss_giou_dn_5: 1.0437 (1.0893)  loss_giou_enc_0: 1.2113 (1.2856)  loss_vfl: 1.1172 (1.0669)  loss_vfl_aux_0: 1.0784 (1.0373)  loss_vfl_aux_1: 1.0957 (1.0381)  loss_vfl_aux_2: 1.1072 (1.0448)  loss_vfl_aux_3: 1.0906 (1.0529)  loss_vfl_aux_4: 1.1157 (1.0613)  loss_vfl_dn_0: 0.4680 (0.4714)  loss_vfl_dn_1: 0.5063 (0.5052)  loss_vfl_dn_2: 0.5349 (0.5316)  loss_vfl_dn_3: 0.5686 (0.5623)  loss_vfl_dn_4: 0.5963 (0.5874)  loss_vfl_dn_5: 0.5994 (0.6056)  loss_vfl_enc_0: 0.9568 (0.9317)  time: 0.9546  data: 0.0316  max mem: 10356\r\n",
      "Epoch: [23] Total time: 0:01:25 (1.0794 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 30.6230 (31.0163)  loss_bbox: 0.3835 (0.3954)  loss_bbox_aux_0: 0.4037 (0.4213)  loss_bbox_aux_1: 0.4041 (0.4146)  loss_bbox_aux_2: 0.3842 (0.4081)  loss_bbox_aux_3: 0.4108 (0.4035)  loss_bbox_aux_4: 0.3998 (0.3983)  loss_bbox_dn_0: 0.4439 (0.4463)  loss_bbox_dn_1: 0.4216 (0.4252)  loss_bbox_dn_2: 0.4194 (0.4147)  loss_bbox_dn_3: 0.4229 (0.4087)  loss_bbox_dn_4: 0.4312 (0.4051)  loss_bbox_dn_5: 0.4329 (0.4046)  loss_bbox_enc_0: 0.4503 (0.4666)  loss_giou: 1.0797 (1.1693)  loss_giou_aux_0: 1.1114 (1.2000)  loss_giou_aux_1: 1.1045 (1.1880)  loss_giou_aux_2: 1.0863 (1.1804)  loss_giou_aux_3: 1.0627 (1.1758)  loss_giou_aux_4: 1.0575 (1.1681)  loss_giou_dn_0: 1.1865 (1.2044)  loss_giou_dn_1: 1.1084 (1.1422)  loss_giou_dn_2: 1.0785 (1.1155)  loss_giou_dn_3: 1.0549 (1.0993)  loss_giou_dn_4: 1.0450 (1.0896)  loss_giou_dn_5: 1.0437 (1.0893)  loss_giou_enc_0: 1.2113 (1.2856)  loss_vfl: 1.1172 (1.0669)  loss_vfl_aux_0: 1.0784 (1.0373)  loss_vfl_aux_1: 1.0957 (1.0381)  loss_vfl_aux_2: 1.1072 (1.0448)  loss_vfl_aux_3: 1.0906 (1.0529)  loss_vfl_aux_4: 1.1157 (1.0613)  loss_vfl_dn_0: 0.4680 (0.4714)  loss_vfl_dn_1: 0.5063 (0.5052)  loss_vfl_dn_2: 0.5349 (0.5316)  loss_vfl_dn_3: 0.5686 (0.5623)  loss_vfl_dn_4: 0.5963 (0.5874)  loss_vfl_dn_5: 0.5994 (0.6056)  loss_vfl_enc_0: 0.9568 (0.9317)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3714  data: 1.4057  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0809  data: 0.2235  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0999 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.19s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.015\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.011\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.021\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.021\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.116\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.172\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.182\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.044\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.271\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.252\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.274\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.204\r\n",
      "best_stat: {'epoch': 23, 'coco_eval_bbox': 0.009539567979990633}\r\n",
      "Epoch: [24]  [ 0/79]  eta: 0:05:19  lr: 0.000020  loss: 32.1923 (32.1923)  loss_bbox: 0.5001 (0.5001)  loss_bbox_aux_0: 0.4749 (0.4749)  loss_bbox_aux_1: 0.4889 (0.4889)  loss_bbox_aux_2: 0.5137 (0.5137)  loss_bbox_aux_3: 0.4864 (0.4864)  loss_bbox_aux_4: 0.4938 (0.4938)  loss_bbox_dn_0: 0.5660 (0.5660)  loss_bbox_dn_1: 0.5491 (0.5491)  loss_bbox_dn_2: 0.5407 (0.5407)  loss_bbox_dn_3: 0.5336 (0.5336)  loss_bbox_dn_4: 0.5315 (0.5315)  loss_bbox_dn_5: 0.5309 (0.5309)  loss_bbox_enc_0: 0.4768 (0.4768)  loss_giou: 1.2789 (1.2789)  loss_giou_aux_0: 1.3152 (1.3152)  loss_giou_aux_1: 1.3064 (1.3064)  loss_giou_aux_2: 1.2882 (1.2882)  loss_giou_aux_3: 1.3095 (1.3095)  loss_giou_aux_4: 1.2620 (1.2620)  loss_giou_dn_0: 1.2511 (1.2511)  loss_giou_dn_1: 1.2199 (1.2199)  loss_giou_dn_2: 1.2009 (1.2009)  loss_giou_dn_3: 1.1877 (1.1877)  loss_giou_dn_4: 1.1848 (1.1848)  loss_giou_dn_5: 1.1835 (1.1835)  loss_giou_enc_0: 1.3448 (1.3448)  loss_vfl: 0.9204 (0.9204)  loss_vfl_aux_0: 0.8806 (0.8806)  loss_vfl_aux_1: 0.8784 (0.8784)  loss_vfl_aux_2: 0.8687 (0.8687)  loss_vfl_aux_3: 0.8914 (0.8914)  loss_vfl_aux_4: 0.9158 (0.9158)  loss_vfl_dn_0: 0.4496 (0.4496)  loss_vfl_dn_1: 0.4607 (0.4607)  loss_vfl_dn_2: 0.4700 (0.4700)  loss_vfl_dn_3: 0.5052 (0.5052)  loss_vfl_dn_4: 0.5164 (0.5164)  loss_vfl_dn_5: 0.5328 (0.5328)  loss_vfl_enc_0: 0.8828 (0.8828)  time: 4.0390  data: 2.4733  max mem: 10356\r\n",
      "Epoch: [24]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 30.3524 (30.9987)  loss_bbox: 0.3524 (0.3899)  loss_bbox_aux_0: 0.3690 (0.4178)  loss_bbox_aux_1: 0.3777 (0.4137)  loss_bbox_aux_2: 0.3652 (0.4035)  loss_bbox_aux_3: 0.3558 (0.3971)  loss_bbox_aux_4: 0.3639 (0.3943)  loss_bbox_dn_0: 0.4047 (0.4511)  loss_bbox_dn_1: 0.3720 (0.4295)  loss_bbox_dn_2: 0.3583 (0.4186)  loss_bbox_dn_3: 0.3498 (0.4126)  loss_bbox_dn_4: 0.3440 (0.4084)  loss_bbox_dn_5: 0.3434 (0.4077)  loss_bbox_enc_0: 0.3830 (0.4653)  loss_giou: 1.1048 (1.1450)  loss_giou_aux_0: 1.1237 (1.1823)  loss_giou_aux_1: 1.1043 (1.1654)  loss_giou_aux_2: 1.1089 (1.1556)  loss_giou_aux_3: 1.0969 (1.1499)  loss_giou_aux_4: 1.0964 (1.1453)  loss_giou_dn_0: 1.1872 (1.1978)  loss_giou_dn_1: 1.1143 (1.1314)  loss_giou_dn_2: 1.0715 (1.1027)  loss_giou_dn_3: 1.0467 (1.0848)  loss_giou_dn_4: 1.0318 (1.0739)  loss_giou_dn_5: 1.0322 (1.0732)  loss_giou_enc_0: 1.1758 (1.2663)  loss_vfl: 1.1411 (1.0898)  loss_vfl_aux_0: 1.1355 (1.0719)  loss_vfl_aux_1: 1.1108 (1.0686)  loss_vfl_aux_2: 1.1116 (1.0717)  loss_vfl_aux_3: 1.1562 (1.0876)  loss_vfl_aux_4: 1.1050 (1.0861)  loss_vfl_dn_0: 0.4707 (0.4741)  loss_vfl_dn_1: 0.5156 (0.5084)  loss_vfl_dn_2: 0.5369 (0.5349)  loss_vfl_dn_3: 0.5654 (0.5647)  loss_vfl_dn_4: 0.5901 (0.5903)  loss_vfl_dn_5: 0.6106 (0.6074)  loss_vfl_enc_0: 1.0083 (0.9604)  time: 1.0045  data: 0.0306  max mem: 10356\r\n",
      "Epoch: [24] Total time: 0:01:26 (1.0968 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 30.3524 (30.9987)  loss_bbox: 0.3524 (0.3899)  loss_bbox_aux_0: 0.3690 (0.4178)  loss_bbox_aux_1: 0.3777 (0.4137)  loss_bbox_aux_2: 0.3652 (0.4035)  loss_bbox_aux_3: 0.3558 (0.3971)  loss_bbox_aux_4: 0.3639 (0.3943)  loss_bbox_dn_0: 0.4047 (0.4511)  loss_bbox_dn_1: 0.3720 (0.4295)  loss_bbox_dn_2: 0.3583 (0.4186)  loss_bbox_dn_3: 0.3498 (0.4126)  loss_bbox_dn_4: 0.3440 (0.4084)  loss_bbox_dn_5: 0.3434 (0.4077)  loss_bbox_enc_0: 0.3830 (0.4653)  loss_giou: 1.1048 (1.1450)  loss_giou_aux_0: 1.1237 (1.1823)  loss_giou_aux_1: 1.1043 (1.1654)  loss_giou_aux_2: 1.1089 (1.1556)  loss_giou_aux_3: 1.0969 (1.1499)  loss_giou_aux_4: 1.0964 (1.1453)  loss_giou_dn_0: 1.1872 (1.1978)  loss_giou_dn_1: 1.1143 (1.1314)  loss_giou_dn_2: 1.0715 (1.1027)  loss_giou_dn_3: 1.0467 (1.0848)  loss_giou_dn_4: 1.0318 (1.0739)  loss_giou_dn_5: 1.0322 (1.0732)  loss_giou_enc_0: 1.1758 (1.2663)  loss_vfl: 1.1411 (1.0898)  loss_vfl_aux_0: 1.1355 (1.0719)  loss_vfl_aux_1: 1.1108 (1.0686)  loss_vfl_aux_2: 1.1116 (1.0717)  loss_vfl_aux_3: 1.1562 (1.0876)  loss_vfl_aux_4: 1.1050 (1.0861)  loss_vfl_dn_0: 0.4707 (0.4741)  loss_vfl_dn_1: 0.5156 (0.5084)  loss_vfl_dn_2: 0.5369 (0.5349)  loss_vfl_dn_3: 0.5654 (0.5647)  loss_vfl_dn_4: 0.5901 (0.5903)  loss_vfl_dn_5: 0.6106 (0.6074)  loss_vfl_enc_0: 1.0083 (0.9604)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.1689  data: 1.2159  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0688  data: 0.2119  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0850 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.20s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.010\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.019\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.013\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.108\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.159\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.167\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.045\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.263\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.215\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.268\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.168\r\n",
      "best_stat: {'epoch': 23, 'coco_eval_bbox': 0.009539567979990633}\r\n",
      "Epoch: [25]  [ 0/79]  eta: 0:06:25  lr: 0.000020  loss: 30.9610 (30.9610)  loss_bbox: 0.4495 (0.4495)  loss_bbox_aux_0: 0.4089 (0.4089)  loss_bbox_aux_1: 0.4483 (0.4483)  loss_bbox_aux_2: 0.4215 (0.4215)  loss_bbox_aux_3: 0.4338 (0.4338)  loss_bbox_aux_4: 0.4495 (0.4495)  loss_bbox_dn_0: 0.2312 (0.2312)  loss_bbox_dn_1: 0.2160 (0.2160)  loss_bbox_dn_2: 0.2070 (0.2070)  loss_bbox_dn_3: 0.2030 (0.2030)  loss_bbox_dn_4: 0.1994 (0.1994)  loss_bbox_dn_5: 0.1988 (0.1988)  loss_bbox_enc_0: 0.4259 (0.4259)  loss_giou: 1.3688 (1.3688)  loss_giou_aux_0: 1.4035 (1.4035)  loss_giou_aux_1: 1.3766 (1.3766)  loss_giou_aux_2: 1.3693 (1.3693)  loss_giou_aux_3: 1.3890 (1.3890)  loss_giou_aux_4: 1.3522 (1.3522)  loss_giou_dn_0: 1.1893 (1.1893)  loss_giou_dn_1: 1.1443 (1.1443)  loss_giou_dn_2: 1.1363 (1.1363)  loss_giou_dn_3: 1.1212 (1.1212)  loss_giou_dn_4: 1.1043 (1.1043)  loss_giou_dn_5: 1.1016 (1.1016)  loss_giou_enc_0: 1.4595 (1.4595)  loss_vfl: 1.0129 (1.0129)  loss_vfl_aux_0: 0.9717 (0.9717)  loss_vfl_aux_1: 0.9680 (0.9680)  loss_vfl_aux_2: 0.9990 (0.9990)  loss_vfl_aux_3: 1.0173 (1.0173)  loss_vfl_aux_4: 1.0417 (1.0417)  loss_vfl_dn_0: 0.4813 (0.4813)  loss_vfl_dn_1: 0.5125 (0.5125)  loss_vfl_dn_2: 0.5425 (0.5425)  loss_vfl_dn_3: 0.5577 (0.5577)  loss_vfl_dn_4: 0.5957 (0.5957)  loss_vfl_dn_5: 0.6052 (0.6052)  loss_vfl_enc_0: 0.8467 (0.8467)  time: 4.8740  data: 3.0110  max mem: 10356\r\n",
      "Epoch: [25]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 31.1914 (30.9410)  loss_bbox: 0.3733 (0.3852)  loss_bbox_aux_0: 0.3884 (0.4095)  loss_bbox_aux_1: 0.3866 (0.4061)  loss_bbox_aux_2: 0.3875 (0.3982)  loss_bbox_aux_3: 0.3921 (0.3932)  loss_bbox_aux_4: 0.3761 (0.3865)  loss_bbox_dn_0: 0.4465 (0.4508)  loss_bbox_dn_1: 0.4340 (0.4285)  loss_bbox_dn_2: 0.4276 (0.4176)  loss_bbox_dn_3: 0.4262 (0.4112)  loss_bbox_dn_4: 0.4265 (0.4077)  loss_bbox_dn_5: 0.4252 (0.4071)  loss_bbox_enc_0: 0.4372 (0.4522)  loss_giou: 1.1525 (1.1562)  loss_giou_aux_0: 1.1529 (1.1878)  loss_giou_aux_1: 1.1747 (1.1773)  loss_giou_aux_2: 1.1461 (1.1677)  loss_giou_aux_3: 1.1686 (1.1640)  loss_giou_aux_4: 1.1544 (1.1562)  loss_giou_dn_0: 1.1768 (1.1877)  loss_giou_dn_1: 1.1068 (1.1219)  loss_giou_dn_2: 1.0777 (1.0944)  loss_giou_dn_3: 1.0714 (1.0783)  loss_giou_dn_4: 1.0640 (1.0686)  loss_giou_dn_5: 1.0614 (1.0678)  loss_giou_enc_0: 1.2503 (1.2684)  loss_vfl: 1.0713 (1.0840)  loss_vfl_aux_0: 1.0354 (1.0658)  loss_vfl_aux_1: 1.0176 (1.0551)  loss_vfl_aux_2: 1.0376 (1.0631)  loss_vfl_aux_3: 1.0557 (1.0767)  loss_vfl_aux_4: 1.0632 (1.0835)  loss_vfl_dn_0: 0.4766 (0.4775)  loss_vfl_dn_1: 0.5106 (0.5118)  loss_vfl_dn_2: 0.5247 (0.5375)  loss_vfl_dn_3: 0.5588 (0.5660)  loss_vfl_dn_4: 0.5836 (0.5928)  loss_vfl_dn_5: 0.5992 (0.6062)  loss_vfl_enc_0: 0.9519 (0.9707)  time: 0.9824  data: 0.0351  max mem: 10356\r\n",
      "Epoch: [25] Total time: 0:01:24 (1.0747 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 31.1914 (30.9410)  loss_bbox: 0.3733 (0.3852)  loss_bbox_aux_0: 0.3884 (0.4095)  loss_bbox_aux_1: 0.3866 (0.4061)  loss_bbox_aux_2: 0.3875 (0.3982)  loss_bbox_aux_3: 0.3921 (0.3932)  loss_bbox_aux_4: 0.3761 (0.3865)  loss_bbox_dn_0: 0.4465 (0.4508)  loss_bbox_dn_1: 0.4340 (0.4285)  loss_bbox_dn_2: 0.4276 (0.4176)  loss_bbox_dn_3: 0.4262 (0.4112)  loss_bbox_dn_4: 0.4265 (0.4077)  loss_bbox_dn_5: 0.4252 (0.4071)  loss_bbox_enc_0: 0.4372 (0.4522)  loss_giou: 1.1525 (1.1562)  loss_giou_aux_0: 1.1529 (1.1878)  loss_giou_aux_1: 1.1747 (1.1773)  loss_giou_aux_2: 1.1461 (1.1677)  loss_giou_aux_3: 1.1686 (1.1640)  loss_giou_aux_4: 1.1544 (1.1562)  loss_giou_dn_0: 1.1768 (1.1877)  loss_giou_dn_1: 1.1068 (1.1219)  loss_giou_dn_2: 1.0777 (1.0944)  loss_giou_dn_3: 1.0714 (1.0783)  loss_giou_dn_4: 1.0640 (1.0686)  loss_giou_dn_5: 1.0614 (1.0678)  loss_giou_enc_0: 1.2503 (1.2684)  loss_vfl: 1.0713 (1.0840)  loss_vfl_aux_0: 1.0354 (1.0658)  loss_vfl_aux_1: 1.0176 (1.0551)  loss_vfl_aux_2: 1.0376 (1.0631)  loss_vfl_aux_3: 1.0557 (1.0767)  loss_vfl_aux_4: 1.0632 (1.0835)  loss_vfl_dn_0: 0.4766 (0.4775)  loss_vfl_dn_1: 0.5106 (0.5118)  loss_vfl_dn_2: 0.5247 (0.5375)  loss_vfl_dn_3: 0.5588 (0.5660)  loss_vfl_dn_4: 0.5836 (0.5928)  loss_vfl_dn_5: 0.5992 (0.6062)  loss_vfl_enc_0: 0.9519 (0.9707)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.2953  data: 1.3353  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0820  data: 0.2201  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0988 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.012\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.031\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.018\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.107\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.153\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.160\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.047\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.256\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.200\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.255\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.155\r\n",
      "best_stat: {'epoch': 23, 'coco_eval_bbox': 0.009539567979990633}\r\n",
      "Epoch: [26]  [ 0/79]  eta: 0:06:35  lr: 0.000020  loss: 30.8716 (30.8716)  loss_bbox: 0.3033 (0.3033)  loss_bbox_aux_0: 0.3491 (0.3491)  loss_bbox_aux_1: 0.3316 (0.3316)  loss_bbox_aux_2: 0.3084 (0.3084)  loss_bbox_aux_3: 0.3021 (0.3021)  loss_bbox_aux_4: 0.3035 (0.3035)  loss_bbox_dn_0: 0.5824 (0.5824)  loss_bbox_dn_1: 0.5377 (0.5377)  loss_bbox_dn_2: 0.5153 (0.5153)  loss_bbox_dn_3: 0.5004 (0.5004)  loss_bbox_dn_4: 0.4937 (0.4937)  loss_bbox_dn_5: 0.4923 (0.4923)  loss_bbox_enc_0: 0.4123 (0.4123)  loss_giou: 0.8601 (0.8601)  loss_giou_aux_0: 0.9369 (0.9369)  loss_giou_aux_1: 0.9340 (0.9340)  loss_giou_aux_2: 0.8653 (0.8653)  loss_giou_aux_3: 0.8784 (0.8784)  loss_giou_aux_4: 0.8645 (0.8645)  loss_giou_dn_0: 1.1458 (1.1458)  loss_giou_dn_1: 1.0566 (1.0566)  loss_giou_dn_2: 1.0145 (1.0145)  loss_giou_dn_3: 0.9908 (0.9908)  loss_giou_dn_4: 0.9766 (0.9766)  loss_giou_dn_5: 0.9756 (0.9756)  loss_giou_enc_0: 1.0437 (1.0437)  loss_vfl: 1.3794 (1.3794)  loss_vfl_aux_0: 1.3123 (1.3123)  loss_vfl_aux_1: 1.3115 (1.3115)  loss_vfl_aux_2: 1.3396 (1.3396)  loss_vfl_aux_3: 1.3787 (1.3787)  loss_vfl_aux_4: 1.3809 (1.3809)  loss_vfl_dn_0: 0.4871 (0.4871)  loss_vfl_dn_1: 0.5380 (0.5380)  loss_vfl_dn_2: 0.5701 (0.5701)  loss_vfl_dn_3: 0.6182 (0.6182)  loss_vfl_dn_4: 0.6479 (0.6479)  loss_vfl_dn_5: 0.6754 (0.6754)  loss_vfl_enc_0: 1.2578 (1.2578)  time: 5.0069  data: 3.2416  max mem: 10356\r\n",
      "Epoch: [26]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 30.8720 (30.8556)  loss_bbox: 0.3559 (0.3787)  loss_bbox_aux_0: 0.3674 (0.4027)  loss_bbox_aux_1: 0.3613 (0.3963)  loss_bbox_aux_2: 0.3522 (0.3874)  loss_bbox_aux_3: 0.3534 (0.3822)  loss_bbox_aux_4: 0.3514 (0.3800)  loss_bbox_dn_0: 0.4540 (0.4427)  loss_bbox_dn_1: 0.4289 (0.4197)  loss_bbox_dn_2: 0.4171 (0.4087)  loss_bbox_dn_3: 0.4117 (0.4025)  loss_bbox_dn_4: 0.4162 (0.3989)  loss_bbox_dn_5: 0.4165 (0.3983)  loss_bbox_enc_0: 0.4261 (0.4473)  loss_giou: 1.1034 (1.1421)  loss_giou_aux_0: 1.1479 (1.1823)  loss_giou_aux_1: 1.1484 (1.1691)  loss_giou_aux_2: 1.1226 (1.1571)  loss_giou_aux_3: 1.1277 (1.1484)  loss_giou_aux_4: 1.1331 (1.1454)  loss_giou_dn_0: 1.1790 (1.1939)  loss_giou_dn_1: 1.1032 (1.1278)  loss_giou_dn_2: 1.0703 (1.0992)  loss_giou_dn_3: 1.0555 (1.0830)  loss_giou_dn_4: 1.0444 (1.0737)  loss_giou_dn_5: 1.0453 (1.0741)  loss_giou_enc_0: 1.2296 (1.2712)  loss_vfl: 1.1074 (1.0927)  loss_vfl_aux_0: 1.0625 (1.0715)  loss_vfl_aux_1: 1.0767 (1.0753)  loss_vfl_aux_2: 1.0586 (1.0772)  loss_vfl_aux_3: 1.1089 (1.0938)  loss_vfl_aux_4: 1.1128 (1.0903)  loss_vfl_dn_0: 0.4755 (0.4761)  loss_vfl_dn_1: 0.5197 (0.5112)  loss_vfl_dn_2: 0.5469 (0.5363)  loss_vfl_dn_3: 0.5786 (0.5650)  loss_vfl_dn_4: 0.6055 (0.5902)  loss_vfl_dn_5: 0.6150 (0.6072)  loss_vfl_enc_0: 0.9644 (0.9563)  time: 1.0092  data: 0.0330  max mem: 10356\r\n",
      "Epoch: [26] Total time: 0:01:26 (1.0985 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 30.8720 (30.8556)  loss_bbox: 0.3559 (0.3787)  loss_bbox_aux_0: 0.3674 (0.4027)  loss_bbox_aux_1: 0.3613 (0.3963)  loss_bbox_aux_2: 0.3522 (0.3874)  loss_bbox_aux_3: 0.3534 (0.3822)  loss_bbox_aux_4: 0.3514 (0.3800)  loss_bbox_dn_0: 0.4540 (0.4427)  loss_bbox_dn_1: 0.4289 (0.4197)  loss_bbox_dn_2: 0.4171 (0.4087)  loss_bbox_dn_3: 0.4117 (0.4025)  loss_bbox_dn_4: 0.4162 (0.3989)  loss_bbox_dn_5: 0.4165 (0.3983)  loss_bbox_enc_0: 0.4261 (0.4473)  loss_giou: 1.1034 (1.1421)  loss_giou_aux_0: 1.1479 (1.1823)  loss_giou_aux_1: 1.1484 (1.1691)  loss_giou_aux_2: 1.1226 (1.1571)  loss_giou_aux_3: 1.1277 (1.1484)  loss_giou_aux_4: 1.1331 (1.1454)  loss_giou_dn_0: 1.1790 (1.1939)  loss_giou_dn_1: 1.1032 (1.1278)  loss_giou_dn_2: 1.0703 (1.0992)  loss_giou_dn_3: 1.0555 (1.0830)  loss_giou_dn_4: 1.0444 (1.0737)  loss_giou_dn_5: 1.0453 (1.0741)  loss_giou_enc_0: 1.2296 (1.2712)  loss_vfl: 1.1074 (1.0927)  loss_vfl_aux_0: 1.0625 (1.0715)  loss_vfl_aux_1: 1.0767 (1.0753)  loss_vfl_aux_2: 1.0586 (1.0772)  loss_vfl_aux_3: 1.1089 (1.0938)  loss_vfl_aux_4: 1.1128 (1.0903)  loss_vfl_dn_0: 0.4755 (0.4761)  loss_vfl_dn_1: 0.5197 (0.5112)  loss_vfl_dn_2: 0.5469 (0.5363)  loss_vfl_dn_3: 0.5786 (0.5650)  loss_vfl_dn_4: 0.6055 (0.5902)  loss_vfl_dn_5: 0.6150 (0.6072)  loss_vfl_enc_0: 0.9644 (0.9563)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.2585  data: 1.2893  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0728  data: 0.2158  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0902 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.014\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.019\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.015\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.031\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.023\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.127\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.171\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.179\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.044\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.258\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.234\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.259\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.187\r\n",
      "best_stat: {'epoch': 26, 'coco_eval_bbox': 0.014030793290516257}\r\n",
      "Epoch: [27]  [ 0/79]  eta: 0:05:41  lr: 0.000020  loss: 34.0273 (34.0273)  loss_bbox: 0.5397 (0.5397)  loss_bbox_aux_0: 0.5661 (0.5661)  loss_bbox_aux_1: 0.5886 (0.5886)  loss_bbox_aux_2: 0.5743 (0.5743)  loss_bbox_aux_3: 0.5152 (0.5152)  loss_bbox_aux_4: 0.5925 (0.5925)  loss_bbox_dn_0: 0.6848 (0.6848)  loss_bbox_dn_1: 0.6664 (0.6664)  loss_bbox_dn_2: 0.6544 (0.6544)  loss_bbox_dn_3: 0.6469 (0.6469)  loss_bbox_dn_4: 0.6437 (0.6437)  loss_bbox_dn_5: 0.6441 (0.6441)  loss_bbox_enc_0: 0.5638 (0.5638)  loss_giou: 0.9745 (0.9745)  loss_giou_aux_0: 0.9988 (0.9988)  loss_giou_aux_1: 0.9888 (0.9888)  loss_giou_aux_2: 0.9987 (0.9987)  loss_giou_aux_3: 1.0230 (1.0230)  loss_giou_aux_4: 0.9723 (0.9723)  loss_giou_dn_0: 1.1929 (1.1929)  loss_giou_dn_1: 1.1220 (1.1220)  loss_giou_dn_2: 1.0813 (1.0813)  loss_giou_dn_3: 1.0612 (1.0612)  loss_giou_dn_4: 1.0451 (1.0451)  loss_giou_dn_5: 1.0452 (1.0452)  loss_giou_enc_0: 1.0751 (1.0751)  loss_vfl: 1.2207 (1.2207)  loss_vfl_aux_0: 1.2559 (1.2559)  loss_vfl_aux_1: 1.2573 (1.2573)  loss_vfl_aux_2: 1.3271 (1.3271)  loss_vfl_aux_3: 1.3232 (1.3232)  loss_vfl_aux_4: 1.2339 (1.2339)  loss_vfl_dn_0: 0.5189 (0.5189)  loss_vfl_dn_1: 0.5759 (0.5759)  loss_vfl_dn_2: 0.6289 (0.6289)  loss_vfl_dn_3: 0.6689 (0.6689)  loss_vfl_dn_4: 0.6816 (0.6816)  loss_vfl_dn_5: 0.6838 (0.6838)  loss_vfl_enc_0: 1.1914 (1.1914)  time: 4.3230  data: 2.8996  max mem: 10356\r\n",
      "Epoch: [27]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 30.6685 (30.5090)  loss_bbox: 0.3592 (0.3606)  loss_bbox_aux_0: 0.3889 (0.3839)  loss_bbox_aux_1: 0.3868 (0.3800)  loss_bbox_aux_2: 0.3744 (0.3744)  loss_bbox_aux_3: 0.3631 (0.3674)  loss_bbox_aux_4: 0.3712 (0.3646)  loss_bbox_dn_0: 0.4749 (0.4253)  loss_bbox_dn_1: 0.4643 (0.4021)  loss_bbox_dn_2: 0.4601 (0.3907)  loss_bbox_dn_3: 0.4541 (0.3838)  loss_bbox_dn_4: 0.4504 (0.3797)  loss_bbox_dn_5: 0.4507 (0.3791)  loss_bbox_enc_0: 0.4469 (0.4266)  loss_giou: 1.0743 (1.1409)  loss_giou_aux_0: 1.0896 (1.1729)  loss_giou_aux_1: 1.0830 (1.1614)  loss_giou_aux_2: 1.0772 (1.1539)  loss_giou_aux_3: 1.0781 (1.1492)  loss_giou_aux_4: 1.0665 (1.1424)  loss_giou_dn_0: 1.1748 (1.1826)  loss_giou_dn_1: 1.1069 (1.1132)  loss_giou_dn_2: 1.0799 (1.0844)  loss_giou_dn_3: 1.0653 (1.0669)  loss_giou_dn_4: 1.0537 (1.0564)  loss_giou_dn_5: 1.0539 (1.0556)  loss_giou_enc_0: 1.1891 (1.2619)  loss_vfl: 1.1436 (1.0848)  loss_vfl_aux_0: 1.0791 (1.0816)  loss_vfl_aux_1: 1.0913 (1.0670)  loss_vfl_aux_2: 1.1177 (1.0647)  loss_vfl_aux_3: 1.1401 (1.0759)  loss_vfl_aux_4: 1.1328 (1.0821)  loss_vfl_dn_0: 0.4786 (0.4810)  loss_vfl_dn_1: 0.5077 (0.5178)  loss_vfl_dn_2: 0.5317 (0.5426)  loss_vfl_dn_3: 0.5557 (0.5710)  loss_vfl_dn_4: 0.5901 (0.5965)  loss_vfl_dn_5: 0.5945 (0.6112)  loss_vfl_enc_0: 0.9578 (0.9730)  time: 0.9964  data: 0.0315  max mem: 10356\r\n",
      "Epoch: [27] Total time: 0:01:26 (1.0944 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 30.6685 (30.5090)  loss_bbox: 0.3592 (0.3606)  loss_bbox_aux_0: 0.3889 (0.3839)  loss_bbox_aux_1: 0.3868 (0.3800)  loss_bbox_aux_2: 0.3744 (0.3744)  loss_bbox_aux_3: 0.3631 (0.3674)  loss_bbox_aux_4: 0.3712 (0.3646)  loss_bbox_dn_0: 0.4749 (0.4253)  loss_bbox_dn_1: 0.4643 (0.4021)  loss_bbox_dn_2: 0.4601 (0.3907)  loss_bbox_dn_3: 0.4541 (0.3838)  loss_bbox_dn_4: 0.4504 (0.3797)  loss_bbox_dn_5: 0.4507 (0.3791)  loss_bbox_enc_0: 0.4469 (0.4266)  loss_giou: 1.0743 (1.1409)  loss_giou_aux_0: 1.0896 (1.1729)  loss_giou_aux_1: 1.0830 (1.1614)  loss_giou_aux_2: 1.0772 (1.1539)  loss_giou_aux_3: 1.0781 (1.1492)  loss_giou_aux_4: 1.0665 (1.1424)  loss_giou_dn_0: 1.1748 (1.1826)  loss_giou_dn_1: 1.1069 (1.1132)  loss_giou_dn_2: 1.0799 (1.0844)  loss_giou_dn_3: 1.0653 (1.0669)  loss_giou_dn_4: 1.0537 (1.0564)  loss_giou_dn_5: 1.0539 (1.0556)  loss_giou_enc_0: 1.1891 (1.2619)  loss_vfl: 1.1436 (1.0848)  loss_vfl_aux_0: 1.0791 (1.0816)  loss_vfl_aux_1: 1.0913 (1.0670)  loss_vfl_aux_2: 1.1177 (1.0647)  loss_vfl_aux_3: 1.1401 (1.0759)  loss_vfl_aux_4: 1.1328 (1.0821)  loss_vfl_dn_0: 0.4786 (0.4810)  loss_vfl_dn_1: 0.5077 (0.5178)  loss_vfl_dn_2: 0.5317 (0.5426)  loss_vfl_dn_3: 0.5557 (0.5710)  loss_vfl_dn_4: 0.5901 (0.5965)  loss_vfl_dn_5: 0.5945 (0.6112)  loss_vfl_enc_0: 0.9578 (0.9730)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3105  data: 1.2940  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0758  data: 0.2152  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0930 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.19s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.011\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.017\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.012\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.038\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.022\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.126\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.166\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.173\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.042\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.256\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.239\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.262\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.179\r\n",
      "best_stat: {'epoch': 26, 'coco_eval_bbox': 0.014030793290516257}\r\n",
      "Epoch: [28]  [ 0/79]  eta: 0:05:51  lr: 0.000020  loss: 32.0925 (32.0925)  loss_bbox: 0.5383 (0.5383)  loss_bbox_aux_0: 0.5126 (0.5126)  loss_bbox_aux_1: 0.5512 (0.5512)  loss_bbox_aux_2: 0.5441 (0.5441)  loss_bbox_aux_3: 0.5575 (0.5575)  loss_bbox_aux_4: 0.5362 (0.5362)  loss_bbox_dn_0: 0.3187 (0.3187)  loss_bbox_dn_1: 0.3032 (0.3032)  loss_bbox_dn_2: 0.2989 (0.2989)  loss_bbox_dn_3: 0.2926 (0.2926)  loss_bbox_dn_4: 0.2887 (0.2887)  loss_bbox_dn_5: 0.2885 (0.2885)  loss_bbox_enc_0: 0.5313 (0.5313)  loss_giou: 1.7646 (1.7646)  loss_giou_aux_0: 1.8229 (1.8229)  loss_giou_aux_1: 1.8053 (1.8053)  loss_giou_aux_2: 1.7845 (1.7845)  loss_giou_aux_3: 1.7927 (1.7927)  loss_giou_aux_4: 1.7694 (1.7694)  loss_giou_dn_0: 1.3262 (1.3262)  loss_giou_dn_1: 1.3152 (1.3152)  loss_giou_dn_2: 1.3153 (1.3153)  loss_giou_dn_3: 1.3147 (1.3147)  loss_giou_dn_4: 1.3122 (1.3122)  loss_giou_dn_5: 1.3178 (1.3178)  loss_giou_enc_0: 1.8569 (1.8569)  loss_vfl: 0.5311 (0.5311)  loss_vfl_aux_0: 0.5151 (0.5151)  loss_vfl_aux_1: 0.5107 (0.5107)  loss_vfl_aux_2: 0.5161 (0.5161)  loss_vfl_aux_3: 0.5089 (0.5089)  loss_vfl_aux_4: 0.5105 (0.5105)  loss_vfl_dn_0: 0.3969 (0.3969)  loss_vfl_dn_1: 0.4016 (0.4016)  loss_vfl_dn_2: 0.4037 (0.4037)  loss_vfl_dn_3: 0.4182 (0.4182)  loss_vfl_dn_4: 0.4194 (0.4194)  loss_vfl_dn_5: 0.4323 (0.4323)  loss_vfl_enc_0: 0.4683 (0.4683)  time: 4.4461  data: 2.9898  max mem: 10356\r\n",
      "Epoch: [28]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 30.3728 (30.6814)  loss_bbox: 0.3605 (0.3711)  loss_bbox_aux_0: 0.3936 (0.3969)  loss_bbox_aux_1: 0.3847 (0.3905)  loss_bbox_aux_2: 0.3790 (0.3803)  loss_bbox_aux_3: 0.3783 (0.3765)  loss_bbox_aux_4: 0.3723 (0.3740)  loss_bbox_dn_0: 0.4283 (0.4548)  loss_bbox_dn_1: 0.4121 (0.4295)  loss_bbox_dn_2: 0.3936 (0.4169)  loss_bbox_dn_3: 0.3774 (0.4095)  loss_bbox_dn_4: 0.3669 (0.4048)  loss_bbox_dn_5: 0.3666 (0.4041)  loss_bbox_enc_0: 0.4172 (0.4371)  loss_giou: 1.1295 (1.1205)  loss_giou_aux_0: 1.1432 (1.1529)  loss_giou_aux_1: 1.1335 (1.1403)  loss_giou_aux_2: 1.1350 (1.1292)  loss_giou_aux_3: 1.1269 (1.1244)  loss_giou_aux_4: 1.1322 (1.1212)  loss_giou_dn_0: 1.1749 (1.1795)  loss_giou_dn_1: 1.0900 (1.1115)  loss_giou_dn_2: 1.0512 (1.0813)  loss_giou_dn_3: 1.0343 (1.0644)  loss_giou_dn_4: 1.0236 (1.0541)  loss_giou_dn_5: 1.0225 (1.0540)  loss_giou_enc_0: 1.2297 (1.2330)  loss_vfl: 1.0569 (1.1038)  loss_vfl_aux_0: 1.0408 (1.0915)  loss_vfl_aux_1: 1.0051 (1.0858)  loss_vfl_aux_2: 1.0349 (1.0903)  loss_vfl_aux_3: 1.0493 (1.1005)  loss_vfl_aux_4: 1.0532 (1.1005)  loss_vfl_dn_0: 0.4738 (0.4791)  loss_vfl_dn_1: 0.5161 (0.5134)  loss_vfl_dn_2: 0.5405 (0.5378)  loss_vfl_dn_3: 0.5715 (0.5667)  loss_vfl_dn_4: 0.5947 (0.5909)  loss_vfl_dn_5: 0.6143 (0.6088)  loss_vfl_enc_0: 0.9470 (1.0000)  time: 0.9894  data: 0.0332  max mem: 10356\r\n",
      "Epoch: [28] Total time: 0:01:24 (1.0754 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 30.3728 (30.6814)  loss_bbox: 0.3605 (0.3711)  loss_bbox_aux_0: 0.3936 (0.3969)  loss_bbox_aux_1: 0.3847 (0.3905)  loss_bbox_aux_2: 0.3790 (0.3803)  loss_bbox_aux_3: 0.3783 (0.3765)  loss_bbox_aux_4: 0.3723 (0.3740)  loss_bbox_dn_0: 0.4283 (0.4548)  loss_bbox_dn_1: 0.4121 (0.4295)  loss_bbox_dn_2: 0.3936 (0.4169)  loss_bbox_dn_3: 0.3774 (0.4095)  loss_bbox_dn_4: 0.3669 (0.4048)  loss_bbox_dn_5: 0.3666 (0.4041)  loss_bbox_enc_0: 0.4172 (0.4371)  loss_giou: 1.1295 (1.1205)  loss_giou_aux_0: 1.1432 (1.1529)  loss_giou_aux_1: 1.1335 (1.1403)  loss_giou_aux_2: 1.1350 (1.1292)  loss_giou_aux_3: 1.1269 (1.1244)  loss_giou_aux_4: 1.1322 (1.1212)  loss_giou_dn_0: 1.1749 (1.1795)  loss_giou_dn_1: 1.0900 (1.1115)  loss_giou_dn_2: 1.0512 (1.0813)  loss_giou_dn_3: 1.0343 (1.0644)  loss_giou_dn_4: 1.0236 (1.0541)  loss_giou_dn_5: 1.0225 (1.0540)  loss_giou_enc_0: 1.2297 (1.2330)  loss_vfl: 1.0569 (1.1038)  loss_vfl_aux_0: 1.0408 (1.0915)  loss_vfl_aux_1: 1.0051 (1.0858)  loss_vfl_aux_2: 1.0349 (1.0903)  loss_vfl_aux_3: 1.0493 (1.1005)  loss_vfl_aux_4: 1.0532 (1.1005)  loss_vfl_dn_0: 0.4738 (0.4791)  loss_vfl_dn_1: 0.5161 (0.5134)  loss_vfl_dn_2: 0.5405 (0.5378)  loss_vfl_dn_3: 0.5715 (0.5667)  loss_vfl_dn_4: 0.5947 (0.5909)  loss_vfl_dn_5: 0.6143 (0.6088)  loss_vfl_enc_0: 0.9470 (1.0000)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.4084  data: 1.4892  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0794  data: 0.2250  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0965 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.012\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.018\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.014\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.031\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.023\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.109\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.176\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.194\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.055\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.268\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.259\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.294\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.203\r\n",
      "best_stat: {'epoch': 26, 'coco_eval_bbox': 0.014030793290516257}\r\n",
      "Epoch: [29]  [ 0/79]  eta: 0:07:09  lr: 0.000020  loss: 29.7601 (29.7601)  loss_bbox: 0.3476 (0.3476)  loss_bbox_aux_0: 0.3513 (0.3513)  loss_bbox_aux_1: 0.3785 (0.3785)  loss_bbox_aux_2: 0.3621 (0.3621)  loss_bbox_aux_3: 0.3649 (0.3649)  loss_bbox_aux_4: 0.3459 (0.3459)  loss_bbox_dn_0: 0.2330 (0.2330)  loss_bbox_dn_1: 0.2206 (0.2206)  loss_bbox_dn_2: 0.2132 (0.2132)  loss_bbox_dn_3: 0.2078 (0.2078)  loss_bbox_dn_4: 0.2028 (0.2028)  loss_bbox_dn_5: 0.2020 (0.2020)  loss_bbox_enc_0: 0.3545 (0.3545)  loss_giou: 1.4728 (1.4728)  loss_giou_aux_0: 1.4551 (1.4551)  loss_giou_aux_1: 1.4670 (1.4670)  loss_giou_aux_2: 1.4906 (1.4906)  loss_giou_aux_3: 1.4879 (1.4879)  loss_giou_aux_4: 1.4768 (1.4768)  loss_giou_dn_0: 1.3318 (1.3318)  loss_giou_dn_1: 1.3020 (1.3020)  loss_giou_dn_2: 1.2899 (1.2899)  loss_giou_dn_3: 1.2740 (1.2740)  loss_giou_dn_4: 1.2703 (1.2703)  loss_giou_dn_5: 1.2736 (1.2736)  loss_giou_enc_0: 1.5095 (1.5095)  loss_vfl: 0.7686 (0.7686)  loss_vfl_aux_0: 0.7366 (0.7366)  loss_vfl_aux_1: 0.7666 (0.7666)  loss_vfl_aux_2: 0.7634 (0.7634)  loss_vfl_aux_3: 0.7517 (0.7517)  loss_vfl_aux_4: 0.7590 (0.7590)  loss_vfl_dn_0: 0.4135 (0.4135)  loss_vfl_dn_1: 0.4113 (0.4113)  loss_vfl_dn_2: 0.4178 (0.4178)  loss_vfl_dn_3: 0.4432 (0.4432)  loss_vfl_dn_4: 0.4661 (0.4661)  loss_vfl_dn_5: 0.4818 (0.4818)  loss_vfl_enc_0: 0.6948 (0.6948)  time: 5.4399  data: 3.6905  max mem: 10356\r\n",
      "Epoch: [29]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 31.0141 (30.8562)  loss_bbox: 0.3675 (0.3872)  loss_bbox_aux_0: 0.4077 (0.4122)  loss_bbox_aux_1: 0.3701 (0.4067)  loss_bbox_aux_2: 0.3735 (0.4002)  loss_bbox_aux_3: 0.3694 (0.3917)  loss_bbox_aux_4: 0.3639 (0.3902)  loss_bbox_dn_0: 0.4158 (0.4448)  loss_bbox_dn_1: 0.4030 (0.4194)  loss_bbox_dn_2: 0.3964 (0.4069)  loss_bbox_dn_3: 0.3914 (0.3990)  loss_bbox_dn_4: 0.3874 (0.3942)  loss_bbox_dn_5: 0.3861 (0.3935)  loss_bbox_enc_0: 0.4283 (0.4517)  loss_giou: 1.0765 (1.1384)  loss_giou_aux_0: 1.1187 (1.1803)  loss_giou_aux_1: 1.1017 (1.1693)  loss_giou_aux_2: 1.0747 (1.1554)  loss_giou_aux_3: 1.0987 (1.1515)  loss_giou_aux_4: 1.0876 (1.1430)  loss_giou_dn_0: 1.1546 (1.1769)  loss_giou_dn_1: 1.0684 (1.1047)  loss_giou_dn_2: 1.0389 (1.0747)  loss_giou_dn_3: 1.0261 (1.0561)  loss_giou_dn_4: 1.0125 (1.0447)  loss_giou_dn_5: 1.0101 (1.0437)  loss_giou_enc_0: 1.2184 (1.2591)  loss_vfl: 1.1587 (1.1081)  loss_vfl_aux_0: 1.0857 (1.0820)  loss_vfl_aux_1: 1.0828 (1.0770)  loss_vfl_aux_2: 1.1216 (1.0867)  loss_vfl_aux_3: 1.1267 (1.0966)  loss_vfl_aux_4: 1.1331 (1.0942)  loss_vfl_dn_0: 0.4824 (0.4826)  loss_vfl_dn_1: 0.5330 (0.5189)  loss_vfl_dn_2: 0.5531 (0.5423)  loss_vfl_dn_3: 0.5806 (0.5717)  loss_vfl_dn_4: 0.6088 (0.5961)  loss_vfl_dn_5: 0.6361 (0.6109)  loss_vfl_enc_0: 0.9766 (0.9934)  time: 1.0673  data: 0.0315  max mem: 10356\r\n",
      "Epoch: [29] Total time: 0:01:27 (1.1027 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 31.0141 (30.8562)  loss_bbox: 0.3675 (0.3872)  loss_bbox_aux_0: 0.4077 (0.4122)  loss_bbox_aux_1: 0.3701 (0.4067)  loss_bbox_aux_2: 0.3735 (0.4002)  loss_bbox_aux_3: 0.3694 (0.3917)  loss_bbox_aux_4: 0.3639 (0.3902)  loss_bbox_dn_0: 0.4158 (0.4448)  loss_bbox_dn_1: 0.4030 (0.4194)  loss_bbox_dn_2: 0.3964 (0.4069)  loss_bbox_dn_3: 0.3914 (0.3990)  loss_bbox_dn_4: 0.3874 (0.3942)  loss_bbox_dn_5: 0.3861 (0.3935)  loss_bbox_enc_0: 0.4283 (0.4517)  loss_giou: 1.0765 (1.1384)  loss_giou_aux_0: 1.1187 (1.1803)  loss_giou_aux_1: 1.1017 (1.1693)  loss_giou_aux_2: 1.0747 (1.1554)  loss_giou_aux_3: 1.0987 (1.1515)  loss_giou_aux_4: 1.0876 (1.1430)  loss_giou_dn_0: 1.1546 (1.1769)  loss_giou_dn_1: 1.0684 (1.1047)  loss_giou_dn_2: 1.0389 (1.0747)  loss_giou_dn_3: 1.0261 (1.0561)  loss_giou_dn_4: 1.0125 (1.0447)  loss_giou_dn_5: 1.0101 (1.0437)  loss_giou_enc_0: 1.2184 (1.2591)  loss_vfl: 1.1587 (1.1081)  loss_vfl_aux_0: 1.0857 (1.0820)  loss_vfl_aux_1: 1.0828 (1.0770)  loss_vfl_aux_2: 1.1216 (1.0867)  loss_vfl_aux_3: 1.1267 (1.0966)  loss_vfl_aux_4: 1.1331 (1.0942)  loss_vfl_dn_0: 0.4824 (0.4826)  loss_vfl_dn_1: 0.5330 (0.5189)  loss_vfl_dn_2: 0.5531 (0.5423)  loss_vfl_dn_3: 0.5806 (0.5717)  loss_vfl_dn_4: 0.6088 (0.5961)  loss_vfl_dn_5: 0.6361 (0.6109)  loss_vfl_enc_0: 0.9766 (0.9934)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.1998  data: 1.2484  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0628  data: 0.2072  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0811 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.016\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.011\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.023\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.023\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.121\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.183\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.192\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.066\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.270\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.252\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.286\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.205\r\n",
      "best_stat: {'epoch': 26, 'coco_eval_bbox': 0.014030793290516257}\r\n",
      "Epoch: [30]  [ 0/79]  eta: 0:06:47  lr: 0.000020  loss: 30.3627 (30.3627)  loss_bbox: 0.3568 (0.3568)  loss_bbox_aux_0: 0.4156 (0.4156)  loss_bbox_aux_1: 0.3898 (0.3898)  loss_bbox_aux_2: 0.3813 (0.3813)  loss_bbox_aux_3: 0.3602 (0.3602)  loss_bbox_aux_4: 0.3785 (0.3785)  loss_bbox_dn_0: 0.2481 (0.2481)  loss_bbox_dn_1: 0.2322 (0.2322)  loss_bbox_dn_2: 0.2254 (0.2254)  loss_bbox_dn_3: 0.2197 (0.2197)  loss_bbox_dn_4: 0.2173 (0.2173)  loss_bbox_dn_5: 0.2165 (0.2165)  loss_bbox_enc_0: 0.4182 (0.4182)  loss_giou: 1.6260 (1.6260)  loss_giou_aux_0: 1.6532 (1.6532)  loss_giou_aux_1: 1.6623 (1.6623)  loss_giou_aux_2: 1.6194 (1.6194)  loss_giou_aux_3: 1.6031 (1.6031)  loss_giou_aux_4: 1.5790 (1.5790)  loss_giou_dn_0: 1.2946 (1.2946)  loss_giou_dn_1: 1.2666 (1.2666)  loss_giou_dn_2: 1.2506 (1.2506)  loss_giou_dn_3: 1.2396 (1.2396)  loss_giou_dn_4: 1.2436 (1.2436)  loss_giou_dn_5: 1.2403 (1.2403)  loss_giou_enc_0: 1.6848 (1.6848)  loss_vfl: 0.6714 (0.6714)  loss_vfl_aux_0: 0.6707 (0.6707)  loss_vfl_aux_1: 0.6860 (0.6860)  loss_vfl_aux_2: 0.6775 (0.6775)  loss_vfl_aux_3: 0.6831 (0.6831)  loss_vfl_aux_4: 0.6787 (0.6787)  loss_vfl_dn_0: 0.4038 (0.4038)  loss_vfl_dn_1: 0.4120 (0.4120)  loss_vfl_dn_2: 0.4243 (0.4243)  loss_vfl_dn_3: 0.4386 (0.4386)  loss_vfl_dn_4: 0.4612 (0.4612)  loss_vfl_dn_5: 0.4644 (0.4644)  loss_vfl_enc_0: 0.6685 (0.6685)  time: 5.1526  data: 3.5090  max mem: 10356\r\n",
      "Epoch: [30]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 30.0283 (30.2846)  loss_bbox: 0.3194 (0.3428)  loss_bbox_aux_0: 0.3120 (0.3721)  loss_bbox_aux_1: 0.3242 (0.3614)  loss_bbox_aux_2: 0.3084 (0.3526)  loss_bbox_aux_3: 0.3208 (0.3468)  loss_bbox_aux_4: 0.3195 (0.3445)  loss_bbox_dn_0: 0.4086 (0.4289)  loss_bbox_dn_1: 0.3847 (0.4023)  loss_bbox_dn_2: 0.3682 (0.3892)  loss_bbox_dn_3: 0.3548 (0.3812)  loss_bbox_dn_4: 0.3472 (0.3764)  loss_bbox_dn_5: 0.3468 (0.3756)  loss_bbox_enc_0: 0.3691 (0.4128)  loss_giou: 1.0343 (1.1209)  loss_giou_aux_0: 1.0631 (1.1602)  loss_giou_aux_1: 1.0490 (1.1464)  loss_giou_aux_2: 1.0269 (1.1328)  loss_giou_aux_3: 1.0331 (1.1294)  loss_giou_aux_4: 1.0251 (1.1208)  loss_giou_dn_0: 1.1670 (1.1823)  loss_giou_dn_1: 1.0992 (1.1136)  loss_giou_dn_2: 1.0747 (1.0849)  loss_giou_dn_3: 1.0549 (1.0673)  loss_giou_dn_4: 1.0421 (1.0566)  loss_giou_dn_5: 1.0403 (1.0563)  loss_giou_enc_0: 1.1507 (1.2371)  loss_vfl: 1.1177 (1.0922)  loss_vfl_aux_0: 1.0276 (1.0757)  loss_vfl_aux_1: 1.0566 (1.0724)  loss_vfl_aux_2: 1.0962 (1.0762)  loss_vfl_aux_3: 1.1299 (1.0907)  loss_vfl_aux_4: 1.1133 (1.0892)  loss_vfl_dn_0: 0.4805 (0.4811)  loss_vfl_dn_1: 0.5177 (0.5160)  loss_vfl_dn_2: 0.5400 (0.5390)  loss_vfl_dn_3: 0.5698 (0.5663)  loss_vfl_dn_4: 0.5834 (0.5903)  loss_vfl_dn_5: 0.6040 (0.6051)  loss_vfl_enc_0: 0.9963 (0.9952)  time: 1.0050  data: 0.0315  max mem: 10356\r\n",
      "Epoch: [30] Total time: 0:01:25 (1.0872 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 30.0283 (30.2846)  loss_bbox: 0.3194 (0.3428)  loss_bbox_aux_0: 0.3120 (0.3721)  loss_bbox_aux_1: 0.3242 (0.3614)  loss_bbox_aux_2: 0.3084 (0.3526)  loss_bbox_aux_3: 0.3208 (0.3468)  loss_bbox_aux_4: 0.3195 (0.3445)  loss_bbox_dn_0: 0.4086 (0.4289)  loss_bbox_dn_1: 0.3847 (0.4023)  loss_bbox_dn_2: 0.3682 (0.3892)  loss_bbox_dn_3: 0.3548 (0.3812)  loss_bbox_dn_4: 0.3472 (0.3764)  loss_bbox_dn_5: 0.3468 (0.3756)  loss_bbox_enc_0: 0.3691 (0.4128)  loss_giou: 1.0343 (1.1209)  loss_giou_aux_0: 1.0631 (1.1602)  loss_giou_aux_1: 1.0490 (1.1464)  loss_giou_aux_2: 1.0269 (1.1328)  loss_giou_aux_3: 1.0331 (1.1294)  loss_giou_aux_4: 1.0251 (1.1208)  loss_giou_dn_0: 1.1670 (1.1823)  loss_giou_dn_1: 1.0992 (1.1136)  loss_giou_dn_2: 1.0747 (1.0849)  loss_giou_dn_3: 1.0549 (1.0673)  loss_giou_dn_4: 1.0421 (1.0566)  loss_giou_dn_5: 1.0403 (1.0563)  loss_giou_enc_0: 1.1507 (1.2371)  loss_vfl: 1.1177 (1.0922)  loss_vfl_aux_0: 1.0276 (1.0757)  loss_vfl_aux_1: 1.0566 (1.0724)  loss_vfl_aux_2: 1.0962 (1.0762)  loss_vfl_aux_3: 1.1299 (1.0907)  loss_vfl_aux_4: 1.1133 (1.0892)  loss_vfl_dn_0: 0.4805 (0.4811)  loss_vfl_dn_1: 0.5177 (0.5160)  loss_vfl_dn_2: 0.5400 (0.5390)  loss_vfl_dn_3: 0.5698 (0.5663)  loss_vfl_dn_4: 0.5834 (0.5903)  loss_vfl_dn_5: 0.6040 (0.6051)  loss_vfl_enc_0: 0.9963 (0.9952)\r\n",
      "Test:  [0/8]  eta: 0:00:16    time: 2.1157  data: 1.1678  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0587  data: 0.2011  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0761 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.019\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.028\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.021\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.041\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.031\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.134\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.189\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.200\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.051\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.257\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.290\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.212\r\n",
      "best_stat: {'epoch': 30, 'coco_eval_bbox': 0.018630100024127526}\r\n",
      "Epoch: [31]  [ 0/79]  eta: 0:06:02  lr: 0.000020  loss: 31.0450 (31.0450)  loss_bbox: 0.3896 (0.3896)  loss_bbox_aux_0: 0.4163 (0.4163)  loss_bbox_aux_1: 0.4206 (0.4206)  loss_bbox_aux_2: 0.4127 (0.4127)  loss_bbox_aux_3: 0.4147 (0.4147)  loss_bbox_aux_4: 0.4119 (0.4119)  loss_bbox_dn_0: 0.4197 (0.4197)  loss_bbox_dn_1: 0.3941 (0.3941)  loss_bbox_dn_2: 0.3810 (0.3810)  loss_bbox_dn_3: 0.3698 (0.3698)  loss_bbox_dn_4: 0.3631 (0.3631)  loss_bbox_dn_5: 0.3622 (0.3622)  loss_bbox_enc_0: 0.4537 (0.4537)  loss_giou: 1.1571 (1.1571)  loss_giou_aux_0: 1.2141 (1.2141)  loss_giou_aux_1: 1.1820 (1.1820)  loss_giou_aux_2: 1.1823 (1.1823)  loss_giou_aux_3: 1.1806 (1.1806)  loss_giou_aux_4: 1.1614 (1.1614)  loss_giou_dn_0: 1.1769 (1.1769)  loss_giou_dn_1: 1.1015 (1.1015)  loss_giou_dn_2: 1.0556 (1.0556)  loss_giou_dn_3: 1.0448 (1.0448)  loss_giou_dn_4: 1.0396 (1.0396)  loss_giou_dn_5: 1.0438 (1.0438)  loss_giou_enc_0: 1.3569 (1.3569)  loss_vfl: 1.1106 (1.1106)  loss_vfl_aux_0: 1.0823 (1.0823)  loss_vfl_aux_1: 1.1113 (1.1113)  loss_vfl_aux_2: 1.0876 (1.0876)  loss_vfl_aux_3: 1.0852 (1.0852)  loss_vfl_aux_4: 1.0852 (1.0852)  loss_vfl_dn_0: 0.4902 (0.4902)  loss_vfl_dn_1: 0.5546 (0.5546)  loss_vfl_dn_2: 0.5723 (0.5723)  loss_vfl_dn_3: 0.6060 (0.6060)  loss_vfl_dn_4: 0.6173 (0.6173)  loss_vfl_dn_5: 0.6162 (0.6162)  loss_vfl_enc_0: 0.9202 (0.9202)  time: 4.5924  data: 3.1430  max mem: 10356\r\n",
      "Epoch: [31]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 30.1487 (30.2935)  loss_bbox: 0.3643 (0.3592)  loss_bbox_aux_0: 0.3802 (0.3845)  loss_bbox_aux_1: 0.3991 (0.3780)  loss_bbox_aux_2: 0.3730 (0.3727)  loss_bbox_aux_3: 0.3899 (0.3701)  loss_bbox_aux_4: 0.3682 (0.3615)  loss_bbox_dn_0: 0.4699 (0.4368)  loss_bbox_dn_1: 0.4354 (0.4112)  loss_bbox_dn_2: 0.4180 (0.3986)  loss_bbox_dn_3: 0.4066 (0.3909)  loss_bbox_dn_4: 0.3990 (0.3866)  loss_bbox_dn_5: 0.3980 (0.3860)  loss_bbox_enc_0: 0.4064 (0.4234)  loss_giou: 1.0502 (1.1070)  loss_giou_aux_0: 1.0908 (1.1446)  loss_giou_aux_1: 1.0771 (1.1353)  loss_giou_aux_2: 1.0667 (1.1200)  loss_giou_aux_3: 1.0625 (1.1188)  loss_giou_aux_4: 1.0333 (1.1107)  loss_giou_dn_0: 1.1469 (1.1674)  loss_giou_dn_1: 1.0657 (1.0930)  loss_giou_dn_2: 1.0262 (1.0620)  loss_giou_dn_3: 1.0033 (1.0442)  loss_giou_dn_4: 0.9883 (1.0331)  loss_giou_dn_5: 0.9854 (1.0326)  loss_giou_enc_0: 1.1642 (1.2196)  loss_vfl: 1.0498 (1.0937)  loss_vfl_aux_0: 1.0723 (1.0834)  loss_vfl_aux_1: 1.0884 (1.0727)  loss_vfl_aux_2: 1.0659 (1.0740)  loss_vfl_aux_3: 1.0593 (1.0827)  loss_vfl_aux_4: 1.0371 (1.0885)  loss_vfl_dn_0: 0.4868 (0.4877)  loss_vfl_dn_1: 0.5289 (0.5250)  loss_vfl_dn_2: 0.5496 (0.5476)  loss_vfl_dn_3: 0.5732 (0.5741)  loss_vfl_dn_4: 0.5859 (0.5974)  loss_vfl_dn_5: 0.5994 (0.6123)  loss_vfl_enc_0: 0.9707 (1.0065)  time: 0.9666  data: 0.0320  max mem: 10356\r\n",
      "Epoch: [31] Total time: 0:01:24 (1.0677 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 30.1487 (30.2935)  loss_bbox: 0.3643 (0.3592)  loss_bbox_aux_0: 0.3802 (0.3845)  loss_bbox_aux_1: 0.3991 (0.3780)  loss_bbox_aux_2: 0.3730 (0.3727)  loss_bbox_aux_3: 0.3899 (0.3701)  loss_bbox_aux_4: 0.3682 (0.3615)  loss_bbox_dn_0: 0.4699 (0.4368)  loss_bbox_dn_1: 0.4354 (0.4112)  loss_bbox_dn_2: 0.4180 (0.3986)  loss_bbox_dn_3: 0.4066 (0.3909)  loss_bbox_dn_4: 0.3990 (0.3866)  loss_bbox_dn_5: 0.3980 (0.3860)  loss_bbox_enc_0: 0.4064 (0.4234)  loss_giou: 1.0502 (1.1070)  loss_giou_aux_0: 1.0908 (1.1446)  loss_giou_aux_1: 1.0771 (1.1353)  loss_giou_aux_2: 1.0667 (1.1200)  loss_giou_aux_3: 1.0625 (1.1188)  loss_giou_aux_4: 1.0333 (1.1107)  loss_giou_dn_0: 1.1469 (1.1674)  loss_giou_dn_1: 1.0657 (1.0930)  loss_giou_dn_2: 1.0262 (1.0620)  loss_giou_dn_3: 1.0033 (1.0442)  loss_giou_dn_4: 0.9883 (1.0331)  loss_giou_dn_5: 0.9854 (1.0326)  loss_giou_enc_0: 1.1642 (1.2196)  loss_vfl: 1.0498 (1.0937)  loss_vfl_aux_0: 1.0723 (1.0834)  loss_vfl_aux_1: 1.0884 (1.0727)  loss_vfl_aux_2: 1.0659 (1.0740)  loss_vfl_aux_3: 1.0593 (1.0827)  loss_vfl_aux_4: 1.0371 (1.0885)  loss_vfl_dn_0: 0.4868 (0.4877)  loss_vfl_dn_1: 0.5289 (0.5250)  loss_vfl_dn_2: 0.5496 (0.5476)  loss_vfl_dn_3: 0.5732 (0.5741)  loss_vfl_dn_4: 0.5859 (0.5974)  loss_vfl_dn_5: 0.5994 (0.6123)  loss_vfl_enc_0: 0.9707 (1.0065)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.4299  data: 1.5116  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0886  data: 0.2276  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1073 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.017\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.026\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.019\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.033\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.039\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.134\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.179\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.186\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.054\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.234\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.265\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.290\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.195\r\n",
      "best_stat: {'epoch': 30, 'coco_eval_bbox': 0.018630100024127526}\r\n",
      "Epoch: [32]  [ 0/79]  eta: 0:05:57  lr: 0.000020  loss: 31.5794 (31.5794)  loss_bbox: 0.4565 (0.4565)  loss_bbox_aux_0: 0.4361 (0.4361)  loss_bbox_aux_1: 0.4641 (0.4641)  loss_bbox_aux_2: 0.4614 (0.4614)  loss_bbox_aux_3: 0.4687 (0.4687)  loss_bbox_aux_4: 0.4431 (0.4431)  loss_bbox_dn_0: 0.6867 (0.6867)  loss_bbox_dn_1: 0.6446 (0.6446)  loss_bbox_dn_2: 0.6255 (0.6255)  loss_bbox_dn_3: 0.6146 (0.6146)  loss_bbox_dn_4: 0.6053 (0.6053)  loss_bbox_dn_5: 0.6041 (0.6041)  loss_bbox_enc_0: 0.4919 (0.4919)  loss_giou: 0.9021 (0.9021)  loss_giou_aux_0: 0.9746 (0.9746)  loss_giou_aux_1: 0.9507 (0.9507)  loss_giou_aux_2: 0.9345 (0.9345)  loss_giou_aux_3: 0.9264 (0.9264)  loss_giou_aux_4: 0.8983 (0.8983)  loss_giou_dn_0: 1.1600 (1.1600)  loss_giou_dn_1: 1.0872 (1.0872)  loss_giou_dn_2: 1.0607 (1.0607)  loss_giou_dn_3: 1.0436 (1.0436)  loss_giou_dn_4: 1.0264 (1.0264)  loss_giou_dn_5: 1.0255 (1.0255)  loss_giou_enc_0: 1.0487 (1.0487)  loss_vfl: 1.2173 (1.2173)  loss_vfl_aux_0: 1.1821 (1.1821)  loss_vfl_aux_1: 1.2100 (1.2100)  loss_vfl_aux_2: 1.1948 (1.1948)  loss_vfl_aux_3: 1.2126 (1.2126)  loss_vfl_aux_4: 1.2258 (1.2258)  loss_vfl_dn_0: 0.4666 (0.4666)  loss_vfl_dn_1: 0.5007 (0.5007)  loss_vfl_dn_2: 0.5135 (0.5135)  loss_vfl_dn_3: 0.5294 (0.5294)  loss_vfl_dn_4: 0.5640 (0.5640)  loss_vfl_dn_5: 0.5771 (0.5771)  loss_vfl_enc_0: 1.1436 (1.1436)  time: 4.5190  data: 3.0058  max mem: 10356\r\n",
      "Epoch: [32]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 30.3550 (30.4319)  loss_bbox: 0.3590 (0.3642)  loss_bbox_aux_0: 0.3727 (0.3986)  loss_bbox_aux_1: 0.3775 (0.3879)  loss_bbox_aux_2: 0.3661 (0.3798)  loss_bbox_aux_3: 0.3569 (0.3727)  loss_bbox_aux_4: 0.3578 (0.3666)  loss_bbox_dn_0: 0.4417 (0.4442)  loss_bbox_dn_1: 0.4155 (0.4159)  loss_bbox_dn_2: 0.4019 (0.4021)  loss_bbox_dn_3: 0.3940 (0.3935)  loss_bbox_dn_4: 0.3875 (0.3882)  loss_bbox_dn_5: 0.3876 (0.3873)  loss_bbox_enc_0: 0.4306 (0.4360)  loss_giou: 1.0548 (1.1302)  loss_giou_aux_0: 1.0606 (1.1715)  loss_giou_aux_1: 1.0358 (1.1585)  loss_giou_aux_2: 1.0456 (1.1447)  loss_giou_aux_3: 1.0491 (1.1377)  loss_giou_aux_4: 1.0522 (1.1338)  loss_giou_dn_0: 1.1465 (1.1731)  loss_giou_dn_1: 1.0607 (1.0983)  loss_giou_dn_2: 1.0302 (1.0668)  loss_giou_dn_3: 1.0085 (1.0489)  loss_giou_dn_4: 1.0056 (1.0379)  loss_giou_dn_5: 1.0045 (1.0373)  loss_giou_enc_0: 1.1705 (1.2538)  loss_vfl: 1.0879 (1.0774)  loss_vfl_aux_0: 1.0476 (1.0603)  loss_vfl_aux_1: 1.0432 (1.0645)  loss_vfl_aux_2: 1.0757 (1.0676)  loss_vfl_aux_3: 1.0894 (1.0756)  loss_vfl_aux_4: 1.0869 (1.0795)  loss_vfl_dn_0: 0.4877 (0.4816)  loss_vfl_dn_1: 0.5302 (0.5189)  loss_vfl_dn_2: 0.5503 (0.5396)  loss_vfl_dn_3: 0.5759 (0.5655)  loss_vfl_dn_4: 0.6061 (0.5883)  loss_vfl_dn_5: 0.6140 (0.6028)  loss_vfl_enc_0: 0.9045 (0.9807)  time: 1.0150  data: 0.0323  max mem: 10356\r\n",
      "Epoch: [32] Total time: 0:01:26 (1.1001 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 30.3550 (30.4319)  loss_bbox: 0.3590 (0.3642)  loss_bbox_aux_0: 0.3727 (0.3986)  loss_bbox_aux_1: 0.3775 (0.3879)  loss_bbox_aux_2: 0.3661 (0.3798)  loss_bbox_aux_3: 0.3569 (0.3727)  loss_bbox_aux_4: 0.3578 (0.3666)  loss_bbox_dn_0: 0.4417 (0.4442)  loss_bbox_dn_1: 0.4155 (0.4159)  loss_bbox_dn_2: 0.4019 (0.4021)  loss_bbox_dn_3: 0.3940 (0.3935)  loss_bbox_dn_4: 0.3875 (0.3882)  loss_bbox_dn_5: 0.3876 (0.3873)  loss_bbox_enc_0: 0.4306 (0.4360)  loss_giou: 1.0548 (1.1302)  loss_giou_aux_0: 1.0606 (1.1715)  loss_giou_aux_1: 1.0358 (1.1585)  loss_giou_aux_2: 1.0456 (1.1447)  loss_giou_aux_3: 1.0491 (1.1377)  loss_giou_aux_4: 1.0522 (1.1338)  loss_giou_dn_0: 1.1465 (1.1731)  loss_giou_dn_1: 1.0607 (1.0983)  loss_giou_dn_2: 1.0302 (1.0668)  loss_giou_dn_3: 1.0085 (1.0489)  loss_giou_dn_4: 1.0056 (1.0379)  loss_giou_dn_5: 1.0045 (1.0373)  loss_giou_enc_0: 1.1705 (1.2538)  loss_vfl: 1.0879 (1.0774)  loss_vfl_aux_0: 1.0476 (1.0603)  loss_vfl_aux_1: 1.0432 (1.0645)  loss_vfl_aux_2: 1.0757 (1.0676)  loss_vfl_aux_3: 1.0894 (1.0756)  loss_vfl_aux_4: 1.0869 (1.0795)  loss_vfl_dn_0: 0.4877 (0.4816)  loss_vfl_dn_1: 0.5302 (0.5189)  loss_vfl_dn_2: 0.5503 (0.5396)  loss_vfl_dn_3: 0.5759 (0.5655)  loss_vfl_dn_4: 0.6061 (0.5883)  loss_vfl_dn_5: 0.6140 (0.6028)  loss_vfl_enc_0: 0.9045 (0.9807)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.1570  data: 1.1859  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0740  data: 0.2068  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0908 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.013\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.019\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.014\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.029\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.031\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.138\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.201\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.217\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.055\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.282\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.310\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.320\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.227\r\n",
      "best_stat: {'epoch': 30, 'coco_eval_bbox': 0.018630100024127526}\r\n",
      "Epoch: [33]  [ 0/79]  eta: 0:06:08  lr: 0.000020  loss: 30.5723 (30.5723)  loss_bbox: 0.3336 (0.3336)  loss_bbox_aux_0: 0.2994 (0.2994)  loss_bbox_aux_1: 0.3306 (0.3306)  loss_bbox_aux_2: 0.3237 (0.3237)  loss_bbox_aux_3: 0.3269 (0.3269)  loss_bbox_aux_4: 0.3399 (0.3399)  loss_bbox_dn_0: 0.4942 (0.4942)  loss_bbox_dn_1: 0.4502 (0.4502)  loss_bbox_dn_2: 0.4335 (0.4335)  loss_bbox_dn_3: 0.4239 (0.4239)  loss_bbox_dn_4: 0.4192 (0.4192)  loss_bbox_dn_5: 0.4185 (0.4185)  loss_bbox_enc_0: 0.3828 (0.3828)  loss_giou: 0.9675 (0.9675)  loss_giou_aux_0: 0.9559 (0.9559)  loss_giou_aux_1: 0.9412 (0.9412)  loss_giou_aux_2: 0.9373 (0.9373)  loss_giou_aux_3: 0.9582 (0.9582)  loss_giou_aux_4: 0.9708 (0.9708)  loss_giou_dn_0: 1.1475 (1.1475)  loss_giou_dn_1: 1.0329 (1.0329)  loss_giou_dn_2: 0.9932 (0.9932)  loss_giou_dn_3: 0.9785 (0.9785)  loss_giou_dn_4: 0.9617 (0.9617)  loss_giou_dn_5: 0.9636 (0.9636)  loss_giou_enc_0: 1.0706 (1.0706)  loss_vfl: 1.2241 (1.2241)  loss_vfl_aux_0: 1.4243 (1.4243)  loss_vfl_aux_1: 1.3984 (1.3984)  loss_vfl_aux_2: 1.3401 (1.3401)  loss_vfl_aux_3: 1.3022 (1.3022)  loss_vfl_aux_4: 1.2378 (1.2378)  loss_vfl_dn_0: 0.4742 (0.4742)  loss_vfl_dn_1: 0.5515 (0.5515)  loss_vfl_dn_2: 0.5842 (0.5842)  loss_vfl_dn_3: 0.6162 (0.6162)  loss_vfl_dn_4: 0.6459 (0.6459)  loss_vfl_dn_5: 0.6516 (0.6516)  loss_vfl_enc_0: 1.2661 (1.2661)  time: 4.6641  data: 2.7286  max mem: 10356\r\n",
      "Epoch: [33]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 30.1734 (30.2098)  loss_bbox: 0.3888 (0.3639)  loss_bbox_aux_0: 0.4033 (0.3901)  loss_bbox_aux_1: 0.3963 (0.3842)  loss_bbox_aux_2: 0.3879 (0.3758)  loss_bbox_aux_3: 0.3850 (0.3722)  loss_bbox_aux_4: 0.3771 (0.3690)  loss_bbox_dn_0: 0.3813 (0.4281)  loss_bbox_dn_1: 0.3492 (0.4004)  loss_bbox_dn_2: 0.3321 (0.3875)  loss_bbox_dn_3: 0.3286 (0.3798)  loss_bbox_dn_4: 0.3260 (0.3755)  loss_bbox_dn_5: 0.3263 (0.3748)  loss_bbox_enc_0: 0.4421 (0.4226)  loss_giou: 1.1345 (1.1194)  loss_giou_aux_0: 1.1528 (1.1639)  loss_giou_aux_1: 1.1844 (1.1493)  loss_giou_aux_2: 1.1955 (1.1360)  loss_giou_aux_3: 1.2373 (1.1322)  loss_giou_aux_4: 1.1518 (1.1234)  loss_giou_dn_0: 1.1648 (1.1640)  loss_giou_dn_1: 1.1068 (1.0871)  loss_giou_dn_2: 1.0761 (1.0557)  loss_giou_dn_3: 1.0647 (1.0388)  loss_giou_dn_4: 1.0558 (1.0283)  loss_giou_dn_5: 1.0547 (1.0282)  loss_giou_enc_0: 1.2531 (1.2418)  loss_vfl: 0.9407 (1.0885)  loss_vfl_aux_0: 0.9009 (1.0652)  loss_vfl_aux_1: 0.8901 (1.0633)  loss_vfl_aux_2: 0.9170 (1.0649)  loss_vfl_aux_3: 0.9561 (1.0717)  loss_vfl_aux_4: 0.9988 (1.0852)  loss_vfl_dn_0: 0.4791 (0.4843)  loss_vfl_dn_1: 0.5140 (0.5215)  loss_vfl_dn_2: 0.5166 (0.5411)  loss_vfl_dn_3: 0.5530 (0.5662)  loss_vfl_dn_4: 0.5676 (0.5874)  loss_vfl_dn_5: 0.5652 (0.5991)  loss_vfl_enc_0: 0.8364 (0.9794)  time: 1.0060  data: 0.0320  max mem: 10356\r\n",
      "Epoch: [33] Total time: 0:01:24 (1.0718 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 30.1734 (30.2098)  loss_bbox: 0.3888 (0.3639)  loss_bbox_aux_0: 0.4033 (0.3901)  loss_bbox_aux_1: 0.3963 (0.3842)  loss_bbox_aux_2: 0.3879 (0.3758)  loss_bbox_aux_3: 0.3850 (0.3722)  loss_bbox_aux_4: 0.3771 (0.3690)  loss_bbox_dn_0: 0.3813 (0.4281)  loss_bbox_dn_1: 0.3492 (0.4004)  loss_bbox_dn_2: 0.3321 (0.3875)  loss_bbox_dn_3: 0.3286 (0.3798)  loss_bbox_dn_4: 0.3260 (0.3755)  loss_bbox_dn_5: 0.3263 (0.3748)  loss_bbox_enc_0: 0.4421 (0.4226)  loss_giou: 1.1345 (1.1194)  loss_giou_aux_0: 1.1528 (1.1639)  loss_giou_aux_1: 1.1844 (1.1493)  loss_giou_aux_2: 1.1955 (1.1360)  loss_giou_aux_3: 1.2373 (1.1322)  loss_giou_aux_4: 1.1518 (1.1234)  loss_giou_dn_0: 1.1648 (1.1640)  loss_giou_dn_1: 1.1068 (1.0871)  loss_giou_dn_2: 1.0761 (1.0557)  loss_giou_dn_3: 1.0647 (1.0388)  loss_giou_dn_4: 1.0558 (1.0283)  loss_giou_dn_5: 1.0547 (1.0282)  loss_giou_enc_0: 1.2531 (1.2418)  loss_vfl: 0.9407 (1.0885)  loss_vfl_aux_0: 0.9009 (1.0652)  loss_vfl_aux_1: 0.8901 (1.0633)  loss_vfl_aux_2: 0.9170 (1.0649)  loss_vfl_aux_3: 0.9561 (1.0717)  loss_vfl_aux_4: 0.9988 (1.0852)  loss_vfl_dn_0: 0.4791 (0.4843)  loss_vfl_dn_1: 0.5140 (0.5215)  loss_vfl_dn_2: 0.5166 (0.5411)  loss_vfl_dn_3: 0.5530 (0.5662)  loss_vfl_dn_4: 0.5676 (0.5874)  loss_vfl_dn_5: 0.5652 (0.5991)  loss_vfl_enc_0: 0.8364 (0.9794)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.2412  data: 1.2712  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0774  data: 0.2164  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0945 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.019\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.028\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.022\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.044\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.036\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.127\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.186\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.193\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.042\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.266\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.272\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.274\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.211\r\n",
      "best_stat: {'epoch': 33, 'coco_eval_bbox': 0.01933803381323522}\r\n",
      "Epoch: [34]  [ 0/79]  eta: 0:05:41  lr: 0.000020  loss: 31.0732 (31.0732)  loss_bbox: 0.4256 (0.4256)  loss_bbox_aux_0: 0.4628 (0.4628)  loss_bbox_aux_1: 0.4164 (0.4164)  loss_bbox_aux_2: 0.4399 (0.4399)  loss_bbox_aux_3: 0.4129 (0.4129)  loss_bbox_aux_4: 0.4386 (0.4386)  loss_bbox_dn_0: 0.3665 (0.3665)  loss_bbox_dn_1: 0.3401 (0.3401)  loss_bbox_dn_2: 0.3258 (0.3258)  loss_bbox_dn_3: 0.3181 (0.3181)  loss_bbox_dn_4: 0.3112 (0.3112)  loss_bbox_dn_5: 0.3096 (0.3096)  loss_bbox_enc_0: 0.4498 (0.4498)  loss_giou: 1.4080 (1.4080)  loss_giou_aux_0: 1.4092 (1.4092)  loss_giou_aux_1: 1.4403 (1.4403)  loss_giou_aux_2: 1.4434 (1.4434)  loss_giou_aux_3: 1.4308 (1.4308)  loss_giou_aux_4: 1.4159 (1.4159)  loss_giou_dn_0: 1.1868 (1.1868)  loss_giou_dn_1: 1.1197 (1.1197)  loss_giou_dn_2: 1.0865 (1.0865)  loss_giou_dn_3: 1.0741 (1.0741)  loss_giou_dn_4: 1.0622 (1.0622)  loss_giou_dn_5: 1.0600 (1.0600)  loss_giou_enc_0: 1.4522 (1.4522)  loss_vfl: 0.9241 (0.9241)  loss_vfl_aux_0: 0.8879 (0.8879)  loss_vfl_aux_1: 0.8584 (0.8584)  loss_vfl_aux_2: 0.8640 (0.8640)  loss_vfl_aux_3: 0.9236 (0.9236)  loss_vfl_aux_4: 0.9087 (0.9087)  loss_vfl_dn_0: 0.4617 (0.4617)  loss_vfl_dn_1: 0.4969 (0.4969)  loss_vfl_dn_2: 0.5291 (0.5291)  loss_vfl_dn_3: 0.5544 (0.5544)  loss_vfl_dn_4: 0.5751 (0.5751)  loss_vfl_dn_5: 0.5986 (0.5986)  loss_vfl_enc_0: 0.8843 (0.8843)  time: 4.3198  data: 2.7865  max mem: 10356\r\n",
      "Epoch: [34]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 29.6300 (30.2231)  loss_bbox: 0.3336 (0.3549)  loss_bbox_aux_0: 0.3838 (0.3901)  loss_bbox_aux_1: 0.3572 (0.3806)  loss_bbox_aux_2: 0.3544 (0.3702)  loss_bbox_aux_3: 0.3848 (0.3656)  loss_bbox_aux_4: 0.3494 (0.3581)  loss_bbox_dn_0: 0.3426 (0.4257)  loss_bbox_dn_1: 0.3232 (0.3976)  loss_bbox_dn_2: 0.3155 (0.3849)  loss_bbox_dn_3: 0.3106 (0.3776)  loss_bbox_dn_4: 0.3060 (0.3734)  loss_bbox_dn_5: 0.3054 (0.3728)  loss_bbox_enc_0: 0.3832 (0.4256)  loss_giou: 1.1840 (1.0951)  loss_giou_aux_0: 1.2235 (1.1374)  loss_giou_aux_1: 1.1974 (1.1200)  loss_giou_aux_2: 1.2016 (1.1100)  loss_giou_aux_3: 1.2000 (1.1005)  loss_giou_aux_4: 1.2197 (1.0968)  loss_giou_dn_0: 1.1788 (1.1481)  loss_giou_dn_1: 1.1194 (1.0696)  loss_giou_dn_2: 1.0843 (1.0358)  loss_giou_dn_3: 1.0664 (1.0179)  loss_giou_dn_4: 1.0598 (1.0067)  loss_giou_dn_5: 1.0608 (1.0061)  loss_giou_enc_0: 1.2989 (1.2131)  loss_vfl: 0.9597 (1.1232)  loss_vfl_aux_0: 0.9412 (1.1037)  loss_vfl_aux_1: 0.9155 (1.1080)  loss_vfl_aux_2: 0.9270 (1.1075)  loss_vfl_aux_3: 0.9436 (1.1215)  loss_vfl_aux_4: 0.9348 (1.1225)  loss_vfl_dn_0: 0.4833 (0.4944)  loss_vfl_dn_1: 0.5244 (0.5332)  loss_vfl_dn_2: 0.5392 (0.5548)  loss_vfl_dn_3: 0.5605 (0.5791)  loss_vfl_dn_4: 0.5784 (0.6007)  loss_vfl_dn_5: 0.5811 (0.6147)  loss_vfl_enc_0: 0.8879 (1.0253)  time: 1.0604  data: 0.0318  max mem: 10356\r\n",
      "Epoch: [34] Total time: 0:01:26 (1.0948 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 29.6300 (30.2231)  loss_bbox: 0.3336 (0.3549)  loss_bbox_aux_0: 0.3838 (0.3901)  loss_bbox_aux_1: 0.3572 (0.3806)  loss_bbox_aux_2: 0.3544 (0.3702)  loss_bbox_aux_3: 0.3848 (0.3656)  loss_bbox_aux_4: 0.3494 (0.3581)  loss_bbox_dn_0: 0.3426 (0.4257)  loss_bbox_dn_1: 0.3232 (0.3976)  loss_bbox_dn_2: 0.3155 (0.3849)  loss_bbox_dn_3: 0.3106 (0.3776)  loss_bbox_dn_4: 0.3060 (0.3734)  loss_bbox_dn_5: 0.3054 (0.3728)  loss_bbox_enc_0: 0.3832 (0.4256)  loss_giou: 1.1840 (1.0951)  loss_giou_aux_0: 1.2235 (1.1374)  loss_giou_aux_1: 1.1974 (1.1200)  loss_giou_aux_2: 1.2016 (1.1100)  loss_giou_aux_3: 1.2000 (1.1005)  loss_giou_aux_4: 1.2197 (1.0968)  loss_giou_dn_0: 1.1788 (1.1481)  loss_giou_dn_1: 1.1194 (1.0696)  loss_giou_dn_2: 1.0843 (1.0358)  loss_giou_dn_3: 1.0664 (1.0179)  loss_giou_dn_4: 1.0598 (1.0067)  loss_giou_dn_5: 1.0608 (1.0061)  loss_giou_enc_0: 1.2989 (1.2131)  loss_vfl: 0.9597 (1.1232)  loss_vfl_aux_0: 0.9412 (1.1037)  loss_vfl_aux_1: 0.9155 (1.1080)  loss_vfl_aux_2: 0.9270 (1.1075)  loss_vfl_aux_3: 0.9436 (1.1215)  loss_vfl_aux_4: 0.9348 (1.1225)  loss_vfl_dn_0: 0.4833 (0.4944)  loss_vfl_dn_1: 0.5244 (0.5332)  loss_vfl_dn_2: 0.5392 (0.5548)  loss_vfl_dn_3: 0.5605 (0.5791)  loss_vfl_dn_4: 0.5784 (0.6007)  loss_vfl_dn_5: 0.5811 (0.6147)  loss_vfl_enc_0: 0.8879 (1.0253)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3711  data: 1.4463  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0761  data: 0.2206  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0938 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.017\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.018\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.025\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.028\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.144\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.206\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.215\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.052\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.269\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.311\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.317\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.240\r\n",
      "best_stat: {'epoch': 33, 'coco_eval_bbox': 0.01933803381323522}\r\n",
      "Epoch: [35]  [ 0/79]  eta: 0:06:25  lr: 0.000020  loss: 33.0683 (33.0683)  loss_bbox: 0.3698 (0.3698)  loss_bbox_aux_0: 0.3924 (0.3924)  loss_bbox_aux_1: 0.4081 (0.4081)  loss_bbox_aux_2: 0.3786 (0.3786)  loss_bbox_aux_3: 0.3289 (0.3289)  loss_bbox_aux_4: 0.3240 (0.3240)  loss_bbox_dn_0: 0.6991 (0.6991)  loss_bbox_dn_1: 0.6511 (0.6511)  loss_bbox_dn_2: 0.6267 (0.6267)  loss_bbox_dn_3: 0.6132 (0.6132)  loss_bbox_dn_4: 0.6014 (0.6014)  loss_bbox_dn_5: 0.5990 (0.5990)  loss_bbox_enc_0: 0.4321 (0.4321)  loss_giou: 0.8072 (0.8072)  loss_giou_aux_0: 0.8449 (0.8449)  loss_giou_aux_1: 0.8144 (0.8144)  loss_giou_aux_2: 0.7979 (0.7979)  loss_giou_aux_3: 0.8136 (0.8136)  loss_giou_aux_4: 0.8186 (0.8186)  loss_giou_dn_0: 1.1299 (1.1299)  loss_giou_dn_1: 1.0374 (1.0374)  loss_giou_dn_2: 1.0049 (1.0049)  loss_giou_dn_3: 0.9812 (0.9812)  loss_giou_dn_4: 0.9750 (0.9750)  loss_giou_dn_5: 0.9731 (0.9731)  loss_giou_enc_0: 0.8892 (0.8892)  loss_vfl: 1.4346 (1.4346)  loss_vfl_aux_0: 1.5991 (1.5991)  loss_vfl_aux_1: 1.4917 (1.4917)  loss_vfl_aux_2: 1.5288 (1.5288)  loss_vfl_aux_3: 1.5654 (1.5654)  loss_vfl_aux_4: 1.5122 (1.5122)  loss_vfl_dn_0: 0.5813 (0.5813)  loss_vfl_dn_1: 0.6523 (0.6523)  loss_vfl_dn_2: 0.6992 (0.6992)  loss_vfl_dn_3: 0.7393 (0.7393)  loss_vfl_dn_4: 0.7510 (0.7510)  loss_vfl_dn_5: 0.7168 (0.7168)  loss_vfl_enc_0: 1.4849 (1.4849)  time: 4.8778  data: 3.1340  max mem: 10356\r\n",
      "Epoch: [35]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 30.4141 (30.2417)  loss_bbox: 0.3132 (0.3548)  loss_bbox_aux_0: 0.3724 (0.3845)  loss_bbox_aux_1: 0.3595 (0.3780)  loss_bbox_aux_2: 0.3272 (0.3659)  loss_bbox_aux_3: 0.3280 (0.3605)  loss_bbox_aux_4: 0.3163 (0.3571)  loss_bbox_dn_0: 0.4122 (0.4292)  loss_bbox_dn_1: 0.3917 (0.4005)  loss_bbox_dn_2: 0.3806 (0.3867)  loss_bbox_dn_3: 0.3656 (0.3781)  loss_bbox_dn_4: 0.3593 (0.3732)  loss_bbox_dn_5: 0.3580 (0.3724)  loss_bbox_enc_0: 0.3990 (0.4157)  loss_giou: 1.0973 (1.1203)  loss_giou_aux_0: 1.1323 (1.1599)  loss_giou_aux_1: 1.1408 (1.1445)  loss_giou_aux_2: 1.1059 (1.1356)  loss_giou_aux_3: 1.1169 (1.1303)  loss_giou_aux_4: 1.1026 (1.1224)  loss_giou_dn_0: 1.1507 (1.1534)  loss_giou_dn_1: 1.0797 (1.0772)  loss_giou_dn_2: 1.0449 (1.0449)  loss_giou_dn_3: 1.0250 (1.0264)  loss_giou_dn_4: 1.0130 (1.0156)  loss_giou_dn_5: 1.0130 (1.0150)  loss_giou_enc_0: 1.2324 (1.2360)  loss_vfl: 1.0549 (1.1075)  loss_vfl_aux_0: 1.1235 (1.0914)  loss_vfl_aux_1: 1.1021 (1.0829)  loss_vfl_aux_2: 1.0605 (1.0881)  loss_vfl_aux_3: 1.0718 (1.0972)  loss_vfl_aux_4: 1.0657 (1.1016)  loss_vfl_dn_0: 0.4862 (0.4909)  loss_vfl_dn_1: 0.5300 (0.5248)  loss_vfl_dn_2: 0.5562 (0.5444)  loss_vfl_dn_3: 0.5865 (0.5679)  loss_vfl_dn_4: 0.6030 (0.5886)  loss_vfl_dn_5: 0.6130 (0.6008)  loss_vfl_enc_0: 1.0234 (1.0175)  time: 0.9979  data: 0.0319  max mem: 10356\r\n",
      "Epoch: [35] Total time: 0:01:26 (1.0895 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 30.4141 (30.2417)  loss_bbox: 0.3132 (0.3548)  loss_bbox_aux_0: 0.3724 (0.3845)  loss_bbox_aux_1: 0.3595 (0.3780)  loss_bbox_aux_2: 0.3272 (0.3659)  loss_bbox_aux_3: 0.3280 (0.3605)  loss_bbox_aux_4: 0.3163 (0.3571)  loss_bbox_dn_0: 0.4122 (0.4292)  loss_bbox_dn_1: 0.3917 (0.4005)  loss_bbox_dn_2: 0.3806 (0.3867)  loss_bbox_dn_3: 0.3656 (0.3781)  loss_bbox_dn_4: 0.3593 (0.3732)  loss_bbox_dn_5: 0.3580 (0.3724)  loss_bbox_enc_0: 0.3990 (0.4157)  loss_giou: 1.0973 (1.1203)  loss_giou_aux_0: 1.1323 (1.1599)  loss_giou_aux_1: 1.1408 (1.1445)  loss_giou_aux_2: 1.1059 (1.1356)  loss_giou_aux_3: 1.1169 (1.1303)  loss_giou_aux_4: 1.1026 (1.1224)  loss_giou_dn_0: 1.1507 (1.1534)  loss_giou_dn_1: 1.0797 (1.0772)  loss_giou_dn_2: 1.0449 (1.0449)  loss_giou_dn_3: 1.0250 (1.0264)  loss_giou_dn_4: 1.0130 (1.0156)  loss_giou_dn_5: 1.0130 (1.0150)  loss_giou_enc_0: 1.2324 (1.2360)  loss_vfl: 1.0549 (1.1075)  loss_vfl_aux_0: 1.1235 (1.0914)  loss_vfl_aux_1: 1.1021 (1.0829)  loss_vfl_aux_2: 1.0605 (1.0881)  loss_vfl_aux_3: 1.0718 (1.0972)  loss_vfl_aux_4: 1.0657 (1.1016)  loss_vfl_dn_0: 0.4862 (0.4909)  loss_vfl_dn_1: 0.5300 (0.5248)  loss_vfl_dn_2: 0.5562 (0.5444)  loss_vfl_dn_3: 0.5865 (0.5679)  loss_vfl_dn_4: 0.6030 (0.5886)  loss_vfl_dn_5: 0.6130 (0.6008)  loss_vfl_enc_0: 1.0234 (1.0175)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.1276  data: 1.1712  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0719  data: 0.2070  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0892 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.19s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.018\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.027\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.019\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.033\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.026\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.144\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.208\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.218\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.282\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.307\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.321\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.220\r\n",
      "best_stat: {'epoch': 33, 'coco_eval_bbox': 0.01933803381323522}\r\n",
      "Epoch: [36]  [ 0/79]  eta: 0:06:25  lr: 0.000020  loss: 28.8454 (28.8454)  loss_bbox: 0.3446 (0.3446)  loss_bbox_aux_0: 0.3722 (0.3722)  loss_bbox_aux_1: 0.3733 (0.3733)  loss_bbox_aux_2: 0.3708 (0.3708)  loss_bbox_aux_3: 0.3479 (0.3479)  loss_bbox_aux_4: 0.3541 (0.3541)  loss_bbox_dn_0: 0.3346 (0.3346)  loss_bbox_dn_1: 0.3024 (0.3024)  loss_bbox_dn_2: 0.2870 (0.2870)  loss_bbox_dn_3: 0.2772 (0.2772)  loss_bbox_dn_4: 0.2697 (0.2697)  loss_bbox_dn_5: 0.2683 (0.2683)  loss_bbox_enc_0: 0.3725 (0.3725)  loss_giou: 1.2651 (1.2651)  loss_giou_aux_0: 1.2810 (1.2810)  loss_giou_aux_1: 1.3087 (1.3087)  loss_giou_aux_2: 1.2742 (1.2742)  loss_giou_aux_3: 1.2877 (1.2877)  loss_giou_aux_4: 1.2839 (1.2839)  loss_giou_dn_0: 1.1607 (1.1607)  loss_giou_dn_1: 1.0897 (1.0897)  loss_giou_dn_2: 1.0511 (1.0511)  loss_giou_dn_3: 1.0330 (1.0330)  loss_giou_dn_4: 1.0189 (1.0189)  loss_giou_dn_5: 1.0192 (1.0192)  loss_giou_enc_0: 1.3635 (1.3635)  loss_vfl: 0.8540 (0.8540)  loss_vfl_aux_0: 0.9309 (0.9309)  loss_vfl_aux_1: 0.8679 (0.8679)  loss_vfl_aux_2: 0.8889 (0.8889)  loss_vfl_aux_3: 0.8535 (0.8535)  loss_vfl_aux_4: 0.8352 (0.8352)  loss_vfl_dn_0: 0.4718 (0.4718)  loss_vfl_dn_1: 0.4869 (0.4869)  loss_vfl_dn_2: 0.4988 (0.4988)  loss_vfl_dn_3: 0.5221 (0.5221)  loss_vfl_dn_4: 0.5287 (0.5287)  loss_vfl_dn_5: 0.5374 (0.5374)  loss_vfl_enc_0: 0.8579 (0.8579)  time: 4.8831  data: 3.3724  max mem: 10356\r\n",
      "Epoch: [36]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 29.5382 (29.8661)  loss_bbox: 0.3102 (0.3379)  loss_bbox_aux_0: 0.3252 (0.3705)  loss_bbox_aux_1: 0.3274 (0.3588)  loss_bbox_aux_2: 0.3113 (0.3486)  loss_bbox_aux_3: 0.3118 (0.3427)  loss_bbox_aux_4: 0.3067 (0.3380)  loss_bbox_dn_0: 0.3733 (0.4095)  loss_bbox_dn_1: 0.3496 (0.3797)  loss_bbox_dn_2: 0.3347 (0.3664)  loss_bbox_dn_3: 0.3247 (0.3584)  loss_bbox_dn_4: 0.3202 (0.3543)  loss_bbox_dn_5: 0.3198 (0.3536)  loss_bbox_enc_0: 0.3670 (0.4031)  loss_giou: 1.1321 (1.1136)  loss_giou_aux_0: 1.1632 (1.1534)  loss_giou_aux_1: 1.1389 (1.1390)  loss_giou_aux_2: 1.1541 (1.1289)  loss_giou_aux_3: 1.1152 (1.1233)  loss_giou_aux_4: 1.1226 (1.1163)  loss_giou_dn_0: 1.1355 (1.1499)  loss_giou_dn_1: 1.0695 (1.0735)  loss_giou_dn_2: 1.0488 (1.0428)  loss_giou_dn_3: 1.0393 (1.0250)  loss_giou_dn_4: 1.0263 (1.0149)  loss_giou_dn_5: 1.0252 (1.0147)  loss_giou_enc_0: 1.2310 (1.2308)  loss_vfl: 0.9893 (1.0935)  loss_vfl_aux_0: 1.0154 (1.0818)  loss_vfl_aux_1: 1.0293 (1.0799)  loss_vfl_aux_2: 1.0278 (1.0772)  loss_vfl_aux_3: 1.0208 (1.0836)  loss_vfl_aux_4: 1.0100 (1.0925)  loss_vfl_dn_0: 0.4880 (0.4898)  loss_vfl_dn_1: 0.5227 (0.5256)  loss_vfl_dn_2: 0.5420 (0.5437)  loss_vfl_dn_3: 0.5583 (0.5658)  loss_vfl_dn_4: 0.5808 (0.5866)  loss_vfl_dn_5: 0.6033 (0.5989)  loss_vfl_enc_0: 0.8872 (0.9997)  time: 1.0489  data: 0.0304  max mem: 10356\r\n",
      "Epoch: [36] Total time: 0:01:25 (1.0878 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 29.5382 (29.8661)  loss_bbox: 0.3102 (0.3379)  loss_bbox_aux_0: 0.3252 (0.3705)  loss_bbox_aux_1: 0.3274 (0.3588)  loss_bbox_aux_2: 0.3113 (0.3486)  loss_bbox_aux_3: 0.3118 (0.3427)  loss_bbox_aux_4: 0.3067 (0.3380)  loss_bbox_dn_0: 0.3733 (0.4095)  loss_bbox_dn_1: 0.3496 (0.3797)  loss_bbox_dn_2: 0.3347 (0.3664)  loss_bbox_dn_3: 0.3247 (0.3584)  loss_bbox_dn_4: 0.3202 (0.3543)  loss_bbox_dn_5: 0.3198 (0.3536)  loss_bbox_enc_0: 0.3670 (0.4031)  loss_giou: 1.1321 (1.1136)  loss_giou_aux_0: 1.1632 (1.1534)  loss_giou_aux_1: 1.1389 (1.1390)  loss_giou_aux_2: 1.1541 (1.1289)  loss_giou_aux_3: 1.1152 (1.1233)  loss_giou_aux_4: 1.1226 (1.1163)  loss_giou_dn_0: 1.1355 (1.1499)  loss_giou_dn_1: 1.0695 (1.0735)  loss_giou_dn_2: 1.0488 (1.0428)  loss_giou_dn_3: 1.0393 (1.0250)  loss_giou_dn_4: 1.0263 (1.0149)  loss_giou_dn_5: 1.0252 (1.0147)  loss_giou_enc_0: 1.2310 (1.2308)  loss_vfl: 0.9893 (1.0935)  loss_vfl_aux_0: 1.0154 (1.0818)  loss_vfl_aux_1: 1.0293 (1.0799)  loss_vfl_aux_2: 1.0278 (1.0772)  loss_vfl_aux_3: 1.0208 (1.0836)  loss_vfl_aux_4: 1.0100 (1.0925)  loss_vfl_dn_0: 0.4880 (0.4898)  loss_vfl_dn_1: 0.5227 (0.5256)  loss_vfl_dn_2: 0.5420 (0.5437)  loss_vfl_dn_3: 0.5583 (0.5658)  loss_vfl_dn_4: 0.5808 (0.5866)  loss_vfl_dn_5: 0.6033 (0.5989)  loss_vfl_enc_0: 0.8872 (0.9997)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.2236  data: 1.2434  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0723  data: 0.2082  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0889 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.021\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.030\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.026\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.044\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.027\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.155\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.211\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.221\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.064\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.255\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.318\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.333\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.240\r\n",
      "best_stat: {'epoch': 36, 'coco_eval_bbox': 0.021310717283170674}\r\n",
      "Epoch: [37]  [ 0/79]  eta: 0:04:55  lr: 0.000020  loss: 28.8028 (28.8028)  loss_bbox: 0.3901 (0.3901)  loss_bbox_aux_0: 0.3713 (0.3713)  loss_bbox_aux_1: 0.3565 (0.3565)  loss_bbox_aux_2: 0.3288 (0.3288)  loss_bbox_aux_3: 0.3667 (0.3667)  loss_bbox_aux_4: 0.3667 (0.3667)  loss_bbox_dn_0: 0.3658 (0.3658)  loss_bbox_dn_1: 0.3317 (0.3317)  loss_bbox_dn_2: 0.3129 (0.3129)  loss_bbox_dn_3: 0.3058 (0.3058)  loss_bbox_dn_4: 0.2988 (0.2988)  loss_bbox_dn_5: 0.2978 (0.2978)  loss_bbox_enc_0: 0.4008 (0.4008)  loss_giou: 1.1749 (1.1749)  loss_giou_aux_0: 1.1855 (1.1855)  loss_giou_aux_1: 1.1666 (1.1666)  loss_giou_aux_2: 1.1512 (1.1512)  loss_giou_aux_3: 1.2119 (1.2119)  loss_giou_aux_4: 1.1722 (1.1722)  loss_giou_dn_0: 1.1653 (1.1653)  loss_giou_dn_1: 1.0951 (1.0951)  loss_giou_dn_2: 1.0652 (1.0652)  loss_giou_dn_3: 1.0506 (1.0506)  loss_giou_dn_4: 1.0398 (1.0398)  loss_giou_dn_5: 1.0388 (1.0388)  loss_giou_enc_0: 1.2753 (1.2753)  loss_vfl: 0.8865 (0.8865)  loss_vfl_aux_0: 0.9165 (0.9165)  loss_vfl_aux_1: 0.9404 (0.9404)  loss_vfl_aux_2: 0.9219 (0.9219)  loss_vfl_aux_3: 0.9146 (0.9146)  loss_vfl_aux_4: 0.8948 (0.8948)  loss_vfl_dn_0: 0.4803 (0.4803)  loss_vfl_dn_1: 0.5128 (0.5128)  loss_vfl_dn_2: 0.5374 (0.5374)  loss_vfl_dn_3: 0.5576 (0.5576)  loss_vfl_dn_4: 0.5798 (0.5798)  loss_vfl_dn_5: 0.5889 (0.5889)  loss_vfl_enc_0: 0.7849 (0.7849)  time: 3.7425  data: 2.5931  max mem: 10356\r\n",
      "Epoch: [37]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 29.7096 (30.1685)  loss_bbox: 0.3747 (0.3643)  loss_bbox_aux_0: 0.3918 (0.3913)  loss_bbox_aux_1: 0.3846 (0.3836)  loss_bbox_aux_2: 0.3750 (0.3753)  loss_bbox_aux_3: 0.3786 (0.3677)  loss_bbox_aux_4: 0.3782 (0.3681)  loss_bbox_dn_0: 0.3372 (0.4276)  loss_bbox_dn_1: 0.3040 (0.3970)  loss_bbox_dn_2: 0.2949 (0.3834)  loss_bbox_dn_3: 0.2913 (0.3754)  loss_bbox_dn_4: 0.2880 (0.3710)  loss_bbox_dn_5: 0.2872 (0.3702)  loss_bbox_enc_0: 0.4194 (0.4221)  loss_giou: 1.2480 (1.1061)  loss_giou_aux_0: 1.2792 (1.1513)  loss_giou_aux_1: 1.2417 (1.1334)  loss_giou_aux_2: 1.2530 (1.1214)  loss_giou_aux_3: 1.2560 (1.1172)  loss_giou_aux_4: 1.2570 (1.1081)  loss_giou_dn_0: 1.1596 (1.1457)  loss_giou_dn_1: 1.0702 (1.0639)  loss_giou_dn_2: 1.0381 (1.0309)  loss_giou_dn_3: 1.0228 (1.0126)  loss_giou_dn_4: 1.0106 (1.0016)  loss_giou_dn_5: 1.0105 (1.0011)  loss_giou_enc_0: 1.3092 (1.2298)  loss_vfl: 0.9707 (1.0929)  loss_vfl_aux_0: 0.9849 (1.0979)  loss_vfl_aux_1: 1.0269 (1.0912)  loss_vfl_aux_2: 0.9817 (1.0918)  loss_vfl_aux_3: 0.9897 (1.0935)  loss_vfl_aux_4: 0.9858 (1.0988)  loss_vfl_dn_0: 0.4902 (0.4933)  loss_vfl_dn_1: 0.5190 (0.5325)  loss_vfl_dn_2: 0.5515 (0.5531)  loss_vfl_dn_3: 0.5715 (0.5759)  loss_vfl_dn_4: 0.5898 (0.5974)  loss_vfl_dn_5: 0.5895 (0.6080)  loss_vfl_enc_0: 0.9836 (1.0221)  time: 0.9845  data: 0.0314  max mem: 10356\r\n",
      "Epoch: [37] Total time: 0:01:26 (1.0953 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 29.7096 (30.1685)  loss_bbox: 0.3747 (0.3643)  loss_bbox_aux_0: 0.3918 (0.3913)  loss_bbox_aux_1: 0.3846 (0.3836)  loss_bbox_aux_2: 0.3750 (0.3753)  loss_bbox_aux_3: 0.3786 (0.3677)  loss_bbox_aux_4: 0.3782 (0.3681)  loss_bbox_dn_0: 0.3372 (0.4276)  loss_bbox_dn_1: 0.3040 (0.3970)  loss_bbox_dn_2: 0.2949 (0.3834)  loss_bbox_dn_3: 0.2913 (0.3754)  loss_bbox_dn_4: 0.2880 (0.3710)  loss_bbox_dn_5: 0.2872 (0.3702)  loss_bbox_enc_0: 0.4194 (0.4221)  loss_giou: 1.2480 (1.1061)  loss_giou_aux_0: 1.2792 (1.1513)  loss_giou_aux_1: 1.2417 (1.1334)  loss_giou_aux_2: 1.2530 (1.1214)  loss_giou_aux_3: 1.2560 (1.1172)  loss_giou_aux_4: 1.2570 (1.1081)  loss_giou_dn_0: 1.1596 (1.1457)  loss_giou_dn_1: 1.0702 (1.0639)  loss_giou_dn_2: 1.0381 (1.0309)  loss_giou_dn_3: 1.0228 (1.0126)  loss_giou_dn_4: 1.0106 (1.0016)  loss_giou_dn_5: 1.0105 (1.0011)  loss_giou_enc_0: 1.3092 (1.2298)  loss_vfl: 0.9707 (1.0929)  loss_vfl_aux_0: 0.9849 (1.0979)  loss_vfl_aux_1: 1.0269 (1.0912)  loss_vfl_aux_2: 0.9817 (1.0918)  loss_vfl_aux_3: 0.9897 (1.0935)  loss_vfl_aux_4: 0.9858 (1.0988)  loss_vfl_dn_0: 0.4902 (0.4933)  loss_vfl_dn_1: 0.5190 (0.5325)  loss_vfl_dn_2: 0.5515 (0.5531)  loss_vfl_dn_3: 0.5715 (0.5759)  loss_vfl_dn_4: 0.5898 (0.5974)  loss_vfl_dn_5: 0.5895 (0.6080)  loss_vfl_enc_0: 0.9836 (1.0221)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3655  data: 1.3863  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0840  data: 0.2267  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1011 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.015\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.024\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.016\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.028\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.032\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.124\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.206\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.216\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.056\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.270\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.322\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.321\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.242\r\n",
      "best_stat: {'epoch': 36, 'coco_eval_bbox': 0.021310717283170674}\r\n",
      "Epoch: [38]  [ 0/79]  eta: 0:05:35  lr: 0.000020  loss: 30.9804 (30.9804)  loss_bbox: 0.4248 (0.4248)  loss_bbox_aux_0: 0.4612 (0.4612)  loss_bbox_aux_1: 0.4494 (0.4494)  loss_bbox_aux_2: 0.4649 (0.4649)  loss_bbox_aux_3: 0.4039 (0.4039)  loss_bbox_aux_4: 0.4271 (0.4271)  loss_bbox_dn_0: 0.4113 (0.4113)  loss_bbox_dn_1: 0.3978 (0.3978)  loss_bbox_dn_2: 0.3878 (0.3878)  loss_bbox_dn_3: 0.3864 (0.3864)  loss_bbox_dn_4: 0.3829 (0.3829)  loss_bbox_dn_5: 0.3826 (0.3826)  loss_bbox_enc_0: 0.4550 (0.4550)  loss_giou: 1.2449 (1.2449)  loss_giou_aux_0: 1.3016 (1.3016)  loss_giou_aux_1: 1.2745 (1.2745)  loss_giou_aux_2: 1.2421 (1.2421)  loss_giou_aux_3: 1.2842 (1.2842)  loss_giou_aux_4: 1.2410 (1.2410)  loss_giou_dn_0: 1.1775 (1.1775)  loss_giou_dn_1: 1.1163 (1.1163)  loss_giou_dn_2: 1.0899 (1.0899)  loss_giou_dn_3: 1.0794 (1.0794)  loss_giou_dn_4: 1.0679 (1.0679)  loss_giou_dn_5: 1.0683 (1.0683)  loss_giou_enc_0: 1.3657 (1.3657)  loss_vfl: 0.9932 (0.9932)  loss_vfl_aux_0: 0.9197 (0.9197)  loss_vfl_aux_1: 1.0020 (1.0020)  loss_vfl_aux_2: 0.9929 (0.9929)  loss_vfl_aux_3: 1.0178 (1.0178)  loss_vfl_aux_4: 1.0203 (1.0203)  loss_vfl_dn_0: 0.4863 (0.4863)  loss_vfl_dn_1: 0.5050 (0.5050)  loss_vfl_dn_2: 0.5134 (0.5134)  loss_vfl_dn_3: 0.5298 (0.5298)  loss_vfl_dn_4: 0.5552 (0.5552)  loss_vfl_dn_5: 0.5649 (0.5649)  loss_vfl_enc_0: 0.8914 (0.8914)  time: 4.2417  data: 2.3468  max mem: 10356\r\n",
      "Epoch: [38]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 29.3861 (29.8400)  loss_bbox: 0.3026 (0.3382)  loss_bbox_aux_0: 0.3139 (0.3677)  loss_bbox_aux_1: 0.3078 (0.3576)  loss_bbox_aux_2: 0.3180 (0.3497)  loss_bbox_aux_3: 0.3023 (0.3439)  loss_bbox_aux_4: 0.3018 (0.3387)  loss_bbox_dn_0: 0.3630 (0.4128)  loss_bbox_dn_1: 0.3291 (0.3821)  loss_bbox_dn_2: 0.3131 (0.3683)  loss_bbox_dn_3: 0.3025 (0.3597)  loss_bbox_dn_4: 0.3025 (0.3547)  loss_bbox_dn_5: 0.3026 (0.3540)  loss_bbox_enc_0: 0.3527 (0.4036)  loss_giou: 0.9010 (1.0924)  loss_giou_aux_0: 0.9255 (1.1266)  loss_giou_aux_1: 0.9229 (1.1154)  loss_giou_aux_2: 0.9128 (1.1049)  loss_giou_aux_3: 0.9034 (1.1023)  loss_giou_aux_4: 0.8955 (1.0924)  loss_giou_dn_0: 1.1334 (1.1447)  loss_giou_dn_1: 1.0424 (1.0658)  loss_giou_dn_2: 0.9984 (1.0337)  loss_giou_dn_3: 0.9614 (1.0165)  loss_giou_dn_4: 0.9490 (1.0058)  loss_giou_dn_5: 0.9463 (1.0057)  loss_giou_enc_0: 1.1126 (1.2133)  loss_vfl: 1.1970 (1.1082)  loss_vfl_aux_0: 1.2061 (1.1086)  loss_vfl_aux_1: 1.2393 (1.1057)  loss_vfl_aux_2: 1.2236 (1.1057)  loss_vfl_aux_3: 1.2046 (1.1008)  loss_vfl_aux_4: 1.1948 (1.1074)  loss_vfl_dn_0: 0.4958 (0.4952)  loss_vfl_dn_1: 0.5310 (0.5319)  loss_vfl_dn_2: 0.5503 (0.5496)  loss_vfl_dn_3: 0.5613 (0.5712)  loss_vfl_dn_4: 0.5811 (0.5920)  loss_vfl_dn_5: 0.5979 (0.6045)  loss_vfl_enc_0: 1.0439 (1.0085)  time: 0.9817  data: 0.0320  max mem: 10356\r\n",
      "Epoch: [38] Total time: 0:01:25 (1.0849 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 29.3861 (29.8400)  loss_bbox: 0.3026 (0.3382)  loss_bbox_aux_0: 0.3139 (0.3677)  loss_bbox_aux_1: 0.3078 (0.3576)  loss_bbox_aux_2: 0.3180 (0.3497)  loss_bbox_aux_3: 0.3023 (0.3439)  loss_bbox_aux_4: 0.3018 (0.3387)  loss_bbox_dn_0: 0.3630 (0.4128)  loss_bbox_dn_1: 0.3291 (0.3821)  loss_bbox_dn_2: 0.3131 (0.3683)  loss_bbox_dn_3: 0.3025 (0.3597)  loss_bbox_dn_4: 0.3025 (0.3547)  loss_bbox_dn_5: 0.3026 (0.3540)  loss_bbox_enc_0: 0.3527 (0.4036)  loss_giou: 0.9010 (1.0924)  loss_giou_aux_0: 0.9255 (1.1266)  loss_giou_aux_1: 0.9229 (1.1154)  loss_giou_aux_2: 0.9128 (1.1049)  loss_giou_aux_3: 0.9034 (1.1023)  loss_giou_aux_4: 0.8955 (1.0924)  loss_giou_dn_0: 1.1334 (1.1447)  loss_giou_dn_1: 1.0424 (1.0658)  loss_giou_dn_2: 0.9984 (1.0337)  loss_giou_dn_3: 0.9614 (1.0165)  loss_giou_dn_4: 0.9490 (1.0058)  loss_giou_dn_5: 0.9463 (1.0057)  loss_giou_enc_0: 1.1126 (1.2133)  loss_vfl: 1.1970 (1.1082)  loss_vfl_aux_0: 1.2061 (1.1086)  loss_vfl_aux_1: 1.2393 (1.1057)  loss_vfl_aux_2: 1.2236 (1.1057)  loss_vfl_aux_3: 1.2046 (1.1008)  loss_vfl_aux_4: 1.1948 (1.1074)  loss_vfl_dn_0: 0.4958 (0.4952)  loss_vfl_dn_1: 0.5310 (0.5319)  loss_vfl_dn_2: 0.5503 (0.5496)  loss_vfl_dn_3: 0.5613 (0.5712)  loss_vfl_dn_4: 0.5811 (0.5920)  loss_vfl_dn_5: 0.5979 (0.6045)  loss_vfl_enc_0: 1.0439 (1.0085)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.1503  data: 1.1977  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0606  data: 0.2070  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0788 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.028\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.037\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.030\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.051\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.032\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.149\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.217\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.230\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.290\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.360\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.339\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.249\r\n",
      "best_stat: {'epoch': 38, 'coco_eval_bbox': 0.028053103962876885}\r\n",
      "Epoch: [39]  [ 0/79]  eta: 0:05:39  lr: 0.000020  loss: 29.0613 (29.0613)  loss_bbox: 0.3493 (0.3493)  loss_bbox_aux_0: 0.3719 (0.3719)  loss_bbox_aux_1: 0.3815 (0.3815)  loss_bbox_aux_2: 0.3640 (0.3640)  loss_bbox_aux_3: 0.3556 (0.3556)  loss_bbox_aux_4: 0.3522 (0.3522)  loss_bbox_dn_0: 0.3552 (0.3552)  loss_bbox_dn_1: 0.3290 (0.3290)  loss_bbox_dn_2: 0.3180 (0.3180)  loss_bbox_dn_3: 0.3123 (0.3123)  loss_bbox_dn_4: 0.3079 (0.3079)  loss_bbox_dn_5: 0.3074 (0.3074)  loss_bbox_enc_0: 0.4042 (0.4042)  loss_giou: 1.0268 (1.0268)  loss_giou_aux_0: 1.0983 (1.0983)  loss_giou_aux_1: 1.0275 (1.0275)  loss_giou_aux_2: 1.0454 (1.0454)  loss_giou_aux_3: 1.0334 (1.0334)  loss_giou_aux_4: 1.0152 (1.0152)  loss_giou_dn_0: 1.0740 (1.0740)  loss_giou_dn_1: 0.9697 (0.9697)  loss_giou_dn_2: 0.9293 (0.9293)  loss_giou_dn_3: 0.9129 (0.9129)  loss_giou_dn_4: 0.8958 (0.8958)  loss_giou_dn_5: 0.8955 (0.8955)  loss_giou_enc_0: 1.2244 (1.2244)  loss_vfl: 1.1426 (1.1426)  loss_vfl_aux_0: 1.1177 (1.1177)  loss_vfl_aux_1: 1.1719 (1.1719)  loss_vfl_aux_2: 1.1514 (1.1514)  loss_vfl_aux_3: 1.1919 (1.1919)  loss_vfl_aux_4: 1.1958 (1.1958)  loss_vfl_dn_0: 0.4976 (0.4976)  loss_vfl_dn_1: 0.5391 (0.5391)  loss_vfl_dn_2: 0.5505 (0.5505)  loss_vfl_dn_3: 0.5840 (0.5840)  loss_vfl_dn_4: 0.6201 (0.6201)  loss_vfl_dn_5: 0.6355 (0.6355)  loss_vfl_enc_0: 1.0066 (1.0066)  time: 4.2979  data: 2.8064  max mem: 10356\r\n",
      "Epoch: [39]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 29.7444 (29.7172)  loss_bbox: 0.3418 (0.3251)  loss_bbox_aux_0: 0.3662 (0.3514)  loss_bbox_aux_1: 0.3570 (0.3504)  loss_bbox_aux_2: 0.3412 (0.3388)  loss_bbox_aux_3: 0.3485 (0.3342)  loss_bbox_aux_4: 0.3468 (0.3273)  loss_bbox_dn_0: 0.4400 (0.4163)  loss_bbox_dn_1: 0.4059 (0.3854)  loss_bbox_dn_2: 0.3892 (0.3711)  loss_bbox_dn_3: 0.3792 (0.3630)  loss_bbox_dn_4: 0.3707 (0.3580)  loss_bbox_dn_5: 0.3698 (0.3573)  loss_bbox_enc_0: 0.4081 (0.3942)  loss_giou: 1.0130 (1.0645)  loss_giou_aux_0: 1.0836 (1.1102)  loss_giou_aux_1: 1.0658 (1.0953)  loss_giou_aux_2: 1.0101 (1.0827)  loss_giou_aux_3: 1.0098 (1.0738)  loss_giou_aux_4: 1.0087 (1.0678)  loss_giou_dn_0: 1.1260 (1.1363)  loss_giou_dn_1: 1.0488 (1.0551)  loss_giou_dn_2: 1.0222 (1.0217)  loss_giou_dn_3: 0.9939 (1.0036)  loss_giou_dn_4: 0.9810 (0.9925)  loss_giou_dn_5: 0.9796 (0.9914)  loss_giou_enc_0: 1.1587 (1.2015)  loss_vfl: 1.2402 (1.1302)  loss_vfl_aux_0: 1.1646 (1.1266)  loss_vfl_aux_1: 1.1899 (1.1162)  loss_vfl_aux_2: 1.1758 (1.1195)  loss_vfl_aux_3: 1.2441 (1.1342)  loss_vfl_aux_4: 1.2500 (1.1326)  loss_vfl_dn_0: 0.5034 (0.4992)  loss_vfl_dn_1: 0.5424 (0.5342)  loss_vfl_dn_2: 0.5695 (0.5517)  loss_vfl_dn_3: 0.5989 (0.5732)  loss_vfl_dn_4: 0.6270 (0.5934)  loss_vfl_dn_5: 0.6306 (0.6032)  loss_vfl_enc_0: 1.1035 (1.0342)  time: 1.0410  data: 0.0321  max mem: 10356\r\n",
      "Epoch: [39] Total time: 0:01:26 (1.0909 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 29.7444 (29.7172)  loss_bbox: 0.3418 (0.3251)  loss_bbox_aux_0: 0.3662 (0.3514)  loss_bbox_aux_1: 0.3570 (0.3504)  loss_bbox_aux_2: 0.3412 (0.3388)  loss_bbox_aux_3: 0.3485 (0.3342)  loss_bbox_aux_4: 0.3468 (0.3273)  loss_bbox_dn_0: 0.4400 (0.4163)  loss_bbox_dn_1: 0.4059 (0.3854)  loss_bbox_dn_2: 0.3892 (0.3711)  loss_bbox_dn_3: 0.3792 (0.3630)  loss_bbox_dn_4: 0.3707 (0.3580)  loss_bbox_dn_5: 0.3698 (0.3573)  loss_bbox_enc_0: 0.4081 (0.3942)  loss_giou: 1.0130 (1.0645)  loss_giou_aux_0: 1.0836 (1.1102)  loss_giou_aux_1: 1.0658 (1.0953)  loss_giou_aux_2: 1.0101 (1.0827)  loss_giou_aux_3: 1.0098 (1.0738)  loss_giou_aux_4: 1.0087 (1.0678)  loss_giou_dn_0: 1.1260 (1.1363)  loss_giou_dn_1: 1.0488 (1.0551)  loss_giou_dn_2: 1.0222 (1.0217)  loss_giou_dn_3: 0.9939 (1.0036)  loss_giou_dn_4: 0.9810 (0.9925)  loss_giou_dn_5: 0.9796 (0.9914)  loss_giou_enc_0: 1.1587 (1.2015)  loss_vfl: 1.2402 (1.1302)  loss_vfl_aux_0: 1.1646 (1.1266)  loss_vfl_aux_1: 1.1899 (1.1162)  loss_vfl_aux_2: 1.1758 (1.1195)  loss_vfl_aux_3: 1.2441 (1.1342)  loss_vfl_aux_4: 1.2500 (1.1326)  loss_vfl_dn_0: 0.5034 (0.4992)  loss_vfl_dn_1: 0.5424 (0.5342)  loss_vfl_dn_2: 0.5695 (0.5517)  loss_vfl_dn_3: 0.5989 (0.5732)  loss_vfl_dn_4: 0.6270 (0.5934)  loss_vfl_dn_5: 0.6306 (0.6032)  loss_vfl_enc_0: 1.1035 (1.0342)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.1957  data: 1.2537  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0695  data: 0.2090  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0882 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.19s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.018\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.028\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.019\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.029\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.031\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.140\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.194\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.203\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.049\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.291\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.277\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.292\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.223\r\n",
      "best_stat: {'epoch': 38, 'coco_eval_bbox': 0.028053103962876885}\r\n",
      "Epoch: [40]  [ 0/79]  eta: 0:06:35  lr: 0.000002  loss: 32.2311 (32.2311)  loss_bbox: 0.3666 (0.3666)  loss_bbox_aux_0: 0.4704 (0.4704)  loss_bbox_aux_1: 0.4100 (0.4100)  loss_bbox_aux_2: 0.4248 (0.4248)  loss_bbox_aux_3: 0.4241 (0.4241)  loss_bbox_aux_4: 0.4199 (0.4199)  loss_bbox_dn_0: 0.7919 (0.7919)  loss_bbox_dn_1: 0.7048 (0.7048)  loss_bbox_dn_2: 0.6642 (0.6642)  loss_bbox_dn_3: 0.6380 (0.6380)  loss_bbox_dn_4: 0.6223 (0.6223)  loss_bbox_dn_5: 0.6194 (0.6194)  loss_bbox_enc_0: 0.6251 (0.6251)  loss_giou: 0.7668 (0.7668)  loss_giou_aux_0: 0.7599 (0.7599)  loss_giou_aux_1: 0.8130 (0.8130)  loss_giou_aux_2: 0.7902 (0.7902)  loss_giou_aux_3: 0.7456 (0.7456)  loss_giou_aux_4: 0.7293 (0.7293)  loss_giou_dn_0: 1.0512 (1.0512)  loss_giou_dn_1: 0.8961 (0.8961)  loss_giou_dn_2: 0.8334 (0.8334)  loss_giou_dn_3: 0.7912 (0.7912)  loss_giou_dn_4: 0.7641 (0.7641)  loss_giou_dn_5: 0.7622 (0.7622)  loss_giou_enc_0: 1.0108 (1.0108)  loss_vfl: 1.5278 (1.5278)  loss_vfl_aux_0: 1.6650 (1.6650)  loss_vfl_aux_1: 1.5508 (1.5508)  loss_vfl_aux_2: 1.4697 (1.4697)  loss_vfl_aux_3: 1.5034 (1.5034)  loss_vfl_aux_4: 1.4941 (1.4941)  loss_vfl_dn_0: 0.5342 (0.5342)  loss_vfl_dn_1: 0.6199 (0.6199)  loss_vfl_dn_2: 0.6191 (0.6191)  loss_vfl_dn_3: 0.6631 (0.6631)  loss_vfl_dn_4: 0.6855 (0.6855)  loss_vfl_dn_5: 0.7207 (0.7207)  loss_vfl_enc_0: 1.2822 (1.2822)  time: 5.0075  data: 2.5164  max mem: 10356\r\n",
      "Epoch: [40]  [78/79]  eta: 0:00:01  lr: 0.000002  loss: 29.1802 (29.7050)  loss_bbox: 0.2779 (0.3366)  loss_bbox_aux_0: 0.3198 (0.3635)  loss_bbox_aux_1: 0.3076 (0.3564)  loss_bbox_aux_2: 0.3022 (0.3441)  loss_bbox_aux_3: 0.2920 (0.3409)  loss_bbox_aux_4: 0.2983 (0.3413)  loss_bbox_dn_0: 0.3553 (0.4230)  loss_bbox_dn_1: 0.3248 (0.3898)  loss_bbox_dn_2: 0.3128 (0.3746)  loss_bbox_dn_3: 0.3044 (0.3657)  loss_bbox_dn_4: 0.3002 (0.3609)  loss_bbox_dn_5: 0.2994 (0.3603)  loss_bbox_enc_0: 0.3261 (0.3999)  loss_giou: 1.0437 (1.0765)  loss_giou_aux_0: 1.0825 (1.1190)  loss_giou_aux_1: 1.0448 (1.1025)  loss_giou_aux_2: 1.0341 (1.0877)  loss_giou_aux_3: 1.0348 (1.0863)  loss_giou_aux_4: 1.0351 (1.0777)  loss_giou_dn_0: 1.1293 (1.1288)  loss_giou_dn_1: 1.0480 (1.0431)  loss_giou_dn_2: 1.0168 (1.0086)  loss_giou_dn_3: 0.9973 (0.9905)  loss_giou_dn_4: 0.9803 (0.9795)  loss_giou_dn_5: 0.9790 (0.9788)  loss_giou_enc_0: 1.1643 (1.1946)  loss_vfl: 1.0259 (1.1023)  loss_vfl_aux_0: 1.0623 (1.1233)  loss_vfl_aux_1: 1.0134 (1.1033)  loss_vfl_aux_2: 1.0613 (1.1079)  loss_vfl_aux_3: 1.0630 (1.1095)  loss_vfl_aux_4: 1.0388 (1.1116)  loss_vfl_dn_0: 0.4985 (0.5005)  loss_vfl_dn_1: 0.5371 (0.5391)  loss_vfl_dn_2: 0.5469 (0.5556)  loss_vfl_dn_3: 0.5781 (0.5766)  loss_vfl_dn_4: 0.6028 (0.5993)  loss_vfl_dn_5: 0.6082 (0.6091)  loss_vfl_enc_0: 0.9956 (1.0363)  time: 0.9942  data: 0.0311  max mem: 10356\r\n",
      "Epoch: [40] Total time: 0:01:26 (1.1011 s / it)\r\n",
      "Averaged stats: lr: 0.000002  loss: 29.1802 (29.7050)  loss_bbox: 0.2779 (0.3366)  loss_bbox_aux_0: 0.3198 (0.3635)  loss_bbox_aux_1: 0.3076 (0.3564)  loss_bbox_aux_2: 0.3022 (0.3441)  loss_bbox_aux_3: 0.2920 (0.3409)  loss_bbox_aux_4: 0.2983 (0.3413)  loss_bbox_dn_0: 0.3553 (0.4230)  loss_bbox_dn_1: 0.3248 (0.3898)  loss_bbox_dn_2: 0.3128 (0.3746)  loss_bbox_dn_3: 0.3044 (0.3657)  loss_bbox_dn_4: 0.3002 (0.3609)  loss_bbox_dn_5: 0.2994 (0.3603)  loss_bbox_enc_0: 0.3261 (0.3999)  loss_giou: 1.0437 (1.0765)  loss_giou_aux_0: 1.0825 (1.1190)  loss_giou_aux_1: 1.0448 (1.1025)  loss_giou_aux_2: 1.0341 (1.0877)  loss_giou_aux_3: 1.0348 (1.0863)  loss_giou_aux_4: 1.0351 (1.0777)  loss_giou_dn_0: 1.1293 (1.1288)  loss_giou_dn_1: 1.0480 (1.0431)  loss_giou_dn_2: 1.0168 (1.0086)  loss_giou_dn_3: 0.9973 (0.9905)  loss_giou_dn_4: 0.9803 (0.9795)  loss_giou_dn_5: 0.9790 (0.9788)  loss_giou_enc_0: 1.1643 (1.1946)  loss_vfl: 1.0259 (1.1023)  loss_vfl_aux_0: 1.0623 (1.1233)  loss_vfl_aux_1: 1.0134 (1.1033)  loss_vfl_aux_2: 1.0613 (1.1079)  loss_vfl_aux_3: 1.0630 (1.1095)  loss_vfl_aux_4: 1.0388 (1.1116)  loss_vfl_dn_0: 0.4985 (0.5005)  loss_vfl_dn_1: 0.5371 (0.5391)  loss_vfl_dn_2: 0.5469 (0.5556)  loss_vfl_dn_3: 0.5781 (0.5766)  loss_vfl_dn_4: 0.6028 (0.5993)  loss_vfl_dn_5: 0.6082 (0.6091)  loss_vfl_enc_0: 0.9956 (1.0363)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.2821  data: 1.3329  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0809  data: 0.2217  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0986 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.33s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.028\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.041\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.030\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.047\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.041\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.148\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.223\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.232\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.063\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.313\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.319\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.341\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.247\r\n",
      "best_stat: {'epoch': 40, 'coco_eval_bbox': 0.028070499497685263}\r\n",
      "Epoch: [41]  [ 0/79]  eta: 0:05:39  lr: 0.000002  loss: 29.2397 (29.2397)  loss_bbox: 0.3199 (0.3199)  loss_bbox_aux_0: 0.3424 (0.3424)  loss_bbox_aux_1: 0.3377 (0.3377)  loss_bbox_aux_2: 0.3392 (0.3392)  loss_bbox_aux_3: 0.3088 (0.3088)  loss_bbox_aux_4: 0.3219 (0.3219)  loss_bbox_dn_0: 0.3068 (0.3068)  loss_bbox_dn_1: 0.2885 (0.2885)  loss_bbox_dn_2: 0.2805 (0.2805)  loss_bbox_dn_3: 0.2780 (0.2780)  loss_bbox_dn_4: 0.2793 (0.2793)  loss_bbox_dn_5: 0.2796 (0.2796)  loss_bbox_enc_0: 0.3374 (0.3374)  loss_giou: 1.1591 (1.1591)  loss_giou_aux_0: 1.1944 (1.1944)  loss_giou_aux_1: 1.1804 (1.1804)  loss_giou_aux_2: 1.1892 (1.1892)  loss_giou_aux_3: 1.1883 (1.1883)  loss_giou_aux_4: 1.1611 (1.1611)  loss_giou_dn_0: 1.0955 (1.0955)  loss_giou_dn_1: 1.0096 (1.0096)  loss_giou_dn_2: 0.9803 (0.9803)  loss_giou_dn_3: 0.9580 (0.9580)  loss_giou_dn_4: 0.9520 (0.9520)  loss_giou_dn_5: 0.9533 (0.9533)  loss_giou_enc_0: 1.2142 (1.2142)  loss_vfl: 1.0605 (1.0605)  loss_vfl_aux_0: 1.0986 (1.0986)  loss_vfl_aux_1: 1.0481 (1.0481)  loss_vfl_aux_2: 0.9880 (0.9880)  loss_vfl_aux_3: 1.0129 (1.0129)  loss_vfl_aux_4: 1.0630 (1.0630)  loss_vfl_dn_0: 0.5292 (0.5292)  loss_vfl_dn_1: 0.5715 (0.5715)  loss_vfl_dn_2: 0.5894 (0.5894)  loss_vfl_dn_3: 0.6069 (0.6069)  loss_vfl_dn_4: 0.6292 (0.6292)  loss_vfl_dn_5: 0.6453 (0.6453)  loss_vfl_enc_0: 1.1416 (1.1416)  time: 4.2920  data: 2.9359  max mem: 10356\r\n",
      "Epoch: [41]  [78/79]  eta: 0:00:01  lr: 0.000002  loss: 29.1754 (29.6110)  loss_bbox: 0.3215 (0.3347)  loss_bbox_aux_0: 0.3674 (0.3608)  loss_bbox_aux_1: 0.3425 (0.3556)  loss_bbox_aux_2: 0.3380 (0.3461)  loss_bbox_aux_3: 0.3327 (0.3400)  loss_bbox_aux_4: 0.3355 (0.3386)  loss_bbox_dn_0: 0.3904 (0.4086)  loss_bbox_dn_1: 0.3523 (0.3752)  loss_bbox_dn_2: 0.3376 (0.3601)  loss_bbox_dn_3: 0.3267 (0.3513)  loss_bbox_dn_4: 0.3198 (0.3462)  loss_bbox_dn_5: 0.3181 (0.3456)  loss_bbox_enc_0: 0.3911 (0.3919)  loss_giou: 1.0537 (1.0898)  loss_giou_aux_0: 1.0629 (1.1344)  loss_giou_aux_1: 1.1021 (1.1150)  loss_giou_aux_2: 1.0788 (1.1019)  loss_giou_aux_3: 1.0536 (1.0954)  loss_giou_aux_4: 1.0450 (1.0881)  loss_giou_dn_0: 1.1160 (1.1318)  loss_giou_dn_1: 1.0234 (1.0451)  loss_giou_dn_2: 0.9880 (1.0088)  loss_giou_dn_3: 0.9635 (0.9889)  loss_giou_dn_4: 0.9544 (0.9769)  loss_giou_dn_5: 0.9525 (0.9761)  loss_giou_enc_0: 1.1857 (1.2061)  loss_vfl: 1.1025 (1.0896)  loss_vfl_aux_0: 1.0994 (1.1160)  loss_vfl_aux_1: 1.1208 (1.1041)  loss_vfl_aux_2: 1.1035 (1.0937)  loss_vfl_aux_3: 1.0967 (1.1020)  loss_vfl_aux_4: 1.1113 (1.0926)  loss_vfl_dn_0: 0.4988 (0.4993)  loss_vfl_dn_1: 0.5422 (0.5376)  loss_vfl_dn_2: 0.5654 (0.5553)  loss_vfl_dn_3: 0.5945 (0.5756)  loss_vfl_dn_4: 0.6135 (0.5963)  loss_vfl_dn_5: 0.6160 (0.6049)  loss_vfl_enc_0: 1.0110 (1.0309)  time: 0.9891  data: 0.0317  max mem: 10356\r\n",
      "Epoch: [41] Total time: 0:01:25 (1.0770 s / it)\r\n",
      "Averaged stats: lr: 0.000002  loss: 29.1754 (29.6110)  loss_bbox: 0.3215 (0.3347)  loss_bbox_aux_0: 0.3674 (0.3608)  loss_bbox_aux_1: 0.3425 (0.3556)  loss_bbox_aux_2: 0.3380 (0.3461)  loss_bbox_aux_3: 0.3327 (0.3400)  loss_bbox_aux_4: 0.3355 (0.3386)  loss_bbox_dn_0: 0.3904 (0.4086)  loss_bbox_dn_1: 0.3523 (0.3752)  loss_bbox_dn_2: 0.3376 (0.3601)  loss_bbox_dn_3: 0.3267 (0.3513)  loss_bbox_dn_4: 0.3198 (0.3462)  loss_bbox_dn_5: 0.3181 (0.3456)  loss_bbox_enc_0: 0.3911 (0.3919)  loss_giou: 1.0537 (1.0898)  loss_giou_aux_0: 1.0629 (1.1344)  loss_giou_aux_1: 1.1021 (1.1150)  loss_giou_aux_2: 1.0788 (1.1019)  loss_giou_aux_3: 1.0536 (1.0954)  loss_giou_aux_4: 1.0450 (1.0881)  loss_giou_dn_0: 1.1160 (1.1318)  loss_giou_dn_1: 1.0234 (1.0451)  loss_giou_dn_2: 0.9880 (1.0088)  loss_giou_dn_3: 0.9635 (0.9889)  loss_giou_dn_4: 0.9544 (0.9769)  loss_giou_dn_5: 0.9525 (0.9761)  loss_giou_enc_0: 1.1857 (1.2061)  loss_vfl: 1.1025 (1.0896)  loss_vfl_aux_0: 1.0994 (1.1160)  loss_vfl_aux_1: 1.1208 (1.1041)  loss_vfl_aux_2: 1.1035 (1.0937)  loss_vfl_aux_3: 1.0967 (1.1020)  loss_vfl_aux_4: 1.1113 (1.0926)  loss_vfl_dn_0: 0.4988 (0.4993)  loss_vfl_dn_1: 0.5422 (0.5376)  loss_vfl_dn_2: 0.5654 (0.5553)  loss_vfl_dn_3: 0.5945 (0.5756)  loss_vfl_dn_4: 0.6135 (0.5963)  loss_vfl_dn_5: 0.6160 (0.6049)  loss_vfl_enc_0: 1.0110 (1.0309)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3000  data: 1.3540  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0822  data: 0.2177  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1002 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.028\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.038\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.032\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.046\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.040\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.150\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.223\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.234\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.062\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.316\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.319\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.336\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.250\r\n",
      "best_stat: {'epoch': 40, 'coco_eval_bbox': 0.028070499497685263}\r\n",
      "Epoch: [42]  [ 0/79]  eta: 0:05:35  lr: 0.000002  loss: 29.5774 (29.5774)  loss_bbox: 0.3467 (0.3467)  loss_bbox_aux_0: 0.3481 (0.3481)  loss_bbox_aux_1: 0.3397 (0.3397)  loss_bbox_aux_2: 0.3480 (0.3480)  loss_bbox_aux_3: 0.3563 (0.3563)  loss_bbox_aux_4: 0.3556 (0.3556)  loss_bbox_dn_0: 0.4380 (0.4380)  loss_bbox_dn_1: 0.3939 (0.3939)  loss_bbox_dn_2: 0.3794 (0.3794)  loss_bbox_dn_3: 0.3714 (0.3714)  loss_bbox_dn_4: 0.3680 (0.3680)  loss_bbox_dn_5: 0.3677 (0.3677)  loss_bbox_enc_0: 0.3562 (0.3562)  loss_giou: 0.9488 (0.9488)  loss_giou_aux_0: 0.9721 (0.9721)  loss_giou_aux_1: 0.9469 (0.9469)  loss_giou_aux_2: 0.9613 (0.9613)  loss_giou_aux_3: 0.9597 (0.9597)  loss_giou_aux_4: 0.9582 (0.9582)  loss_giou_dn_0: 1.0770 (1.0770)  loss_giou_dn_1: 0.9400 (0.9400)  loss_giou_dn_2: 0.9022 (0.9022)  loss_giou_dn_3: 0.8776 (0.8776)  loss_giou_dn_4: 0.8666 (0.8666)  loss_giou_dn_5: 0.8698 (0.8698)  loss_giou_enc_0: 1.0727 (1.0727)  loss_vfl: 1.2532 (1.2532)  loss_vfl_aux_0: 1.3374 (1.3374)  loss_vfl_aux_1: 1.3042 (1.3042)  loss_vfl_aux_2: 1.2651 (1.2651)  loss_vfl_aux_3: 1.2522 (1.2522)  loss_vfl_aux_4: 1.2207 (1.2207)  loss_vfl_dn_0: 0.5266 (0.5266)  loss_vfl_dn_1: 0.5735 (0.5735)  loss_vfl_dn_2: 0.5874 (0.5874)  loss_vfl_dn_3: 0.6377 (0.6377)  loss_vfl_dn_4: 0.6465 (0.6465)  loss_vfl_dn_5: 0.6750 (0.6750)  loss_vfl_enc_0: 1.1758 (1.1758)  time: 4.2414  data: 2.6219  max mem: 10356\r\n",
      "Epoch: [42]  [78/79]  eta: 0:00:01  lr: 0.000002  loss: 28.6545 (29.4725)  loss_bbox: 0.2817 (0.3209)  loss_bbox_aux_0: 0.3048 (0.3511)  loss_bbox_aux_1: 0.2894 (0.3400)  loss_bbox_aux_2: 0.2931 (0.3319)  loss_bbox_aux_3: 0.2778 (0.3279)  loss_bbox_aux_4: 0.2830 (0.3242)  loss_bbox_dn_0: 0.3735 (0.4087)  loss_bbox_dn_1: 0.3488 (0.3748)  loss_bbox_dn_2: 0.3185 (0.3593)  loss_bbox_dn_3: 0.3029 (0.3506)  loss_bbox_dn_4: 0.2919 (0.3454)  loss_bbox_dn_5: 0.2905 (0.3447)  loss_bbox_enc_0: 0.3515 (0.3880)  loss_giou: 1.1004 (1.0818)  loss_giou_aux_0: 1.1621 (1.1259)  loss_giou_aux_1: 1.1416 (1.1089)  loss_giou_aux_2: 1.1131 (1.0945)  loss_giou_aux_3: 1.1139 (1.0925)  loss_giou_aux_4: 1.1185 (1.0828)  loss_giou_dn_0: 1.1106 (1.1323)  loss_giou_dn_1: 1.0259 (1.0467)  loss_giou_dn_2: 0.9932 (1.0121)  loss_giou_dn_3: 0.9836 (0.9930)  loss_giou_dn_4: 0.9811 (0.9815)  loss_giou_dn_5: 0.9782 (0.9809)  loss_giou_enc_0: 1.2382 (1.2012)  loss_vfl: 1.0806 (1.0871)  loss_vfl_aux_0: 1.0596 (1.1132)  loss_vfl_aux_1: 1.0771 (1.0951)  loss_vfl_aux_2: 1.0603 (1.0943)  loss_vfl_aux_3: 1.0962 (1.0905)  loss_vfl_aux_4: 1.0640 (1.0900)  loss_vfl_dn_0: 0.4934 (0.5018)  loss_vfl_dn_1: 0.5271 (0.5380)  loss_vfl_dn_2: 0.5404 (0.5534)  loss_vfl_dn_3: 0.5625 (0.5737)  loss_vfl_dn_4: 0.5747 (0.5924)  loss_vfl_dn_5: 0.5886 (0.6014)  loss_vfl_enc_0: 0.9971 (1.0401)  time: 1.0468  data: 0.0319  max mem: 10356\r\n",
      "Epoch: [42] Total time: 0:01:26 (1.0887 s / it)\r\n",
      "Averaged stats: lr: 0.000002  loss: 28.6545 (29.4725)  loss_bbox: 0.2817 (0.3209)  loss_bbox_aux_0: 0.3048 (0.3511)  loss_bbox_aux_1: 0.2894 (0.3400)  loss_bbox_aux_2: 0.2931 (0.3319)  loss_bbox_aux_3: 0.2778 (0.3279)  loss_bbox_aux_4: 0.2830 (0.3242)  loss_bbox_dn_0: 0.3735 (0.4087)  loss_bbox_dn_1: 0.3488 (0.3748)  loss_bbox_dn_2: 0.3185 (0.3593)  loss_bbox_dn_3: 0.3029 (0.3506)  loss_bbox_dn_4: 0.2919 (0.3454)  loss_bbox_dn_5: 0.2905 (0.3447)  loss_bbox_enc_0: 0.3515 (0.3880)  loss_giou: 1.1004 (1.0818)  loss_giou_aux_0: 1.1621 (1.1259)  loss_giou_aux_1: 1.1416 (1.1089)  loss_giou_aux_2: 1.1131 (1.0945)  loss_giou_aux_3: 1.1139 (1.0925)  loss_giou_aux_4: 1.1185 (1.0828)  loss_giou_dn_0: 1.1106 (1.1323)  loss_giou_dn_1: 1.0259 (1.0467)  loss_giou_dn_2: 0.9932 (1.0121)  loss_giou_dn_3: 0.9836 (0.9930)  loss_giou_dn_4: 0.9811 (0.9815)  loss_giou_dn_5: 0.9782 (0.9809)  loss_giou_enc_0: 1.2382 (1.2012)  loss_vfl: 1.0806 (1.0871)  loss_vfl_aux_0: 1.0596 (1.1132)  loss_vfl_aux_1: 1.0771 (1.0951)  loss_vfl_aux_2: 1.0603 (1.0943)  loss_vfl_aux_3: 1.0962 (1.0905)  loss_vfl_aux_4: 1.0640 (1.0900)  loss_vfl_dn_0: 0.4934 (0.5018)  loss_vfl_dn_1: 0.5271 (0.5380)  loss_vfl_dn_2: 0.5404 (0.5534)  loss_vfl_dn_3: 0.5625 (0.5737)  loss_vfl_dn_4: 0.5747 (0.5924)  loss_vfl_dn_5: 0.5886 (0.6014)  loss_vfl_enc_0: 0.9971 (1.0401)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.2482  data: 1.3193  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0647  data: 0.2115  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0816 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.022\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.030\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.025\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.036\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.042\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.153\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.230\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.240\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.062\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.316\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.333\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.340\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.259\r\n",
      "best_stat: {'epoch': 40, 'coco_eval_bbox': 0.028070499497685263}\r\n",
      "Epoch: [43]  [ 0/79]  eta: 0:06:25  lr: 0.000002  loss: 31.3809 (31.3809)  loss_bbox: 0.4902 (0.4902)  loss_bbox_aux_0: 0.4893 (0.4893)  loss_bbox_aux_1: 0.5005 (0.5005)  loss_bbox_aux_2: 0.5011 (0.5011)  loss_bbox_aux_3: 0.4991 (0.4991)  loss_bbox_aux_4: 0.4862 (0.4862)  loss_bbox_dn_0: 0.6433 (0.6433)  loss_bbox_dn_1: 0.5986 (0.5986)  loss_bbox_dn_2: 0.5807 (0.5807)  loss_bbox_dn_3: 0.5676 (0.5676)  loss_bbox_dn_4: 0.5608 (0.5608)  loss_bbox_dn_5: 0.5606 (0.5606)  loss_bbox_enc_0: 0.5441 (0.5441)  loss_giou: 0.8167 (0.8167)  loss_giou_aux_0: 0.8605 (0.8605)  loss_giou_aux_1: 0.8254 (0.8254)  loss_giou_aux_2: 0.8051 (0.8051)  loss_giou_aux_3: 0.8088 (0.8088)  loss_giou_aux_4: 0.7994 (0.7994)  loss_giou_dn_0: 1.0408 (1.0408)  loss_giou_dn_1: 0.9405 (0.9405)  loss_giou_dn_2: 0.8958 (0.8958)  loss_giou_dn_3: 0.8677 (0.8677)  loss_giou_dn_4: 0.8517 (0.8517)  loss_giou_dn_5: 0.8510 (0.8510)  loss_giou_enc_0: 0.9802 (0.9802)  loss_vfl: 1.3628 (1.3628)  loss_vfl_aux_0: 1.4795 (1.4795)  loss_vfl_aux_1: 1.3677 (1.3677)  loss_vfl_aux_2: 1.3403 (1.3403)  loss_vfl_aux_3: 1.3389 (1.3389)  loss_vfl_aux_4: 1.3452 (1.3452)  loss_vfl_dn_0: 0.5217 (0.5217)  loss_vfl_dn_1: 0.5625 (0.5625)  loss_vfl_dn_2: 0.5762 (0.5762)  loss_vfl_dn_3: 0.5959 (0.5959)  loss_vfl_dn_4: 0.6084 (0.6084)  loss_vfl_dn_5: 0.6345 (0.6345)  loss_vfl_enc_0: 1.2812 (1.2812)  time: 4.8743  data: 1.9100  max mem: 10356\r\n",
      "Epoch: [43]  [78/79]  eta: 0:00:01  lr: 0.000002  loss: 29.3967 (29.5816)  loss_bbox: 0.3240 (0.3357)  loss_bbox_aux_0: 0.3469 (0.3614)  loss_bbox_aux_1: 0.3375 (0.3502)  loss_bbox_aux_2: 0.3302 (0.3421)  loss_bbox_aux_3: 0.3368 (0.3411)  loss_bbox_aux_4: 0.3270 (0.3377)  loss_bbox_dn_0: 0.3520 (0.4207)  loss_bbox_dn_1: 0.3173 (0.3868)  loss_bbox_dn_2: 0.3004 (0.3718)  loss_bbox_dn_3: 0.2900 (0.3629)  loss_bbox_dn_4: 0.2839 (0.3577)  loss_bbox_dn_5: 0.2835 (0.3569)  loss_bbox_enc_0: 0.3748 (0.4001)  loss_giou: 1.0610 (1.0730)  loss_giou_aux_0: 1.1111 (1.1155)  loss_giou_aux_1: 1.0714 (1.0986)  loss_giou_aux_2: 1.0554 (1.0832)  loss_giou_aux_3: 1.0663 (1.0814)  loss_giou_aux_4: 1.0362 (1.0733)  loss_giou_dn_0: 1.1445 (1.1346)  loss_giou_dn_1: 1.0672 (1.0489)  loss_giou_dn_2: 1.0345 (1.0144)  loss_giou_dn_3: 1.0215 (0.9958)  loss_giou_dn_4: 1.0174 (0.9854)  loss_giou_dn_5: 1.0157 (0.9846)  loss_giou_enc_0: 1.1840 (1.1938)  loss_vfl: 1.0061 (1.0931)  loss_vfl_aux_0: 1.0400 (1.1134)  loss_vfl_aux_1: 1.0430 (1.1034)  loss_vfl_aux_2: 1.0642 (1.0988)  loss_vfl_aux_3: 1.0557 (1.0956)  loss_vfl_aux_4: 1.0352 (1.0935)  loss_vfl_dn_0: 0.4807 (0.4979)  loss_vfl_dn_1: 0.5262 (0.5355)  loss_vfl_dn_2: 0.5398 (0.5519)  loss_vfl_dn_3: 0.5649 (0.5724)  loss_vfl_dn_4: 0.5803 (0.5917)  loss_vfl_dn_5: 0.5892 (0.6003)  loss_vfl_enc_0: 0.9514 (1.0269)  time: 1.0060  data: 0.0344  max mem: 10356\r\n",
      "Epoch: [43] Total time: 0:01:26 (1.0975 s / it)\r\n",
      "Averaged stats: lr: 0.000002  loss: 29.3967 (29.5816)  loss_bbox: 0.3240 (0.3357)  loss_bbox_aux_0: 0.3469 (0.3614)  loss_bbox_aux_1: 0.3375 (0.3502)  loss_bbox_aux_2: 0.3302 (0.3421)  loss_bbox_aux_3: 0.3368 (0.3411)  loss_bbox_aux_4: 0.3270 (0.3377)  loss_bbox_dn_0: 0.3520 (0.4207)  loss_bbox_dn_1: 0.3173 (0.3868)  loss_bbox_dn_2: 0.3004 (0.3718)  loss_bbox_dn_3: 0.2900 (0.3629)  loss_bbox_dn_4: 0.2839 (0.3577)  loss_bbox_dn_5: 0.2835 (0.3569)  loss_bbox_enc_0: 0.3748 (0.4001)  loss_giou: 1.0610 (1.0730)  loss_giou_aux_0: 1.1111 (1.1155)  loss_giou_aux_1: 1.0714 (1.0986)  loss_giou_aux_2: 1.0554 (1.0832)  loss_giou_aux_3: 1.0663 (1.0814)  loss_giou_aux_4: 1.0362 (1.0733)  loss_giou_dn_0: 1.1445 (1.1346)  loss_giou_dn_1: 1.0672 (1.0489)  loss_giou_dn_2: 1.0345 (1.0144)  loss_giou_dn_3: 1.0215 (0.9958)  loss_giou_dn_4: 1.0174 (0.9854)  loss_giou_dn_5: 1.0157 (0.9846)  loss_giou_enc_0: 1.1840 (1.1938)  loss_vfl: 1.0061 (1.0931)  loss_vfl_aux_0: 1.0400 (1.1134)  loss_vfl_aux_1: 1.0430 (1.1034)  loss_vfl_aux_2: 1.0642 (1.0988)  loss_vfl_aux_3: 1.0557 (1.0956)  loss_vfl_aux_4: 1.0352 (1.0935)  loss_vfl_dn_0: 0.4807 (0.4979)  loss_vfl_dn_1: 0.5262 (0.5355)  loss_vfl_dn_2: 0.5398 (0.5519)  loss_vfl_dn_3: 0.5649 (0.5724)  loss_vfl_dn_4: 0.5803 (0.5917)  loss_vfl_dn_5: 0.5892 (0.6003)  loss_vfl_enc_0: 0.9514 (1.0269)\r\n",
      "Test:  [0/8]  eta: 0:00:16    time: 2.0804  data: 1.1312  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0604  data: 0.2013  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0775 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.028\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.039\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.031\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.047\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.039\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.147\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.226\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.238\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.062\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.319\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.324\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.345\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.250\r\n",
      "best_stat: {'epoch': 43, 'coco_eval_bbox': 0.028147784505056186}\r\n",
      "Epoch: [44]  [ 0/79]  eta: 0:05:37  lr: 0.000002  loss: 30.2213 (30.2213)  loss_bbox: 0.3142 (0.3142)  loss_bbox_aux_0: 0.3650 (0.3650)  loss_bbox_aux_1: 0.3541 (0.3541)  loss_bbox_aux_2: 0.3381 (0.3381)  loss_bbox_aux_3: 0.3398 (0.3398)  loss_bbox_aux_4: 0.3202 (0.3202)  loss_bbox_dn_0: 0.3907 (0.3907)  loss_bbox_dn_1: 0.3757 (0.3757)  loss_bbox_dn_2: 0.3683 (0.3683)  loss_bbox_dn_3: 0.3647 (0.3647)  loss_bbox_dn_4: 0.3625 (0.3625)  loss_bbox_dn_5: 0.3626 (0.3626)  loss_bbox_enc_0: 0.4092 (0.4092)  loss_giou: 1.3455 (1.3455)  loss_giou_aux_0: 1.3966 (1.3966)  loss_giou_aux_1: 1.4149 (1.4149)  loss_giou_aux_2: 1.3660 (1.3660)  loss_giou_aux_3: 1.3605 (1.3605)  loss_giou_aux_4: 1.3342 (1.3342)  loss_giou_dn_0: 1.2157 (1.2157)  loss_giou_dn_1: 1.1827 (1.1827)  loss_giou_dn_2: 1.1619 (1.1619)  loss_giou_dn_3: 1.1515 (1.1515)  loss_giou_dn_4: 1.1441 (1.1441)  loss_giou_dn_5: 1.1441 (1.1441)  loss_giou_enc_0: 1.4162 (1.4162)  loss_vfl: 0.9219 (0.9219)  loss_vfl_aux_0: 0.8105 (0.8105)  loss_vfl_aux_1: 0.8467 (0.8467)  loss_vfl_aux_2: 0.8743 (0.8743)  loss_vfl_aux_3: 0.9138 (0.9138)  loss_vfl_aux_4: 0.9373 (0.9373)  loss_vfl_dn_0: 0.4408 (0.4408)  loss_vfl_dn_1: 0.4495 (0.4495)  loss_vfl_dn_2: 0.4584 (0.4584)  loss_vfl_dn_3: 0.4585 (0.4585)  loss_vfl_dn_4: 0.4763 (0.4763)  loss_vfl_dn_5: 0.4791 (0.4791)  loss_vfl_enc_0: 0.8552 (0.8552)  time: 4.2681  data: 2.7328  max mem: 10356\r\n",
      "Epoch: [44]  [78/79]  eta: 0:00:01  lr: 0.000002  loss: 28.4281 (29.4583)  loss_bbox: 0.2888 (0.3251)  loss_bbox_aux_0: 0.3156 (0.3508)  loss_bbox_aux_1: 0.2971 (0.3413)  loss_bbox_aux_2: 0.2986 (0.3345)  loss_bbox_aux_3: 0.3012 (0.3300)  loss_bbox_aux_4: 0.2838 (0.3263)  loss_bbox_dn_0: 0.3025 (0.4072)  loss_bbox_dn_1: 0.2735 (0.3728)  loss_bbox_dn_2: 0.2558 (0.3565)  loss_bbox_dn_3: 0.2481 (0.3467)  loss_bbox_dn_4: 0.2445 (0.3410)  loss_bbox_dn_5: 0.2439 (0.3401)  loss_bbox_enc_0: 0.3296 (0.3867)  loss_giou: 1.1003 (1.0723)  loss_giou_aux_0: 1.1099 (1.1155)  loss_giou_aux_1: 1.1268 (1.0981)  loss_giou_aux_2: 1.0969 (1.0865)  loss_giou_aux_3: 1.0912 (1.0813)  loss_giou_aux_4: 1.0996 (1.0728)  loss_giou_dn_0: 1.1415 (1.1332)  loss_giou_dn_1: 1.0540 (1.0469)  loss_giou_dn_2: 1.0010 (1.0104)  loss_giou_dn_3: 0.9775 (0.9897)  loss_giou_dn_4: 0.9631 (0.9773)  loss_giou_dn_5: 0.9622 (0.9761)  loss_giou_enc_0: 1.1963 (1.1900)  loss_vfl: 1.0093 (1.0962)  loss_vfl_aux_0: 1.0447 (1.1244)  loss_vfl_aux_1: 1.0364 (1.1134)  loss_vfl_aux_2: 1.0076 (1.1025)  loss_vfl_aux_3: 1.0059 (1.1059)  loss_vfl_aux_4: 1.0122 (1.1055)  loss_vfl_dn_0: 0.4967 (0.4994)  loss_vfl_dn_1: 0.5325 (0.5372)  loss_vfl_dn_2: 0.5560 (0.5530)  loss_vfl_dn_3: 0.5781 (0.5732)  loss_vfl_dn_4: 0.5947 (0.5922)  loss_vfl_dn_5: 0.6106 (0.5996)  loss_vfl_enc_0: 0.9324 (1.0466)  time: 0.9561  data: 0.0319  max mem: 10356\r\n",
      "Epoch: [44] Total time: 0:01:26 (1.0910 s / it)\r\n",
      "Averaged stats: lr: 0.000002  loss: 28.4281 (29.4583)  loss_bbox: 0.2888 (0.3251)  loss_bbox_aux_0: 0.3156 (0.3508)  loss_bbox_aux_1: 0.2971 (0.3413)  loss_bbox_aux_2: 0.2986 (0.3345)  loss_bbox_aux_3: 0.3012 (0.3300)  loss_bbox_aux_4: 0.2838 (0.3263)  loss_bbox_dn_0: 0.3025 (0.4072)  loss_bbox_dn_1: 0.2735 (0.3728)  loss_bbox_dn_2: 0.2558 (0.3565)  loss_bbox_dn_3: 0.2481 (0.3467)  loss_bbox_dn_4: 0.2445 (0.3410)  loss_bbox_dn_5: 0.2439 (0.3401)  loss_bbox_enc_0: 0.3296 (0.3867)  loss_giou: 1.1003 (1.0723)  loss_giou_aux_0: 1.1099 (1.1155)  loss_giou_aux_1: 1.1268 (1.0981)  loss_giou_aux_2: 1.0969 (1.0865)  loss_giou_aux_3: 1.0912 (1.0813)  loss_giou_aux_4: 1.0996 (1.0728)  loss_giou_dn_0: 1.1415 (1.1332)  loss_giou_dn_1: 1.0540 (1.0469)  loss_giou_dn_2: 1.0010 (1.0104)  loss_giou_dn_3: 0.9775 (0.9897)  loss_giou_dn_4: 0.9631 (0.9773)  loss_giou_dn_5: 0.9622 (0.9761)  loss_giou_enc_0: 1.1963 (1.1900)  loss_vfl: 1.0093 (1.0962)  loss_vfl_aux_0: 1.0447 (1.1244)  loss_vfl_aux_1: 1.0364 (1.1134)  loss_vfl_aux_2: 1.0076 (1.1025)  loss_vfl_aux_3: 1.0059 (1.1059)  loss_vfl_aux_4: 1.0122 (1.1055)  loss_vfl_dn_0: 0.4967 (0.4994)  loss_vfl_dn_1: 0.5325 (0.5372)  loss_vfl_dn_2: 0.5560 (0.5530)  loss_vfl_dn_3: 0.5781 (0.5732)  loss_vfl_dn_4: 0.5947 (0.5922)  loss_vfl_dn_5: 0.6106 (0.5996)  loss_vfl_enc_0: 0.9324 (1.0466)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.2522  data: 1.2448  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0789  data: 0.2160  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0967 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.029\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.040\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.031\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.051\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.041\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.145\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.220\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.231\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.063\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.317\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.317\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.332\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.246\r\n",
      "best_stat: {'epoch': 44, 'coco_eval_bbox': 0.029159801562864712}\r\n",
      "Epoch: [45]  [ 0/79]  eta: 0:05:20  lr: 0.000002  loss: 28.0230 (28.0230)  loss_bbox: 0.2732 (0.2732)  loss_bbox_aux_0: 0.2875 (0.2875)  loss_bbox_aux_1: 0.2753 (0.2753)  loss_bbox_aux_2: 0.2842 (0.2842)  loss_bbox_aux_3: 0.2737 (0.2737)  loss_bbox_aux_4: 0.2749 (0.2749)  loss_bbox_dn_0: 0.3155 (0.3155)  loss_bbox_dn_1: 0.2872 (0.2872)  loss_bbox_dn_2: 0.2778 (0.2778)  loss_bbox_dn_3: 0.2694 (0.2694)  loss_bbox_dn_4: 0.2655 (0.2655)  loss_bbox_dn_5: 0.2651 (0.2651)  loss_bbox_enc_0: 0.3089 (0.3089)  loss_giou: 1.1321 (1.1321)  loss_giou_aux_0: 1.1365 (1.1365)  loss_giou_aux_1: 1.1297 (1.1297)  loss_giou_aux_2: 1.1374 (1.1374)  loss_giou_aux_3: 1.1302 (1.1302)  loss_giou_aux_4: 1.1390 (1.1390)  loss_giou_dn_0: 1.1590 (1.1590)  loss_giou_dn_1: 1.0715 (1.0715)  loss_giou_dn_2: 1.0422 (1.0422)  loss_giou_dn_3: 1.0259 (1.0259)  loss_giou_dn_4: 1.0132 (1.0132)  loss_giou_dn_5: 1.0121 (1.0121)  loss_giou_enc_0: 1.2102 (1.2102)  loss_vfl: 0.9919 (0.9919)  loss_vfl_aux_0: 1.0137 (1.0137)  loss_vfl_aux_1: 1.0107 (1.0107)  loss_vfl_aux_2: 1.0039 (1.0039)  loss_vfl_aux_3: 0.9961 (0.9961)  loss_vfl_aux_4: 0.9712 (0.9712)  loss_vfl_dn_0: 0.4706 (0.4706)  loss_vfl_dn_1: 0.5082 (0.5082)  loss_vfl_dn_2: 0.5135 (0.5135)  loss_vfl_dn_3: 0.5294 (0.5294)  loss_vfl_dn_4: 0.5428 (0.5428)  loss_vfl_dn_5: 0.5615 (0.5615)  loss_vfl_enc_0: 0.9125 (0.9125)  time: 4.0509  data: 2.4190  max mem: 10356\r\n",
      "Epoch: [45]  [78/79]  eta: 0:00:01  lr: 0.000002  loss: 28.7894 (29.4694)  loss_bbox: 0.2922 (0.3276)  loss_bbox_aux_0: 0.3320 (0.3553)  loss_bbox_aux_1: 0.3139 (0.3447)  loss_bbox_aux_2: 0.3061 (0.3379)  loss_bbox_aux_3: 0.2936 (0.3344)  loss_bbox_aux_4: 0.2985 (0.3306)  loss_bbox_dn_0: 0.3195 (0.4166)  loss_bbox_dn_1: 0.2941 (0.3815)  loss_bbox_dn_2: 0.2818 (0.3663)  loss_bbox_dn_3: 0.2817 (0.3565)  loss_bbox_dn_4: 0.2855 (0.3512)  loss_bbox_dn_5: 0.2867 (0.3503)  loss_bbox_enc_0: 0.3689 (0.3937)  loss_giou: 1.0648 (1.0647)  loss_giou_aux_0: 1.0857 (1.1028)  loss_giou_aux_1: 1.0961 (1.0863)  loss_giou_aux_2: 1.1154 (1.0772)  loss_giou_aux_3: 1.0965 (1.0720)  loss_giou_aux_4: 1.0854 (1.0656)  loss_giou_dn_0: 1.1406 (1.1320)  loss_giou_dn_1: 1.0503 (1.0455)  loss_giou_dn_2: 1.0081 (1.0109)  loss_giou_dn_3: 0.9842 (0.9909)  loss_giou_dn_4: 0.9646 (0.9792)  loss_giou_dn_5: 0.9631 (0.9782)  loss_giou_enc_0: 1.1687 (1.1805)  loss_vfl: 0.9602 (1.0985)  loss_vfl_aux_0: 1.0054 (1.1311)  loss_vfl_aux_1: 1.0210 (1.1140)  loss_vfl_aux_2: 1.0081 (1.1027)  loss_vfl_aux_3: 0.9756 (1.1037)  loss_vfl_aux_4: 0.9973 (1.1032)  loss_vfl_dn_0: 0.4883 (0.4990)  loss_vfl_dn_1: 0.5217 (0.5358)  loss_vfl_dn_2: 0.5376 (0.5510)  loss_vfl_dn_3: 0.5461 (0.5726)  loss_vfl_dn_4: 0.5573 (0.5899)  loss_vfl_dn_5: 0.5695 (0.5982)  loss_vfl_enc_0: 0.9263 (1.0375)  time: 0.9394  data: 0.0316  max mem: 10356\r\n",
      "Epoch: [45] Total time: 0:01:23 (1.0540 s / it)\r\n",
      "Averaged stats: lr: 0.000002  loss: 28.7894 (29.4694)  loss_bbox: 0.2922 (0.3276)  loss_bbox_aux_0: 0.3320 (0.3553)  loss_bbox_aux_1: 0.3139 (0.3447)  loss_bbox_aux_2: 0.3061 (0.3379)  loss_bbox_aux_3: 0.2936 (0.3344)  loss_bbox_aux_4: 0.2985 (0.3306)  loss_bbox_dn_0: 0.3195 (0.4166)  loss_bbox_dn_1: 0.2941 (0.3815)  loss_bbox_dn_2: 0.2818 (0.3663)  loss_bbox_dn_3: 0.2817 (0.3565)  loss_bbox_dn_4: 0.2855 (0.3512)  loss_bbox_dn_5: 0.2867 (0.3503)  loss_bbox_enc_0: 0.3689 (0.3937)  loss_giou: 1.0648 (1.0647)  loss_giou_aux_0: 1.0857 (1.1028)  loss_giou_aux_1: 1.0961 (1.0863)  loss_giou_aux_2: 1.1154 (1.0772)  loss_giou_aux_3: 1.0965 (1.0720)  loss_giou_aux_4: 1.0854 (1.0656)  loss_giou_dn_0: 1.1406 (1.1320)  loss_giou_dn_1: 1.0503 (1.0455)  loss_giou_dn_2: 1.0081 (1.0109)  loss_giou_dn_3: 0.9842 (0.9909)  loss_giou_dn_4: 0.9646 (0.9792)  loss_giou_dn_5: 0.9631 (0.9782)  loss_giou_enc_0: 1.1687 (1.1805)  loss_vfl: 0.9602 (1.0985)  loss_vfl_aux_0: 1.0054 (1.1311)  loss_vfl_aux_1: 1.0210 (1.1140)  loss_vfl_aux_2: 1.0081 (1.1027)  loss_vfl_aux_3: 0.9756 (1.1037)  loss_vfl_aux_4: 0.9973 (1.1032)  loss_vfl_dn_0: 0.4883 (0.4990)  loss_vfl_dn_1: 0.5217 (0.5358)  loss_vfl_dn_2: 0.5376 (0.5510)  loss_vfl_dn_3: 0.5461 (0.5726)  loss_vfl_dn_4: 0.5573 (0.5899)  loss_vfl_dn_5: 0.5695 (0.5982)  loss_vfl_enc_0: 0.9263 (1.0375)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.2425  data: 1.2925  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0726  data: 0.2195  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0891 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.026\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.037\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.027\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.045\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.044\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.156\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.231\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.239\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.063\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.319\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.329\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.346\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.254\r\n",
      "best_stat: {'epoch': 44, 'coco_eval_bbox': 0.029159801562864712}\r\n",
      "Epoch: [46]  [ 0/79]  eta: 0:06:36  lr: 0.000002  loss: 27.4959 (27.4959)  loss_bbox: 0.2437 (0.2437)  loss_bbox_aux_0: 0.2800 (0.2800)  loss_bbox_aux_1: 0.2774 (0.2774)  loss_bbox_aux_2: 0.2603 (0.2603)  loss_bbox_aux_3: 0.2465 (0.2465)  loss_bbox_aux_4: 0.2384 (0.2384)  loss_bbox_dn_0: 0.3969 (0.3969)  loss_bbox_dn_1: 0.3397 (0.3397)  loss_bbox_dn_2: 0.3221 (0.3221)  loss_bbox_dn_3: 0.3115 (0.3115)  loss_bbox_dn_4: 0.3055 (0.3055)  loss_bbox_dn_5: 0.3043 (0.3043)  loss_bbox_enc_0: 0.3310 (0.3310)  loss_giou: 0.7142 (0.7142)  loss_giou_aux_0: 0.7605 (0.7605)  loss_giou_aux_1: 0.7238 (0.7238)  loss_giou_aux_2: 0.7461 (0.7461)  loss_giou_aux_3: 0.7248 (0.7248)  loss_giou_aux_4: 0.7082 (0.7082)  loss_giou_dn_0: 0.9727 (0.9727)  loss_giou_dn_1: 0.8355 (0.8355)  loss_giou_dn_2: 0.7881 (0.7881)  loss_giou_dn_3: 0.7654 (0.7654)  loss_giou_dn_4: 0.7492 (0.7492)  loss_giou_dn_5: 0.7453 (0.7453)  loss_giou_enc_0: 0.9064 (0.9064)  loss_vfl: 1.4048 (1.4048)  loss_vfl_aux_0: 1.4990 (1.4990)  loss_vfl_aux_1: 1.4478 (1.4478)  loss_vfl_aux_2: 1.3804 (1.3804)  loss_vfl_aux_3: 1.3594 (1.3594)  loss_vfl_aux_4: 1.3950 (1.3950)  loss_vfl_dn_0: 0.5475 (0.5475)  loss_vfl_dn_1: 0.5884 (0.5884)  loss_vfl_dn_2: 0.6018 (0.6018)  loss_vfl_dn_3: 0.6199 (0.6199)  loss_vfl_dn_4: 0.6562 (0.6562)  loss_vfl_dn_5: 0.6670 (0.6670)  loss_vfl_enc_0: 1.3315 (1.3315)  time: 5.0174  data: 3.1465  max mem: 10356\r\n",
      "Epoch: [46]  [78/79]  eta: 0:00:01  lr: 0.000002  loss: 29.4637 (29.1553)  loss_bbox: 0.3174 (0.3111)  loss_bbox_aux_0: 0.3494 (0.3342)  loss_bbox_aux_1: 0.3225 (0.3263)  loss_bbox_aux_2: 0.3180 (0.3167)  loss_bbox_aux_3: 0.3133 (0.3148)  loss_bbox_aux_4: 0.3140 (0.3122)  loss_bbox_dn_0: 0.4104 (0.4025)  loss_bbox_dn_1: 0.3933 (0.3676)  loss_bbox_dn_2: 0.3813 (0.3519)  loss_bbox_dn_3: 0.3654 (0.3428)  loss_bbox_dn_4: 0.3576 (0.3374)  loss_bbox_dn_5: 0.3563 (0.3366)  loss_bbox_enc_0: 0.3664 (0.3792)  loss_giou: 0.9846 (1.0396)  loss_giou_aux_0: 1.0262 (1.0775)  loss_giou_aux_1: 0.9991 (1.0585)  loss_giou_aux_2: 0.9869 (1.0491)  loss_giou_aux_3: 0.9912 (1.0449)  loss_giou_aux_4: 0.9865 (1.0398)  loss_giou_dn_0: 1.1232 (1.1240)  loss_giou_dn_1: 1.0300 (1.0375)  loss_giou_dn_2: 0.9907 (1.0014)  loss_giou_dn_3: 0.9708 (0.9818)  loss_giou_dn_4: 0.9606 (0.9705)  loss_giou_dn_5: 0.9582 (0.9695)  loss_giou_enc_0: 1.1047 (1.1676)  loss_vfl: 1.1172 (1.1083)  loss_vfl_aux_0: 1.1450 (1.1449)  loss_vfl_aux_1: 1.0974 (1.1298)  loss_vfl_aux_2: 1.0867 (1.1184)  loss_vfl_aux_3: 1.0930 (1.1173)  loss_vfl_aux_4: 1.1160 (1.1183)  loss_vfl_dn_0: 0.5002 (0.5040)  loss_vfl_dn_1: 0.5472 (0.5412)  loss_vfl_dn_2: 0.5684 (0.5579)  loss_vfl_dn_3: 0.5908 (0.5789)  loss_vfl_dn_4: 0.6097 (0.5984)  loss_vfl_dn_5: 0.6213 (0.6060)  loss_vfl_enc_0: 1.0627 (1.0369)  time: 0.9683  data: 0.0320  max mem: 10356\r\n",
      "Epoch: [46] Total time: 0:01:26 (1.0899 s / it)\r\n",
      "Averaged stats: lr: 0.000002  loss: 29.4637 (29.1553)  loss_bbox: 0.3174 (0.3111)  loss_bbox_aux_0: 0.3494 (0.3342)  loss_bbox_aux_1: 0.3225 (0.3263)  loss_bbox_aux_2: 0.3180 (0.3167)  loss_bbox_aux_3: 0.3133 (0.3148)  loss_bbox_aux_4: 0.3140 (0.3122)  loss_bbox_dn_0: 0.4104 (0.4025)  loss_bbox_dn_1: 0.3933 (0.3676)  loss_bbox_dn_2: 0.3813 (0.3519)  loss_bbox_dn_3: 0.3654 (0.3428)  loss_bbox_dn_4: 0.3576 (0.3374)  loss_bbox_dn_5: 0.3563 (0.3366)  loss_bbox_enc_0: 0.3664 (0.3792)  loss_giou: 0.9846 (1.0396)  loss_giou_aux_0: 1.0262 (1.0775)  loss_giou_aux_1: 0.9991 (1.0585)  loss_giou_aux_2: 0.9869 (1.0491)  loss_giou_aux_3: 0.9912 (1.0449)  loss_giou_aux_4: 0.9865 (1.0398)  loss_giou_dn_0: 1.1232 (1.1240)  loss_giou_dn_1: 1.0300 (1.0375)  loss_giou_dn_2: 0.9907 (1.0014)  loss_giou_dn_3: 0.9708 (0.9818)  loss_giou_dn_4: 0.9606 (0.9705)  loss_giou_dn_5: 0.9582 (0.9695)  loss_giou_enc_0: 1.1047 (1.1676)  loss_vfl: 1.1172 (1.1083)  loss_vfl_aux_0: 1.1450 (1.1449)  loss_vfl_aux_1: 1.0974 (1.1298)  loss_vfl_aux_2: 1.0867 (1.1184)  loss_vfl_aux_3: 1.0930 (1.1173)  loss_vfl_aux_4: 1.1160 (1.1183)  loss_vfl_dn_0: 0.5002 (0.5040)  loss_vfl_dn_1: 0.5472 (0.5412)  loss_vfl_dn_2: 0.5684 (0.5579)  loss_vfl_dn_3: 0.5908 (0.5789)  loss_vfl_dn_4: 0.6097 (0.5984)  loss_vfl_dn_5: 0.6213 (0.6060)  loss_vfl_enc_0: 1.0627 (1.0369)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.2155  data: 1.2053  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0685  data: 0.2131  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0859 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.025\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.036\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.026\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.042\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.043\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.146\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.222\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.235\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.069\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.321\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.335\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.347\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.239\r\n",
      "best_stat: {'epoch': 44, 'coco_eval_bbox': 0.029159801562864712}\r\n",
      "Epoch: [47]  [ 0/79]  eta: 0:06:10  lr: 0.000002  loss: 31.5845 (31.5845)  loss_bbox: 0.5576 (0.5576)  loss_bbox_aux_0: 0.5673 (0.5673)  loss_bbox_aux_1: 0.5671 (0.5671)  loss_bbox_aux_2: 0.5723 (0.5723)  loss_bbox_aux_3: 0.5861 (0.5861)  loss_bbox_aux_4: 0.5552 (0.5552)  loss_bbox_dn_0: 0.4960 (0.4960)  loss_bbox_dn_1: 0.4712 (0.4712)  loss_bbox_dn_2: 0.4640 (0.4640)  loss_bbox_dn_3: 0.4583 (0.4583)  loss_bbox_dn_4: 0.4571 (0.4571)  loss_bbox_dn_5: 0.4568 (0.4568)  loss_bbox_enc_0: 0.5991 (0.5991)  loss_giou: 1.3551 (1.3551)  loss_giou_aux_0: 1.3926 (1.3926)  loss_giou_aux_1: 1.4023 (1.4023)  loss_giou_aux_2: 1.3865 (1.3865)  loss_giou_aux_3: 1.3451 (1.3451)  loss_giou_aux_4: 1.3611 (1.3611)  loss_giou_dn_0: 1.2127 (1.2127)  loss_giou_dn_1: 1.1585 (1.1585)  loss_giou_dn_2: 1.1446 (1.1446)  loss_giou_dn_3: 1.1366 (1.1366)  loss_giou_dn_4: 1.1371 (1.1371)  loss_giou_dn_5: 1.1380 (1.1380)  loss_giou_enc_0: 1.4294 (1.4294)  loss_vfl: 0.7749 (0.7749)  loss_vfl_aux_0: 0.7600 (0.7600)  loss_vfl_aux_1: 0.7708 (0.7708)  loss_vfl_aux_2: 0.7935 (0.7935)  loss_vfl_aux_3: 0.7742 (0.7742)  loss_vfl_aux_4: 0.7493 (0.7493)  loss_vfl_dn_0: 0.4453 (0.4453)  loss_vfl_dn_1: 0.4592 (0.4592)  loss_vfl_dn_2: 0.4650 (0.4650)  loss_vfl_dn_3: 0.4742 (0.4742)  loss_vfl_dn_4: 0.4761 (0.4761)  loss_vfl_dn_5: 0.4841 (0.4841)  loss_vfl_enc_0: 0.7502 (0.7502)  time: 4.6889  data: 2.7744  max mem: 10356\r\n",
      "Epoch: [47]  [78/79]  eta: 0:00:01  lr: 0.000002  loss: 29.5641 (29.4222)  loss_bbox: 0.3513 (0.3334)  loss_bbox_aux_0: 0.3409 (0.3602)  loss_bbox_aux_1: 0.3445 (0.3495)  loss_bbox_aux_2: 0.3501 (0.3417)  loss_bbox_aux_3: 0.3507 (0.3393)  loss_bbox_aux_4: 0.3480 (0.3346)  loss_bbox_dn_0: 0.3834 (0.4225)  loss_bbox_dn_1: 0.3506 (0.3876)  loss_bbox_dn_2: 0.3303 (0.3718)  loss_bbox_dn_3: 0.3192 (0.3621)  loss_bbox_dn_4: 0.3134 (0.3568)  loss_bbox_dn_5: 0.3132 (0.3560)  loss_bbox_enc_0: 0.3984 (0.4015)  loss_giou: 1.1083 (1.0492)  loss_giou_aux_0: 1.1678 (1.0860)  loss_giou_aux_1: 1.1241 (1.0730)  loss_giou_aux_2: 1.1184 (1.0607)  loss_giou_aux_3: 1.1060 (1.0544)  loss_giou_aux_4: 1.0983 (1.0488)  loss_giou_dn_0: 1.1394 (1.1203)  loss_giou_dn_1: 1.0620 (1.0339)  loss_giou_dn_2: 1.0281 (0.9984)  loss_giou_dn_3: 1.0076 (0.9796)  loss_giou_dn_4: 0.9961 (0.9688)  loss_giou_dn_5: 0.9977 (0.9681)  loss_giou_enc_0: 1.2175 (1.1706)  loss_vfl: 1.0642 (1.0901)  loss_vfl_aux_0: 1.0886 (1.1356)  loss_vfl_aux_1: 1.0469 (1.1168)  loss_vfl_aux_2: 1.0979 (1.1080)  loss_vfl_aux_3: 1.1064 (1.1055)  loss_vfl_aux_4: 1.0759 (1.1020)  loss_vfl_dn_0: 0.5000 (0.5075)  loss_vfl_dn_1: 0.5333 (0.5449)  loss_vfl_dn_2: 0.5645 (0.5612)  loss_vfl_dn_3: 0.5781 (0.5791)  loss_vfl_dn_4: 0.5974 (0.5956)  loss_vfl_dn_5: 0.6057 (0.6024)  loss_vfl_enc_0: 0.9900 (1.0449)  time: 0.9536  data: 0.0318  max mem: 10356\r\n",
      "Epoch: [47] Total time: 0:01:25 (1.0780 s / it)\r\n",
      "Averaged stats: lr: 0.000002  loss: 29.5641 (29.4222)  loss_bbox: 0.3513 (0.3334)  loss_bbox_aux_0: 0.3409 (0.3602)  loss_bbox_aux_1: 0.3445 (0.3495)  loss_bbox_aux_2: 0.3501 (0.3417)  loss_bbox_aux_3: 0.3507 (0.3393)  loss_bbox_aux_4: 0.3480 (0.3346)  loss_bbox_dn_0: 0.3834 (0.4225)  loss_bbox_dn_1: 0.3506 (0.3876)  loss_bbox_dn_2: 0.3303 (0.3718)  loss_bbox_dn_3: 0.3192 (0.3621)  loss_bbox_dn_4: 0.3134 (0.3568)  loss_bbox_dn_5: 0.3132 (0.3560)  loss_bbox_enc_0: 0.3984 (0.4015)  loss_giou: 1.1083 (1.0492)  loss_giou_aux_0: 1.1678 (1.0860)  loss_giou_aux_1: 1.1241 (1.0730)  loss_giou_aux_2: 1.1184 (1.0607)  loss_giou_aux_3: 1.1060 (1.0544)  loss_giou_aux_4: 1.0983 (1.0488)  loss_giou_dn_0: 1.1394 (1.1203)  loss_giou_dn_1: 1.0620 (1.0339)  loss_giou_dn_2: 1.0281 (0.9984)  loss_giou_dn_3: 1.0076 (0.9796)  loss_giou_dn_4: 0.9961 (0.9688)  loss_giou_dn_5: 0.9977 (0.9681)  loss_giou_enc_0: 1.2175 (1.1706)  loss_vfl: 1.0642 (1.0901)  loss_vfl_aux_0: 1.0886 (1.1356)  loss_vfl_aux_1: 1.0469 (1.1168)  loss_vfl_aux_2: 1.0979 (1.1080)  loss_vfl_aux_3: 1.1064 (1.1055)  loss_vfl_aux_4: 1.0759 (1.1020)  loss_vfl_dn_0: 0.5000 (0.5075)  loss_vfl_dn_1: 0.5333 (0.5449)  loss_vfl_dn_2: 0.5645 (0.5612)  loss_vfl_dn_3: 0.5781 (0.5791)  loss_vfl_dn_4: 0.5974 (0.5956)  loss_vfl_dn_5: 0.6057 (0.6024)  loss_vfl_enc_0: 0.9900 (1.0449)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.1777  data: 1.2099  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0659  data: 0.2095  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0835 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.026\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.036\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.029\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.042\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.044\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.147\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.222\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.231\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.305\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.322\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.334\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.241\r\n",
      "best_stat: {'epoch': 44, 'coco_eval_bbox': 0.029159801562864712}\r\n",
      "Epoch: [48]  [ 0/79]  eta: 0:06:42  lr: 0.000002  loss: 32.8627 (32.8627)  loss_bbox: 0.5749 (0.5749)  loss_bbox_aux_0: 0.5316 (0.5316)  loss_bbox_aux_1: 0.5877 (0.5877)  loss_bbox_aux_2: 0.5909 (0.5909)  loss_bbox_aux_3: 0.5748 (0.5748)  loss_bbox_aux_4: 0.5707 (0.5707)  loss_bbox_dn_0: 0.2274 (0.2274)  loss_bbox_dn_1: 0.2067 (0.2067)  loss_bbox_dn_2: 0.2008 (0.2008)  loss_bbox_dn_3: 0.1982 (0.1982)  loss_bbox_dn_4: 0.1963 (0.1963)  loss_bbox_dn_5: 0.1961 (0.1961)  loss_bbox_enc_0: 0.5285 (0.5285)  loss_giou: 1.8160 (1.8160)  loss_giou_aux_0: 1.9012 (1.9012)  loss_giou_aux_1: 1.8295 (1.8295)  loss_giou_aux_2: 1.8110 (1.8110)  loss_giou_aux_3: 1.8257 (1.8257)  loss_giou_aux_4: 1.8330 (1.8330)  loss_giou_dn_0: 1.1902 (1.1902)  loss_giou_dn_1: 1.1426 (1.1426)  loss_giou_dn_2: 1.1271 (1.1271)  loss_giou_dn_3: 1.1089 (1.1089)  loss_giou_dn_4: 1.1048 (1.1048)  loss_giou_dn_5: 1.1055 (1.1055)  loss_giou_enc_0: 1.9683 (1.9683)  loss_vfl: 0.6775 (0.6775)  loss_vfl_aux_0: 0.7014 (0.7014)  loss_vfl_aux_1: 0.7227 (0.7227)  loss_vfl_aux_2: 0.6909 (0.6909)  loss_vfl_aux_3: 0.7305 (0.7305)  loss_vfl_aux_4: 0.7051 (0.7051)  loss_vfl_dn_0: 0.4901 (0.4901)  loss_vfl_dn_1: 0.4994 (0.4994)  loss_vfl_dn_2: 0.5105 (0.5105)  loss_vfl_dn_3: 0.5237 (0.5237)  loss_vfl_dn_4: 0.5272 (0.5272)  loss_vfl_dn_5: 0.5299 (0.5299)  loss_vfl_enc_0: 0.6055 (0.6055)  time: 5.0892  data: 3.5965  max mem: 10356\r\n",
      "Epoch: [48]  [78/79]  eta: 0:00:01  lr: 0.000002  loss: 29.2364 (29.5642)  loss_bbox: 0.2943 (0.3270)  loss_bbox_aux_0: 0.3103 (0.3551)  loss_bbox_aux_1: 0.3170 (0.3449)  loss_bbox_aux_2: 0.2945 (0.3383)  loss_bbox_aux_3: 0.3122 (0.3323)  loss_bbox_aux_4: 0.2845 (0.3263)  loss_bbox_dn_0: 0.3720 (0.4251)  loss_bbox_dn_1: 0.3473 (0.3897)  loss_bbox_dn_2: 0.3303 (0.3733)  loss_bbox_dn_3: 0.3257 (0.3638)  loss_bbox_dn_4: 0.3225 (0.3582)  loss_bbox_dn_5: 0.3222 (0.3574)  loss_bbox_enc_0: 0.3579 (0.3945)  loss_giou: 0.9634 (1.0583)  loss_giou_aux_0: 0.9966 (1.0991)  loss_giou_aux_1: 0.9921 (1.0837)  loss_giou_aux_2: 0.9431 (1.0696)  loss_giou_aux_3: 0.9805 (1.0625)  loss_giou_aux_4: 0.9477 (1.0602)  loss_giou_dn_0: 1.0829 (1.1236)  loss_giou_dn_1: 0.9941 (1.0359)  loss_giou_dn_2: 0.9544 (0.9995)  loss_giou_dn_3: 0.9326 (0.9795)  loss_giou_dn_4: 0.9190 (0.9674)  loss_giou_dn_5: 0.9194 (0.9662)  loss_giou_enc_0: 1.0533 (1.1863)  loss_vfl: 1.1733 (1.1123)  loss_vfl_aux_0: 1.2095 (1.1397)  loss_vfl_aux_1: 1.1919 (1.1306)  loss_vfl_aux_2: 1.1953 (1.1204)  loss_vfl_aux_3: 1.1934 (1.1280)  loss_vfl_aux_4: 1.1968 (1.1207)  loss_vfl_dn_0: 0.5179 (0.5038)  loss_vfl_dn_1: 0.5624 (0.5436)  loss_vfl_dn_2: 0.5863 (0.5604)  loss_vfl_dn_3: 0.6187 (0.5801)  loss_vfl_dn_4: 0.6404 (0.5974)  loss_vfl_dn_5: 0.6343 (0.6065)  loss_vfl_enc_0: 1.0815 (1.0429)  time: 1.0284  data: 0.0318  max mem: 10356\r\n",
      "Epoch: [48] Total time: 0:01:26 (1.0910 s / it)\r\n",
      "Averaged stats: lr: 0.000002  loss: 29.2364 (29.5642)  loss_bbox: 0.2943 (0.3270)  loss_bbox_aux_0: 0.3103 (0.3551)  loss_bbox_aux_1: 0.3170 (0.3449)  loss_bbox_aux_2: 0.2945 (0.3383)  loss_bbox_aux_3: 0.3122 (0.3323)  loss_bbox_aux_4: 0.2845 (0.3263)  loss_bbox_dn_0: 0.3720 (0.4251)  loss_bbox_dn_1: 0.3473 (0.3897)  loss_bbox_dn_2: 0.3303 (0.3733)  loss_bbox_dn_3: 0.3257 (0.3638)  loss_bbox_dn_4: 0.3225 (0.3582)  loss_bbox_dn_5: 0.3222 (0.3574)  loss_bbox_enc_0: 0.3579 (0.3945)  loss_giou: 0.9634 (1.0583)  loss_giou_aux_0: 0.9966 (1.0991)  loss_giou_aux_1: 0.9921 (1.0837)  loss_giou_aux_2: 0.9431 (1.0696)  loss_giou_aux_3: 0.9805 (1.0625)  loss_giou_aux_4: 0.9477 (1.0602)  loss_giou_dn_0: 1.0829 (1.1236)  loss_giou_dn_1: 0.9941 (1.0359)  loss_giou_dn_2: 0.9544 (0.9995)  loss_giou_dn_3: 0.9326 (0.9795)  loss_giou_dn_4: 0.9190 (0.9674)  loss_giou_dn_5: 0.9194 (0.9662)  loss_giou_enc_0: 1.0533 (1.1863)  loss_vfl: 1.1733 (1.1123)  loss_vfl_aux_0: 1.2095 (1.1397)  loss_vfl_aux_1: 1.1919 (1.1306)  loss_vfl_aux_2: 1.1953 (1.1204)  loss_vfl_aux_3: 1.1934 (1.1280)  loss_vfl_aux_4: 1.1968 (1.1207)  loss_vfl_dn_0: 0.5179 (0.5038)  loss_vfl_dn_1: 0.5624 (0.5436)  loss_vfl_dn_2: 0.5863 (0.5604)  loss_vfl_dn_3: 0.6187 (0.5801)  loss_vfl_dn_4: 0.6404 (0.5974)  loss_vfl_dn_5: 0.6343 (0.6065)  loss_vfl_enc_0: 1.0815 (1.0429)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.2206  data: 1.2731  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0670  data: 0.2129  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0839 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.023\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.034\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.024\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.035\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.041\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.150\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.225\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.235\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.066\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.319\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.325\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.341\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.244\r\n",
      "best_stat: {'epoch': 44, 'coco_eval_bbox': 0.029159801562864712}\r\n",
      "Epoch: [49]  [ 0/79]  eta: 0:05:29  lr: 0.000002  loss: 28.4562 (28.4562)  loss_bbox: 0.2563 (0.2563)  loss_bbox_aux_0: 0.2736 (0.2736)  loss_bbox_aux_1: 0.2718 (0.2718)  loss_bbox_aux_2: 0.2622 (0.2622)  loss_bbox_aux_3: 0.2553 (0.2553)  loss_bbox_aux_4: 0.2669 (0.2669)  loss_bbox_dn_0: 0.3153 (0.3153)  loss_bbox_dn_1: 0.2836 (0.2836)  loss_bbox_dn_2: 0.2689 (0.2689)  loss_bbox_dn_3: 0.2559 (0.2559)  loss_bbox_dn_4: 0.2507 (0.2507)  loss_bbox_dn_5: 0.2497 (0.2497)  loss_bbox_enc_0: 0.3352 (0.3352)  loss_giou: 1.0518 (1.0518)  loss_giou_aux_0: 1.1126 (1.1126)  loss_giou_aux_1: 1.0668 (1.0668)  loss_giou_aux_2: 1.0704 (1.0704)  loss_giou_aux_3: 1.0565 (1.0565)  loss_giou_aux_4: 1.0563 (1.0563)  loss_giou_dn_0: 1.1488 (1.1488)  loss_giou_dn_1: 1.0609 (1.0609)  loss_giou_dn_2: 1.0269 (1.0269)  loss_giou_dn_3: 1.0038 (1.0038)  loss_giou_dn_4: 0.9958 (0.9958)  loss_giou_dn_5: 0.9965 (0.9965)  loss_giou_enc_0: 1.2002 (1.2002)  loss_vfl: 1.1248 (1.1248)  loss_vfl_aux_0: 1.1140 (1.1140)  loss_vfl_aux_1: 1.1511 (1.1511)  loss_vfl_aux_2: 1.1335 (1.1335)  loss_vfl_aux_3: 1.1548 (1.1548)  loss_vfl_aux_4: 1.1384 (1.1384)  loss_vfl_dn_0: 0.4729 (0.4729)  loss_vfl_dn_1: 0.5095 (0.5095)  loss_vfl_dn_2: 0.5305 (0.5305)  loss_vfl_dn_3: 0.5583 (0.5583)  loss_vfl_dn_4: 0.5724 (0.5724)  loss_vfl_dn_5: 0.5972 (0.5972)  loss_vfl_enc_0: 1.0059 (1.0059)  time: 4.1677  data: 2.5172  max mem: 10356\r\n",
      "Epoch: [49]  [78/79]  eta: 0:00:01  lr: 0.000002  loss: 29.1016 (29.4093)  loss_bbox: 0.3129 (0.3224)  loss_bbox_aux_0: 0.3301 (0.3522)  loss_bbox_aux_1: 0.3211 (0.3399)  loss_bbox_aux_2: 0.3256 (0.3316)  loss_bbox_aux_3: 0.3220 (0.3298)  loss_bbox_aux_4: 0.3224 (0.3263)  loss_bbox_dn_0: 0.4373 (0.4187)  loss_bbox_dn_1: 0.3862 (0.3826)  loss_bbox_dn_2: 0.3642 (0.3657)  loss_bbox_dn_3: 0.3520 (0.3559)  loss_bbox_dn_4: 0.3454 (0.3499)  loss_bbox_dn_5: 0.3441 (0.3490)  loss_bbox_enc_0: 0.3727 (0.3881)  loss_giou: 0.9879 (1.0443)  loss_giou_aux_0: 1.0298 (1.0842)  loss_giou_aux_1: 1.0093 (1.0683)  loss_giou_aux_2: 0.9949 (1.0559)  loss_giou_aux_3: 0.9894 (1.0526)  loss_giou_aux_4: 1.0117 (1.0457)  loss_giou_dn_0: 1.1169 (1.1228)  loss_giou_dn_1: 1.0273 (1.0342)  loss_giou_dn_2: 0.9876 (0.9975)  loss_giou_dn_3: 0.9670 (0.9772)  loss_giou_dn_4: 0.9541 (0.9653)  loss_giou_dn_5: 0.9519 (0.9638)  loss_giou_enc_0: 1.1471 (1.1691)  loss_vfl: 1.1060 (1.1152)  loss_vfl_aux_0: 1.1826 (1.1483)  loss_vfl_aux_1: 1.1719 (1.1362)  loss_vfl_aux_2: 1.1338 (1.1276)  loss_vfl_aux_3: 1.1450 (1.1253)  loss_vfl_aux_4: 1.1274 (1.1259)  loss_vfl_dn_0: 0.5085 (0.5038)  loss_vfl_dn_1: 0.5514 (0.5422)  loss_vfl_dn_2: 0.5557 (0.5585)  loss_vfl_dn_3: 0.5894 (0.5790)  loss_vfl_dn_4: 0.5979 (0.5960)  loss_vfl_dn_5: 0.6147 (0.6042)  loss_vfl_enc_0: 1.1074 (1.0540)  time: 1.0057  data: 0.0320  max mem: 10356\r\n",
      "Epoch: [49] Total time: 0:01:25 (1.0879 s / it)\r\n",
      "Averaged stats: lr: 0.000002  loss: 29.1016 (29.4093)  loss_bbox: 0.3129 (0.3224)  loss_bbox_aux_0: 0.3301 (0.3522)  loss_bbox_aux_1: 0.3211 (0.3399)  loss_bbox_aux_2: 0.3256 (0.3316)  loss_bbox_aux_3: 0.3220 (0.3298)  loss_bbox_aux_4: 0.3224 (0.3263)  loss_bbox_dn_0: 0.4373 (0.4187)  loss_bbox_dn_1: 0.3862 (0.3826)  loss_bbox_dn_2: 0.3642 (0.3657)  loss_bbox_dn_3: 0.3520 (0.3559)  loss_bbox_dn_4: 0.3454 (0.3499)  loss_bbox_dn_5: 0.3441 (0.3490)  loss_bbox_enc_0: 0.3727 (0.3881)  loss_giou: 0.9879 (1.0443)  loss_giou_aux_0: 1.0298 (1.0842)  loss_giou_aux_1: 1.0093 (1.0683)  loss_giou_aux_2: 0.9949 (1.0559)  loss_giou_aux_3: 0.9894 (1.0526)  loss_giou_aux_4: 1.0117 (1.0457)  loss_giou_dn_0: 1.1169 (1.1228)  loss_giou_dn_1: 1.0273 (1.0342)  loss_giou_dn_2: 0.9876 (0.9975)  loss_giou_dn_3: 0.9670 (0.9772)  loss_giou_dn_4: 0.9541 (0.9653)  loss_giou_dn_5: 0.9519 (0.9638)  loss_giou_enc_0: 1.1471 (1.1691)  loss_vfl: 1.1060 (1.1152)  loss_vfl_aux_0: 1.1826 (1.1483)  loss_vfl_aux_1: 1.1719 (1.1362)  loss_vfl_aux_2: 1.1338 (1.1276)  loss_vfl_aux_3: 1.1450 (1.1253)  loss_vfl_aux_4: 1.1274 (1.1259)  loss_vfl_dn_0: 0.5085 (0.5038)  loss_vfl_dn_1: 0.5514 (0.5422)  loss_vfl_dn_2: 0.5557 (0.5585)  loss_vfl_dn_3: 0.5894 (0.5790)  loss_vfl_dn_4: 0.5979 (0.5960)  loss_vfl_dn_5: 0.6147 (0.6042)  loss_vfl_enc_0: 1.1074 (1.0540)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.4196  data: 1.3787  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0859  data: 0.2247  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1025 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.17s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.029\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.041\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.030\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.048\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.036\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.151\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.225\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.235\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.071\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.325\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.317\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.344\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.245\r\n",
      "best_stat: {'epoch': 44, 'coco_eval_bbox': 0.029159801562864712}\r\n",
      "Training time 1:23:08\r\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/RT-DETR/rtdetrv2_pytorch/\n",
    "\n",
    "!torchrun --nproc_per_node=2 tools/train.py \\\n",
    "    -c configs/rtdetrv2/rtdetrv2_taco_finetune_vit.yml \\\n",
    "    --use-amp \\\n",
    "    --seed=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d890d79",
   "metadata": {
    "_cell_guid": "0bfb3530-9f09-45a9-a843-e985fc5ba278",
    "_uuid": "c1a5c301-84a7-4a0e-9e22-266aefad66a3",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.248985,
     "end_time": "2025-10-30T22:57:25.614796",
     "exception": false,
     "start_time": "2025-10-30T22:57:25.365811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# With baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77f0467f",
   "metadata": {
    "_cell_guid": "86cb2aa3-9faa-4bd4-a026-ae7f47d60ddf",
    "_uuid": "501c4dba-bade-4c90-b88a-d9e23133ecc2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-30T22:57:26.206190Z",
     "iopub.status.busy": "2025-10-30T22:57:26.205558Z",
     "iopub.status.idle": "2025-10-30T22:57:26.211757Z",
     "shell.execute_reply": "2025-10-30T22:57:26.211005Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.263196,
     "end_time": "2025-10-30T22:57:26.213052",
     "exception": false,
     "start_time": "2025-10-30T22:57:25.949856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/RT-DETR/rtdetrv2_pytorch/configs/rtdetrv2/rtdetrv2_taco_finetune_BASELINE.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/RT-DETR/rtdetrv2_pytorch/configs/rtdetrv2/rtdetrv2_taco_finetune_BASELINE.yml\n",
    "__include__: [\n",
    "  '../dataset/coco_detection.yml',\n",
    "  '../runtime.yml',\n",
    "  './include/dataloader.yml',\n",
    "  './include/rtdetrv2_r50vd.yml',\n",
    "]\n",
    "\n",
    "output_dir: /kaggle/working/FINAL/FINETUNE_BASELINE/rtdetrv2_finetune_taco_finetune_BASELINE\n",
    "\n",
    "RTDETR:\n",
    "  backbone: PResNet\n",
    "\n",
    "PResNet:\n",
    "  depth: 50\n",
    "  variant: d\n",
    "  freeze_at: 0\n",
    "  return_idx: [1, 2, 3]\n",
    "  num_stages: 4\n",
    "  freeze_norm: True\n",
    "  pretrained: False\n",
    "\n",
    "task: detection\n",
    "remap_mscoco_category: false\n",
    "\n",
    "compile: true\n",
    "epoches: 50\n",
    "num_classes: 60\n",
    "\n",
    "\n",
    "train_dataloader:\n",
    "  num_workers: 4\n",
    "  dataset:\n",
    "    type: CocoDetection\n",
    "    img_folder: /kaggle/input/dsp-pre-final/processed_taco_coco/train2017\n",
    "    ann_file: /kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_train2017.json\n",
    "\n",
    "val_dataloader:\n",
    "  num_workers: 4\n",
    "  dataset:\n",
    "    type: CocoDetection\n",
    "    img_folder: /kaggle/input/dsp-pre-final/processed_taco_coco/val2017\n",
    "    ann_file: /kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_val2017.json\n",
    "\n",
    "batch_size: 16\n",
    "\n",
    "optimizer:\n",
    "  type: AdamW\n",
    "  params:\n",
    "    - params: '^(?=.*backbone)'\n",
    "      lr: 0.00002   \n",
    "  lr: 0.00002   \n",
    "  weight_decay: 0.0001\n",
    "  betas: [0.9, 0.999]\n",
    "\n",
    "lr_scheduler:\n",
    "  type: MultiStepLR\n",
    "  milestones: [40]\n",
    "  gamma: 0.1\n",
    "\n",
    "checkpoint_freq: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb6b91fc",
   "metadata": {
    "_cell_guid": "b367cdf7-001c-48f8-8284-b625b9eeeeca",
    "_uuid": "98e54552-f78a-4643-8b41-dfa3a0977c0b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-30T22:57:26.727199Z",
     "iopub.status.busy": "2025-10-30T22:57:26.726536Z",
     "iopub.status.idle": "2025-10-31T00:20:50.544271Z",
     "shell.execute_reply": "2025-10-31T00:20:50.543472Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 5004.07651,
     "end_time": "2025-10-31T00:20:50.545718",
     "exception": false,
     "start_time": "2025-10-30T22:57:26.469208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/RT-DETR/rtdetrv2_pytorch\n",
      "W1030 22:57:29.114000 15688 torch/distributed/run.py:793] \r\n",
      "W1030 22:57:29.114000 15688 torch/distributed/run.py:793] *****************************************\r\n",
      "W1030 22:57:29.114000 15688 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \r\n",
      "W1030 22:57:29.114000 15688 torch/distributed/run.py:793] *****************************************\r\n",
      "2025-10-30 22:57:31.524595: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2025-10-30 22:57:31.524597: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1761865051.545856   15694 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1761865051.545912   15693 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1761865051.552713   15694 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "E0000 00:00:1761865051.552712   15693 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Initialized distributed mode...\r\n",
      "cfg:  {'task': 'detection', '_model': None, '_postprocessor': None, '_criterion': None, '_optimizer': None, '_lr_scheduler': None, '_lr_warmup_scheduler': None, '_train_dataloader': None, '_val_dataloader': None, '_ema': None, '_scaler': None, '_train_dataset': None, '_val_dataset': None, '_collate_fn': None, '_evaluator': None, '_writer': None, 'num_workers': 0, 'batch_size': 16, '_train_batch_size': None, '_val_batch_size': None, '_train_shuffle': None, '_val_shuffle': None, 'resume': None, 'tuning': None, 'epoches': 50, 'last_epoch': -1, 'use_amp': True, 'use_ema': False, 'ema_decay': 0.9999, 'ema_warmups': 2000, 'sync_bn': True, 'clip_max_norm': 0.0, 'find_unused_parameters': False, 'seed': 0, 'print_freq': 100, 'checkpoint_freq': 10, 'output_dir': '/kaggle/working/FINAL/FINETUNE_BASELINE/rtdetrv2_finetune_taco_finetune_BASELINE', 'summary_dir': None, 'device': '', 'yaml_cfg': {'task': 'detection', 'evaluator': {'type': 'CocoEvaluator', 'iou_types': ['bbox']}, 'num_classes': 60, 'remap_mscoco_category': False, 'train_dataloader': {'type': 'DataLoader', 'dataset': {'type': 'CocoDetection', 'img_folder': '/kaggle/input/dsp-pre-final/processed_taco_coco/train2017', 'ann_file': '/kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_train2017.json', 'return_masks': False, 'transforms': {'type': 'Compose', 'ops': [{'type': 'RandomPhotometricDistort', 'p': 0.5}, {'type': 'RandomZoomOut', 'fill': 0}, {'type': 'RandomIoUCrop', 'p': 0.8}, {'type': 'SanitizeBoundingBoxes', 'min_size': 1}, {'type': 'RandomHorizontalFlip'}, {'type': 'Resize', 'size': [640, 640]}, {'type': 'SanitizeBoundingBoxes', 'min_size': 1}, {'type': 'ConvertPILImage', 'dtype': 'float32', 'scale': True}, {'type': 'ConvertBoxes', 'fmt': 'cxcywh', 'normalize': True}], 'policy': {'name': 'stop_epoch', 'epoch': 71, 'ops': ['RandomPhotometricDistort', 'RandomZoomOut', 'RandomIoUCrop']}}}, 'shuffle': True, 'num_workers': 4, 'drop_last': True, 'collate_fn': {'type': 'BatchImageCollateFuncion', 'scales': [480, 512, 544, 576, 608, 640, 640, 640, 672, 704, 736, 768, 800], 'stop_epoch': 71}, 'total_batch_size': 16}, 'val_dataloader': {'type': 'DataLoader', 'dataset': {'type': 'CocoDetection', 'img_folder': '/kaggle/input/dsp-pre-final/processed_taco_coco/val2017', 'ann_file': '/kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_val2017.json', 'return_masks': False, 'transforms': {'type': 'Compose', 'ops': [{'type': 'Resize', 'size': [640, 640]}, {'type': 'ConvertPILImage', 'dtype': 'float32', 'scale': True}]}}, 'shuffle': False, 'num_workers': 4, 'drop_last': False, 'collate_fn': {'type': 'BatchImageCollateFuncion'}, 'total_batch_size': 32}, 'print_freq': 100, 'output_dir': '/kaggle/working/FINAL/FINETUNE_BASELINE/rtdetrv2_finetune_taco_finetune_BASELINE', 'checkpoint_freq': 10, 'sync_bn': True, 'find_unused_parameters': False, 'use_amp': True, 'scaler': {'type': 'GradScaler', 'enabled': True}, 'use_ema': False, 'ema': {'type': 'ModelEMA', 'decay': 0.9999, 'warmups': 2000}, 'model': 'RTDETR', 'criterion': 'RTDETRCriterionv2', 'postprocessor': 'RTDETRPostProcessor', 'use_focal_loss': True, 'eval_spatial_size': [640, 640], 'RTDETR': {'backbone': 'PResNet', 'encoder': 'HybridEncoder', 'decoder': 'RTDETRTransformerv2'}, 'PResNet': {'depth': 50, 'variant': 'd', 'freeze_at': 0, 'return_idx': [1, 2, 3], 'num_stages': 4, 'freeze_norm': True, 'pretrained': False}, 'HybridEncoder': {'in_channels': [512, 1024, 2048], 'feat_strides': [8, 16, 32], 'hidden_dim': 256, 'use_encoder_idx': [2], 'num_encoder_layers': 1, 'nhead': 8, 'dim_feedforward': 1024, 'dropout': 0.0, 'enc_act': 'gelu', 'expansion': 1.0, 'depth_mult': 1, 'act': 'silu'}, 'RTDETRTransformerv2': {'feat_channels': [256, 256, 256], 'feat_strides': [8, 16, 32], 'hidden_dim': 256, 'num_levels': 3, 'num_layers': 6, 'num_queries': 300, 'num_denoising': 100, 'label_noise_ratio': 0.5, 'box_noise_scale': 1.0, 'eval_idx': -1, 'num_points': [4, 4, 4], 'cross_attn_method': 'default', 'query_select_method': 'default'}, 'RTDETRPostProcessor': {'num_top_queries': 300}, 'RTDETRCriterionv2': {'weight_dict': {'loss_vfl': 1, 'loss_bbox': 5, 'loss_giou': 2}, 'losses': ['vfl', 'boxes'], 'alpha': 0.75, 'gamma': 2.0, 'matcher': {'type': 'HungarianMatcher', 'weight_dict': {'cost_class': 2, 'cost_bbox': 5, 'cost_giou': 2}, 'alpha': 0.25, 'gamma': 2.0}}, '__include__': ['../dataset/coco_detection.yml', '../runtime.yml', './include/dataloader.yml', './include/rtdetrv2_r50vd.yml'], 'compile': True, 'epoches': 50, 'batch_size': 16, 'optimizer': {'type': 'AdamW', 'params': [{'params': '^(?=.*backbone)', 'lr': 2e-05}], 'lr': 2e-05, 'weight_decay': 0.0001, 'betas': [0.9, 0.999]}, 'lr_scheduler': {'type': 'MultiStepLR', 'milestones': [40], 'gamma': 0.1}, 'config': 'configs/rtdetrv2/rtdetrv2_taco_finetune_BASELINE.yml', 'seed': 0, 'test_only': False, 'print_method': 'builtin', 'print_rank': 0}}\r\n",
      "Start training\r\n",
      "Initialized distributed mode...\r\n",
      "/kaggle/working/RT-DETR/rtdetrv2_pytorch/tools/../src/core/workspace.py:179: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\r\n",
      "  return module(**module_kwargs)\r\n",
      "/kaggle/working/RT-DETR/rtdetrv2_pytorch/tools/../src/core/workspace.py:179: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\r\n",
      "  return module(**module_kwargs)\r\n",
      "Initial lr: [2e-05, 2e-05]\r\n",
      "building train_dataloader with batch_size=8...\r\n",
      "building val_dataloader with batch_size=16...\r\n",
      "number of trainable parameters: 42821760\r\n",
      "Epoch: [0]  [ 0/79]  eta: 0:09:02  lr: 0.000020  loss: 36.6440 (36.6440)  loss_bbox: 0.7998 (0.7998)  loss_bbox_aux_0: 0.8393 (0.8393)  loss_bbox_aux_1: 0.8246 (0.8246)  loss_bbox_aux_2: 0.7953 (0.7953)  loss_bbox_aux_3: 0.8299 (0.8299)  loss_bbox_aux_4: 0.8143 (0.8143)  loss_bbox_dn_0: 0.4249 (0.4249)  loss_bbox_dn_1: 0.4249 (0.4249)  loss_bbox_dn_2: 0.4249 (0.4249)  loss_bbox_dn_3: 0.4249 (0.4249)  loss_bbox_dn_4: 0.4249 (0.4249)  loss_bbox_dn_5: 0.4249 (0.4249)  loss_bbox_enc_0: 0.8313 (0.8313)  loss_giou: 1.8573 (1.8573)  loss_giou_aux_0: 1.8459 (1.8459)  loss_giou_aux_1: 1.8473 (1.8473)  loss_giou_aux_2: 1.8874 (1.8874)  loss_giou_aux_3: 1.8201 (1.8201)  loss_giou_aux_4: 1.8360 (1.8360)  loss_giou_dn_0: 1.3827 (1.3827)  loss_giou_dn_1: 1.3827 (1.3827)  loss_giou_dn_2: 1.3827 (1.3827)  loss_giou_dn_3: 1.3827 (1.3827)  loss_giou_dn_4: 1.3827 (1.3827)  loss_giou_dn_5: 1.3827 (1.3827)  loss_giou_enc_0: 1.8677 (1.8677)  loss_vfl: 0.3421 (0.3421)  loss_vfl_aux_0: 0.3530 (0.3530)  loss_vfl_aux_1: 0.3052 (0.3052)  loss_vfl_aux_2: 0.3124 (0.3124)  loss_vfl_aux_3: 0.3624 (0.3624)  loss_vfl_aux_4: 0.3417 (0.3417)  loss_vfl_dn_0: 0.8298 (0.8298)  loss_vfl_dn_1: 0.7654 (0.7654)  loss_vfl_dn_2: 0.7646 (0.7646)  loss_vfl_dn_3: 0.8049 (0.8049)  loss_vfl_dn_4: 0.7761 (0.7761)  loss_vfl_dn_5: 0.8066 (0.8066)  loss_vfl_enc_0: 0.3377 (0.3377)  time: 6.8669  data: 3.0890  max mem: 7012\r\n",
      "Epoch: [0]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 37.2164 (37.6956)  loss_bbox: 0.9421 (1.0146)  loss_bbox_aux_0: 0.9759 (1.0310)  loss_bbox_aux_1: 0.9792 (1.0225)  loss_bbox_aux_2: 0.9576 (1.0172)  loss_bbox_aux_3: 0.9655 (1.0173)  loss_bbox_aux_4: 0.9539 (1.0154)  loss_bbox_dn_0: 0.5002 (0.4982)  loss_bbox_dn_1: 0.5017 (0.4989)  loss_bbox_dn_2: 0.5033 (0.4998)  loss_bbox_dn_3: 0.5046 (0.5006)  loss_bbox_dn_4: 0.5058 (0.5013)  loss_bbox_dn_5: 0.5070 (0.5020)  loss_bbox_enc_0: 1.0232 (1.0583)  loss_giou: 1.7716 (1.8419)  loss_giou_aux_0: 1.8001 (1.8598)  loss_giou_aux_1: 1.7991 (1.8550)  loss_giou_aux_2: 1.7934 (1.8461)  loss_giou_aux_3: 1.7893 (1.8446)  loss_giou_aux_4: 1.7867 (1.8416)  loss_giou_dn_0: 1.3724 (1.3702)  loss_giou_dn_1: 1.3713 (1.3704)  loss_giou_dn_2: 1.3704 (1.3711)  loss_giou_dn_3: 1.3702 (1.3720)  loss_giou_dn_4: 1.3834 (1.3732)  loss_giou_dn_5: 1.3844 (1.3748)  loss_giou_enc_0: 1.8513 (1.8750)  loss_vfl: 0.3243 (0.2932)  loss_vfl_aux_0: 0.2830 (0.2739)  loss_vfl_aux_1: 0.3115 (0.2808)  loss_vfl_aux_2: 0.3210 (0.2848)  loss_vfl_aux_3: 0.3236 (0.2948)  loss_vfl_aux_4: 0.3276 (0.2922)  loss_vfl_dn_0: 0.6614 (0.7320)  loss_vfl_dn_1: 0.6653 (0.7311)  loss_vfl_dn_2: 0.6616 (0.7214)  loss_vfl_dn_3: 0.6444 (0.7158)  loss_vfl_dn_4: 0.6294 (0.7017)  loss_vfl_dn_5: 0.6304 (0.7106)  loss_vfl_enc_0: 0.2881 (0.2907)  time: 0.9830  data: 0.0307  max mem: 10338\r\n",
      "Epoch: [0] Total time: 0:01:28 (1.1142 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 37.2164 (37.6956)  loss_bbox: 0.9421 (1.0146)  loss_bbox_aux_0: 0.9759 (1.0310)  loss_bbox_aux_1: 0.9792 (1.0225)  loss_bbox_aux_2: 0.9576 (1.0172)  loss_bbox_aux_3: 0.9655 (1.0173)  loss_bbox_aux_4: 0.9539 (1.0154)  loss_bbox_dn_0: 0.5002 (0.4982)  loss_bbox_dn_1: 0.5017 (0.4989)  loss_bbox_dn_2: 0.5033 (0.4998)  loss_bbox_dn_3: 0.5046 (0.5006)  loss_bbox_dn_4: 0.5058 (0.5013)  loss_bbox_dn_5: 0.5070 (0.5020)  loss_bbox_enc_0: 1.0232 (1.0583)  loss_giou: 1.7716 (1.8419)  loss_giou_aux_0: 1.8001 (1.8598)  loss_giou_aux_1: 1.7991 (1.8550)  loss_giou_aux_2: 1.7934 (1.8461)  loss_giou_aux_3: 1.7893 (1.8446)  loss_giou_aux_4: 1.7867 (1.8416)  loss_giou_dn_0: 1.3724 (1.3702)  loss_giou_dn_1: 1.3713 (1.3704)  loss_giou_dn_2: 1.3704 (1.3711)  loss_giou_dn_3: 1.3702 (1.3720)  loss_giou_dn_4: 1.3834 (1.3732)  loss_giou_dn_5: 1.3844 (1.3748)  loss_giou_enc_0: 1.8513 (1.8750)  loss_vfl: 0.3243 (0.2932)  loss_vfl_aux_0: 0.2830 (0.2739)  loss_vfl_aux_1: 0.3115 (0.2808)  loss_vfl_aux_2: 0.3210 (0.2848)  loss_vfl_aux_3: 0.3236 (0.2948)  loss_vfl_aux_4: 0.3276 (0.2922)  loss_vfl_dn_0: 0.6614 (0.7320)  loss_vfl_dn_1: 0.6653 (0.7311)  loss_vfl_dn_2: 0.6616 (0.7214)  loss_vfl_dn_3: 0.6444 (0.7158)  loss_vfl_dn_4: 0.6294 (0.7017)  loss_vfl_dn_5: 0.6304 (0.7106)  loss_vfl_enc_0: 0.2881 (0.2907)\r\n",
      "Test:  [0/8]  eta: 0:00:21    time: 2.6301  data: 1.4657  max mem: 10338\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.1075  data: 0.2373  max mem: 10338\r\n",
      "Test: Total time: 0:00:08 (1.1220 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.15s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      "best_stat: {'epoch': 0, 'coco_eval_bbox': 3.670944952558828e-07}\r\n",
      "Epoch: [1]  [ 0/79]  eta: 0:05:16  lr: 0.000020  loss: 34.1723 (34.1723)  loss_bbox: 0.7109 (0.7109)  loss_bbox_aux_0: 0.7243 (0.7243)  loss_bbox_aux_1: 0.7385 (0.7385)  loss_bbox_aux_2: 0.7117 (0.7117)  loss_bbox_aux_3: 0.7154 (0.7154)  loss_bbox_aux_4: 0.7055 (0.7055)  loss_bbox_dn_0: 0.3486 (0.3486)  loss_bbox_dn_1: 0.3508 (0.3508)  loss_bbox_dn_2: 0.3533 (0.3533)  loss_bbox_dn_3: 0.3555 (0.3555)  loss_bbox_dn_4: 0.3573 (0.3573)  loss_bbox_dn_5: 0.3589 (0.3589)  loss_bbox_enc_0: 0.7936 (0.7936)  loss_giou: 1.7863 (1.7863)  loss_giou_aux_0: 1.8082 (1.8082)  loss_giou_aux_1: 1.7734 (1.7734)  loss_giou_aux_2: 1.7990 (1.7990)  loss_giou_aux_3: 1.7885 (1.7885)  loss_giou_aux_4: 1.8000 (1.8000)  loss_giou_dn_0: 1.4005 (1.4005)  loss_giou_dn_1: 1.4025 (1.4025)  loss_giou_dn_2: 1.4025 (1.4025)  loss_giou_dn_3: 1.4033 (1.4033)  loss_giou_dn_4: 1.4067 (1.4067)  loss_giou_dn_5: 1.4104 (1.4104)  loss_giou_enc_0: 1.8100 (1.8100)  loss_vfl: 0.3540 (0.3540)  loss_vfl_aux_0: 0.3298 (0.3298)  loss_vfl_aux_1: 0.3291 (0.3291)  loss_vfl_aux_2: 0.3414 (0.3414)  loss_vfl_aux_3: 0.3481 (0.3481)  loss_vfl_aux_4: 0.3726 (0.3726)  loss_vfl_dn_0: 0.5986 (0.5986)  loss_vfl_dn_1: 0.5830 (0.5830)  loss_vfl_dn_2: 0.5984 (0.5984)  loss_vfl_dn_3: 0.5732 (0.5732)  loss_vfl_dn_4: 0.5836 (0.5836)  loss_vfl_dn_5: 0.5806 (0.5806)  loss_vfl_enc_0: 0.3643 (0.3643)  time: 4.0078  data: 2.7270  max mem: 10338\r\n",
      "Epoch: [1]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 35.2530 (36.3855)  loss_bbox: 0.8219 (0.9475)  loss_bbox_aux_0: 0.8546 (0.9651)  loss_bbox_aux_1: 0.8353 (0.9538)  loss_bbox_aux_2: 0.8430 (0.9519)  loss_bbox_aux_3: 0.8205 (0.9475)  loss_bbox_aux_4: 0.8182 (0.9463)  loss_bbox_dn_0: 0.4080 (0.4981)  loss_bbox_dn_1: 0.4079 (0.4998)  loss_bbox_dn_2: 0.4082 (0.5018)  loss_bbox_dn_3: 0.4084 (0.5032)  loss_bbox_dn_4: 0.4083 (0.5043)  loss_bbox_dn_5: 0.4083 (0.5052)  loss_bbox_enc_0: 0.8872 (0.9971)  loss_giou: 1.7007 (1.7179)  loss_giou_aux_0: 1.7101 (1.7343)  loss_giou_aux_1: 1.7053 (1.7259)  loss_giou_aux_2: 1.7035 (1.7189)  loss_giou_aux_3: 1.7032 (1.7193)  loss_giou_aux_4: 1.6930 (1.7180)  loss_giou_dn_0: 1.3690 (1.3692)  loss_giou_dn_1: 1.3686 (1.3690)  loss_giou_dn_2: 1.3700 (1.3692)  loss_giou_dn_3: 1.3713 (1.3701)  loss_giou_dn_4: 1.3729 (1.3714)  loss_giou_dn_5: 1.3741 (1.3731)  loss_giou_enc_0: 1.7196 (1.7473)  loss_vfl: 0.4688 (0.4325)  loss_vfl_aux_0: 0.3828 (0.3740)  loss_vfl_aux_1: 0.4208 (0.3986)  loss_vfl_aux_2: 0.4108 (0.3917)  loss_vfl_aux_3: 0.4272 (0.4127)  loss_vfl_aux_4: 0.4510 (0.4239)  loss_vfl_dn_0: 0.5382 (0.5885)  loss_vfl_dn_1: 0.5522 (0.5904)  loss_vfl_dn_2: 0.5609 (0.6011)  loss_vfl_dn_3: 0.5740 (0.6006)  loss_vfl_dn_4: 0.5649 (0.5897)  loss_vfl_dn_5: 0.5610 (0.5889)  loss_vfl_enc_0: 0.3740 (0.3676)  time: 0.9725  data: 0.0330  max mem: 10356\r\n",
      "Epoch: [1] Total time: 0:01:25 (1.0770 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 35.2530 (36.3855)  loss_bbox: 0.8219 (0.9475)  loss_bbox_aux_0: 0.8546 (0.9651)  loss_bbox_aux_1: 0.8353 (0.9538)  loss_bbox_aux_2: 0.8430 (0.9519)  loss_bbox_aux_3: 0.8205 (0.9475)  loss_bbox_aux_4: 0.8182 (0.9463)  loss_bbox_dn_0: 0.4080 (0.4981)  loss_bbox_dn_1: 0.4079 (0.4998)  loss_bbox_dn_2: 0.4082 (0.5018)  loss_bbox_dn_3: 0.4084 (0.5032)  loss_bbox_dn_4: 0.4083 (0.5043)  loss_bbox_dn_5: 0.4083 (0.5052)  loss_bbox_enc_0: 0.8872 (0.9971)  loss_giou: 1.7007 (1.7179)  loss_giou_aux_0: 1.7101 (1.7343)  loss_giou_aux_1: 1.7053 (1.7259)  loss_giou_aux_2: 1.7035 (1.7189)  loss_giou_aux_3: 1.7032 (1.7193)  loss_giou_aux_4: 1.6930 (1.7180)  loss_giou_dn_0: 1.3690 (1.3692)  loss_giou_dn_1: 1.3686 (1.3690)  loss_giou_dn_2: 1.3700 (1.3692)  loss_giou_dn_3: 1.3713 (1.3701)  loss_giou_dn_4: 1.3729 (1.3714)  loss_giou_dn_5: 1.3741 (1.3731)  loss_giou_enc_0: 1.7196 (1.7473)  loss_vfl: 0.4688 (0.4325)  loss_vfl_aux_0: 0.3828 (0.3740)  loss_vfl_aux_1: 0.4208 (0.3986)  loss_vfl_aux_2: 0.4108 (0.3917)  loss_vfl_aux_3: 0.4272 (0.4127)  loss_vfl_aux_4: 0.4510 (0.4239)  loss_vfl_dn_0: 0.5382 (0.5885)  loss_vfl_dn_1: 0.5522 (0.5904)  loss_vfl_dn_2: 0.5609 (0.6011)  loss_vfl_dn_3: 0.5740 (0.6006)  loss_vfl_dn_4: 0.5649 (0.5897)  loss_vfl_dn_5: 0.5610 (0.5889)  loss_vfl_enc_0: 0.3740 (0.3676)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.4627  data: 1.5560  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0801  data: 0.2423  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0996 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.13s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.008\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      "best_stat: {'epoch': 1, 'coco_eval_bbox': 2.1499556990106964e-06}\r\n",
      "Epoch: [2]  [ 0/79]  eta: 0:05:47  lr: 0.000020  loss: 34.9113 (34.9113)  loss_bbox: 0.7932 (0.7932)  loss_bbox_aux_0: 0.7898 (0.7898)  loss_bbox_aux_1: 0.7707 (0.7707)  loss_bbox_aux_2: 0.7730 (0.7730)  loss_bbox_aux_3: 0.7599 (0.7599)  loss_bbox_aux_4: 0.7797 (0.7797)  loss_bbox_dn_0: 0.3856 (0.3856)  loss_bbox_dn_1: 0.3868 (0.3868)  loss_bbox_dn_2: 0.3879 (0.3879)  loss_bbox_dn_3: 0.3884 (0.3884)  loss_bbox_dn_4: 0.3886 (0.3886)  loss_bbox_dn_5: 0.3888 (0.3888)  loss_bbox_enc_0: 0.7957 (0.7957)  loss_giou: 1.6993 (1.6993)  loss_giou_aux_0: 1.7011 (1.7011)  loss_giou_aux_1: 1.7069 (1.7069)  loss_giou_aux_2: 1.7130 (1.7130)  loss_giou_aux_3: 1.7079 (1.7079)  loss_giou_aux_4: 1.6902 (1.6902)  loss_giou_dn_0: 1.3651 (1.3651)  loss_giou_dn_1: 1.3675 (1.3675)  loss_giou_dn_2: 1.3692 (1.3692)  loss_giou_dn_3: 1.3709 (1.3709)  loss_giou_dn_4: 1.3728 (1.3728)  loss_giou_dn_5: 1.3751 (1.3751)  loss_giou_enc_0: 1.7287 (1.7287)  loss_vfl: 0.5072 (0.5072)  loss_vfl_aux_0: 0.4498 (0.4498)  loss_vfl_aux_1: 0.4994 (0.4994)  loss_vfl_aux_2: 0.4917 (0.4917)  loss_vfl_aux_3: 0.4934 (0.4934)  loss_vfl_aux_4: 0.5337 (0.5337)  loss_vfl_dn_0: 0.5671 (0.5671)  loss_vfl_dn_1: 0.5894 (0.5894)  loss_vfl_dn_2: 0.5846 (0.5846)  loss_vfl_dn_3: 0.5974 (0.5974)  loss_vfl_dn_4: 0.6108 (0.6108)  loss_vfl_dn_5: 0.6056 (0.6056)  loss_vfl_enc_0: 0.4252 (0.4252)  time: 4.3986  data: 2.9717  max mem: 10356\r\n",
      "Epoch: [2]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 34.9907 (36.1513)  loss_bbox: 0.8970 (0.9384)  loss_bbox_aux_0: 0.9357 (0.9631)  loss_bbox_aux_1: 0.9159 (0.9472)  loss_bbox_aux_2: 0.9052 (0.9411)  loss_bbox_aux_3: 0.9015 (0.9399)  loss_bbox_aux_4: 0.8996 (0.9396)  loss_bbox_dn_0: 0.4191 (0.5214)  loss_bbox_dn_1: 0.4204 (0.5222)  loss_bbox_dn_2: 0.4211 (0.5225)  loss_bbox_dn_3: 0.4208 (0.5225)  loss_bbox_dn_4: 0.4200 (0.5222)  loss_bbox_dn_5: 0.4193 (0.5219)  loss_bbox_enc_0: 0.9588 (0.9855)  loss_giou: 1.6040 (1.6180)  loss_giou_aux_0: 1.6066 (1.6289)  loss_giou_aux_1: 1.6234 (1.6247)  loss_giou_aux_2: 1.6087 (1.6215)  loss_giou_aux_3: 1.6090 (1.6204)  loss_giou_aux_4: 1.6120 (1.6171)  loss_giou_dn_0: 1.3679 (1.3672)  loss_giou_dn_1: 1.3668 (1.3667)  loss_giou_dn_2: 1.3648 (1.3664)  loss_giou_dn_3: 1.3639 (1.3665)  loss_giou_dn_4: 1.3629 (1.3666)  loss_giou_dn_5: 1.3621 (1.3667)  loss_giou_enc_0: 1.6506 (1.6421)  loss_vfl: 0.4978 (0.5430)  loss_vfl_aux_0: 0.4412 (0.4717)  loss_vfl_aux_1: 0.4504 (0.4994)  loss_vfl_aux_2: 0.4506 (0.5032)  loss_vfl_aux_3: 0.4613 (0.5233)  loss_vfl_aux_4: 0.4961 (0.5385)  loss_vfl_dn_0: 0.4800 (0.5137)  loss_vfl_dn_1: 0.5137 (0.5322)  loss_vfl_dn_2: 0.5211 (0.5469)  loss_vfl_dn_3: 0.5356 (0.5602)  loss_vfl_dn_4: 0.5455 (0.5587)  loss_vfl_dn_5: 0.5548 (0.5655)  loss_vfl_enc_0: 0.3882 (0.4348)  time: 1.0156  data: 0.0304  max mem: 10356\r\n",
      "Epoch: [2] Total time: 0:01:27 (1.1106 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 34.9907 (36.1513)  loss_bbox: 0.8970 (0.9384)  loss_bbox_aux_0: 0.9357 (0.9631)  loss_bbox_aux_1: 0.9159 (0.9472)  loss_bbox_aux_2: 0.9052 (0.9411)  loss_bbox_aux_3: 0.9015 (0.9399)  loss_bbox_aux_4: 0.8996 (0.9396)  loss_bbox_dn_0: 0.4191 (0.5214)  loss_bbox_dn_1: 0.4204 (0.5222)  loss_bbox_dn_2: 0.4211 (0.5225)  loss_bbox_dn_3: 0.4208 (0.5225)  loss_bbox_dn_4: 0.4200 (0.5222)  loss_bbox_dn_5: 0.4193 (0.5219)  loss_bbox_enc_0: 0.9588 (0.9855)  loss_giou: 1.6040 (1.6180)  loss_giou_aux_0: 1.6066 (1.6289)  loss_giou_aux_1: 1.6234 (1.6247)  loss_giou_aux_2: 1.6087 (1.6215)  loss_giou_aux_3: 1.6090 (1.6204)  loss_giou_aux_4: 1.6120 (1.6171)  loss_giou_dn_0: 1.3679 (1.3672)  loss_giou_dn_1: 1.3668 (1.3667)  loss_giou_dn_2: 1.3648 (1.3664)  loss_giou_dn_3: 1.3639 (1.3665)  loss_giou_dn_4: 1.3629 (1.3666)  loss_giou_dn_5: 1.3621 (1.3667)  loss_giou_enc_0: 1.6506 (1.6421)  loss_vfl: 0.4978 (0.5430)  loss_vfl_aux_0: 0.4412 (0.4717)  loss_vfl_aux_1: 0.4504 (0.4994)  loss_vfl_aux_2: 0.4506 (0.5032)  loss_vfl_aux_3: 0.4613 (0.5233)  loss_vfl_aux_4: 0.4961 (0.5385)  loss_vfl_dn_0: 0.4800 (0.5137)  loss_vfl_dn_1: 0.5137 (0.5322)  loss_vfl_dn_2: 0.5211 (0.5469)  loss_vfl_dn_3: 0.5356 (0.5602)  loss_vfl_dn_4: 0.5455 (0.5587)  loss_vfl_dn_5: 0.5548 (0.5655)  loss_vfl_enc_0: 0.3882 (0.4348)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3346  data: 1.3569  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0696  data: 0.2088  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0857 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.14s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.002\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.010\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.012\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      "best_stat: {'epoch': 2, 'coco_eval_bbox': 1.3243644314998678e-05}\r\n",
      "Epoch: [3]  [ 0/79]  eta: 0:06:14  lr: 0.000020  loss: 35.2880 (35.2880)  loss_bbox: 0.9235 (0.9235)  loss_bbox_aux_0: 0.9625 (0.9625)  loss_bbox_aux_1: 0.9275 (0.9275)  loss_bbox_aux_2: 0.9221 (0.9221)  loss_bbox_aux_3: 0.9192 (0.9192)  loss_bbox_aux_4: 0.9200 (0.9200)  loss_bbox_dn_0: 0.4257 (0.4257)  loss_bbox_dn_1: 0.4262 (0.4262)  loss_bbox_dn_2: 0.4260 (0.4260)  loss_bbox_dn_3: 0.4256 (0.4256)  loss_bbox_dn_4: 0.4250 (0.4250)  loss_bbox_dn_5: 0.4245 (0.4245)  loss_bbox_enc_0: 0.9698 (0.9698)  loss_giou: 1.7088 (1.7088)  loss_giou_aux_0: 1.7107 (1.7107)  loss_giou_aux_1: 1.7263 (1.7263)  loss_giou_aux_2: 1.7141 (1.7141)  loss_giou_aux_3: 1.7215 (1.7215)  loss_giou_aux_4: 1.7156 (1.7156)  loss_giou_dn_0: 1.3453 (1.3453)  loss_giou_dn_1: 1.3468 (1.3468)  loss_giou_dn_2: 1.3480 (1.3480)  loss_giou_dn_3: 1.3540 (1.3540)  loss_giou_dn_4: 1.3606 (1.3606)  loss_giou_dn_5: 1.3594 (1.3594)  loss_giou_enc_0: 1.7352 (1.7352)  loss_vfl: 0.4844 (0.4844)  loss_vfl_aux_0: 0.3903 (0.3903)  loss_vfl_aux_1: 0.4227 (0.4227)  loss_vfl_aux_2: 0.4232 (0.4232)  loss_vfl_aux_3: 0.4562 (0.4562)  loss_vfl_aux_4: 0.4661 (0.4661)  loss_vfl_dn_0: 0.4655 (0.4655)  loss_vfl_dn_1: 0.4720 (0.4720)  loss_vfl_dn_2: 0.4963 (0.4963)  loss_vfl_dn_3: 0.5189 (0.5189)  loss_vfl_dn_4: 0.5281 (0.5281)  loss_vfl_dn_5: 0.5394 (0.5394)  loss_vfl_enc_0: 0.3809 (0.3809)  time: 4.7408  data: 3.4902  max mem: 10356\r\n",
      "Epoch: [3]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 35.5600 (35.8429)  loss_bbox: 0.8573 (0.8882)  loss_bbox_aux_0: 0.8702 (0.9117)  loss_bbox_aux_1: 0.8655 (0.9028)  loss_bbox_aux_2: 0.8602 (0.8992)  loss_bbox_aux_3: 0.8614 (0.8934)  loss_bbox_aux_4: 0.8578 (0.8891)  loss_bbox_dn_0: 0.5051 (0.5359)  loss_bbox_dn_1: 0.5048 (0.5360)  loss_bbox_dn_2: 0.5037 (0.5354)  loss_bbox_dn_3: 0.5026 (0.5346)  loss_bbox_dn_4: 0.5013 (0.5335)  loss_bbox_dn_5: 0.5004 (0.5328)  loss_bbox_enc_0: 0.8703 (0.9422)  loss_giou: 1.5285 (1.5602)  loss_giou_aux_0: 1.5579 (1.5733)  loss_giou_aux_1: 1.5434 (1.5677)  loss_giou_aux_2: 1.5664 (1.5637)  loss_giou_aux_3: 1.5508 (1.5647)  loss_giou_aux_4: 1.5301 (1.5630)  loss_giou_dn_0: 1.3768 (1.3677)  loss_giou_dn_1: 1.3777 (1.3678)  loss_giou_dn_2: 1.3765 (1.3687)  loss_giou_dn_3: 1.3805 (1.3708)  loss_giou_dn_4: 1.3866 (1.3728)  loss_giou_dn_5: 1.3877 (1.3752)  loss_giou_enc_0: 1.5588 (1.5804)  loss_vfl: 0.6415 (0.6298)  loss_vfl_aux_0: 0.5775 (0.5494)  loss_vfl_aux_1: 0.5957 (0.5660)  loss_vfl_aux_2: 0.5778 (0.5743)  loss_vfl_aux_3: 0.6143 (0.5969)  loss_vfl_aux_4: 0.6448 (0.6138)  loss_vfl_dn_0: 0.4576 (0.4793)  loss_vfl_dn_1: 0.4646 (0.4887)  loss_vfl_dn_2: 0.4765 (0.5035)  loss_vfl_dn_3: 0.5081 (0.5268)  loss_vfl_dn_4: 0.5112 (0.5327)  loss_vfl_dn_5: 0.5326 (0.5453)  loss_vfl_enc_0: 0.5060 (0.5055)  time: 0.9506  data: 0.0333  max mem: 10356\r\n",
      "Epoch: [3] Total time: 0:01:27 (1.1081 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 35.5600 (35.8429)  loss_bbox: 0.8573 (0.8882)  loss_bbox_aux_0: 0.8702 (0.9117)  loss_bbox_aux_1: 0.8655 (0.9028)  loss_bbox_aux_2: 0.8602 (0.8992)  loss_bbox_aux_3: 0.8614 (0.8934)  loss_bbox_aux_4: 0.8578 (0.8891)  loss_bbox_dn_0: 0.5051 (0.5359)  loss_bbox_dn_1: 0.5048 (0.5360)  loss_bbox_dn_2: 0.5037 (0.5354)  loss_bbox_dn_3: 0.5026 (0.5346)  loss_bbox_dn_4: 0.5013 (0.5335)  loss_bbox_dn_5: 0.5004 (0.5328)  loss_bbox_enc_0: 0.8703 (0.9422)  loss_giou: 1.5285 (1.5602)  loss_giou_aux_0: 1.5579 (1.5733)  loss_giou_aux_1: 1.5434 (1.5677)  loss_giou_aux_2: 1.5664 (1.5637)  loss_giou_aux_3: 1.5508 (1.5647)  loss_giou_aux_4: 1.5301 (1.5630)  loss_giou_dn_0: 1.3768 (1.3677)  loss_giou_dn_1: 1.3777 (1.3678)  loss_giou_dn_2: 1.3765 (1.3687)  loss_giou_dn_3: 1.3805 (1.3708)  loss_giou_dn_4: 1.3866 (1.3728)  loss_giou_dn_5: 1.3877 (1.3752)  loss_giou_enc_0: 1.5588 (1.5804)  loss_vfl: 0.6415 (0.6298)  loss_vfl_aux_0: 0.5775 (0.5494)  loss_vfl_aux_1: 0.5957 (0.5660)  loss_vfl_aux_2: 0.5778 (0.5743)  loss_vfl_aux_3: 0.6143 (0.5969)  loss_vfl_aux_4: 0.6448 (0.6138)  loss_vfl_dn_0: 0.4576 (0.4793)  loss_vfl_dn_1: 0.4646 (0.4887)  loss_vfl_dn_2: 0.4765 (0.5035)  loss_vfl_dn_3: 0.5081 (0.5268)  loss_vfl_dn_4: 0.5112 (0.5327)  loss_vfl_dn_5: 0.5326 (0.5453)  loss_vfl_enc_0: 0.5060 (0.5055)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.2652  data: 1.3126  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0700  data: 0.2170  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0864 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.14s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.002\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.010\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.004\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.014\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\r\n",
      "best_stat: {'epoch': 3, 'coco_eval_bbox': 1.7232681658722588e-05}\r\n",
      "Epoch: [4]  [ 0/79]  eta: 0:05:29  lr: 0.000020  loss: 35.6937 (35.6937)  loss_bbox: 0.6906 (0.6906)  loss_bbox_aux_0: 0.7157 (0.7157)  loss_bbox_aux_1: 0.6943 (0.6943)  loss_bbox_aux_2: 0.6933 (0.6933)  loss_bbox_aux_3: 0.6876 (0.6876)  loss_bbox_aux_4: 0.6838 (0.6838)  loss_bbox_dn_0: 0.5729 (0.5729)  loss_bbox_dn_1: 0.5726 (0.5726)  loss_bbox_dn_2: 0.5709 (0.5709)  loss_bbox_dn_3: 0.5694 (0.5694)  loss_bbox_dn_4: 0.5677 (0.5677)  loss_bbox_dn_5: 0.5667 (0.5667)  loss_bbox_enc_0: 0.7134 (0.7134)  loss_giou: 1.2145 (1.2145)  loss_giou_aux_0: 1.2127 (1.2127)  loss_giou_aux_1: 1.2198 (1.2198)  loss_giou_aux_2: 1.2025 (1.2025)  loss_giou_aux_3: 1.2188 (1.2188)  loss_giou_aux_4: 1.2089 (1.2089)  loss_giou_dn_0: 1.3605 (1.3605)  loss_giou_dn_1: 1.3605 (1.3605)  loss_giou_dn_2: 1.3641 (1.3641)  loss_giou_dn_3: 1.3725 (1.3725)  loss_giou_dn_4: 1.3895 (1.3895)  loss_giou_dn_5: 1.3946 (1.3946)  loss_giou_enc_0: 1.2410 (1.2410)  loss_vfl: 1.0745 (1.0745)  loss_vfl_aux_0: 1.0110 (1.0110)  loss_vfl_aux_1: 1.0081 (1.0081)  loss_vfl_aux_2: 1.0581 (1.0581)  loss_vfl_aux_3: 1.1023 (1.1023)  loss_vfl_aux_4: 1.0881 (1.0881)  loss_vfl_dn_0: 0.5220 (0.5220)  loss_vfl_dn_1: 0.5338 (0.5338)  loss_vfl_dn_2: 0.5480 (0.5480)  loss_vfl_dn_3: 0.5822 (0.5822)  loss_vfl_dn_4: 0.5627 (0.5627)  loss_vfl_dn_5: 0.5721 (0.5721)  loss_vfl_enc_0: 0.9718 (0.9718)  time: 4.1752  data: 2.7704  max mem: 10356\r\n",
      "Epoch: [4]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 34.9442 (34.8714)  loss_bbox: 0.7336 (0.7773)  loss_bbox_aux_0: 0.7268 (0.8057)  loss_bbox_aux_1: 0.7139 (0.7939)  loss_bbox_aux_2: 0.7426 (0.7901)  loss_bbox_aux_3: 0.7149 (0.7844)  loss_bbox_aux_4: 0.7404 (0.7801)  loss_bbox_dn_0: 0.5212 (0.5068)  loss_bbox_dn_1: 0.5209 (0.5059)  loss_bbox_dn_2: 0.5198 (0.5042)  loss_bbox_dn_3: 0.5195 (0.5031)  loss_bbox_dn_4: 0.5192 (0.5018)  loss_bbox_dn_5: 0.5196 (0.5011)  loss_bbox_enc_0: 0.7634 (0.8302)  loss_giou: 1.4986 (1.5420)  loss_giou_aux_0: 1.5284 (1.5492)  loss_giou_aux_1: 1.5318 (1.5483)  loss_giou_aux_2: 1.5316 (1.5464)  loss_giou_aux_3: 1.5598 (1.5461)  loss_giou_aux_4: 1.5070 (1.5441)  loss_giou_dn_0: 1.3694 (1.3707)  loss_giou_dn_1: 1.3666 (1.3694)  loss_giou_dn_2: 1.3621 (1.3685)  loss_giou_dn_3: 1.3606 (1.3685)  loss_giou_dn_4: 1.3592 (1.3690)  loss_giou_dn_5: 1.3582 (1.3698)  loss_giou_enc_0: 1.5575 (1.5532)  loss_vfl: 0.6299 (0.6664)  loss_vfl_aux_0: 0.5848 (0.6013)  loss_vfl_aux_1: 0.6133 (0.6111)  loss_vfl_aux_2: 0.6027 (0.6171)  loss_vfl_aux_3: 0.6044 (0.6307)  loss_vfl_aux_4: 0.6309 (0.6507)  loss_vfl_dn_0: 0.4518 (0.4533)  loss_vfl_dn_1: 0.4495 (0.4594)  loss_vfl_dn_2: 0.4614 (0.4710)  loss_vfl_dn_3: 0.4840 (0.4933)  loss_vfl_dn_4: 0.4916 (0.5028)  loss_vfl_dn_5: 0.5142 (0.5198)  loss_vfl_enc_0: 0.5529 (0.5646)  time: 0.9930  data: 0.0314  max mem: 10356\r\n",
      "Epoch: [4] Total time: 0:01:22 (1.0469 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 34.9442 (34.8714)  loss_bbox: 0.7336 (0.7773)  loss_bbox_aux_0: 0.7268 (0.8057)  loss_bbox_aux_1: 0.7139 (0.7939)  loss_bbox_aux_2: 0.7426 (0.7901)  loss_bbox_aux_3: 0.7149 (0.7844)  loss_bbox_aux_4: 0.7404 (0.7801)  loss_bbox_dn_0: 0.5212 (0.5068)  loss_bbox_dn_1: 0.5209 (0.5059)  loss_bbox_dn_2: 0.5198 (0.5042)  loss_bbox_dn_3: 0.5195 (0.5031)  loss_bbox_dn_4: 0.5192 (0.5018)  loss_bbox_dn_5: 0.5196 (0.5011)  loss_bbox_enc_0: 0.7634 (0.8302)  loss_giou: 1.4986 (1.5420)  loss_giou_aux_0: 1.5284 (1.5492)  loss_giou_aux_1: 1.5318 (1.5483)  loss_giou_aux_2: 1.5316 (1.5464)  loss_giou_aux_3: 1.5598 (1.5461)  loss_giou_aux_4: 1.5070 (1.5441)  loss_giou_dn_0: 1.3694 (1.3707)  loss_giou_dn_1: 1.3666 (1.3694)  loss_giou_dn_2: 1.3621 (1.3685)  loss_giou_dn_3: 1.3606 (1.3685)  loss_giou_dn_4: 1.3592 (1.3690)  loss_giou_dn_5: 1.3582 (1.3698)  loss_giou_enc_0: 1.5575 (1.5532)  loss_vfl: 0.6299 (0.6664)  loss_vfl_aux_0: 0.5848 (0.6013)  loss_vfl_aux_1: 0.6133 (0.6111)  loss_vfl_aux_2: 0.6027 (0.6171)  loss_vfl_aux_3: 0.6044 (0.6307)  loss_vfl_aux_4: 0.6309 (0.6507)  loss_vfl_dn_0: 0.4518 (0.4533)  loss_vfl_dn_1: 0.4495 (0.4594)  loss_vfl_dn_2: 0.4614 (0.4710)  loss_vfl_dn_3: 0.4840 (0.4933)  loss_vfl_dn_4: 0.4916 (0.5028)  loss_vfl_dn_5: 0.5142 (0.5198)  loss_vfl_enc_0: 0.5529 (0.5646)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3706  data: 1.4372  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0754  data: 0.2206  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0915 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.14s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.002\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.011\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\r\n",
      "best_stat: {'epoch': 4, 'coco_eval_bbox': 2.298746147610649e-05}\r\n",
      "Epoch: [5]  [ 0/79]  eta: 0:05:21  lr: 0.000020  loss: 39.4875 (39.4875)  loss_bbox: 0.9950 (0.9950)  loss_bbox_aux_0: 1.0404 (1.0404)  loss_bbox_aux_1: 1.0078 (1.0078)  loss_bbox_aux_2: 0.9988 (0.9988)  loss_bbox_aux_3: 1.0291 (1.0291)  loss_bbox_aux_4: 1.0050 (1.0050)  loss_bbox_dn_0: 0.8430 (0.8430)  loss_bbox_dn_1: 0.8414 (0.8414)  loss_bbox_dn_2: 0.8388 (0.8388)  loss_bbox_dn_3: 0.8368 (0.8368)  loss_bbox_dn_4: 0.8344 (0.8344)  loss_bbox_dn_5: 0.8335 (0.8335)  loss_bbox_enc_0: 1.0397 (1.0397)  loss_giou: 1.5485 (1.5485)  loss_giou_aux_0: 1.5428 (1.5428)  loss_giou_aux_1: 1.5476 (1.5476)  loss_giou_aux_2: 1.5516 (1.5516)  loss_giou_aux_3: 1.5323 (1.5323)  loss_giou_aux_4: 1.5459 (1.5459)  loss_giou_dn_0: 1.3610 (1.3610)  loss_giou_dn_1: 1.3595 (1.3595)  loss_giou_dn_2: 1.3595 (1.3595)  loss_giou_dn_3: 1.3589 (1.3589)  loss_giou_dn_4: 1.3583 (1.3583)  loss_giou_dn_5: 1.3575 (1.3575)  loss_giou_enc_0: 1.5427 (1.5427)  loss_vfl: 0.8606 (0.8606)  loss_vfl_aux_0: 0.7510 (0.7510)  loss_vfl_aux_1: 0.7812 (0.7812)  loss_vfl_aux_2: 0.7744 (0.7744)  loss_vfl_aux_3: 0.7964 (0.7964)  loss_vfl_aux_4: 0.8105 (0.8105)  loss_vfl_dn_0: 0.4440 (0.4440)  loss_vfl_dn_1: 0.4642 (0.4642)  loss_vfl_dn_2: 0.4724 (0.4724)  loss_vfl_dn_3: 0.4951 (0.4951)  loss_vfl_dn_4: 0.5024 (0.5024)  loss_vfl_dn_5: 0.5210 (0.5210)  loss_vfl_enc_0: 0.7043 (0.7043)  time: 4.0645  data: 2.7162  max mem: 10356\r\n",
      "Epoch: [5]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 33.0742 (34.5862)  loss_bbox: 0.6368 (0.7410)  loss_bbox_aux_0: 0.6731 (0.7839)  loss_bbox_aux_1: 0.6473 (0.7696)  loss_bbox_aux_2: 0.6435 (0.7618)  loss_bbox_aux_3: 0.6395 (0.7536)  loss_bbox_aux_4: 0.6291 (0.7434)  loss_bbox_dn_0: 0.4718 (0.5244)  loss_bbox_dn_1: 0.4710 (0.5226)  loss_bbox_dn_2: 0.4676 (0.5200)  loss_bbox_dn_3: 0.4655 (0.5190)  loss_bbox_dn_4: 0.4631 (0.5176)  loss_bbox_dn_5: 0.4619 (0.5173)  loss_bbox_enc_0: 0.6832 (0.8065)  loss_giou: 1.5102 (1.5186)  loss_giou_aux_0: 1.5171 (1.5331)  loss_giou_aux_1: 1.5211 (1.5326)  loss_giou_aux_2: 1.5143 (1.5291)  loss_giou_aux_3: 1.5149 (1.5300)  loss_giou_aux_4: 1.5104 (1.5252)  loss_giou_dn_0: 1.3740 (1.3700)  loss_giou_dn_1: 1.3709 (1.3671)  loss_giou_dn_2: 1.3673 (1.3653)  loss_giou_dn_3: 1.3634 (1.3644)  loss_giou_dn_4: 1.3565 (1.3634)  loss_giou_dn_5: 1.3547 (1.3634)  loss_giou_enc_0: 1.5266 (1.5466)  loss_vfl: 0.6538 (0.6693)  loss_vfl_aux_0: 0.5925 (0.6181)  loss_vfl_aux_1: 0.6068 (0.6248)  loss_vfl_aux_2: 0.6201 (0.6264)  loss_vfl_aux_3: 0.6279 (0.6369)  loss_vfl_aux_4: 0.6180 (0.6486)  loss_vfl_dn_0: 0.4304 (0.4417)  loss_vfl_dn_1: 0.4327 (0.4444)  loss_vfl_dn_2: 0.4462 (0.4558)  loss_vfl_dn_3: 0.4728 (0.4763)  loss_vfl_dn_4: 0.4758 (0.4827)  loss_vfl_dn_5: 0.4883 (0.4946)  loss_vfl_enc_0: 0.5087 (0.5771)  time: 0.9721  data: 0.0316  max mem: 10356\r\n",
      "Epoch: [5] Total time: 0:01:25 (1.0851 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 33.0742 (34.5862)  loss_bbox: 0.6368 (0.7410)  loss_bbox_aux_0: 0.6731 (0.7839)  loss_bbox_aux_1: 0.6473 (0.7696)  loss_bbox_aux_2: 0.6435 (0.7618)  loss_bbox_aux_3: 0.6395 (0.7536)  loss_bbox_aux_4: 0.6291 (0.7434)  loss_bbox_dn_0: 0.4718 (0.5244)  loss_bbox_dn_1: 0.4710 (0.5226)  loss_bbox_dn_2: 0.4676 (0.5200)  loss_bbox_dn_3: 0.4655 (0.5190)  loss_bbox_dn_4: 0.4631 (0.5176)  loss_bbox_dn_5: 0.4619 (0.5173)  loss_bbox_enc_0: 0.6832 (0.8065)  loss_giou: 1.5102 (1.5186)  loss_giou_aux_0: 1.5171 (1.5331)  loss_giou_aux_1: 1.5211 (1.5326)  loss_giou_aux_2: 1.5143 (1.5291)  loss_giou_aux_3: 1.5149 (1.5300)  loss_giou_aux_4: 1.5104 (1.5252)  loss_giou_dn_0: 1.3740 (1.3700)  loss_giou_dn_1: 1.3709 (1.3671)  loss_giou_dn_2: 1.3673 (1.3653)  loss_giou_dn_3: 1.3634 (1.3644)  loss_giou_dn_4: 1.3565 (1.3634)  loss_giou_dn_5: 1.3547 (1.3634)  loss_giou_enc_0: 1.5266 (1.5466)  loss_vfl: 0.6538 (0.6693)  loss_vfl_aux_0: 0.5925 (0.6181)  loss_vfl_aux_1: 0.6068 (0.6248)  loss_vfl_aux_2: 0.6201 (0.6264)  loss_vfl_aux_3: 0.6279 (0.6369)  loss_vfl_aux_4: 0.6180 (0.6486)  loss_vfl_dn_0: 0.4304 (0.4417)  loss_vfl_dn_1: 0.4327 (0.4444)  loss_vfl_dn_2: 0.4462 (0.4558)  loss_vfl_dn_3: 0.4728 (0.4763)  loss_vfl_dn_4: 0.4758 (0.4827)  loss_vfl_dn_5: 0.4883 (0.4946)  loss_vfl_enc_0: 0.5087 (0.5771)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.2899  data: 1.3867  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0614  data: 0.2211  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0777 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.15s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.005\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.014\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.011\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.027\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003\r\n",
      "best_stat: {'epoch': 5, 'coco_eval_bbox': 6.733552907538926e-05}\r\n",
      "Epoch: [6]  [ 0/79]  eta: 0:04:36  lr: 0.000020  loss: 36.5887 (36.5887)  loss_bbox: 0.8919 (0.8919)  loss_bbox_aux_0: 0.9678 (0.9678)  loss_bbox_aux_1: 0.9194 (0.9194)  loss_bbox_aux_2: 0.9201 (0.9201)  loss_bbox_aux_3: 0.8955 (0.8955)  loss_bbox_aux_4: 0.9008 (0.9008)  loss_bbox_dn_0: 0.6152 (0.6152)  loss_bbox_dn_1: 0.6133 (0.6133)  loss_bbox_dn_2: 0.6106 (0.6106)  loss_bbox_dn_3: 0.6089 (0.6089)  loss_bbox_dn_4: 0.6072 (0.6072)  loss_bbox_dn_5: 0.6061 (0.6061)  loss_bbox_enc_0: 1.0055 (1.0055)  loss_giou: 1.6719 (1.6719)  loss_giou_aux_0: 1.6809 (1.6809)  loss_giou_aux_1: 1.6834 (1.6834)  loss_giou_aux_2: 1.6671 (1.6671)  loss_giou_aux_3: 1.6917 (1.6917)  loss_giou_aux_4: 1.6702 (1.6702)  loss_giou_dn_0: 1.3513 (1.3513)  loss_giou_dn_1: 1.3510 (1.3510)  loss_giou_dn_2: 1.3592 (1.3592)  loss_giou_dn_3: 1.3622 (1.3622)  loss_giou_dn_4: 1.3676 (1.3676)  loss_giou_dn_5: 1.3717 (1.3717)  loss_giou_enc_0: 1.7069 (1.7069)  loss_vfl: 0.5413 (0.5413)  loss_vfl_aux_0: 0.5065 (0.5065)  loss_vfl_aux_1: 0.5277 (0.5277)  loss_vfl_aux_2: 0.5261 (0.5261)  loss_vfl_aux_3: 0.5480 (0.5480)  loss_vfl_aux_4: 0.5485 (0.5485)  loss_vfl_dn_0: 0.4655 (0.4655)  loss_vfl_dn_1: 0.4595 (0.4595)  loss_vfl_dn_2: 0.4584 (0.4584)  loss_vfl_dn_3: 0.4666 (0.4666)  loss_vfl_dn_4: 0.4940 (0.4940)  loss_vfl_dn_5: 0.4874 (0.4874)  loss_vfl_enc_0: 0.4618 (0.4618)  time: 3.4976  data: 2.2776  max mem: 10356\r\n",
      "Epoch: [6]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 33.5034 (33.8392)  loss_bbox: 0.6374 (0.6570)  loss_bbox_aux_0: 0.6806 (0.7025)  loss_bbox_aux_1: 0.6606 (0.6914)  loss_bbox_aux_2: 0.6390 (0.6792)  loss_bbox_aux_3: 0.6542 (0.6755)  loss_bbox_aux_4: 0.6477 (0.6637)  loss_bbox_dn_0: 0.4203 (0.5015)  loss_bbox_dn_1: 0.4157 (0.4977)  loss_bbox_dn_2: 0.4114 (0.4937)  loss_bbox_dn_3: 0.4112 (0.4925)  loss_bbox_dn_4: 0.4097 (0.4902)  loss_bbox_dn_5: 0.4110 (0.4902)  loss_bbox_enc_0: 0.6975 (0.7286)  loss_giou: 1.5718 (1.5021)  loss_giou_aux_0: 1.6016 (1.5241)  loss_giou_aux_1: 1.5803 (1.5203)  loss_giou_aux_2: 1.6061 (1.5186)  loss_giou_aux_3: 1.5736 (1.5168)  loss_giou_aux_4: 1.5726 (1.5033)  loss_giou_dn_0: 1.3679 (1.3726)  loss_giou_dn_1: 1.3624 (1.3682)  loss_giou_dn_2: 1.3620 (1.3661)  loss_giou_dn_3: 1.3601 (1.3643)  loss_giou_dn_4: 1.3583 (1.3624)  loss_giou_dn_5: 1.3579 (1.3638)  loss_giou_enc_0: 1.5819 (1.5347)  loss_vfl: 0.6407 (0.6934)  loss_vfl_aux_0: 0.6191 (0.6413)  loss_vfl_aux_1: 0.6323 (0.6451)  loss_vfl_aux_2: 0.6033 (0.6495)  loss_vfl_aux_3: 0.6372 (0.6571)  loss_vfl_aux_4: 0.6362 (0.6748)  loss_vfl_dn_0: 0.4116 (0.4246)  loss_vfl_dn_1: 0.4221 (0.4282)  loss_vfl_dn_2: 0.4329 (0.4377)  loss_vfl_dn_3: 0.4519 (0.4572)  loss_vfl_dn_4: 0.4644 (0.4670)  loss_vfl_dn_5: 0.4663 (0.4747)  loss_vfl_enc_0: 0.5918 (0.6078)  time: 0.9925  data: 0.0320  max mem: 10356\r\n",
      "Epoch: [6] Total time: 0:01:24 (1.0658 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 33.5034 (33.8392)  loss_bbox: 0.6374 (0.6570)  loss_bbox_aux_0: 0.6806 (0.7025)  loss_bbox_aux_1: 0.6606 (0.6914)  loss_bbox_aux_2: 0.6390 (0.6792)  loss_bbox_aux_3: 0.6542 (0.6755)  loss_bbox_aux_4: 0.6477 (0.6637)  loss_bbox_dn_0: 0.4203 (0.5015)  loss_bbox_dn_1: 0.4157 (0.4977)  loss_bbox_dn_2: 0.4114 (0.4937)  loss_bbox_dn_3: 0.4112 (0.4925)  loss_bbox_dn_4: 0.4097 (0.4902)  loss_bbox_dn_5: 0.4110 (0.4902)  loss_bbox_enc_0: 0.6975 (0.7286)  loss_giou: 1.5718 (1.5021)  loss_giou_aux_0: 1.6016 (1.5241)  loss_giou_aux_1: 1.5803 (1.5203)  loss_giou_aux_2: 1.6061 (1.5186)  loss_giou_aux_3: 1.5736 (1.5168)  loss_giou_aux_4: 1.5726 (1.5033)  loss_giou_dn_0: 1.3679 (1.3726)  loss_giou_dn_1: 1.3624 (1.3682)  loss_giou_dn_2: 1.3620 (1.3661)  loss_giou_dn_3: 1.3601 (1.3643)  loss_giou_dn_4: 1.3583 (1.3624)  loss_giou_dn_5: 1.3579 (1.3638)  loss_giou_enc_0: 1.5819 (1.5347)  loss_vfl: 0.6407 (0.6934)  loss_vfl_aux_0: 0.6191 (0.6413)  loss_vfl_aux_1: 0.6323 (0.6451)  loss_vfl_aux_2: 0.6033 (0.6495)  loss_vfl_aux_3: 0.6372 (0.6571)  loss_vfl_aux_4: 0.6362 (0.6748)  loss_vfl_dn_0: 0.4116 (0.4246)  loss_vfl_dn_1: 0.4221 (0.4282)  loss_vfl_dn_2: 0.4329 (0.4377)  loss_vfl_dn_3: 0.4519 (0.4572)  loss_vfl_dn_4: 0.4644 (0.4670)  loss_vfl_dn_5: 0.4663 (0.4747)  loss_vfl_enc_0: 0.5918 (0.6078)\r\n",
      "Test:  [0/8]  eta: 0:00:16    time: 2.0881  data: 1.1610  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0573  data: 0.2066  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0747 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.17s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.003\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.011\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.014\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.013\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.031\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.011\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.042\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.008\r\n",
      "best_stat: {'epoch': 6, 'coco_eval_bbox': 0.00023579993768124195}\r\n",
      "Epoch: [7]  [ 0/79]  eta: 0:04:57  lr: 0.000020  loss: 31.4242 (31.4242)  loss_bbox: 0.4544 (0.4544)  loss_bbox_aux_0: 0.4857 (0.4857)  loss_bbox_aux_1: 0.4854 (0.4854)  loss_bbox_aux_2: 0.4605 (0.4605)  loss_bbox_aux_3: 0.4784 (0.4784)  loss_bbox_aux_4: 0.4411 (0.4411)  loss_bbox_dn_0: 0.4164 (0.4164)  loss_bbox_dn_1: 0.4096 (0.4096)  loss_bbox_dn_2: 0.4022 (0.4022)  loss_bbox_dn_3: 0.3984 (0.3984)  loss_bbox_dn_4: 0.3922 (0.3922)  loss_bbox_dn_5: 0.3909 (0.3909)  loss_bbox_enc_0: 0.5045 (0.5045)  loss_giou: 1.3111 (1.3111)  loss_giou_aux_0: 1.3616 (1.3616)  loss_giou_aux_1: 1.3539 (1.3539)  loss_giou_aux_2: 1.3542 (1.3542)  loss_giou_aux_3: 1.3264 (1.3264)  loss_giou_aux_4: 1.3335 (1.3335)  loss_giou_dn_0: 1.3693 (1.3693)  loss_giou_dn_1: 1.3536 (1.3536)  loss_giou_dn_2: 1.3377 (1.3377)  loss_giou_dn_3: 1.3264 (1.3264)  loss_giou_dn_4: 1.3086 (1.3086)  loss_giou_dn_5: 1.3051 (1.3051)  loss_giou_enc_0: 1.4351 (1.4351)  loss_vfl: 0.8103 (0.8103)  loss_vfl_aux_0: 0.7887 (0.7887)  loss_vfl_aux_1: 0.7644 (0.7644)  loss_vfl_aux_2: 0.7959 (0.7959)  loss_vfl_aux_3: 0.7898 (0.7898)  loss_vfl_aux_4: 0.8102 (0.8102)  loss_vfl_dn_0: 0.4199 (0.4199)  loss_vfl_dn_1: 0.4301 (0.4301)  loss_vfl_dn_2: 0.4506 (0.4506)  loss_vfl_dn_3: 0.4696 (0.4696)  loss_vfl_dn_4: 0.4846 (0.4846)  loss_vfl_dn_5: 0.4868 (0.4868)  loss_vfl_enc_0: 0.7271 (0.7271)  time: 3.7657  data: 2.5671  max mem: 10356\r\n",
      "Epoch: [7]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 32.4423 (33.6346)  loss_bbox: 0.4851 (0.5927)  loss_bbox_aux_0: 0.5718 (0.6569)  loss_bbox_aux_1: 0.5428 (0.6411)  loss_bbox_aux_2: 0.5176 (0.6257)  loss_bbox_aux_3: 0.5008 (0.6135)  loss_bbox_aux_4: 0.4845 (0.5957)  loss_bbox_dn_0: 0.4675 (0.5168)  loss_bbox_dn_1: 0.4620 (0.5102)  loss_bbox_dn_2: 0.4551 (0.5034)  loss_bbox_dn_3: 0.4538 (0.4999)  loss_bbox_dn_4: 0.4498 (0.4949)  loss_bbox_dn_5: 0.4511 (0.4946)  loss_bbox_enc_0: 0.6213 (0.6855)  loss_giou: 1.3473 (1.4131)  loss_giou_aux_0: 1.4107 (1.4689)  loss_giou_aux_1: 1.4056 (1.4571)  loss_giou_aux_2: 1.3844 (1.4455)  loss_giou_aux_3: 1.3609 (1.4375)  loss_giou_aux_4: 1.3313 (1.4164)  loss_giou_dn_0: 1.3480 (1.3620)  loss_giou_dn_1: 1.3299 (1.3475)  loss_giou_dn_2: 1.3200 (1.3355)  loss_giou_dn_3: 1.3060 (1.3275)  loss_giou_dn_4: 1.2946 (1.3158)  loss_giou_dn_5: 1.2923 (1.3146)  loss_giou_enc_0: 1.4589 (1.4913)  loss_vfl: 0.8308 (0.8196)  loss_vfl_aux_0: 0.7415 (0.7253)  loss_vfl_aux_1: 0.7620 (0.7371)  loss_vfl_aux_2: 0.7581 (0.7535)  loss_vfl_aux_3: 0.7932 (0.7730)  loss_vfl_aux_4: 0.8333 (0.8002)  loss_vfl_dn_0: 0.4247 (0.4249)  loss_vfl_dn_1: 0.4363 (0.4349)  loss_vfl_dn_2: 0.4690 (0.4526)  loss_vfl_dn_3: 0.4900 (0.4755)  loss_vfl_dn_4: 0.5192 (0.4944)  loss_vfl_dn_5: 0.5232 (0.5032)  loss_vfl_enc_0: 0.6855 (0.6769)  time: 1.0579  data: 0.0317  max mem: 10356\r\n",
      "Epoch: [7] Total time: 0:01:26 (1.0957 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 32.4423 (33.6346)  loss_bbox: 0.4851 (0.5927)  loss_bbox_aux_0: 0.5718 (0.6569)  loss_bbox_aux_1: 0.5428 (0.6411)  loss_bbox_aux_2: 0.5176 (0.6257)  loss_bbox_aux_3: 0.5008 (0.6135)  loss_bbox_aux_4: 0.4845 (0.5957)  loss_bbox_dn_0: 0.4675 (0.5168)  loss_bbox_dn_1: 0.4620 (0.5102)  loss_bbox_dn_2: 0.4551 (0.5034)  loss_bbox_dn_3: 0.4538 (0.4999)  loss_bbox_dn_4: 0.4498 (0.4949)  loss_bbox_dn_5: 0.4511 (0.4946)  loss_bbox_enc_0: 0.6213 (0.6855)  loss_giou: 1.3473 (1.4131)  loss_giou_aux_0: 1.4107 (1.4689)  loss_giou_aux_1: 1.4056 (1.4571)  loss_giou_aux_2: 1.3844 (1.4455)  loss_giou_aux_3: 1.3609 (1.4375)  loss_giou_aux_4: 1.3313 (1.4164)  loss_giou_dn_0: 1.3480 (1.3620)  loss_giou_dn_1: 1.3299 (1.3475)  loss_giou_dn_2: 1.3200 (1.3355)  loss_giou_dn_3: 1.3060 (1.3275)  loss_giou_dn_4: 1.2946 (1.3158)  loss_giou_dn_5: 1.2923 (1.3146)  loss_giou_enc_0: 1.4589 (1.4913)  loss_vfl: 0.8308 (0.8196)  loss_vfl_aux_0: 0.7415 (0.7253)  loss_vfl_aux_1: 0.7620 (0.7371)  loss_vfl_aux_2: 0.7581 (0.7535)  loss_vfl_aux_3: 0.7932 (0.7730)  loss_vfl_aux_4: 0.8333 (0.8002)  loss_vfl_dn_0: 0.4247 (0.4249)  loss_vfl_dn_1: 0.4363 (0.4349)  loss_vfl_dn_2: 0.4690 (0.4526)  loss_vfl_dn_3: 0.4900 (0.4755)  loss_vfl_dn_4: 0.5192 (0.4944)  loss_vfl_dn_5: 0.5232 (0.5032)  loss_vfl_enc_0: 0.6855 (0.6769)\r\n",
      "Test:  [0/8]  eta: 0:00:21    time: 2.7241  data: 1.2248  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0596  data: 0.2056  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0766 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.17s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.008\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.025\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.032\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.062\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.045\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.082\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.018\r\n",
      "best_stat: {'epoch': 7, 'coco_eval_bbox': 0.00045391034706491784}\r\n",
      "Epoch: [8]  [ 0/79]  eta: 0:05:37  lr: 0.000020  loss: 34.1787 (34.1787)  loss_bbox: 0.6347 (0.6347)  loss_bbox_aux_0: 0.6679 (0.6679)  loss_bbox_aux_1: 0.6712 (0.6712)  loss_bbox_aux_2: 0.6572 (0.6572)  loss_bbox_aux_3: 0.6481 (0.6481)  loss_bbox_aux_4: 0.6153 (0.6153)  loss_bbox_dn_0: 0.5348 (0.5348)  loss_bbox_dn_1: 0.5261 (0.5261)  loss_bbox_dn_2: 0.5175 (0.5175)  loss_bbox_dn_3: 0.5121 (0.5121)  loss_bbox_dn_4: 0.5038 (0.5038)  loss_bbox_dn_5: 0.5022 (0.5022)  loss_bbox_enc_0: 0.6867 (0.6867)  loss_giou: 1.3946 (1.3946)  loss_giou_aux_0: 1.4743 (1.4743)  loss_giou_aux_1: 1.4427 (1.4427)  loss_giou_aux_2: 1.4278 (1.4278)  loss_giou_aux_3: 1.4269 (1.4269)  loss_giou_aux_4: 1.4099 (1.4099)  loss_giou_dn_0: 1.3945 (1.3945)  loss_giou_dn_1: 1.3723 (1.3723)  loss_giou_dn_2: 1.3552 (1.3552)  loss_giou_dn_3: 1.3434 (1.3434)  loss_giou_dn_4: 1.3385 (1.3385)  loss_giou_dn_5: 1.3371 (1.3371)  loss_giou_enc_0: 1.5417 (1.5417)  loss_vfl: 0.7944 (0.7944)  loss_vfl_aux_0: 0.7463 (0.7463)  loss_vfl_aux_1: 0.7363 (0.7363)  loss_vfl_aux_2: 0.7690 (0.7690)  loss_vfl_aux_3: 0.7983 (0.7983)  loss_vfl_aux_4: 0.8196 (0.8196)  loss_vfl_dn_0: 0.4176 (0.4176)  loss_vfl_dn_1: 0.4492 (0.4492)  loss_vfl_dn_2: 0.4846 (0.4846)  loss_vfl_dn_3: 0.5153 (0.5153)  loss_vfl_dn_4: 0.5209 (0.5209)  loss_vfl_dn_5: 0.5349 (0.5349)  loss_vfl_enc_0: 0.6558 (0.6558)  time: 4.2751  data: 3.1119  max mem: 10356\r\n",
      "Epoch: [8]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 32.5016 (33.2254)  loss_bbox: 0.5052 (0.5520)  loss_bbox_aux_0: 0.5715 (0.6220)  loss_bbox_aux_1: 0.5549 (0.6050)  loss_bbox_aux_2: 0.5230 (0.5805)  loss_bbox_aux_3: 0.5296 (0.5693)  loss_bbox_aux_4: 0.5055 (0.5552)  loss_bbox_dn_0: 0.4802 (0.5131)  loss_bbox_dn_1: 0.4643 (0.5033)  loss_bbox_dn_2: 0.4501 (0.4919)  loss_bbox_dn_3: 0.4470 (0.4892)  loss_bbox_dn_4: 0.4478 (0.4876)  loss_bbox_dn_5: 0.4487 (0.4885)  loss_bbox_enc_0: 0.5909 (0.6495)  loss_giou: 1.2642 (1.3745)  loss_giou_aux_0: 1.4092 (1.4459)  loss_giou_aux_1: 1.3770 (1.4312)  loss_giou_aux_2: 1.3226 (1.4047)  loss_giou_aux_3: 1.2965 (1.3926)  loss_giou_aux_4: 1.2731 (1.3752)  loss_giou_dn_0: 1.3505 (1.3600)  loss_giou_dn_1: 1.3258 (1.3385)  loss_giou_dn_2: 1.3056 (1.3186)  loss_giou_dn_3: 1.2928 (1.3084)  loss_giou_dn_4: 1.2776 (1.3009)  loss_giou_dn_5: 1.2723 (1.3023)  loss_giou_enc_0: 1.4362 (1.4741)  loss_vfl: 0.9460 (0.8460)  loss_vfl_aux_0: 0.7976 (0.7326)  loss_vfl_aux_1: 0.8250 (0.7458)  loss_vfl_aux_2: 0.8838 (0.7846)  loss_vfl_aux_3: 0.9189 (0.8138)  loss_vfl_aux_4: 0.9373 (0.8350)  loss_vfl_dn_0: 0.4244 (0.4225)  loss_vfl_dn_1: 0.4336 (0.4398)  loss_vfl_dn_2: 0.4657 (0.4661)  loss_vfl_dn_3: 0.5022 (0.4919)  loss_vfl_dn_4: 0.5323 (0.5120)  loss_vfl_dn_5: 0.5354 (0.5207)  loss_vfl_enc_0: 0.7078 (0.6805)  time: 1.0033  data: 0.0315  max mem: 10356\r\n",
      "Epoch: [8] Total time: 0:01:24 (1.0722 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 32.5016 (33.2254)  loss_bbox: 0.5052 (0.5520)  loss_bbox_aux_0: 0.5715 (0.6220)  loss_bbox_aux_1: 0.5549 (0.6050)  loss_bbox_aux_2: 0.5230 (0.5805)  loss_bbox_aux_3: 0.5296 (0.5693)  loss_bbox_aux_4: 0.5055 (0.5552)  loss_bbox_dn_0: 0.4802 (0.5131)  loss_bbox_dn_1: 0.4643 (0.5033)  loss_bbox_dn_2: 0.4501 (0.4919)  loss_bbox_dn_3: 0.4470 (0.4892)  loss_bbox_dn_4: 0.4478 (0.4876)  loss_bbox_dn_5: 0.4487 (0.4885)  loss_bbox_enc_0: 0.5909 (0.6495)  loss_giou: 1.2642 (1.3745)  loss_giou_aux_0: 1.4092 (1.4459)  loss_giou_aux_1: 1.3770 (1.4312)  loss_giou_aux_2: 1.3226 (1.4047)  loss_giou_aux_3: 1.2965 (1.3926)  loss_giou_aux_4: 1.2731 (1.3752)  loss_giou_dn_0: 1.3505 (1.3600)  loss_giou_dn_1: 1.3258 (1.3385)  loss_giou_dn_2: 1.3056 (1.3186)  loss_giou_dn_3: 1.2928 (1.3084)  loss_giou_dn_4: 1.2776 (1.3009)  loss_giou_dn_5: 1.2723 (1.3023)  loss_giou_enc_0: 1.4362 (1.4741)  loss_vfl: 0.9460 (0.8460)  loss_vfl_aux_0: 0.7976 (0.7326)  loss_vfl_aux_1: 0.8250 (0.7458)  loss_vfl_aux_2: 0.8838 (0.7846)  loss_vfl_aux_3: 0.9189 (0.8138)  loss_vfl_aux_4: 0.9373 (0.8350)  loss_vfl_dn_0: 0.4244 (0.4225)  loss_vfl_dn_1: 0.4336 (0.4398)  loss_vfl_dn_2: 0.4657 (0.4661)  loss_vfl_dn_3: 0.5022 (0.4919)  loss_vfl_dn_4: 0.5323 (0.5120)  loss_vfl_dn_5: 0.5354 (0.5207)  loss_vfl_enc_0: 0.7078 (0.6805)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.2494  data: 1.2822  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0724  data: 0.2128  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0884 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.16s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.007\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.026\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.031\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.017\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.059\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.048\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.083\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.014\r\n",
      "best_stat: {'epoch': 7, 'coco_eval_bbox': 0.00045391034706491784}\r\n",
      "Epoch: [9]  [ 0/79]  eta: 0:06:06  lr: 0.000020  loss: 35.4693 (35.4693)  loss_bbox: 0.7641 (0.7641)  loss_bbox_aux_0: 0.8150 (0.8150)  loss_bbox_aux_1: 0.8065 (0.8065)  loss_bbox_aux_2: 0.7747 (0.7747)  loss_bbox_aux_3: 0.7271 (0.7271)  loss_bbox_aux_4: 0.7577 (0.7577)  loss_bbox_dn_0: 0.4536 (0.4536)  loss_bbox_dn_1: 0.4404 (0.4404)  loss_bbox_dn_2: 0.4233 (0.4233)  loss_bbox_dn_3: 0.4176 (0.4176)  loss_bbox_dn_4: 0.4157 (0.4157)  loss_bbox_dn_5: 0.4161 (0.4161)  loss_bbox_enc_0: 0.7913 (0.7913)  loss_giou: 1.8048 (1.8048)  loss_giou_aux_0: 1.7758 (1.7758)  loss_giou_aux_1: 1.7912 (1.7912)  loss_giou_aux_2: 1.7920 (1.7920)  loss_giou_aux_3: 1.8658 (1.8658)  loss_giou_aux_4: 1.8268 (1.8268)  loss_giou_dn_0: 1.3785 (1.3785)  loss_giou_dn_1: 1.3720 (1.3720)  loss_giou_dn_2: 1.3408 (1.3408)  loss_giou_dn_3: 1.3403 (1.3403)  loss_giou_dn_4: 1.3459 (1.3459)  loss_giou_dn_5: 1.3512 (1.3512)  loss_giou_enc_0: 1.8666 (1.8666)  loss_vfl: 0.6174 (0.6174)  loss_vfl_aux_0: 0.5435 (0.5435)  loss_vfl_aux_1: 0.5425 (0.5425)  loss_vfl_aux_2: 0.6021 (0.6021)  loss_vfl_aux_3: 0.6074 (0.6074)  loss_vfl_aux_4: 0.5903 (0.5903)  loss_vfl_dn_0: 0.4083 (0.4083)  loss_vfl_dn_1: 0.4192 (0.4192)  loss_vfl_dn_2: 0.4365 (0.4365)  loss_vfl_dn_3: 0.4550 (0.4550)  loss_vfl_dn_4: 0.4591 (0.4591)  loss_vfl_dn_5: 0.4691 (0.4691)  loss_vfl_enc_0: 0.4641 (0.4641)  time: 4.6360  data: 2.9264  max mem: 10356\r\n",
      "Epoch: [9]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 32.6332 (32.8833)  loss_bbox: 0.5036 (0.5251)  loss_bbox_aux_0: 0.5561 (0.5888)  loss_bbox_aux_1: 0.5187 (0.5683)  loss_bbox_aux_2: 0.5019 (0.5429)  loss_bbox_aux_3: 0.5074 (0.5374)  loss_bbox_aux_4: 0.5054 (0.5303)  loss_bbox_dn_0: 0.4945 (0.5047)  loss_bbox_dn_1: 0.4793 (0.4911)  loss_bbox_dn_2: 0.4662 (0.4769)  loss_bbox_dn_3: 0.4617 (0.4745)  loss_bbox_dn_4: 0.4602 (0.4742)  loss_bbox_dn_5: 0.4618 (0.4749)  loss_bbox_enc_0: 0.5823 (0.6118)  loss_giou: 1.3440 (1.3610)  loss_giou_aux_0: 1.3985 (1.4348)  loss_giou_aux_1: 1.3838 (1.4086)  loss_giou_aux_2: 1.3535 (1.3767)  loss_giou_aux_3: 1.3346 (1.3725)  loss_giou_aux_4: 1.3301 (1.3633)  loss_giou_dn_0: 1.3404 (1.3515)  loss_giou_dn_1: 1.3016 (1.3206)  loss_giou_dn_2: 1.2576 (1.2933)  loss_giou_dn_3: 1.2423 (1.2846)  loss_giou_dn_4: 1.2339 (1.2798)  loss_giou_dn_5: 1.2326 (1.2795)  loss_giou_enc_0: 1.4241 (1.4695)  loss_vfl: 0.8708 (0.8725)  loss_vfl_aux_0: 0.7969 (0.7469)  loss_vfl_aux_1: 0.8093 (0.7746)  loss_vfl_aux_2: 0.8594 (0.8184)  loss_vfl_aux_3: 0.8708 (0.8407)  loss_vfl_aux_4: 0.8564 (0.8563)  loss_vfl_dn_0: 0.4181 (0.4224)  loss_vfl_dn_1: 0.4537 (0.4445)  loss_vfl_dn_2: 0.4873 (0.4749)  loss_vfl_dn_3: 0.5166 (0.4994)  loss_vfl_dn_4: 0.5377 (0.5169)  loss_vfl_dn_5: 0.5498 (0.5287)  loss_vfl_enc_0: 0.7375 (0.6906)  time: 1.0403  data: 0.0305  max mem: 10356\r\n",
      "Epoch: [9] Total time: 0:01:25 (1.0853 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 32.6332 (32.8833)  loss_bbox: 0.5036 (0.5251)  loss_bbox_aux_0: 0.5561 (0.5888)  loss_bbox_aux_1: 0.5187 (0.5683)  loss_bbox_aux_2: 0.5019 (0.5429)  loss_bbox_aux_3: 0.5074 (0.5374)  loss_bbox_aux_4: 0.5054 (0.5303)  loss_bbox_dn_0: 0.4945 (0.5047)  loss_bbox_dn_1: 0.4793 (0.4911)  loss_bbox_dn_2: 0.4662 (0.4769)  loss_bbox_dn_3: 0.4617 (0.4745)  loss_bbox_dn_4: 0.4602 (0.4742)  loss_bbox_dn_5: 0.4618 (0.4749)  loss_bbox_enc_0: 0.5823 (0.6118)  loss_giou: 1.3440 (1.3610)  loss_giou_aux_0: 1.3985 (1.4348)  loss_giou_aux_1: 1.3838 (1.4086)  loss_giou_aux_2: 1.3535 (1.3767)  loss_giou_aux_3: 1.3346 (1.3725)  loss_giou_aux_4: 1.3301 (1.3633)  loss_giou_dn_0: 1.3404 (1.3515)  loss_giou_dn_1: 1.3016 (1.3206)  loss_giou_dn_2: 1.2576 (1.2933)  loss_giou_dn_3: 1.2423 (1.2846)  loss_giou_dn_4: 1.2339 (1.2798)  loss_giou_dn_5: 1.2326 (1.2795)  loss_giou_enc_0: 1.4241 (1.4695)  loss_vfl: 0.8708 (0.8725)  loss_vfl_aux_0: 0.7969 (0.7469)  loss_vfl_aux_1: 0.8093 (0.7746)  loss_vfl_aux_2: 0.8594 (0.8184)  loss_vfl_aux_3: 0.8708 (0.8407)  loss_vfl_aux_4: 0.8564 (0.8563)  loss_vfl_dn_0: 0.4181 (0.4224)  loss_vfl_dn_1: 0.4537 (0.4445)  loss_vfl_dn_2: 0.4873 (0.4749)  loss_vfl_dn_3: 0.5166 (0.4994)  loss_vfl_dn_4: 0.5377 (0.5169)  loss_vfl_dn_5: 0.5498 (0.5287)  loss_vfl_enc_0: 0.7375 (0.6906)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3452  data: 1.4194  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0704  data: 0.2211  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0866 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.023\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.049\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.054\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.018\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.102\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.065\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.125\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.032\r\n",
      "best_stat: {'epoch': 9, 'coco_eval_bbox': 0.000874906552686063}\r\n",
      "Epoch: [10]  [ 0/79]  eta: 0:05:16  lr: 0.000020  loss: 29.9342 (29.9342)  loss_bbox: 0.3862 (0.3862)  loss_bbox_aux_0: 0.3929 (0.3929)  loss_bbox_aux_1: 0.3908 (0.3908)  loss_bbox_aux_2: 0.3884 (0.3884)  loss_bbox_aux_3: 0.3826 (0.3826)  loss_bbox_aux_4: 0.3748 (0.3748)  loss_bbox_dn_0: 0.3094 (0.3094)  loss_bbox_dn_1: 0.2983 (0.2983)  loss_bbox_dn_2: 0.2840 (0.2840)  loss_bbox_dn_3: 0.2858 (0.2858)  loss_bbox_dn_4: 0.2866 (0.2866)  loss_bbox_dn_5: 0.2892 (0.2892)  loss_bbox_enc_0: 0.4099 (0.4099)  loss_giou: 1.3194 (1.3194)  loss_giou_aux_0: 1.3987 (1.3987)  loss_giou_aux_1: 1.3574 (1.3574)  loss_giou_aux_2: 1.3271 (1.3271)  loss_giou_aux_3: 1.3306 (1.3306)  loss_giou_aux_4: 1.3146 (1.3146)  loss_giou_dn_0: 1.3481 (1.3481)  loss_giou_dn_1: 1.2986 (1.2986)  loss_giou_dn_2: 1.2563 (1.2563)  loss_giou_dn_3: 1.2355 (1.2355)  loss_giou_dn_4: 1.2229 (1.2229)  loss_giou_dn_5: 1.2160 (1.2160)  loss_giou_enc_0: 1.4620 (1.4620)  loss_vfl: 0.8037 (0.8037)  loss_vfl_aux_0: 0.7197 (0.7197)  loss_vfl_aux_1: 0.7927 (0.7927)  loss_vfl_aux_2: 0.7878 (0.7878)  loss_vfl_aux_3: 0.7932 (0.7932)  loss_vfl_aux_4: 0.8000 (0.8000)  loss_vfl_dn_0: 0.4167 (0.4167)  loss_vfl_dn_1: 0.4578 (0.4578)  loss_vfl_dn_2: 0.4841 (0.4841)  loss_vfl_dn_3: 0.5314 (0.5314)  loss_vfl_dn_4: 0.5580 (0.5580)  loss_vfl_dn_5: 0.5679 (0.5679)  loss_vfl_enc_0: 0.6549 (0.6549)  time: 4.0031  data: 2.7733  max mem: 10356\r\n",
      "Epoch: [10]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 32.6862 (32.8306)  loss_bbox: 0.5368 (0.5097)  loss_bbox_aux_0: 0.5930 (0.5831)  loss_bbox_aux_1: 0.5474 (0.5435)  loss_bbox_aux_2: 0.5386 (0.5240)  loss_bbox_aux_3: 0.5425 (0.5196)  loss_bbox_aux_4: 0.5387 (0.5137)  loss_bbox_dn_0: 0.4779 (0.5077)  loss_bbox_dn_1: 0.4589 (0.4899)  loss_bbox_dn_2: 0.4478 (0.4783)  loss_bbox_dn_3: 0.4517 (0.4771)  loss_bbox_dn_4: 0.4564 (0.4774)  loss_bbox_dn_5: 0.4604 (0.4782)  loss_bbox_enc_0: 0.6382 (0.6132)  loss_giou: 1.2289 (1.3251)  loss_giou_aux_0: 1.3513 (1.4000)  loss_giou_aux_1: 1.2899 (1.3630)  loss_giou_aux_2: 1.2105 (1.3341)  loss_giou_aux_3: 1.2356 (1.3305)  loss_giou_aux_4: 1.2263 (1.3275)  loss_giou_dn_0: 1.3259 (1.3386)  loss_giou_dn_1: 1.2824 (1.2985)  loss_giou_dn_2: 1.2569 (1.2763)  loss_giou_dn_3: 1.2472 (1.2702)  loss_giou_dn_4: 1.2287 (1.2669)  loss_giou_dn_5: 1.2244 (1.2675)  loss_giou_enc_0: 1.3686 (1.4527)  loss_vfl: 0.9741 (0.9162)  loss_vfl_aux_0: 0.7734 (0.7845)  loss_vfl_aux_1: 0.8621 (0.8373)  loss_vfl_aux_2: 0.9199 (0.8763)  loss_vfl_aux_3: 0.9260 (0.8935)  loss_vfl_aux_4: 0.9446 (0.8989)  loss_vfl_dn_0: 0.4340 (0.4282)  loss_vfl_dn_1: 0.4592 (0.4564)  loss_vfl_dn_2: 0.4756 (0.4847)  loss_vfl_dn_3: 0.5073 (0.5084)  loss_vfl_dn_4: 0.5272 (0.5267)  loss_vfl_dn_5: 0.5579 (0.5393)  loss_vfl_enc_0: 0.7144 (0.7141)  time: 0.9552  data: 0.0325  max mem: 10356\r\n",
      "Epoch: [10] Total time: 0:01:25 (1.0764 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 32.6862 (32.8306)  loss_bbox: 0.5368 (0.5097)  loss_bbox_aux_0: 0.5930 (0.5831)  loss_bbox_aux_1: 0.5474 (0.5435)  loss_bbox_aux_2: 0.5386 (0.5240)  loss_bbox_aux_3: 0.5425 (0.5196)  loss_bbox_aux_4: 0.5387 (0.5137)  loss_bbox_dn_0: 0.4779 (0.5077)  loss_bbox_dn_1: 0.4589 (0.4899)  loss_bbox_dn_2: 0.4478 (0.4783)  loss_bbox_dn_3: 0.4517 (0.4771)  loss_bbox_dn_4: 0.4564 (0.4774)  loss_bbox_dn_5: 0.4604 (0.4782)  loss_bbox_enc_0: 0.6382 (0.6132)  loss_giou: 1.2289 (1.3251)  loss_giou_aux_0: 1.3513 (1.4000)  loss_giou_aux_1: 1.2899 (1.3630)  loss_giou_aux_2: 1.2105 (1.3341)  loss_giou_aux_3: 1.2356 (1.3305)  loss_giou_aux_4: 1.2263 (1.3275)  loss_giou_dn_0: 1.3259 (1.3386)  loss_giou_dn_1: 1.2824 (1.2985)  loss_giou_dn_2: 1.2569 (1.2763)  loss_giou_dn_3: 1.2472 (1.2702)  loss_giou_dn_4: 1.2287 (1.2669)  loss_giou_dn_5: 1.2244 (1.2675)  loss_giou_enc_0: 1.3686 (1.4527)  loss_vfl: 0.9741 (0.9162)  loss_vfl_aux_0: 0.7734 (0.7845)  loss_vfl_aux_1: 0.8621 (0.8373)  loss_vfl_aux_2: 0.9199 (0.8763)  loss_vfl_aux_3: 0.9260 (0.8935)  loss_vfl_aux_4: 0.9446 (0.8989)  loss_vfl_dn_0: 0.4340 (0.4282)  loss_vfl_dn_1: 0.4592 (0.4564)  loss_vfl_dn_2: 0.4756 (0.4847)  loss_vfl_dn_3: 0.5073 (0.5084)  loss_vfl_dn_4: 0.5272 (0.5267)  loss_vfl_dn_5: 0.5579 (0.5393)  loss_vfl_enc_0: 0.7144 (0.7141)\r\n",
      "Test:  [0/8]  eta: 0:00:22    time: 2.8385  data: 1.3494  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0664  data: 0.2146  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0828 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.17s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.008\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.026\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.052\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.058\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.020\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.113\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.070\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.129\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.049\r\n",
      "best_stat: {'epoch': 10, 'coco_eval_bbox': 0.003264261326431365}\r\n",
      "Epoch: [11]  [ 0/79]  eta: 0:05:32  lr: 0.000020  loss: 33.3731 (33.3731)  loss_bbox: 0.5953 (0.5953)  loss_bbox_aux_0: 0.7070 (0.7070)  loss_bbox_aux_1: 0.6297 (0.6297)  loss_bbox_aux_2: 0.6344 (0.6344)  loss_bbox_aux_3: 0.6176 (0.6176)  loss_bbox_aux_4: 0.6040 (0.6040)  loss_bbox_dn_0: 0.4976 (0.4976)  loss_bbox_dn_1: 0.4821 (0.4821)  loss_bbox_dn_2: 0.4777 (0.4777)  loss_bbox_dn_3: 0.4763 (0.4763)  loss_bbox_dn_4: 0.4735 (0.4735)  loss_bbox_dn_5: 0.4733 (0.4733)  loss_bbox_enc_0: 0.6985 (0.6985)  loss_giou: 1.5479 (1.5479)  loss_giou_aux_0: 1.6040 (1.6040)  loss_giou_aux_1: 1.6070 (1.6070)  loss_giou_aux_2: 1.5387 (1.5387)  loss_giou_aux_3: 1.5387 (1.5387)  loss_giou_aux_4: 1.5570 (1.5570)  loss_giou_dn_0: 1.3373 (1.3373)  loss_giou_dn_1: 1.3303 (1.3303)  loss_giou_dn_2: 1.3385 (1.3385)  loss_giou_dn_3: 1.3353 (1.3353)  loss_giou_dn_4: 1.3346 (1.3346)  loss_giou_dn_5: 1.3359 (1.3359)  loss_giou_enc_0: 1.6405 (1.6405)  loss_vfl: 0.7168 (0.7168)  loss_vfl_aux_0: 0.5443 (0.5443)  loss_vfl_aux_1: 0.6179 (0.6179)  loss_vfl_aux_2: 0.6650 (0.6650)  loss_vfl_aux_3: 0.7000 (0.7000)  loss_vfl_aux_4: 0.7122 (0.7122)  loss_vfl_dn_0: 0.4065 (0.4065)  loss_vfl_dn_1: 0.4026 (0.4026)  loss_vfl_dn_2: 0.4086 (0.4086)  loss_vfl_dn_3: 0.4086 (0.4086)  loss_vfl_dn_4: 0.4235 (0.4235)  loss_vfl_dn_5: 0.4434 (0.4434)  loss_vfl_enc_0: 0.5114 (0.5114)  time: 4.2145  data: 3.0564  max mem: 10356\r\n",
      "Epoch: [11]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 31.7976 (32.4415)  loss_bbox: 0.4433 (0.4939)  loss_bbox_aux_0: 0.4777 (0.5526)  loss_bbox_aux_1: 0.4616 (0.5150)  loss_bbox_aux_2: 0.4613 (0.5013)  loss_bbox_aux_3: 0.4661 (0.4998)  loss_bbox_aux_4: 0.4705 (0.4956)  loss_bbox_dn_0: 0.4377 (0.4949)  loss_bbox_dn_1: 0.4273 (0.4748)  loss_bbox_dn_2: 0.4306 (0.4661)  loss_bbox_dn_3: 0.4342 (0.4647)  loss_bbox_dn_4: 0.4385 (0.4642)  loss_bbox_dn_5: 0.4409 (0.4645)  loss_bbox_enc_0: 0.5343 (0.5915)  loss_giou: 1.2711 (1.3055)  loss_giou_aux_0: 1.3436 (1.3715)  loss_giou_aux_1: 1.2844 (1.3284)  loss_giou_aux_2: 1.2844 (1.3158)  loss_giou_aux_3: 1.2684 (1.3136)  loss_giou_aux_4: 1.2665 (1.3061)  loss_giou_dn_0: 1.3100 (1.3167)  loss_giou_dn_1: 1.2598 (1.2630)  loss_giou_dn_2: 1.2462 (1.2415)  loss_giou_dn_3: 1.2355 (1.2320)  loss_giou_dn_4: 1.2287 (1.2261)  loss_giou_dn_5: 1.2268 (1.2247)  loss_giou_enc_0: 1.3965 (1.4386)  loss_vfl: 0.8704 (0.9252)  loss_vfl_aux_0: 0.7961 (0.8176)  loss_vfl_aux_1: 0.8220 (0.8722)  loss_vfl_aux_2: 0.8342 (0.8866)  loss_vfl_aux_3: 0.8472 (0.9016)  loss_vfl_aux_4: 0.8425 (0.9131)  loss_vfl_dn_0: 0.4325 (0.4362)  loss_vfl_dn_1: 0.4729 (0.4708)  loss_vfl_dn_2: 0.4990 (0.4971)  loss_vfl_dn_3: 0.5259 (0.5232)  loss_vfl_dn_4: 0.5421 (0.5452)  loss_vfl_dn_5: 0.5615 (0.5598)  loss_vfl_enc_0: 0.7073 (0.7306)  time: 1.0232  data: 0.0334  max mem: 10356\r\n",
      "Epoch: [11] Total time: 0:01:25 (1.0777 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 31.7976 (32.4415)  loss_bbox: 0.4433 (0.4939)  loss_bbox_aux_0: 0.4777 (0.5526)  loss_bbox_aux_1: 0.4616 (0.5150)  loss_bbox_aux_2: 0.4613 (0.5013)  loss_bbox_aux_3: 0.4661 (0.4998)  loss_bbox_aux_4: 0.4705 (0.4956)  loss_bbox_dn_0: 0.4377 (0.4949)  loss_bbox_dn_1: 0.4273 (0.4748)  loss_bbox_dn_2: 0.4306 (0.4661)  loss_bbox_dn_3: 0.4342 (0.4647)  loss_bbox_dn_4: 0.4385 (0.4642)  loss_bbox_dn_5: 0.4409 (0.4645)  loss_bbox_enc_0: 0.5343 (0.5915)  loss_giou: 1.2711 (1.3055)  loss_giou_aux_0: 1.3436 (1.3715)  loss_giou_aux_1: 1.2844 (1.3284)  loss_giou_aux_2: 1.2844 (1.3158)  loss_giou_aux_3: 1.2684 (1.3136)  loss_giou_aux_4: 1.2665 (1.3061)  loss_giou_dn_0: 1.3100 (1.3167)  loss_giou_dn_1: 1.2598 (1.2630)  loss_giou_dn_2: 1.2462 (1.2415)  loss_giou_dn_3: 1.2355 (1.2320)  loss_giou_dn_4: 1.2287 (1.2261)  loss_giou_dn_5: 1.2268 (1.2247)  loss_giou_enc_0: 1.3965 (1.4386)  loss_vfl: 0.8704 (0.9252)  loss_vfl_aux_0: 0.7961 (0.8176)  loss_vfl_aux_1: 0.8220 (0.8722)  loss_vfl_aux_2: 0.8342 (0.8866)  loss_vfl_aux_3: 0.8472 (0.9016)  loss_vfl_aux_4: 0.8425 (0.9131)  loss_vfl_dn_0: 0.4325 (0.4362)  loss_vfl_dn_1: 0.4729 (0.4708)  loss_vfl_dn_2: 0.4990 (0.4971)  loss_vfl_dn_3: 0.5259 (0.5232)  loss_vfl_dn_4: 0.5421 (0.5452)  loss_vfl_dn_5: 0.5615 (0.5598)  loss_vfl_enc_0: 0.7073 (0.7306)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.2244  data: 1.2986  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0651  data: 0.2086  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0823 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.004\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.033\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.060\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.068\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.022\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.127\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.085\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.133\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.063\r\n",
      "best_stat: {'epoch': 10, 'coco_eval_bbox': 0.003264261326431365}\r\n",
      "Epoch: [12]  [ 0/79]  eta: 0:06:34  lr: 0.000020  loss: 34.9628 (34.9628)  loss_bbox: 0.5064 (0.5064)  loss_bbox_aux_0: 0.6096 (0.6096)  loss_bbox_aux_1: 0.5484 (0.5484)  loss_bbox_aux_2: 0.5289 (0.5289)  loss_bbox_aux_3: 0.5440 (0.5440)  loss_bbox_aux_4: 0.5109 (0.5109)  loss_bbox_dn_0: 0.6223 (0.6223)  loss_bbox_dn_1: 0.5977 (0.5977)  loss_bbox_dn_2: 0.5880 (0.5880)  loss_bbox_dn_3: 0.5874 (0.5874)  loss_bbox_dn_4: 0.5868 (0.5868)  loss_bbox_dn_5: 0.5878 (0.5878)  loss_bbox_enc_0: 0.6815 (0.6815)  loss_giou: 1.2126 (1.2126)  loss_giou_aux_0: 1.2833 (1.2833)  loss_giou_aux_1: 1.2962 (1.2962)  loss_giou_aux_2: 1.2650 (1.2650)  loss_giou_aux_3: 1.2221 (1.2221)  loss_giou_aux_4: 1.2039 (1.2039)  loss_giou_dn_0: 1.3067 (1.3067)  loss_giou_dn_1: 1.2370 (1.2370)  loss_giou_dn_2: 1.2029 (1.2029)  loss_giou_dn_3: 1.1840 (1.1840)  loss_giou_dn_4: 1.1698 (1.1698)  loss_giou_dn_5: 1.1660 (1.1660)  loss_giou_enc_0: 1.3270 (1.3270)  loss_vfl: 1.3130 (1.3130)  loss_vfl_aux_0: 1.0039 (1.0039)  loss_vfl_aux_1: 1.0967 (1.0967)  loss_vfl_aux_2: 1.1763 (1.1763)  loss_vfl_aux_3: 1.2896 (1.2896)  loss_vfl_aux_4: 1.3145 (1.3145)  loss_vfl_dn_0: 0.4347 (0.4347)  loss_vfl_dn_1: 0.4795 (0.4795)  loss_vfl_dn_2: 0.5359 (0.5359)  loss_vfl_dn_3: 0.5757 (0.5757)  loss_vfl_dn_4: 0.5916 (0.5916)  loss_vfl_dn_5: 0.6082 (0.6082)  loss_vfl_enc_0: 0.9673 (0.9673)  time: 4.9990  data: 3.4349  max mem: 10356\r\n",
      "Epoch: [12]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 32.1139 (32.3328)  loss_bbox: 0.4608 (0.4727)  loss_bbox_aux_0: 0.5322 (0.5277)  loss_bbox_aux_1: 0.5112 (0.4948)  loss_bbox_aux_2: 0.4864 (0.4868)  loss_bbox_aux_3: 0.4926 (0.4843)  loss_bbox_aux_4: 0.4740 (0.4756)  loss_bbox_dn_0: 0.4385 (0.4792)  loss_bbox_dn_1: 0.4221 (0.4594)  loss_bbox_dn_2: 0.4243 (0.4527)  loss_bbox_dn_3: 0.4253 (0.4519)  loss_bbox_dn_4: 0.4283 (0.4511)  loss_bbox_dn_5: 0.4293 (0.4515)  loss_bbox_enc_0: 0.5847 (0.5789)  loss_giou: 1.2142 (1.2905)  loss_giou_aux_0: 1.2627 (1.3447)  loss_giou_aux_1: 1.2250 (1.3146)  loss_giou_aux_2: 1.2309 (1.2983)  loss_giou_aux_3: 1.2242 (1.2972)  loss_giou_aux_4: 1.2137 (1.2915)  loss_giou_dn_0: 1.2867 (1.3035)  loss_giou_dn_1: 1.2238 (1.2498)  loss_giou_dn_2: 1.2024 (1.2322)  loss_giou_dn_3: 1.1900 (1.2236)  loss_giou_dn_4: 1.1754 (1.2164)  loss_giou_dn_5: 1.1723 (1.2157)  loss_giou_enc_0: 1.3705 (1.4365)  loss_vfl: 1.0310 (0.9631)  loss_vfl_aux_0: 0.9299 (0.8583)  loss_vfl_aux_1: 0.9924 (0.9107)  loss_vfl_aux_2: 0.9648 (0.9280)  loss_vfl_aux_3: 0.9980 (0.9393)  loss_vfl_aux_4: 1.0237 (0.9533)  loss_vfl_dn_0: 0.4357 (0.4383)  loss_vfl_dn_1: 0.4813 (0.4756)  loss_vfl_dn_2: 0.5129 (0.5016)  loss_vfl_dn_3: 0.5476 (0.5278)  loss_vfl_dn_4: 0.5686 (0.5528)  loss_vfl_dn_5: 0.5839 (0.5662)  loss_vfl_enc_0: 0.7947 (0.7366)  time: 1.0345  data: 0.0325  max mem: 10356\r\n",
      "Epoch: [12] Total time: 0:01:26 (1.0914 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 32.1139 (32.3328)  loss_bbox: 0.4608 (0.4727)  loss_bbox_aux_0: 0.5322 (0.5277)  loss_bbox_aux_1: 0.5112 (0.4948)  loss_bbox_aux_2: 0.4864 (0.4868)  loss_bbox_aux_3: 0.4926 (0.4843)  loss_bbox_aux_4: 0.4740 (0.4756)  loss_bbox_dn_0: 0.4385 (0.4792)  loss_bbox_dn_1: 0.4221 (0.4594)  loss_bbox_dn_2: 0.4243 (0.4527)  loss_bbox_dn_3: 0.4253 (0.4519)  loss_bbox_dn_4: 0.4283 (0.4511)  loss_bbox_dn_5: 0.4293 (0.4515)  loss_bbox_enc_0: 0.5847 (0.5789)  loss_giou: 1.2142 (1.2905)  loss_giou_aux_0: 1.2627 (1.3447)  loss_giou_aux_1: 1.2250 (1.3146)  loss_giou_aux_2: 1.2309 (1.2983)  loss_giou_aux_3: 1.2242 (1.2972)  loss_giou_aux_4: 1.2137 (1.2915)  loss_giou_dn_0: 1.2867 (1.3035)  loss_giou_dn_1: 1.2238 (1.2498)  loss_giou_dn_2: 1.2024 (1.2322)  loss_giou_dn_3: 1.1900 (1.2236)  loss_giou_dn_4: 1.1754 (1.2164)  loss_giou_dn_5: 1.1723 (1.2157)  loss_giou_enc_0: 1.3705 (1.4365)  loss_vfl: 1.0310 (0.9631)  loss_vfl_aux_0: 0.9299 (0.8583)  loss_vfl_aux_1: 0.9924 (0.9107)  loss_vfl_aux_2: 0.9648 (0.9280)  loss_vfl_aux_3: 0.9980 (0.9393)  loss_vfl_aux_4: 1.0237 (0.9533)  loss_vfl_dn_0: 0.4357 (0.4383)  loss_vfl_dn_1: 0.4813 (0.4756)  loss_vfl_dn_2: 0.5129 (0.5016)  loss_vfl_dn_3: 0.5476 (0.5278)  loss_vfl_dn_4: 0.5686 (0.5528)  loss_vfl_dn_5: 0.5839 (0.5662)  loss_vfl_enc_0: 0.7947 (0.7366)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.2053  data: 1.2512  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0662  data: 0.2095  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0838 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.007\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.037\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.067\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.073\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.047\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.133\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.094\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.158\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.061\r\n",
      "best_stat: {'epoch': 10, 'coco_eval_bbox': 0.003264261326431365}\r\n",
      "Epoch: [13]  [ 0/79]  eta: 0:06:27  lr: 0.000020  loss: 29.8687 (29.8687)  loss_bbox: 0.3415 (0.3415)  loss_bbox_aux_0: 0.3384 (0.3384)  loss_bbox_aux_1: 0.3494 (0.3494)  loss_bbox_aux_2: 0.3320 (0.3320)  loss_bbox_aux_3: 0.3423 (0.3423)  loss_bbox_aux_4: 0.3424 (0.3424)  loss_bbox_dn_0: 0.3726 (0.3726)  loss_bbox_dn_1: 0.3506 (0.3506)  loss_bbox_dn_2: 0.3458 (0.3458)  loss_bbox_dn_3: 0.3434 (0.3434)  loss_bbox_dn_4: 0.3436 (0.3436)  loss_bbox_dn_5: 0.3441 (0.3441)  loss_bbox_enc_0: 0.4020 (0.4020)  loss_giou: 1.2302 (1.2302)  loss_giou_aux_0: 1.3223 (1.3223)  loss_giou_aux_1: 1.2713 (1.2713)  loss_giou_aux_2: 1.2711 (1.2711)  loss_giou_aux_3: 1.2223 (1.2223)  loss_giou_aux_4: 1.2464 (1.2464)  loss_giou_dn_0: 1.3024 (1.3024)  loss_giou_dn_1: 1.2367 (1.2367)  loss_giou_dn_2: 1.2135 (1.2135)  loss_giou_dn_3: 1.2023 (1.2023)  loss_giou_dn_4: 1.1979 (1.1979)  loss_giou_dn_5: 1.1962 (1.1962)  loss_giou_enc_0: 1.3764 (1.3764)  loss_vfl: 0.9395 (0.9395)  loss_vfl_aux_0: 0.8174 (0.8174)  loss_vfl_aux_1: 0.8608 (0.8608)  loss_vfl_aux_2: 0.8782 (0.8782)  loss_vfl_aux_3: 0.9187 (0.9187)  loss_vfl_aux_4: 0.9028 (0.9028)  loss_vfl_dn_0: 0.4142 (0.4142)  loss_vfl_dn_1: 0.4670 (0.4670)  loss_vfl_dn_2: 0.4924 (0.4924)  loss_vfl_dn_3: 0.5146 (0.5146)  loss_vfl_dn_4: 0.5355 (0.5355)  loss_vfl_dn_5: 0.5363 (0.5363)  loss_vfl_enc_0: 0.7539 (0.7539)  time: 4.9058  data: 3.2100  max mem: 10356\r\n",
      "Epoch: [13]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 32.3635 (32.1612)  loss_bbox: 0.4854 (0.4600)  loss_bbox_aux_0: 0.5116 (0.4973)  loss_bbox_aux_1: 0.4771 (0.4752)  loss_bbox_aux_2: 0.4967 (0.4731)  loss_bbox_aux_3: 0.4861 (0.4669)  loss_bbox_aux_4: 0.4908 (0.4638)  loss_bbox_dn_0: 0.5160 (0.4827)  loss_bbox_dn_1: 0.4977 (0.4642)  loss_bbox_dn_2: 0.4912 (0.4589)  loss_bbox_dn_3: 0.4975 (0.4573)  loss_bbox_dn_4: 0.4969 (0.4560)  loss_bbox_dn_5: 0.4949 (0.4562)  loss_bbox_enc_0: 0.5348 (0.5562)  loss_giou: 1.2693 (1.2700)  loss_giou_aux_0: 1.3012 (1.3084)  loss_giou_aux_1: 1.2711 (1.2905)  loss_giou_aux_2: 1.2599 (1.2804)  loss_giou_aux_3: 1.2780 (1.2756)  loss_giou_aux_4: 1.2806 (1.2721)  loss_giou_dn_0: 1.2692 (1.2877)  loss_giou_dn_1: 1.2213 (1.2357)  loss_giou_dn_2: 1.2000 (1.2188)  loss_giou_dn_3: 1.1804 (1.2092)  loss_giou_dn_4: 1.1729 (1.2003)  loss_giou_dn_5: 1.1738 (1.1997)  loss_giou_enc_0: 1.4244 (1.4140)  loss_vfl: 0.9250 (0.9761)  loss_vfl_aux_0: 0.8909 (0.8995)  loss_vfl_aux_1: 0.8884 (0.9273)  loss_vfl_aux_2: 0.9058 (0.9398)  loss_vfl_aux_3: 0.9216 (0.9560)  loss_vfl_aux_4: 0.9146 (0.9629)  loss_vfl_dn_0: 0.4418 (0.4457)  loss_vfl_dn_1: 0.4778 (0.4811)  loss_vfl_dn_2: 0.4987 (0.5065)  loss_vfl_dn_3: 0.5352 (0.5341)  loss_vfl_dn_4: 0.5630 (0.5610)  loss_vfl_dn_5: 0.5791 (0.5727)  loss_vfl_enc_0: 0.7358 (0.7684)  time: 1.0194  data: 0.0329  max mem: 10356\r\n",
      "Epoch: [13] Total time: 0:01:25 (1.0795 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 32.3635 (32.1612)  loss_bbox: 0.4854 (0.4600)  loss_bbox_aux_0: 0.5116 (0.4973)  loss_bbox_aux_1: 0.4771 (0.4752)  loss_bbox_aux_2: 0.4967 (0.4731)  loss_bbox_aux_3: 0.4861 (0.4669)  loss_bbox_aux_4: 0.4908 (0.4638)  loss_bbox_dn_0: 0.5160 (0.4827)  loss_bbox_dn_1: 0.4977 (0.4642)  loss_bbox_dn_2: 0.4912 (0.4589)  loss_bbox_dn_3: 0.4975 (0.4573)  loss_bbox_dn_4: 0.4969 (0.4560)  loss_bbox_dn_5: 0.4949 (0.4562)  loss_bbox_enc_0: 0.5348 (0.5562)  loss_giou: 1.2693 (1.2700)  loss_giou_aux_0: 1.3012 (1.3084)  loss_giou_aux_1: 1.2711 (1.2905)  loss_giou_aux_2: 1.2599 (1.2804)  loss_giou_aux_3: 1.2780 (1.2756)  loss_giou_aux_4: 1.2806 (1.2721)  loss_giou_dn_0: 1.2692 (1.2877)  loss_giou_dn_1: 1.2213 (1.2357)  loss_giou_dn_2: 1.2000 (1.2188)  loss_giou_dn_3: 1.1804 (1.2092)  loss_giou_dn_4: 1.1729 (1.2003)  loss_giou_dn_5: 1.1738 (1.1997)  loss_giou_enc_0: 1.4244 (1.4140)  loss_vfl: 0.9250 (0.9761)  loss_vfl_aux_0: 0.8909 (0.8995)  loss_vfl_aux_1: 0.8884 (0.9273)  loss_vfl_aux_2: 0.9058 (0.9398)  loss_vfl_aux_3: 0.9216 (0.9560)  loss_vfl_aux_4: 0.9146 (0.9629)  loss_vfl_dn_0: 0.4418 (0.4457)  loss_vfl_dn_1: 0.4778 (0.4811)  loss_vfl_dn_2: 0.4987 (0.5065)  loss_vfl_dn_3: 0.5352 (0.5341)  loss_vfl_dn_4: 0.5630 (0.5610)  loss_vfl_dn_5: 0.5791 (0.5727)  loss_vfl_enc_0: 0.7358 (0.7684)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.3758  data: 1.4074  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0859  data: 0.2241  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1034 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.007\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.049\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.090\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.095\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.039\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.155\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.140\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.187\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\r\n",
      "best_stat: {'epoch': 13, 'coco_eval_bbox': 0.0033254397095939}\r\n",
      "Epoch: [14]  [ 0/79]  eta: 0:05:24  lr: 0.000020  loss: 30.4300 (30.4300)  loss_bbox: 0.4438 (0.4438)  loss_bbox_aux_0: 0.4714 (0.4714)  loss_bbox_aux_1: 0.4541 (0.4541)  loss_bbox_aux_2: 0.4510 (0.4510)  loss_bbox_aux_3: 0.4357 (0.4357)  loss_bbox_aux_4: 0.4310 (0.4310)  loss_bbox_dn_0: 0.3759 (0.3759)  loss_bbox_dn_1: 0.3658 (0.3658)  loss_bbox_dn_2: 0.3620 (0.3620)  loss_bbox_dn_3: 0.3627 (0.3627)  loss_bbox_dn_4: 0.3624 (0.3624)  loss_bbox_dn_5: 0.3630 (0.3630)  loss_bbox_enc_0: 0.5113 (0.5113)  loss_giou: 1.3818 (1.3818)  loss_giou_aux_0: 1.3588 (1.3588)  loss_giou_aux_1: 1.3766 (1.3766)  loss_giou_aux_2: 1.3834 (1.3834)  loss_giou_aux_3: 1.4000 (1.4000)  loss_giou_aux_4: 1.3940 (1.3940)  loss_giou_dn_0: 1.2828 (1.2828)  loss_giou_dn_1: 1.2507 (1.2507)  loss_giou_dn_2: 1.2319 (1.2319)  loss_giou_dn_3: 1.2233 (1.2233)  loss_giou_dn_4: 1.2179 (1.2179)  loss_giou_dn_5: 1.2180 (1.2180)  loss_giou_enc_0: 1.5368 (1.5368)  loss_vfl: 0.7246 (0.7246)  loss_vfl_aux_0: 0.7229 (0.7229)  loss_vfl_aux_1: 0.7312 (0.7312)  loss_vfl_aux_2: 0.7163 (0.7163)  loss_vfl_aux_3: 0.7131 (0.7131)  loss_vfl_aux_4: 0.7466 (0.7466)  loss_vfl_dn_0: 0.4320 (0.4320)  loss_vfl_dn_1: 0.4497 (0.4497)  loss_vfl_dn_2: 0.4603 (0.4603)  loss_vfl_dn_3: 0.4868 (0.4868)  loss_vfl_dn_4: 0.5164 (0.5164)  loss_vfl_dn_5: 0.5278 (0.5278)  loss_vfl_enc_0: 0.5563 (0.5563)  time: 4.1076  data: 2.5110  max mem: 10356\r\n",
      "Epoch: [14]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 31.2803 (31.9540)  loss_bbox: 0.4094 (0.4495)  loss_bbox_aux_0: 0.4185 (0.4828)  loss_bbox_aux_1: 0.4114 (0.4689)  loss_bbox_aux_2: 0.4173 (0.4561)  loss_bbox_aux_3: 0.4117 (0.4568)  loss_bbox_aux_4: 0.4116 (0.4503)  loss_bbox_dn_0: 0.3880 (0.4605)  loss_bbox_dn_1: 0.3732 (0.4417)  loss_bbox_dn_2: 0.3717 (0.4350)  loss_bbox_dn_3: 0.3735 (0.4324)  loss_bbox_dn_4: 0.3739 (0.4303)  loss_bbox_dn_5: 0.3751 (0.4301)  loss_bbox_enc_0: 0.4554 (0.5501)  loss_giou: 1.1443 (1.2611)  loss_giou_aux_0: 1.1929 (1.2937)  loss_giou_aux_1: 1.1615 (1.2742)  loss_giou_aux_2: 1.1233 (1.2677)  loss_giou_aux_3: 1.1132 (1.2655)  loss_giou_aux_4: 1.1240 (1.2612)  loss_giou_dn_0: 1.2522 (1.2730)  loss_giou_dn_1: 1.1962 (1.2212)  loss_giou_dn_2: 1.1584 (1.2009)  loss_giou_dn_3: 1.1495 (1.1896)  loss_giou_dn_4: 1.1359 (1.1809)  loss_giou_dn_5: 1.1388 (1.1805)  loss_giou_enc_0: 1.3022 (1.4098)  loss_vfl: 1.0439 (0.9954)  loss_vfl_aux_0: 1.0400 (0.9366)  loss_vfl_aux_1: 1.0254 (0.9567)  loss_vfl_aux_2: 1.0120 (0.9642)  loss_vfl_aux_3: 1.0293 (0.9767)  loss_vfl_aux_4: 1.0610 (0.9868)  loss_vfl_dn_0: 0.4530 (0.4485)  loss_vfl_dn_1: 0.4861 (0.4836)  loss_vfl_dn_2: 0.5112 (0.5105)  loss_vfl_dn_3: 0.5515 (0.5406)  loss_vfl_dn_4: 0.5813 (0.5695)  loss_vfl_dn_5: 0.5833 (0.5839)  loss_vfl_enc_0: 0.8420 (0.7773)  time: 1.0192  data: 0.0332  max mem: 10356\r\n",
      "Epoch: [14] Total time: 0:01:24 (1.0708 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 31.2803 (31.9540)  loss_bbox: 0.4094 (0.4495)  loss_bbox_aux_0: 0.4185 (0.4828)  loss_bbox_aux_1: 0.4114 (0.4689)  loss_bbox_aux_2: 0.4173 (0.4561)  loss_bbox_aux_3: 0.4117 (0.4568)  loss_bbox_aux_4: 0.4116 (0.4503)  loss_bbox_dn_0: 0.3880 (0.4605)  loss_bbox_dn_1: 0.3732 (0.4417)  loss_bbox_dn_2: 0.3717 (0.4350)  loss_bbox_dn_3: 0.3735 (0.4324)  loss_bbox_dn_4: 0.3739 (0.4303)  loss_bbox_dn_5: 0.3751 (0.4301)  loss_bbox_enc_0: 0.4554 (0.5501)  loss_giou: 1.1443 (1.2611)  loss_giou_aux_0: 1.1929 (1.2937)  loss_giou_aux_1: 1.1615 (1.2742)  loss_giou_aux_2: 1.1233 (1.2677)  loss_giou_aux_3: 1.1132 (1.2655)  loss_giou_aux_4: 1.1240 (1.2612)  loss_giou_dn_0: 1.2522 (1.2730)  loss_giou_dn_1: 1.1962 (1.2212)  loss_giou_dn_2: 1.1584 (1.2009)  loss_giou_dn_3: 1.1495 (1.1896)  loss_giou_dn_4: 1.1359 (1.1809)  loss_giou_dn_5: 1.1388 (1.1805)  loss_giou_enc_0: 1.3022 (1.4098)  loss_vfl: 1.0439 (0.9954)  loss_vfl_aux_0: 1.0400 (0.9366)  loss_vfl_aux_1: 1.0254 (0.9567)  loss_vfl_aux_2: 1.0120 (0.9642)  loss_vfl_aux_3: 1.0293 (0.9767)  loss_vfl_aux_4: 1.0610 (0.9868)  loss_vfl_dn_0: 0.4530 (0.4485)  loss_vfl_dn_1: 0.4861 (0.4836)  loss_vfl_dn_2: 0.5112 (0.5105)  loss_vfl_dn_3: 0.5515 (0.5406)  loss_vfl_dn_4: 0.5813 (0.5695)  loss_vfl_dn_5: 0.5833 (0.5839)  loss_vfl_enc_0: 0.8420 (0.7773)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.2747  data: 1.3238  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0820  data: 0.2215  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1000 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.012\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.005\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.011\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.054\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.099\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.042\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.183\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.143\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.185\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.105\r\n",
      "best_stat: {'epoch': 14, 'coco_eval_bbox': 0.005994741146160184}\r\n",
      "Epoch: [15]  [ 0/79]  eta: 0:05:01  lr: 0.000020  loss: 34.0860 (34.0860)  loss_bbox: 0.8486 (0.8486)  loss_bbox_aux_0: 0.8227 (0.8227)  loss_bbox_aux_1: 0.8319 (0.8319)  loss_bbox_aux_2: 0.8183 (0.8183)  loss_bbox_aux_3: 0.8334 (0.8334)  loss_bbox_aux_4: 0.8327 (0.8327)  loss_bbox_dn_0: 0.2049 (0.2049)  loss_bbox_dn_1: 0.1998 (0.1998)  loss_bbox_dn_2: 0.1994 (0.1994)  loss_bbox_dn_3: 0.2041 (0.2041)  loss_bbox_dn_4: 0.2071 (0.2071)  loss_bbox_dn_5: 0.2083 (0.2083)  loss_bbox_enc_0: 0.8336 (0.8336)  loss_giou: 2.0100 (2.0100)  loss_giou_aux_0: 2.0053 (2.0053)  loss_giou_aux_1: 2.0053 (2.0053)  loss_giou_aux_2: 2.0235 (2.0235)  loss_giou_aux_3: 2.0170 (2.0170)  loss_giou_aux_4: 2.0212 (2.0212)  loss_giou_dn_0: 1.3318 (1.3318)  loss_giou_dn_1: 1.3473 (1.3473)  loss_giou_dn_2: 1.3600 (1.3600)  loss_giou_dn_3: 1.3697 (1.3697)  loss_giou_dn_4: 1.3749 (1.3749)  loss_giou_dn_5: 1.3834 (1.3834)  loss_giou_enc_0: 2.0059 (2.0059)  loss_vfl: 0.3444 (0.3444)  loss_vfl_aux_0: 0.3148 (0.3148)  loss_vfl_aux_1: 0.3159 (0.3159)  loss_vfl_aux_2: 0.3279 (0.3279)  loss_vfl_aux_3: 0.3330 (0.3330)  loss_vfl_aux_4: 0.3416 (0.3416)  loss_vfl_dn_0: 0.4201 (0.4201)  loss_vfl_dn_1: 0.4296 (0.4296)  loss_vfl_dn_2: 0.4067 (0.4067)  loss_vfl_dn_3: 0.4279 (0.4279)  loss_vfl_dn_4: 0.4282 (0.4282)  loss_vfl_dn_5: 0.4395 (0.4395)  loss_vfl_enc_0: 0.2566 (0.2566)  time: 3.8108  data: 2.3053  max mem: 10356\r\n",
      "Epoch: [15]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 31.1184 (32.0600)  loss_bbox: 0.4051 (0.4452)  loss_bbox_aux_0: 0.4491 (0.4848)  loss_bbox_aux_1: 0.4144 (0.4679)  loss_bbox_aux_2: 0.4181 (0.4611)  loss_bbox_aux_3: 0.4138 (0.4544)  loss_bbox_aux_4: 0.4140 (0.4494)  loss_bbox_dn_0: 0.4114 (0.4839)  loss_bbox_dn_1: 0.4103 (0.4654)  loss_bbox_dn_2: 0.4125 (0.4590)  loss_bbox_dn_3: 0.4139 (0.4564)  loss_bbox_dn_4: 0.4158 (0.4545)  loss_bbox_dn_5: 0.4166 (0.4542)  loss_bbox_enc_0: 0.5102 (0.5581)  loss_giou: 1.2958 (1.2255)  loss_giou_aux_0: 1.2861 (1.2683)  loss_giou_aux_1: 1.3049 (1.2499)  loss_giou_aux_2: 1.2900 (1.2355)  loss_giou_aux_3: 1.2960 (1.2349)  loss_giou_aux_4: 1.2830 (1.2263)  loss_giou_dn_0: 1.2463 (1.2520)  loss_giou_dn_1: 1.2020 (1.1987)  loss_giou_dn_2: 1.1903 (1.1770)  loss_giou_dn_3: 1.1754 (1.1651)  loss_giou_dn_4: 1.1680 (1.1545)  loss_giou_dn_5: 1.1690 (1.1534)  loss_giou_enc_0: 1.4585 (1.3909)  loss_vfl: 0.9297 (1.0425)  loss_vfl_aux_0: 0.9070 (0.9635)  loss_vfl_aux_1: 0.8867 (0.9832)  loss_vfl_aux_2: 0.9041 (1.0000)  loss_vfl_aux_3: 0.8984 (1.0140)  loss_vfl_aux_4: 0.9092 (1.0328)  loss_vfl_dn_0: 0.4609 (0.4595)  loss_vfl_dn_1: 0.4795 (0.4945)  loss_vfl_dn_2: 0.5002 (0.5227)  loss_vfl_dn_3: 0.5215 (0.5505)  loss_vfl_dn_4: 0.5381 (0.5804)  loss_vfl_dn_5: 0.5529 (0.5948)  loss_vfl_enc_0: 0.7104 (0.7955)  time: 0.9879  data: 0.0332  max mem: 10356\r\n",
      "Epoch: [15] Total time: 0:01:23 (1.0622 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 31.1184 (32.0600)  loss_bbox: 0.4051 (0.4452)  loss_bbox_aux_0: 0.4491 (0.4848)  loss_bbox_aux_1: 0.4144 (0.4679)  loss_bbox_aux_2: 0.4181 (0.4611)  loss_bbox_aux_3: 0.4138 (0.4544)  loss_bbox_aux_4: 0.4140 (0.4494)  loss_bbox_dn_0: 0.4114 (0.4839)  loss_bbox_dn_1: 0.4103 (0.4654)  loss_bbox_dn_2: 0.4125 (0.4590)  loss_bbox_dn_3: 0.4139 (0.4564)  loss_bbox_dn_4: 0.4158 (0.4545)  loss_bbox_dn_5: 0.4166 (0.4542)  loss_bbox_enc_0: 0.5102 (0.5581)  loss_giou: 1.2958 (1.2255)  loss_giou_aux_0: 1.2861 (1.2683)  loss_giou_aux_1: 1.3049 (1.2499)  loss_giou_aux_2: 1.2900 (1.2355)  loss_giou_aux_3: 1.2960 (1.2349)  loss_giou_aux_4: 1.2830 (1.2263)  loss_giou_dn_0: 1.2463 (1.2520)  loss_giou_dn_1: 1.2020 (1.1987)  loss_giou_dn_2: 1.1903 (1.1770)  loss_giou_dn_3: 1.1754 (1.1651)  loss_giou_dn_4: 1.1680 (1.1545)  loss_giou_dn_5: 1.1690 (1.1534)  loss_giou_enc_0: 1.4585 (1.3909)  loss_vfl: 0.9297 (1.0425)  loss_vfl_aux_0: 0.9070 (0.9635)  loss_vfl_aux_1: 0.8867 (0.9832)  loss_vfl_aux_2: 0.9041 (1.0000)  loss_vfl_aux_3: 0.8984 (1.0140)  loss_vfl_aux_4: 0.9092 (1.0328)  loss_vfl_dn_0: 0.4609 (0.4595)  loss_vfl_dn_1: 0.4795 (0.4945)  loss_vfl_dn_2: 0.5002 (0.5227)  loss_vfl_dn_3: 0.5215 (0.5505)  loss_vfl_dn_4: 0.5381 (0.5804)  loss_vfl_dn_5: 0.5529 (0.5948)  loss_vfl_enc_0: 0.7104 (0.7955)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.3818  data: 1.3781  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0849  data: 0.2196  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1020 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.009\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.010\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.008\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.066\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.118\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.124\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.043\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.224\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.147\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.203\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.134\r\n",
      "best_stat: {'epoch': 14, 'coco_eval_bbox': 0.005994741146160184}\r\n",
      "Epoch: [16]  [ 0/79]  eta: 0:05:50  lr: 0.000020  loss: 31.4505 (31.4505)  loss_bbox: 0.4153 (0.4153)  loss_bbox_aux_0: 0.4434 (0.4434)  loss_bbox_aux_1: 0.4147 (0.4147)  loss_bbox_aux_2: 0.4523 (0.4523)  loss_bbox_aux_3: 0.4257 (0.4257)  loss_bbox_aux_4: 0.4078 (0.4078)  loss_bbox_dn_0: 0.5115 (0.5115)  loss_bbox_dn_1: 0.4707 (0.4707)  loss_bbox_dn_2: 0.4499 (0.4499)  loss_bbox_dn_3: 0.4396 (0.4396)  loss_bbox_dn_4: 0.4272 (0.4272)  loss_bbox_dn_5: 0.4245 (0.4245)  loss_bbox_enc_0: 0.5940 (0.5940)  loss_giou: 0.9747 (0.9747)  loss_giou_aux_0: 0.9852 (0.9852)  loss_giou_aux_1: 0.9852 (0.9852)  loss_giou_aux_2: 0.9940 (0.9940)  loss_giou_aux_3: 0.9694 (0.9694)  loss_giou_aux_4: 1.0294 (1.0294)  loss_giou_dn_0: 1.2016 (1.2016)  loss_giou_dn_1: 1.1153 (1.1153)  loss_giou_dn_2: 1.0733 (1.0733)  loss_giou_dn_3: 1.0504 (1.0504)  loss_giou_dn_4: 1.0336 (1.0336)  loss_giou_dn_5: 1.0296 (1.0296)  loss_giou_enc_0: 1.1713 (1.1713)  loss_vfl: 1.2583 (1.2583)  loss_vfl_aux_0: 1.2974 (1.2974)  loss_vfl_aux_1: 1.2837 (1.2837)  loss_vfl_aux_2: 1.2036 (1.2036)  loss_vfl_aux_3: 1.2563 (1.2563)  loss_vfl_aux_4: 1.2158 (1.2158)  loss_vfl_dn_0: 0.4695 (0.4695)  loss_vfl_dn_1: 0.5135 (0.5135)  loss_vfl_dn_2: 0.5623 (0.5623)  loss_vfl_dn_3: 0.5891 (0.5891)  loss_vfl_dn_4: 0.6218 (0.6218)  loss_vfl_dn_5: 0.6375 (0.6375)  loss_vfl_enc_0: 1.0520 (1.0520)  time: 4.4391  data: 2.6926  max mem: 10356\r\n",
      "Epoch: [16]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 31.3854 (31.8849)  loss_bbox: 0.4270 (0.4288)  loss_bbox_aux_0: 0.4466 (0.4644)  loss_bbox_aux_1: 0.4427 (0.4519)  loss_bbox_aux_2: 0.4407 (0.4471)  loss_bbox_aux_3: 0.4371 (0.4396)  loss_bbox_aux_4: 0.4473 (0.4334)  loss_bbox_dn_0: 0.3967 (0.4690)  loss_bbox_dn_1: 0.3875 (0.4509)  loss_bbox_dn_2: 0.3853 (0.4437)  loss_bbox_dn_3: 0.3847 (0.4399)  loss_bbox_dn_4: 0.3845 (0.4371)  loss_bbox_dn_5: 0.3845 (0.4366)  loss_bbox_enc_0: 0.5032 (0.5391)  loss_giou: 1.2138 (1.2086)  loss_giou_aux_0: 1.2761 (1.2493)  loss_giou_aux_1: 1.2411 (1.2301)  loss_giou_aux_2: 1.2047 (1.2173)  loss_giou_aux_3: 1.2161 (1.2134)  loss_giou_aux_4: 1.2185 (1.2121)  loss_giou_dn_0: 1.2532 (1.2483)  loss_giou_dn_1: 1.1930 (1.1970)  loss_giou_dn_2: 1.1784 (1.1741)  loss_giou_dn_3: 1.1616 (1.1624)  loss_giou_dn_4: 1.1478 (1.1533)  loss_giou_dn_5: 1.1455 (1.1528)  loss_giou_enc_0: 1.3602 (1.3767)  loss_vfl: 1.0188 (1.0602)  loss_vfl_aux_0: 0.8975 (0.9927)  loss_vfl_aux_1: 1.0100 (1.0123)  loss_vfl_aux_2: 1.0364 (1.0255)  loss_vfl_aux_3: 1.0198 (1.0421)  loss_vfl_aux_4: 0.9995 (1.0472)  loss_vfl_dn_0: 0.4574 (0.4594)  loss_vfl_dn_1: 0.4935 (0.4942)  loss_vfl_dn_2: 0.5186 (0.5244)  loss_vfl_dn_3: 0.5480 (0.5552)  loss_vfl_dn_4: 0.5736 (0.5823)  loss_vfl_dn_5: 0.5864 (0.5991)  loss_vfl_enc_0: 0.7869 (0.8134)  time: 1.0228  data: 0.0309  max mem: 10356\r\n",
      "Epoch: [16] Total time: 0:01:27 (1.1086 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 31.3854 (31.8849)  loss_bbox: 0.4270 (0.4288)  loss_bbox_aux_0: 0.4466 (0.4644)  loss_bbox_aux_1: 0.4427 (0.4519)  loss_bbox_aux_2: 0.4407 (0.4471)  loss_bbox_aux_3: 0.4371 (0.4396)  loss_bbox_aux_4: 0.4473 (0.4334)  loss_bbox_dn_0: 0.3967 (0.4690)  loss_bbox_dn_1: 0.3875 (0.4509)  loss_bbox_dn_2: 0.3853 (0.4437)  loss_bbox_dn_3: 0.3847 (0.4399)  loss_bbox_dn_4: 0.3845 (0.4371)  loss_bbox_dn_5: 0.3845 (0.4366)  loss_bbox_enc_0: 0.5032 (0.5391)  loss_giou: 1.2138 (1.2086)  loss_giou_aux_0: 1.2761 (1.2493)  loss_giou_aux_1: 1.2411 (1.2301)  loss_giou_aux_2: 1.2047 (1.2173)  loss_giou_aux_3: 1.2161 (1.2134)  loss_giou_aux_4: 1.2185 (1.2121)  loss_giou_dn_0: 1.2532 (1.2483)  loss_giou_dn_1: 1.1930 (1.1970)  loss_giou_dn_2: 1.1784 (1.1741)  loss_giou_dn_3: 1.1616 (1.1624)  loss_giou_dn_4: 1.1478 (1.1533)  loss_giou_dn_5: 1.1455 (1.1528)  loss_giou_enc_0: 1.3602 (1.3767)  loss_vfl: 1.0188 (1.0602)  loss_vfl_aux_0: 0.8975 (0.9927)  loss_vfl_aux_1: 1.0100 (1.0123)  loss_vfl_aux_2: 1.0364 (1.0255)  loss_vfl_aux_3: 1.0198 (1.0421)  loss_vfl_aux_4: 0.9995 (1.0472)  loss_vfl_dn_0: 0.4574 (0.4594)  loss_vfl_dn_1: 0.4935 (0.4942)  loss_vfl_dn_2: 0.5186 (0.5244)  loss_vfl_dn_3: 0.5480 (0.5552)  loss_vfl_dn_4: 0.5736 (0.5823)  loss_vfl_dn_5: 0.5864 (0.5991)  loss_vfl_enc_0: 0.7869 (0.8134)\r\n",
      "Test:  [0/8]  eta: 0:00:16    time: 2.1050  data: 1.1467  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0759  data: 0.2105  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0948 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.005\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.010\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.006\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.061\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.097\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.106\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.023\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.163\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.158\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.188\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.104\r\n",
      "best_stat: {'epoch': 14, 'coco_eval_bbox': 0.005994741146160184}\r\n",
      "Epoch: [17]  [ 0/79]  eta: 0:07:00  lr: 0.000020  loss: 30.6179 (30.6179)  loss_bbox: 0.3628 (0.3628)  loss_bbox_aux_0: 0.4511 (0.4511)  loss_bbox_aux_1: 0.4248 (0.4248)  loss_bbox_aux_2: 0.4080 (0.4080)  loss_bbox_aux_3: 0.4299 (0.4299)  loss_bbox_aux_4: 0.3778 (0.3778)  loss_bbox_dn_0: 0.4213 (0.4213)  loss_bbox_dn_1: 0.4113 (0.4113)  loss_bbox_dn_2: 0.4069 (0.4069)  loss_bbox_dn_3: 0.4031 (0.4031)  loss_bbox_dn_4: 0.4021 (0.4021)  loss_bbox_dn_5: 0.4018 (0.4018)  loss_bbox_enc_0: 0.5181 (0.5181)  loss_giou: 1.2767 (1.2767)  loss_giou_aux_0: 1.3333 (1.3333)  loss_giou_aux_1: 1.3000 (1.3000)  loss_giou_aux_2: 1.2874 (1.2874)  loss_giou_aux_3: 1.2913 (1.2913)  loss_giou_aux_4: 1.2695 (1.2695)  loss_giou_dn_0: 1.2691 (1.2691)  loss_giou_dn_1: 1.2254 (1.2254)  loss_giou_dn_2: 1.2084 (1.2084)  loss_giou_dn_3: 1.1999 (1.1999)  loss_giou_dn_4: 1.1921 (1.1921)  loss_giou_dn_5: 1.1909 (1.1909)  loss_giou_enc_0: 1.4276 (1.4276)  loss_vfl: 0.9019 (0.9019)  loss_vfl_aux_0: 0.8318 (0.8318)  loss_vfl_aux_1: 0.8259 (0.8259)  loss_vfl_aux_2: 0.8450 (0.8450)  loss_vfl_aux_3: 0.8516 (0.8516)  loss_vfl_aux_4: 0.8979 (0.8979)  loss_vfl_dn_0: 0.4313 (0.4313)  loss_vfl_dn_1: 0.4586 (0.4586)  loss_vfl_dn_2: 0.4792 (0.4792)  loss_vfl_dn_3: 0.4996 (0.4996)  loss_vfl_dn_4: 0.5295 (0.5295)  loss_vfl_dn_5: 0.5442 (0.5442)  loss_vfl_enc_0: 0.6309 (0.6309)  time: 5.3254  data: 3.8791  max mem: 10356\r\n",
      "Epoch: [17]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 32.1916 (31.5778)  loss_bbox: 0.4395 (0.4204)  loss_bbox_aux_0: 0.4476 (0.4487)  loss_bbox_aux_1: 0.4568 (0.4401)  loss_bbox_aux_2: 0.4314 (0.4301)  loss_bbox_aux_3: 0.4336 (0.4264)  loss_bbox_aux_4: 0.4397 (0.4189)  loss_bbox_dn_0: 0.4167 (0.4564)  loss_bbox_dn_1: 0.3954 (0.4382)  loss_bbox_dn_2: 0.3806 (0.4299)  loss_bbox_dn_3: 0.3746 (0.4261)  loss_bbox_dn_4: 0.3712 (0.4233)  loss_bbox_dn_5: 0.3700 (0.4227)  loss_bbox_enc_0: 0.5111 (0.5169)  loss_giou: 1.2288 (1.2009)  loss_giou_aux_0: 1.2708 (1.2452)  loss_giou_aux_1: 1.2593 (1.2285)  loss_giou_aux_2: 1.2365 (1.2166)  loss_giou_aux_3: 1.2293 (1.2125)  loss_giou_aux_4: 1.2358 (1.2059)  loss_giou_dn_0: 1.2236 (1.2337)  loss_giou_dn_1: 1.1631 (1.1820)  loss_giou_dn_2: 1.1403 (1.1574)  loss_giou_dn_3: 1.1322 (1.1457)  loss_giou_dn_4: 1.1164 (1.1368)  loss_giou_dn_5: 1.1172 (1.1357)  loss_giou_enc_0: 1.3633 (1.3592)  loss_vfl: 0.9021 (1.0579)  loss_vfl_aux_0: 0.8567 (0.9915)  loss_vfl_aux_1: 0.9102 (1.0049)  loss_vfl_aux_2: 0.8909 (1.0172)  loss_vfl_aux_3: 0.8828 (1.0361)  loss_vfl_aux_4: 0.8699 (1.0461)  loss_vfl_dn_0: 0.4550 (0.4648)  loss_vfl_dn_1: 0.4705 (0.4960)  loss_vfl_dn_2: 0.4985 (0.5254)  loss_vfl_dn_3: 0.5309 (0.5567)  loss_vfl_dn_4: 0.5576 (0.5851)  loss_vfl_dn_5: 0.5786 (0.6028)  loss_vfl_enc_0: 0.8000 (0.8352)  time: 1.0364  data: 0.0322  max mem: 10356\r\n",
      "Epoch: [17] Total time: 0:01:27 (1.1083 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 32.1916 (31.5778)  loss_bbox: 0.4395 (0.4204)  loss_bbox_aux_0: 0.4476 (0.4487)  loss_bbox_aux_1: 0.4568 (0.4401)  loss_bbox_aux_2: 0.4314 (0.4301)  loss_bbox_aux_3: 0.4336 (0.4264)  loss_bbox_aux_4: 0.4397 (0.4189)  loss_bbox_dn_0: 0.4167 (0.4564)  loss_bbox_dn_1: 0.3954 (0.4382)  loss_bbox_dn_2: 0.3806 (0.4299)  loss_bbox_dn_3: 0.3746 (0.4261)  loss_bbox_dn_4: 0.3712 (0.4233)  loss_bbox_dn_5: 0.3700 (0.4227)  loss_bbox_enc_0: 0.5111 (0.5169)  loss_giou: 1.2288 (1.2009)  loss_giou_aux_0: 1.2708 (1.2452)  loss_giou_aux_1: 1.2593 (1.2285)  loss_giou_aux_2: 1.2365 (1.2166)  loss_giou_aux_3: 1.2293 (1.2125)  loss_giou_aux_4: 1.2358 (1.2059)  loss_giou_dn_0: 1.2236 (1.2337)  loss_giou_dn_1: 1.1631 (1.1820)  loss_giou_dn_2: 1.1403 (1.1574)  loss_giou_dn_3: 1.1322 (1.1457)  loss_giou_dn_4: 1.1164 (1.1368)  loss_giou_dn_5: 1.1172 (1.1357)  loss_giou_enc_0: 1.3633 (1.3592)  loss_vfl: 0.9021 (1.0579)  loss_vfl_aux_0: 0.8567 (0.9915)  loss_vfl_aux_1: 0.9102 (1.0049)  loss_vfl_aux_2: 0.8909 (1.0172)  loss_vfl_aux_3: 0.8828 (1.0361)  loss_vfl_aux_4: 0.8699 (1.0461)  loss_vfl_dn_0: 0.4550 (0.4648)  loss_vfl_dn_1: 0.4705 (0.4960)  loss_vfl_dn_2: 0.4985 (0.5254)  loss_vfl_dn_3: 0.5309 (0.5567)  loss_vfl_dn_4: 0.5576 (0.5851)  loss_vfl_dn_5: 0.5786 (0.6028)  loss_vfl_enc_0: 0.8000 (0.8352)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.1718  data: 1.2369  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0814  data: 0.2195  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0995 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.017\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.010\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.015\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.016\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.082\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.128\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.135\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.038\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.212\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.214\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.145\r\n",
      "best_stat: {'epoch': 17, 'coco_eval_bbox': 0.009552359181484608}\r\n",
      "Epoch: [18]  [ 0/79]  eta: 0:04:56  lr: 0.000020  loss: 34.6755 (34.6755)  loss_bbox: 0.4464 (0.4464)  loss_bbox_aux_0: 0.5477 (0.5477)  loss_bbox_aux_1: 0.4980 (0.4980)  loss_bbox_aux_2: 0.5117 (0.5117)  loss_bbox_aux_3: 0.4911 (0.4911)  loss_bbox_aux_4: 0.4731 (0.4731)  loss_bbox_dn_0: 0.7558 (0.7558)  loss_bbox_dn_1: 0.6951 (0.6951)  loss_bbox_dn_2: 0.6674 (0.6674)  loss_bbox_dn_3: 0.6485 (0.6485)  loss_bbox_dn_4: 0.6369 (0.6369)  loss_bbox_dn_5: 0.6333 (0.6333)  loss_bbox_enc_0: 0.7127 (0.7127)  loss_giou: 0.9134 (0.9134)  loss_giou_aux_0: 0.9684 (0.9684)  loss_giou_aux_1: 0.9437 (0.9437)  loss_giou_aux_2: 0.9087 (0.9087)  loss_giou_aux_3: 0.8652 (0.8652)  loss_giou_aux_4: 0.8828 (0.8828)  loss_giou_dn_0: 1.2310 (1.2310)  loss_giou_dn_1: 1.1519 (1.1519)  loss_giou_dn_2: 1.1075 (1.1075)  loss_giou_dn_3: 1.0714 (1.0714)  loss_giou_dn_4: 1.0538 (1.0538)  loss_giou_dn_5: 1.0460 (1.0460)  loss_giou_enc_0: 1.1993 (1.1993)  loss_vfl: 1.6157 (1.6157)  loss_vfl_aux_0: 1.4624 (1.4624)  loss_vfl_aux_1: 1.4448 (1.4448)  loss_vfl_aux_2: 1.4917 (1.4917)  loss_vfl_aux_3: 1.5552 (1.5552)  loss_vfl_aux_4: 1.5806 (1.5806)  loss_vfl_dn_0: 0.4376 (0.4376)  loss_vfl_dn_1: 0.4862 (0.4862)  loss_vfl_dn_2: 0.5276 (0.5276)  loss_vfl_dn_3: 0.5872 (0.5872)  loss_vfl_dn_4: 0.6418 (0.6418)  loss_vfl_dn_5: 0.6538 (0.6538)  loss_vfl_enc_0: 1.1299 (1.1299)  time: 3.7470  data: 2.5336  max mem: 10356\r\n",
      "Epoch: [18]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 31.4082 (31.5819)  loss_bbox: 0.3952 (0.4186)  loss_bbox_aux_0: 0.4178 (0.4502)  loss_bbox_aux_1: 0.4045 (0.4365)  loss_bbox_aux_2: 0.3964 (0.4275)  loss_bbox_aux_3: 0.4022 (0.4246)  loss_bbox_aux_4: 0.3892 (0.4202)  loss_bbox_dn_0: 0.4899 (0.4687)  loss_bbox_dn_1: 0.4508 (0.4504)  loss_bbox_dn_2: 0.4353 (0.4412)  loss_bbox_dn_3: 0.4368 (0.4367)  loss_bbox_dn_4: 0.4378 (0.4333)  loss_bbox_dn_5: 0.4383 (0.4327)  loss_bbox_enc_0: 0.4788 (0.5144)  loss_giou: 1.0335 (1.2000)  loss_giou_aux_0: 1.0918 (1.2336)  loss_giou_aux_1: 1.0748 (1.2168)  loss_giou_aux_2: 1.0599 (1.2096)  loss_giou_aux_3: 1.0733 (1.2035)  loss_giou_aux_4: 1.0434 (1.2008)  loss_giou_dn_0: 1.2075 (1.2378)  loss_giou_dn_1: 1.1629 (1.1862)  loss_giou_dn_2: 1.1350 (1.1613)  loss_giou_dn_3: 1.1190 (1.1488)  loss_giou_dn_4: 1.1045 (1.1395)  loss_giou_dn_5: 1.1060 (1.1389)  loss_giou_enc_0: 1.2050 (1.3509)  loss_vfl: 1.1055 (1.0482)  loss_vfl_aux_0: 1.1431 (0.9951)  loss_vfl_aux_1: 1.1125 (1.0097)  loss_vfl_aux_2: 1.1199 (1.0248)  loss_vfl_aux_3: 1.1396 (1.0400)  loss_vfl_aux_4: 1.1323 (1.0425)  loss_vfl_dn_0: 0.4757 (0.4608)  loss_vfl_dn_1: 0.5248 (0.4923)  loss_vfl_dn_2: 0.5520 (0.5216)  loss_vfl_dn_3: 0.5945 (0.5507)  loss_vfl_dn_4: 0.6130 (0.5782)  loss_vfl_dn_5: 0.6353 (0.5948)  loss_vfl_enc_0: 0.9600 (0.8403)  time: 1.0075  data: 0.0315  max mem: 10356\r\n",
      "Epoch: [18] Total time: 0:01:25 (1.0837 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 31.4082 (31.5819)  loss_bbox: 0.3952 (0.4186)  loss_bbox_aux_0: 0.4178 (0.4502)  loss_bbox_aux_1: 0.4045 (0.4365)  loss_bbox_aux_2: 0.3964 (0.4275)  loss_bbox_aux_3: 0.4022 (0.4246)  loss_bbox_aux_4: 0.3892 (0.4202)  loss_bbox_dn_0: 0.4899 (0.4687)  loss_bbox_dn_1: 0.4508 (0.4504)  loss_bbox_dn_2: 0.4353 (0.4412)  loss_bbox_dn_3: 0.4368 (0.4367)  loss_bbox_dn_4: 0.4378 (0.4333)  loss_bbox_dn_5: 0.4383 (0.4327)  loss_bbox_enc_0: 0.4788 (0.5144)  loss_giou: 1.0335 (1.2000)  loss_giou_aux_0: 1.0918 (1.2336)  loss_giou_aux_1: 1.0748 (1.2168)  loss_giou_aux_2: 1.0599 (1.2096)  loss_giou_aux_3: 1.0733 (1.2035)  loss_giou_aux_4: 1.0434 (1.2008)  loss_giou_dn_0: 1.2075 (1.2378)  loss_giou_dn_1: 1.1629 (1.1862)  loss_giou_dn_2: 1.1350 (1.1613)  loss_giou_dn_3: 1.1190 (1.1488)  loss_giou_dn_4: 1.1045 (1.1395)  loss_giou_dn_5: 1.1060 (1.1389)  loss_giou_enc_0: 1.2050 (1.3509)  loss_vfl: 1.1055 (1.0482)  loss_vfl_aux_0: 1.1431 (0.9951)  loss_vfl_aux_1: 1.1125 (1.0097)  loss_vfl_aux_2: 1.1199 (1.0248)  loss_vfl_aux_3: 1.1396 (1.0400)  loss_vfl_aux_4: 1.1323 (1.0425)  loss_vfl_dn_0: 0.4757 (0.4608)  loss_vfl_dn_1: 0.5248 (0.4923)  loss_vfl_dn_2: 0.5520 (0.5216)  loss_vfl_dn_3: 0.5945 (0.5507)  loss_vfl_dn_4: 0.6130 (0.5782)  loss_vfl_dn_5: 0.6353 (0.5948)  loss_vfl_enc_0: 0.9600 (0.8403)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.2906  data: 1.3421  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0762  data: 0.2170  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0925 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.013\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.010\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.019\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.097\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.142\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.150\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.035\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.237\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.233\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.247\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.146\r\n",
      "best_stat: {'epoch': 17, 'coco_eval_bbox': 0.009552359181484608}\r\n",
      "Epoch: [19]  [ 0/79]  eta: 0:06:59  lr: 0.000020  loss: 28.9403 (28.9403)  loss_bbox: 0.3568 (0.3568)  loss_bbox_aux_0: 0.3660 (0.3660)  loss_bbox_aux_1: 0.3563 (0.3563)  loss_bbox_aux_2: 0.3536 (0.3536)  loss_bbox_aux_3: 0.3574 (0.3574)  loss_bbox_aux_4: 0.3619 (0.3619)  loss_bbox_dn_0: 0.2128 (0.2128)  loss_bbox_dn_1: 0.2151 (0.2151)  loss_bbox_dn_2: 0.2149 (0.2149)  loss_bbox_dn_3: 0.2179 (0.2179)  loss_bbox_dn_4: 0.2180 (0.2180)  loss_bbox_dn_5: 0.2182 (0.2182)  loss_bbox_enc_0: 0.3745 (0.3745)  loss_giou: 1.4287 (1.4287)  loss_giou_aux_0: 1.3972 (1.3972)  loss_giou_aux_1: 1.4099 (1.4099)  loss_giou_aux_2: 1.4149 (1.4149)  loss_giou_aux_3: 1.4265 (1.4265)  loss_giou_aux_4: 1.4248 (1.4248)  loss_giou_dn_0: 1.2754 (1.2754)  loss_giou_dn_1: 1.2355 (1.2355)  loss_giou_dn_2: 1.2235 (1.2235)  loss_giou_dn_3: 1.2219 (1.2219)  loss_giou_dn_4: 1.2242 (1.2242)  loss_giou_dn_5: 1.2279 (1.2279)  loss_giou_enc_0: 1.5160 (1.5160)  loss_vfl: 0.7349 (0.7349)  loss_vfl_aux_0: 0.6892 (0.6892)  loss_vfl_aux_1: 0.6863 (0.6863)  loss_vfl_aux_2: 0.6663 (0.6663)  loss_vfl_aux_3: 0.6943 (0.6943)  loss_vfl_aux_4: 0.7185 (0.7185)  loss_vfl_dn_0: 0.4408 (0.4408)  loss_vfl_dn_1: 0.4628 (0.4628)  loss_vfl_dn_2: 0.4802 (0.4802)  loss_vfl_dn_3: 0.5023 (0.5023)  loss_vfl_dn_4: 0.5284 (0.5284)  loss_vfl_dn_5: 0.5371 (0.5371)  loss_vfl_enc_0: 0.5494 (0.5494)  time: 5.3138  data: 3.2668  max mem: 10356\r\n",
      "Epoch: [19]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 31.4338 (31.5852)  loss_bbox: 0.3754 (0.4138)  loss_bbox_aux_0: 0.4136 (0.4423)  loss_bbox_aux_1: 0.3829 (0.4323)  loss_bbox_aux_2: 0.3837 (0.4251)  loss_bbox_aux_3: 0.3838 (0.4217)  loss_bbox_aux_4: 0.3852 (0.4163)  loss_bbox_dn_0: 0.4815 (0.4669)  loss_bbox_dn_1: 0.4531 (0.4471)  loss_bbox_dn_2: 0.4364 (0.4370)  loss_bbox_dn_3: 0.4290 (0.4316)  loss_bbox_dn_4: 0.4248 (0.4283)  loss_bbox_dn_5: 0.4236 (0.4274)  loss_bbox_enc_0: 0.4932 (0.5009)  loss_giou: 0.9877 (1.1847)  loss_giou_aux_0: 1.0182 (1.2237)  loss_giou_aux_1: 1.0084 (1.2085)  loss_giou_aux_2: 1.0019 (1.1958)  loss_giou_aux_3: 0.9999 (1.1938)  loss_giou_aux_4: 0.9917 (1.1886)  loss_giou_dn_0: 1.2075 (1.2257)  loss_giou_dn_1: 1.1417 (1.1707)  loss_giou_dn_2: 1.1024 (1.1442)  loss_giou_dn_3: 1.0861 (1.1309)  loss_giou_dn_4: 1.0763 (1.1211)  loss_giou_dn_5: 1.0739 (1.1205)  loss_giou_enc_0: 1.1866 (1.3372)  loss_vfl: 1.2065 (1.0756)  loss_vfl_aux_0: 1.1602 (1.0220)  loss_vfl_aux_1: 1.1616 (1.0326)  loss_vfl_aux_2: 1.1777 (1.0452)  loss_vfl_aux_3: 1.2241 (1.0588)  loss_vfl_aux_4: 1.1787 (1.0643)  loss_vfl_dn_0: 0.4852 (0.4690)  loss_vfl_dn_1: 0.5287 (0.5024)  loss_vfl_dn_2: 0.5585 (0.5343)  loss_vfl_dn_3: 0.5997 (0.5648)  loss_vfl_dn_4: 0.6194 (0.5928)  loss_vfl_dn_5: 0.6299 (0.6109)  loss_vfl_enc_0: 0.9348 (0.8764)  time: 1.0095  data: 0.0317  max mem: 10356\r\n",
      "Epoch: [19] Total time: 0:01:24 (1.0714 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 31.4338 (31.5852)  loss_bbox: 0.3754 (0.4138)  loss_bbox_aux_0: 0.4136 (0.4423)  loss_bbox_aux_1: 0.3829 (0.4323)  loss_bbox_aux_2: 0.3837 (0.4251)  loss_bbox_aux_3: 0.3838 (0.4217)  loss_bbox_aux_4: 0.3852 (0.4163)  loss_bbox_dn_0: 0.4815 (0.4669)  loss_bbox_dn_1: 0.4531 (0.4471)  loss_bbox_dn_2: 0.4364 (0.4370)  loss_bbox_dn_3: 0.4290 (0.4316)  loss_bbox_dn_4: 0.4248 (0.4283)  loss_bbox_dn_5: 0.4236 (0.4274)  loss_bbox_enc_0: 0.4932 (0.5009)  loss_giou: 0.9877 (1.1847)  loss_giou_aux_0: 1.0182 (1.2237)  loss_giou_aux_1: 1.0084 (1.2085)  loss_giou_aux_2: 1.0019 (1.1958)  loss_giou_aux_3: 0.9999 (1.1938)  loss_giou_aux_4: 0.9917 (1.1886)  loss_giou_dn_0: 1.2075 (1.2257)  loss_giou_dn_1: 1.1417 (1.1707)  loss_giou_dn_2: 1.1024 (1.1442)  loss_giou_dn_3: 1.0861 (1.1309)  loss_giou_dn_4: 1.0763 (1.1211)  loss_giou_dn_5: 1.0739 (1.1205)  loss_giou_enc_0: 1.1866 (1.3372)  loss_vfl: 1.2065 (1.0756)  loss_vfl_aux_0: 1.1602 (1.0220)  loss_vfl_aux_1: 1.1616 (1.0326)  loss_vfl_aux_2: 1.1777 (1.0452)  loss_vfl_aux_3: 1.2241 (1.0588)  loss_vfl_aux_4: 1.1787 (1.0643)  loss_vfl_dn_0: 0.4852 (0.4690)  loss_vfl_dn_1: 0.5287 (0.5024)  loss_vfl_dn_2: 0.5585 (0.5343)  loss_vfl_dn_3: 0.5997 (0.5648)  loss_vfl_dn_4: 0.6194 (0.5928)  loss_vfl_dn_5: 0.6299 (0.6109)  loss_vfl_enc_0: 0.9348 (0.8764)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3498  data: 1.3463  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0843  data: 0.2229  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1015 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.19s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.011\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.013\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.018\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.011\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.097\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.149\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.155\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.051\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.249\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.206\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.260\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.156\r\n",
      "best_stat: {'epoch': 17, 'coco_eval_bbox': 0.009552359181484608}\r\n",
      "Epoch: [20]  [ 0/79]  eta: 0:06:13  lr: 0.000020  loss: 30.3280 (30.3280)  loss_bbox: 0.3669 (0.3669)  loss_bbox_aux_0: 0.3983 (0.3983)  loss_bbox_aux_1: 0.3987 (0.3987)  loss_bbox_aux_2: 0.3754 (0.3754)  loss_bbox_aux_3: 0.3672 (0.3672)  loss_bbox_aux_4: 0.3795 (0.3795)  loss_bbox_dn_0: 0.2951 (0.2951)  loss_bbox_dn_1: 0.3034 (0.3034)  loss_bbox_dn_2: 0.3065 (0.3065)  loss_bbox_dn_3: 0.3135 (0.3135)  loss_bbox_dn_4: 0.3159 (0.3159)  loss_bbox_dn_5: 0.3172 (0.3172)  loss_bbox_enc_0: 0.4606 (0.4606)  loss_giou: 1.3514 (1.3514)  loss_giou_aux_0: 1.3523 (1.3523)  loss_giou_aux_1: 1.3544 (1.3544)  loss_giou_aux_2: 1.3654 (1.3654)  loss_giou_aux_3: 1.3557 (1.3557)  loss_giou_aux_4: 1.3531 (1.3531)  loss_giou_dn_0: 1.1623 (1.1623)  loss_giou_dn_1: 1.1150 (1.1150)  loss_giou_dn_2: 1.1015 (1.1015)  loss_giou_dn_3: 1.0986 (1.0986)  loss_giou_dn_4: 1.0896 (1.0896)  loss_giou_dn_5: 1.0871 (1.0871)  loss_giou_enc_0: 1.4401 (1.4401)  loss_vfl: 0.9441 (0.9441)  loss_vfl_aux_0: 0.8721 (0.8721)  loss_vfl_aux_1: 0.9082 (0.9082)  loss_vfl_aux_2: 0.9038 (0.9038)  loss_vfl_aux_3: 0.9509 (0.9509)  loss_vfl_aux_4: 0.9421 (0.9421)  loss_vfl_dn_0: 0.4929 (0.4929)  loss_vfl_dn_1: 0.5140 (0.5140)  loss_vfl_dn_2: 0.5442 (0.5442)  loss_vfl_dn_3: 0.5546 (0.5546)  loss_vfl_dn_4: 0.5750 (0.5750)  loss_vfl_dn_5: 0.5983 (0.5983)  loss_vfl_enc_0: 0.7032 (0.7032)  time: 4.7311  data: 3.0278  max mem: 10356\r\n",
      "Epoch: [20]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 31.3268 (31.2721)  loss_bbox: 0.3917 (0.4015)  loss_bbox_aux_0: 0.4291 (0.4316)  loss_bbox_aux_1: 0.4185 (0.4229)  loss_bbox_aux_2: 0.4111 (0.4132)  loss_bbox_aux_3: 0.4141 (0.4128)  loss_bbox_aux_4: 0.4029 (0.4056)  loss_bbox_dn_0: 0.4363 (0.4598)  loss_bbox_dn_1: 0.4271 (0.4420)  loss_bbox_dn_2: 0.4193 (0.4327)  loss_bbox_dn_3: 0.4155 (0.4278)  loss_bbox_dn_4: 0.4152 (0.4248)  loss_bbox_dn_5: 0.4147 (0.4242)  loss_bbox_enc_0: 0.4693 (0.4871)  loss_giou: 1.1978 (1.1669)  loss_giou_aux_0: 1.2241 (1.1987)  loss_giou_aux_1: 1.2747 (1.1863)  loss_giou_aux_2: 1.2250 (1.1777)  loss_giou_aux_3: 1.2231 (1.1745)  loss_giou_aux_4: 1.2051 (1.1691)  loss_giou_dn_0: 1.2060 (1.2123)  loss_giou_dn_1: 1.1567 (1.1562)  loss_giou_dn_2: 1.1329 (1.1284)  loss_giou_dn_3: 1.1141 (1.1145)  loss_giou_dn_4: 1.1021 (1.1042)  loss_giou_dn_5: 1.1024 (1.1034)  loss_giou_enc_0: 1.3600 (1.3101)  loss_vfl: 0.9673 (1.0729)  loss_vfl_aux_0: 0.9409 (1.0299)  loss_vfl_aux_1: 0.9272 (1.0368)  loss_vfl_aux_2: 0.9258 (1.0463)  loss_vfl_aux_3: 0.9622 (1.0607)  loss_vfl_aux_4: 0.9675 (1.0704)  loss_vfl_dn_0: 0.4589 (0.4707)  loss_vfl_dn_1: 0.4954 (0.5038)  loss_vfl_dn_2: 0.5288 (0.5347)  loss_vfl_dn_3: 0.5469 (0.5658)  loss_vfl_dn_4: 0.5857 (0.5949)  loss_vfl_dn_5: 0.5994 (0.6115)  loss_vfl_enc_0: 0.7886 (0.8856)  time: 0.9701  data: 0.0320  max mem: 10356\r\n",
      "Epoch: [20] Total time: 0:01:25 (1.0882 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 31.3268 (31.2721)  loss_bbox: 0.3917 (0.4015)  loss_bbox_aux_0: 0.4291 (0.4316)  loss_bbox_aux_1: 0.4185 (0.4229)  loss_bbox_aux_2: 0.4111 (0.4132)  loss_bbox_aux_3: 0.4141 (0.4128)  loss_bbox_aux_4: 0.4029 (0.4056)  loss_bbox_dn_0: 0.4363 (0.4598)  loss_bbox_dn_1: 0.4271 (0.4420)  loss_bbox_dn_2: 0.4193 (0.4327)  loss_bbox_dn_3: 0.4155 (0.4278)  loss_bbox_dn_4: 0.4152 (0.4248)  loss_bbox_dn_5: 0.4147 (0.4242)  loss_bbox_enc_0: 0.4693 (0.4871)  loss_giou: 1.1978 (1.1669)  loss_giou_aux_0: 1.2241 (1.1987)  loss_giou_aux_1: 1.2747 (1.1863)  loss_giou_aux_2: 1.2250 (1.1777)  loss_giou_aux_3: 1.2231 (1.1745)  loss_giou_aux_4: 1.2051 (1.1691)  loss_giou_dn_0: 1.2060 (1.2123)  loss_giou_dn_1: 1.1567 (1.1562)  loss_giou_dn_2: 1.1329 (1.1284)  loss_giou_dn_3: 1.1141 (1.1145)  loss_giou_dn_4: 1.1021 (1.1042)  loss_giou_dn_5: 1.1024 (1.1034)  loss_giou_enc_0: 1.3600 (1.3101)  loss_vfl: 0.9673 (1.0729)  loss_vfl_aux_0: 0.9409 (1.0299)  loss_vfl_aux_1: 0.9272 (1.0368)  loss_vfl_aux_2: 0.9258 (1.0463)  loss_vfl_aux_3: 0.9622 (1.0607)  loss_vfl_aux_4: 0.9675 (1.0704)  loss_vfl_dn_0: 0.4589 (0.4707)  loss_vfl_dn_1: 0.4954 (0.5038)  loss_vfl_dn_2: 0.5288 (0.5347)  loss_vfl_dn_3: 0.5469 (0.5658)  loss_vfl_dn_4: 0.5857 (0.5949)  loss_vfl_dn_5: 0.5994 (0.6115)  loss_vfl_enc_0: 0.7886 (0.8856)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.1687  data: 1.2473  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0646  data: 0.2047  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0837 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.19s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.014\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.005\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.016\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.018\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.089\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.145\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.157\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.042\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.251\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.225\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.258\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.165\r\n",
      "best_stat: {'epoch': 17, 'coco_eval_bbox': 0.009552359181484608}\r\n",
      "Epoch: [21]  [ 0/79]  eta: 0:05:57  lr: 0.000020  loss: 31.1941 (31.1941)  loss_bbox: 0.3379 (0.3379)  loss_bbox_aux_0: 0.3504 (0.3504)  loss_bbox_aux_1: 0.3291 (0.3291)  loss_bbox_aux_2: 0.3280 (0.3280)  loss_bbox_aux_3: 0.3306 (0.3306)  loss_bbox_aux_4: 0.3341 (0.3341)  loss_bbox_dn_0: 0.5083 (0.5083)  loss_bbox_dn_1: 0.4800 (0.4800)  loss_bbox_dn_2: 0.4652 (0.4652)  loss_bbox_dn_3: 0.4521 (0.4521)  loss_bbox_dn_4: 0.4434 (0.4434)  loss_bbox_dn_5: 0.4414 (0.4414)  loss_bbox_enc_0: 0.3921 (0.3921)  loss_giou: 0.8387 (0.8387)  loss_giou_aux_0: 0.9006 (0.9006)  loss_giou_aux_1: 0.8772 (0.8772)  loss_giou_aux_2: 0.8554 (0.8554)  loss_giou_aux_3: 0.8458 (0.8458)  loss_giou_aux_4: 0.8366 (0.8366)  loss_giou_dn_0: 1.1666 (1.1666)  loss_giou_dn_1: 1.0842 (1.0842)  loss_giou_dn_2: 1.0479 (1.0479)  loss_giou_dn_3: 1.0204 (1.0204)  loss_giou_dn_4: 1.0013 (1.0013)  loss_giou_dn_5: 1.0016 (1.0016)  loss_giou_enc_0: 1.0402 (1.0402)  loss_vfl: 1.4497 (1.4497)  loss_vfl_aux_0: 1.3960 (1.3960)  loss_vfl_aux_1: 1.4155 (1.4155)  loss_vfl_aux_2: 1.4438 (1.4438)  loss_vfl_aux_3: 1.5063 (1.5063)  loss_vfl_aux_4: 1.4780 (1.4780)  loss_vfl_dn_0: 0.4907 (0.4907)  loss_vfl_dn_1: 0.5417 (0.5417)  loss_vfl_dn_2: 0.5710 (0.5710)  loss_vfl_dn_3: 0.6323 (0.6323)  loss_vfl_dn_4: 0.6553 (0.6553)  loss_vfl_dn_5: 0.6790 (0.6790)  loss_vfl_enc_0: 1.2256 (1.2256)  time: 4.5222  data: 2.8370  max mem: 10356\r\n",
      "Epoch: [21]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 30.6421 (31.0566)  loss_bbox: 0.3594 (0.3905)  loss_bbox_aux_0: 0.3864 (0.4187)  loss_bbox_aux_1: 0.3785 (0.4101)  loss_bbox_aux_2: 0.3755 (0.4007)  loss_bbox_aux_3: 0.3711 (0.3993)  loss_bbox_aux_4: 0.3665 (0.3938)  loss_bbox_dn_0: 0.4047 (0.4434)  loss_bbox_dn_1: 0.3923 (0.4244)  loss_bbox_dn_2: 0.3816 (0.4148)  loss_bbox_dn_3: 0.3769 (0.4090)  loss_bbox_dn_4: 0.3721 (0.4054)  loss_bbox_dn_5: 0.3710 (0.4048)  loss_bbox_enc_0: 0.4308 (0.4702)  loss_giou: 1.1757 (1.1661)  loss_giou_aux_0: 1.2280 (1.1937)  loss_giou_aux_1: 1.2079 (1.1856)  loss_giou_aux_2: 1.1974 (1.1806)  loss_giou_aux_3: 1.1932 (1.1744)  loss_giou_aux_4: 1.1765 (1.1682)  loss_giou_dn_0: 1.2239 (1.2105)  loss_giou_dn_1: 1.1754 (1.1537)  loss_giou_dn_2: 1.1618 (1.1257)  loss_giou_dn_3: 1.1484 (1.1123)  loss_giou_dn_4: 1.1309 (1.1018)  loss_giou_dn_5: 1.1330 (1.1011)  loss_giou_enc_0: 1.3299 (1.3070)  loss_vfl: 1.0132 (1.0656)  loss_vfl_aux_0: 0.9331 (1.0472)  loss_vfl_aux_1: 0.9888 (1.0457)  loss_vfl_aux_2: 0.9753 (1.0441)  loss_vfl_aux_3: 0.9905 (1.0557)  loss_vfl_aux_4: 1.0049 (1.0567)  loss_vfl_dn_0: 0.4495 (0.4720)  loss_vfl_dn_1: 0.4857 (0.5046)  loss_vfl_dn_2: 0.5116 (0.5339)  loss_vfl_dn_3: 0.5366 (0.5632)  loss_vfl_dn_4: 0.5671 (0.5927)  loss_vfl_dn_5: 0.5809 (0.6113)  loss_vfl_enc_0: 0.8186 (0.8978)  time: 0.9665  data: 0.0318  max mem: 10356\r\n",
      "Epoch: [21] Total time: 0:01:25 (1.0851 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 30.6421 (31.0566)  loss_bbox: 0.3594 (0.3905)  loss_bbox_aux_0: 0.3864 (0.4187)  loss_bbox_aux_1: 0.3785 (0.4101)  loss_bbox_aux_2: 0.3755 (0.4007)  loss_bbox_aux_3: 0.3711 (0.3993)  loss_bbox_aux_4: 0.3665 (0.3938)  loss_bbox_dn_0: 0.4047 (0.4434)  loss_bbox_dn_1: 0.3923 (0.4244)  loss_bbox_dn_2: 0.3816 (0.4148)  loss_bbox_dn_3: 0.3769 (0.4090)  loss_bbox_dn_4: 0.3721 (0.4054)  loss_bbox_dn_5: 0.3710 (0.4048)  loss_bbox_enc_0: 0.4308 (0.4702)  loss_giou: 1.1757 (1.1661)  loss_giou_aux_0: 1.2280 (1.1937)  loss_giou_aux_1: 1.2079 (1.1856)  loss_giou_aux_2: 1.1974 (1.1806)  loss_giou_aux_3: 1.1932 (1.1744)  loss_giou_aux_4: 1.1765 (1.1682)  loss_giou_dn_0: 1.2239 (1.2105)  loss_giou_dn_1: 1.1754 (1.1537)  loss_giou_dn_2: 1.1618 (1.1257)  loss_giou_dn_3: 1.1484 (1.1123)  loss_giou_dn_4: 1.1309 (1.1018)  loss_giou_dn_5: 1.1330 (1.1011)  loss_giou_enc_0: 1.3299 (1.3070)  loss_vfl: 1.0132 (1.0656)  loss_vfl_aux_0: 0.9331 (1.0472)  loss_vfl_aux_1: 0.9888 (1.0457)  loss_vfl_aux_2: 0.9753 (1.0441)  loss_vfl_aux_3: 0.9905 (1.0557)  loss_vfl_aux_4: 1.0049 (1.0567)  loss_vfl_dn_0: 0.4495 (0.4720)  loss_vfl_dn_1: 0.4857 (0.5046)  loss_vfl_dn_2: 0.5116 (0.5339)  loss_vfl_dn_3: 0.5366 (0.5632)  loss_vfl_dn_4: 0.5671 (0.5927)  loss_vfl_dn_5: 0.5809 (0.6113)  loss_vfl_enc_0: 0.8186 (0.8978)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.1959  data: 1.2302  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0674  data: 0.2073  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0854 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.19s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.014\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.014\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.022\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.107\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.159\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.166\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.044\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.262\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.228\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.251\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.171\r\n",
      "best_stat: {'epoch': 17, 'coco_eval_bbox': 0.009552359181484608}\r\n",
      "Epoch: [22]  [ 0/79]  eta: 0:05:50  lr: 0.000020  loss: 31.9194 (31.9194)  loss_bbox: 0.5169 (0.5169)  loss_bbox_aux_0: 0.5400 (0.5400)  loss_bbox_aux_1: 0.5252 (0.5252)  loss_bbox_aux_2: 0.5218 (0.5218)  loss_bbox_aux_3: 0.5457 (0.5457)  loss_bbox_aux_4: 0.5428 (0.5428)  loss_bbox_dn_0: 0.5672 (0.5672)  loss_bbox_dn_1: 0.5615 (0.5615)  loss_bbox_dn_2: 0.5536 (0.5536)  loss_bbox_dn_3: 0.5545 (0.5545)  loss_bbox_dn_4: 0.5552 (0.5552)  loss_bbox_dn_5: 0.5567 (0.5567)  loss_bbox_enc_0: 0.5529 (0.5529)  loss_giou: 1.0717 (1.0717)  loss_giou_aux_0: 1.1396 (1.1396)  loss_giou_aux_1: 1.1260 (1.1260)  loss_giou_aux_2: 1.0888 (1.0888)  loss_giou_aux_3: 1.0947 (1.0947)  loss_giou_aux_4: 1.0503 (1.0503)  loss_giou_dn_0: 1.2201 (1.2201)  loss_giou_dn_1: 1.1695 (1.1695)  loss_giou_dn_2: 1.1420 (1.1420)  loss_giou_dn_3: 1.1348 (1.1348)  loss_giou_dn_4: 1.1260 (1.1260)  loss_giou_dn_5: 1.1271 (1.1271)  loss_giou_enc_0: 1.2458 (1.2458)  loss_vfl: 1.0220 (1.0220)  loss_vfl_aux_0: 0.9795 (0.9795)  loss_vfl_aux_1: 1.0107 (1.0107)  loss_vfl_aux_2: 1.0374 (1.0374)  loss_vfl_aux_3: 1.0020 (1.0020)  loss_vfl_aux_4: 1.0444 (1.0444)  loss_vfl_dn_0: 0.4565 (0.4565)  loss_vfl_dn_1: 0.4967 (0.4967)  loss_vfl_dn_2: 0.5226 (0.5226)  loss_vfl_dn_3: 0.5391 (0.5391)  loss_vfl_dn_4: 0.5610 (0.5610)  loss_vfl_dn_5: 0.5649 (0.5649)  loss_vfl_enc_0: 0.8521 (0.8521)  time: 4.4373  data: 2.6565  max mem: 10356\r\n",
      "Epoch: [22]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 31.0502 (31.0772)  loss_bbox: 0.3900 (0.3800)  loss_bbox_aux_0: 0.4281 (0.4095)  loss_bbox_aux_1: 0.4407 (0.4007)  loss_bbox_aux_2: 0.4256 (0.3892)  loss_bbox_aux_3: 0.4037 (0.3860)  loss_bbox_aux_4: 0.4060 (0.3802)  loss_bbox_dn_0: 0.4364 (0.4582)  loss_bbox_dn_1: 0.4125 (0.4374)  loss_bbox_dn_2: 0.4054 (0.4266)  loss_bbox_dn_3: 0.3984 (0.4206)  loss_bbox_dn_4: 0.3953 (0.4169)  loss_bbox_dn_5: 0.3948 (0.4162)  loss_bbox_enc_0: 0.4801 (0.4612)  loss_giou: 1.2582 (1.1558)  loss_giou_aux_0: 1.2771 (1.1972)  loss_giou_aux_1: 1.2691 (1.1790)  loss_giou_aux_2: 1.2565 (1.1658)  loss_giou_aux_3: 1.2607 (1.1643)  loss_giou_aux_4: 1.2581 (1.1597)  loss_giou_dn_0: 1.1983 (1.2080)  loss_giou_dn_1: 1.1354 (1.1491)  loss_giou_dn_2: 1.1130 (1.1204)  loss_giou_dn_3: 1.1037 (1.1059)  loss_giou_dn_4: 1.0937 (1.0954)  loss_giou_dn_5: 1.0931 (1.0946)  loss_giou_enc_0: 1.3863 (1.3013)  loss_vfl: 0.9805 (1.0840)  loss_vfl_aux_0: 0.9773 (1.0528)  loss_vfl_aux_1: 0.9832 (1.0599)  loss_vfl_aux_2: 0.9775 (1.0686)  loss_vfl_aux_3: 0.9951 (1.0742)  loss_vfl_aux_4: 0.9617 (1.0758)  loss_vfl_dn_0: 0.4576 (0.4706)  loss_vfl_dn_1: 0.4889 (0.5034)  loss_vfl_dn_2: 0.5089 (0.5326)  loss_vfl_dn_3: 0.5347 (0.5613)  loss_vfl_dn_4: 0.5605 (0.5895)  loss_vfl_dn_5: 0.5820 (0.6080)  loss_vfl_enc_0: 0.8203 (0.9177)  time: 0.9909  data: 0.0320  max mem: 10356\r\n",
      "Epoch: [22] Total time: 0:01:25 (1.0836 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 31.0502 (31.0772)  loss_bbox: 0.3900 (0.3800)  loss_bbox_aux_0: 0.4281 (0.4095)  loss_bbox_aux_1: 0.4407 (0.4007)  loss_bbox_aux_2: 0.4256 (0.3892)  loss_bbox_aux_3: 0.4037 (0.3860)  loss_bbox_aux_4: 0.4060 (0.3802)  loss_bbox_dn_0: 0.4364 (0.4582)  loss_bbox_dn_1: 0.4125 (0.4374)  loss_bbox_dn_2: 0.4054 (0.4266)  loss_bbox_dn_3: 0.3984 (0.4206)  loss_bbox_dn_4: 0.3953 (0.4169)  loss_bbox_dn_5: 0.3948 (0.4162)  loss_bbox_enc_0: 0.4801 (0.4612)  loss_giou: 1.2582 (1.1558)  loss_giou_aux_0: 1.2771 (1.1972)  loss_giou_aux_1: 1.2691 (1.1790)  loss_giou_aux_2: 1.2565 (1.1658)  loss_giou_aux_3: 1.2607 (1.1643)  loss_giou_aux_4: 1.2581 (1.1597)  loss_giou_dn_0: 1.1983 (1.2080)  loss_giou_dn_1: 1.1354 (1.1491)  loss_giou_dn_2: 1.1130 (1.1204)  loss_giou_dn_3: 1.1037 (1.1059)  loss_giou_dn_4: 1.0937 (1.0954)  loss_giou_dn_5: 1.0931 (1.0946)  loss_giou_enc_0: 1.3863 (1.3013)  loss_vfl: 0.9805 (1.0840)  loss_vfl_aux_0: 0.9773 (1.0528)  loss_vfl_aux_1: 0.9832 (1.0599)  loss_vfl_aux_2: 0.9775 (1.0686)  loss_vfl_aux_3: 0.9951 (1.0742)  loss_vfl_aux_4: 0.9617 (1.0758)  loss_vfl_dn_0: 0.4576 (0.4706)  loss_vfl_dn_1: 0.4889 (0.5034)  loss_vfl_dn_2: 0.5089 (0.5326)  loss_vfl_dn_3: 0.5347 (0.5613)  loss_vfl_dn_4: 0.5605 (0.5895)  loss_vfl_dn_5: 0.5820 (0.6080)  loss_vfl_enc_0: 0.8203 (0.9177)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.2449  data: 1.2843  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0737  data: 0.2135  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0896 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.19s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.009\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.014\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.010\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.025\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.018\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.096\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.161\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.172\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.049\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.275\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.243\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.268\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.172\r\n",
      "best_stat: {'epoch': 17, 'coco_eval_bbox': 0.009552359181484608}\r\n",
      "Epoch: [23]  [ 0/79]  eta: 0:05:55  lr: 0.000020  loss: 32.3328 (32.3328)  loss_bbox: 0.4436 (0.4436)  loss_bbox_aux_0: 0.4925 (0.4925)  loss_bbox_aux_1: 0.4628 (0.4628)  loss_bbox_aux_2: 0.4640 (0.4640)  loss_bbox_aux_3: 0.4583 (0.4583)  loss_bbox_aux_4: 0.4579 (0.4579)  loss_bbox_dn_0: 0.5399 (0.5399)  loss_bbox_dn_1: 0.5131 (0.5131)  loss_bbox_dn_2: 0.5032 (0.5032)  loss_bbox_dn_3: 0.4972 (0.4972)  loss_bbox_dn_4: 0.4930 (0.4930)  loss_bbox_dn_5: 0.4924 (0.4924)  loss_bbox_enc_0: 0.5247 (0.5247)  loss_giou: 1.2687 (1.2687)  loss_giou_aux_0: 1.3283 (1.3283)  loss_giou_aux_1: 1.3360 (1.3360)  loss_giou_aux_2: 1.3154 (1.3154)  loss_giou_aux_3: 1.2811 (1.2811)  loss_giou_aux_4: 1.2685 (1.2685)  loss_giou_dn_0: 1.2824 (1.2824)  loss_giou_dn_1: 1.2361 (1.2361)  loss_giou_dn_2: 1.2130 (1.2130)  loss_giou_dn_3: 1.1936 (1.1936)  loss_giou_dn_4: 1.1813 (1.1813)  loss_giou_dn_5: 1.1776 (1.1776)  loss_giou_enc_0: 1.4431 (1.4431)  loss_vfl: 0.9644 (0.9644)  loss_vfl_aux_0: 0.9282 (0.9282)  loss_vfl_aux_1: 0.8679 (0.8679)  loss_vfl_aux_2: 0.8945 (0.8945)  loss_vfl_aux_3: 0.9753 (0.9753)  loss_vfl_aux_4: 0.9546 (0.9546)  loss_vfl_dn_0: 0.4504 (0.4504)  loss_vfl_dn_1: 0.4796 (0.4796)  loss_vfl_dn_2: 0.4989 (0.4989)  loss_vfl_dn_3: 0.5209 (0.5209)  loss_vfl_dn_4: 0.5394 (0.5394)  loss_vfl_dn_5: 0.5691 (0.5691)  loss_vfl_enc_0: 0.8218 (0.8218)  time: 4.5023  data: 2.7543  max mem: 10356\r\n",
      "Epoch: [23]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 30.6118 (30.9792)  loss_bbox: 0.3937 (0.3901)  loss_bbox_aux_0: 0.3896 (0.4186)  loss_bbox_aux_1: 0.3897 (0.4093)  loss_bbox_aux_2: 0.3776 (0.4010)  loss_bbox_aux_3: 0.3738 (0.3991)  loss_bbox_aux_4: 0.3770 (0.3947)  loss_bbox_dn_0: 0.4474 (0.4439)  loss_bbox_dn_1: 0.4275 (0.4240)  loss_bbox_dn_2: 0.4278 (0.4136)  loss_bbox_dn_3: 0.4349 (0.4081)  loss_bbox_dn_4: 0.4377 (0.4046)  loss_bbox_dn_5: 0.4378 (0.4039)  loss_bbox_enc_0: 0.4854 (0.4709)  loss_giou: 1.0419 (1.1552)  loss_giou_aux_0: 1.0860 (1.1868)  loss_giou_aux_1: 1.0654 (1.1761)  loss_giou_aux_2: 1.0553 (1.1659)  loss_giou_aux_3: 1.0552 (1.1580)  loss_giou_aux_4: 1.0387 (1.1540)  loss_giou_dn_0: 1.1762 (1.2002)  loss_giou_dn_1: 1.1031 (1.1378)  loss_giou_dn_2: 1.0731 (1.1086)  loss_giou_dn_3: 1.0592 (1.0942)  loss_giou_dn_4: 1.0480 (1.0848)  loss_giou_dn_5: 1.0467 (1.0840)  loss_giou_enc_0: 1.2317 (1.2990)  loss_vfl: 1.0613 (1.0754)  loss_vfl_aux_0: 1.0369 (1.0531)  loss_vfl_aux_1: 1.0764 (1.0516)  loss_vfl_aux_2: 1.1008 (1.0627)  loss_vfl_aux_3: 1.0601 (1.0684)  loss_vfl_aux_4: 1.0430 (1.0703)  loss_vfl_dn_0: 0.4683 (0.4748)  loss_vfl_dn_1: 0.5063 (0.5085)  loss_vfl_dn_2: 0.5383 (0.5371)  loss_vfl_dn_3: 0.5740 (0.5679)  loss_vfl_dn_4: 0.6055 (0.5936)  loss_vfl_dn_5: 0.6123 (0.6121)  loss_vfl_enc_0: 0.8813 (0.9174)  time: 0.9606  data: 0.0327  max mem: 10356\r\n",
      "Epoch: [23] Total time: 0:01:27 (1.1021 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 30.6118 (30.9792)  loss_bbox: 0.3937 (0.3901)  loss_bbox_aux_0: 0.3896 (0.4186)  loss_bbox_aux_1: 0.3897 (0.4093)  loss_bbox_aux_2: 0.3776 (0.4010)  loss_bbox_aux_3: 0.3738 (0.3991)  loss_bbox_aux_4: 0.3770 (0.3947)  loss_bbox_dn_0: 0.4474 (0.4439)  loss_bbox_dn_1: 0.4275 (0.4240)  loss_bbox_dn_2: 0.4278 (0.4136)  loss_bbox_dn_3: 0.4349 (0.4081)  loss_bbox_dn_4: 0.4377 (0.4046)  loss_bbox_dn_5: 0.4378 (0.4039)  loss_bbox_enc_0: 0.4854 (0.4709)  loss_giou: 1.0419 (1.1552)  loss_giou_aux_0: 1.0860 (1.1868)  loss_giou_aux_1: 1.0654 (1.1761)  loss_giou_aux_2: 1.0553 (1.1659)  loss_giou_aux_3: 1.0552 (1.1580)  loss_giou_aux_4: 1.0387 (1.1540)  loss_giou_dn_0: 1.1762 (1.2002)  loss_giou_dn_1: 1.1031 (1.1378)  loss_giou_dn_2: 1.0731 (1.1086)  loss_giou_dn_3: 1.0592 (1.0942)  loss_giou_dn_4: 1.0480 (1.0848)  loss_giou_dn_5: 1.0467 (1.0840)  loss_giou_enc_0: 1.2317 (1.2990)  loss_vfl: 1.0613 (1.0754)  loss_vfl_aux_0: 1.0369 (1.0531)  loss_vfl_aux_1: 1.0764 (1.0516)  loss_vfl_aux_2: 1.1008 (1.0627)  loss_vfl_aux_3: 1.0601 (1.0684)  loss_vfl_aux_4: 1.0430 (1.0703)  loss_vfl_dn_0: 0.4683 (0.4748)  loss_vfl_dn_1: 0.5063 (0.5085)  loss_vfl_dn_2: 0.5383 (0.5371)  loss_vfl_dn_3: 0.5740 (0.5679)  loss_vfl_dn_4: 0.6055 (0.5936)  loss_vfl_dn_5: 0.6123 (0.6121)  loss_vfl_enc_0: 0.8813 (0.9174)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3395  data: 1.3753  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0782  data: 0.2190  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0953 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.009\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.014\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.011\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.018\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.029\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.102\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.166\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.178\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.047\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.278\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.235\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.273\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.183\r\n",
      "best_stat: {'epoch': 17, 'coco_eval_bbox': 0.009552359181484608}\r\n",
      "Epoch: [24]  [ 0/79]  eta: 0:06:00  lr: 0.000020  loss: 32.7145 (32.7145)  loss_bbox: 0.4900 (0.4900)  loss_bbox_aux_0: 0.5237 (0.5237)  loss_bbox_aux_1: 0.5257 (0.5257)  loss_bbox_aux_2: 0.4988 (0.4988)  loss_bbox_aux_3: 0.4955 (0.4955)  loss_bbox_aux_4: 0.5104 (0.5104)  loss_bbox_dn_0: 0.5659 (0.5659)  loss_bbox_dn_1: 0.5483 (0.5483)  loss_bbox_dn_2: 0.5386 (0.5386)  loss_bbox_dn_3: 0.5328 (0.5328)  loss_bbox_dn_4: 0.5295 (0.5295)  loss_bbox_dn_5: 0.5293 (0.5293)  loss_bbox_enc_0: 0.5773 (0.5773)  loss_giou: 1.3630 (1.3630)  loss_giou_aux_0: 1.3779 (1.3779)  loss_giou_aux_1: 1.3739 (1.3739)  loss_giou_aux_2: 1.3750 (1.3750)  loss_giou_aux_3: 1.3410 (1.3410)  loss_giou_aux_4: 1.3636 (1.3636)  loss_giou_dn_0: 1.2513 (1.2513)  loss_giou_dn_1: 1.2189 (1.2189)  loss_giou_dn_2: 1.2000 (1.2000)  loss_giou_dn_3: 1.1916 (1.1916)  loss_giou_dn_4: 1.1871 (1.1871)  loss_giou_dn_5: 1.1872 (1.1872)  loss_giou_enc_0: 1.4295 (1.4295)  loss_vfl: 0.8799 (0.8799)  loss_vfl_aux_0: 0.8650 (0.8650)  loss_vfl_aux_1: 0.8379 (0.8379)  loss_vfl_aux_2: 0.8750 (0.8750)  loss_vfl_aux_3: 0.9023 (0.9023)  loss_vfl_aux_4: 0.8647 (0.8647)  loss_vfl_dn_0: 0.4509 (0.4509)  loss_vfl_dn_1: 0.4628 (0.4628)  loss_vfl_dn_2: 0.4750 (0.4750)  loss_vfl_dn_3: 0.5137 (0.5137)  loss_vfl_dn_4: 0.5178 (0.5178)  loss_vfl_dn_5: 0.5359 (0.5359)  loss_vfl_enc_0: 0.8081 (0.8081)  time: 4.5631  data: 2.6344  max mem: 10356\r\n",
      "Epoch: [24]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 29.8568 (30.8107)  loss_bbox: 0.3369 (0.3783)  loss_bbox_aux_0: 0.3597 (0.4143)  loss_bbox_aux_1: 0.3599 (0.4034)  loss_bbox_aux_2: 0.3394 (0.3913)  loss_bbox_aux_3: 0.3353 (0.3858)  loss_bbox_aux_4: 0.3275 (0.3786)  loss_bbox_dn_0: 0.4015 (0.4479)  loss_bbox_dn_1: 0.3698 (0.4263)  loss_bbox_dn_2: 0.3566 (0.4149)  loss_bbox_dn_3: 0.3491 (0.4088)  loss_bbox_dn_4: 0.3435 (0.4048)  loss_bbox_dn_5: 0.3425 (0.4040)  loss_bbox_enc_0: 0.3993 (0.4677)  loss_giou: 1.0717 (1.1336)  loss_giou_aux_0: 1.1177 (1.1776)  loss_giou_aux_1: 1.0933 (1.1571)  loss_giou_aux_2: 1.0921 (1.1469)  loss_giou_aux_3: 1.0770 (1.1420)  loss_giou_aux_4: 1.0629 (1.1339)  loss_giou_dn_0: 1.1808 (1.1894)  loss_giou_dn_1: 1.1162 (1.1271)  loss_giou_dn_2: 1.0756 (1.0976)  loss_giou_dn_3: 1.0590 (1.0818)  loss_giou_dn_4: 1.0432 (1.0711)  loss_giou_dn_5: 1.0427 (1.0702)  loss_giou_enc_0: 1.2383 (1.2849)  loss_vfl: 1.0901 (1.0930)  loss_vfl_aux_0: 1.0466 (1.0499)  loss_vfl_aux_1: 1.0847 (1.0590)  loss_vfl_aux_2: 1.0813 (1.0725)  loss_vfl_aux_3: 1.1006 (1.0804)  loss_vfl_aux_4: 1.1008 (1.0909)  loss_vfl_dn_0: 0.4844 (0.4798)  loss_vfl_dn_1: 0.5267 (0.5121)  loss_vfl_dn_2: 0.5472 (0.5406)  loss_vfl_dn_3: 0.5737 (0.5702)  loss_vfl_dn_4: 0.5891 (0.5960)  loss_vfl_dn_5: 0.6040 (0.6129)  loss_vfl_enc_0: 0.9382 (0.9140)  time: 1.0048  data: 0.0336  max mem: 10356\r\n",
      "Epoch: [24] Total time: 0:01:27 (1.1070 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 29.8568 (30.8107)  loss_bbox: 0.3369 (0.3783)  loss_bbox_aux_0: 0.3597 (0.4143)  loss_bbox_aux_1: 0.3599 (0.4034)  loss_bbox_aux_2: 0.3394 (0.3913)  loss_bbox_aux_3: 0.3353 (0.3858)  loss_bbox_aux_4: 0.3275 (0.3786)  loss_bbox_dn_0: 0.4015 (0.4479)  loss_bbox_dn_1: 0.3698 (0.4263)  loss_bbox_dn_2: 0.3566 (0.4149)  loss_bbox_dn_3: 0.3491 (0.4088)  loss_bbox_dn_4: 0.3435 (0.4048)  loss_bbox_dn_5: 0.3425 (0.4040)  loss_bbox_enc_0: 0.3993 (0.4677)  loss_giou: 1.0717 (1.1336)  loss_giou_aux_0: 1.1177 (1.1776)  loss_giou_aux_1: 1.0933 (1.1571)  loss_giou_aux_2: 1.0921 (1.1469)  loss_giou_aux_3: 1.0770 (1.1420)  loss_giou_aux_4: 1.0629 (1.1339)  loss_giou_dn_0: 1.1808 (1.1894)  loss_giou_dn_1: 1.1162 (1.1271)  loss_giou_dn_2: 1.0756 (1.0976)  loss_giou_dn_3: 1.0590 (1.0818)  loss_giou_dn_4: 1.0432 (1.0711)  loss_giou_dn_5: 1.0427 (1.0702)  loss_giou_enc_0: 1.2383 (1.2849)  loss_vfl: 1.0901 (1.0930)  loss_vfl_aux_0: 1.0466 (1.0499)  loss_vfl_aux_1: 1.0847 (1.0590)  loss_vfl_aux_2: 1.0813 (1.0725)  loss_vfl_aux_3: 1.1006 (1.0804)  loss_vfl_aux_4: 1.1008 (1.0909)  loss_vfl_dn_0: 0.4844 (0.4798)  loss_vfl_dn_1: 0.5267 (0.5121)  loss_vfl_dn_2: 0.5472 (0.5406)  loss_vfl_dn_3: 0.5737 (0.5702)  loss_vfl_dn_4: 0.5891 (0.5960)  loss_vfl_dn_5: 0.6040 (0.6129)  loss_vfl_enc_0: 0.9382 (0.9140)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.1899  data: 1.2433  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0882  data: 0.2177  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1065 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.19s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.014\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.020\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.025\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.110\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.170\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.177\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.049\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.268\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.241\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.265\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.200\r\n",
      "best_stat: {'epoch': 17, 'coco_eval_bbox': 0.009552359181484608}\r\n",
      "Epoch: [25]  [ 0/79]  eta: 0:06:15  lr: 0.000020  loss: 29.8495 (29.8495)  loss_bbox: 0.3317 (0.3317)  loss_bbox_aux_0: 0.3432 (0.3432)  loss_bbox_aux_1: 0.3357 (0.3357)  loss_bbox_aux_2: 0.3376 (0.3376)  loss_bbox_aux_3: 0.3355 (0.3355)  loss_bbox_aux_4: 0.3318 (0.3318)  loss_bbox_dn_0: 0.2266 (0.2266)  loss_bbox_dn_1: 0.2143 (0.2143)  loss_bbox_dn_2: 0.2087 (0.2087)  loss_bbox_dn_3: 0.2076 (0.2076)  loss_bbox_dn_4: 0.2057 (0.2057)  loss_bbox_dn_5: 0.2052 (0.2052)  loss_bbox_enc_0: 0.3453 (0.3453)  loss_giou: 1.3772 (1.3772)  loss_giou_aux_0: 1.3907 (1.3907)  loss_giou_aux_1: 1.4043 (1.4043)  loss_giou_aux_2: 1.3732 (1.3732)  loss_giou_aux_3: 1.3694 (1.3694)  loss_giou_aux_4: 1.3725 (1.3725)  loss_giou_dn_0: 1.1688 (1.1688)  loss_giou_dn_1: 1.1189 (1.1189)  loss_giou_dn_2: 1.1068 (1.1068)  loss_giou_dn_3: 1.1035 (1.1035)  loss_giou_dn_4: 1.0910 (1.0910)  loss_giou_dn_5: 1.0902 (1.0902)  loss_giou_enc_0: 1.5060 (1.5060)  loss_vfl: 0.9626 (0.9626)  loss_vfl_aux_0: 0.9207 (0.9207)  loss_vfl_aux_1: 0.9033 (0.9033)  loss_vfl_aux_2: 0.9407 (0.9407)  loss_vfl_aux_3: 0.9727 (0.9727)  loss_vfl_aux_4: 0.9536 (0.9536)  loss_vfl_dn_0: 0.4950 (0.4950)  loss_vfl_dn_1: 0.5200 (0.5200)  loss_vfl_dn_2: 0.5507 (0.5507)  loss_vfl_dn_3: 0.5593 (0.5593)  loss_vfl_dn_4: 0.6011 (0.6011)  loss_vfl_dn_5: 0.6130 (0.6130)  loss_vfl_enc_0: 0.7554 (0.7554)  time: 4.7554  data: 3.0204  max mem: 10356\r\n",
      "Epoch: [25]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 30.5815 (30.7222)  loss_bbox: 0.3690 (0.3739)  loss_bbox_aux_0: 0.3899 (0.4021)  loss_bbox_aux_1: 0.3874 (0.3929)  loss_bbox_aux_2: 0.4018 (0.3848)  loss_bbox_aux_3: 0.3763 (0.3806)  loss_bbox_aux_4: 0.3659 (0.3760)  loss_bbox_dn_0: 0.4475 (0.4470)  loss_bbox_dn_1: 0.4337 (0.4247)  loss_bbox_dn_2: 0.4267 (0.4138)  loss_bbox_dn_3: 0.4187 (0.4075)  loss_bbox_dn_4: 0.4101 (0.4035)  loss_bbox_dn_5: 0.4082 (0.4027)  loss_bbox_enc_0: 0.4647 (0.4503)  loss_giou: 1.0940 (1.1447)  loss_giou_aux_0: 1.1528 (1.1845)  loss_giou_aux_1: 1.1333 (1.1682)  loss_giou_aux_2: 1.1094 (1.1547)  loss_giou_aux_3: 1.1120 (1.1518)  loss_giou_aux_4: 1.0981 (1.1443)  loss_giou_dn_0: 1.1688 (1.1848)  loss_giou_dn_1: 1.1082 (1.1233)  loss_giou_dn_2: 1.0735 (1.0947)  loss_giou_dn_3: 1.0633 (1.0801)  loss_giou_dn_4: 1.0573 (1.0699)  loss_giou_dn_5: 1.0547 (1.0695)  loss_giou_enc_0: 1.2858 (1.2830)  loss_vfl: 1.0405 (1.0742)  loss_vfl_aux_0: 1.0422 (1.0490)  loss_vfl_aux_1: 1.0232 (1.0554)  loss_vfl_aux_2: 1.0264 (1.0595)  loss_vfl_aux_3: 1.0522 (1.0652)  loss_vfl_aux_4: 1.0615 (1.0768)  loss_vfl_dn_0: 0.4816 (0.4801)  loss_vfl_dn_1: 0.5088 (0.5126)  loss_vfl_dn_2: 0.5283 (0.5400)  loss_vfl_dn_3: 0.5525 (0.5671)  loss_vfl_dn_4: 0.5815 (0.5957)  loss_vfl_dn_5: 0.6064 (0.6113)  loss_vfl_enc_0: 0.9329 (0.9222)  time: 0.9748  data: 0.0327  max mem: 10356\r\n",
      "Epoch: [25] Total time: 0:01:24 (1.0650 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 30.5815 (30.7222)  loss_bbox: 0.3690 (0.3739)  loss_bbox_aux_0: 0.3899 (0.4021)  loss_bbox_aux_1: 0.3874 (0.3929)  loss_bbox_aux_2: 0.4018 (0.3848)  loss_bbox_aux_3: 0.3763 (0.3806)  loss_bbox_aux_4: 0.3659 (0.3760)  loss_bbox_dn_0: 0.4475 (0.4470)  loss_bbox_dn_1: 0.4337 (0.4247)  loss_bbox_dn_2: 0.4267 (0.4138)  loss_bbox_dn_3: 0.4187 (0.4075)  loss_bbox_dn_4: 0.4101 (0.4035)  loss_bbox_dn_5: 0.4082 (0.4027)  loss_bbox_enc_0: 0.4647 (0.4503)  loss_giou: 1.0940 (1.1447)  loss_giou_aux_0: 1.1528 (1.1845)  loss_giou_aux_1: 1.1333 (1.1682)  loss_giou_aux_2: 1.1094 (1.1547)  loss_giou_aux_3: 1.1120 (1.1518)  loss_giou_aux_4: 1.0981 (1.1443)  loss_giou_dn_0: 1.1688 (1.1848)  loss_giou_dn_1: 1.1082 (1.1233)  loss_giou_dn_2: 1.0735 (1.0947)  loss_giou_dn_3: 1.0633 (1.0801)  loss_giou_dn_4: 1.0573 (1.0699)  loss_giou_dn_5: 1.0547 (1.0695)  loss_giou_enc_0: 1.2858 (1.2830)  loss_vfl: 1.0405 (1.0742)  loss_vfl_aux_0: 1.0422 (1.0490)  loss_vfl_aux_1: 1.0232 (1.0554)  loss_vfl_aux_2: 1.0264 (1.0595)  loss_vfl_aux_3: 1.0522 (1.0652)  loss_vfl_aux_4: 1.0615 (1.0768)  loss_vfl_dn_0: 0.4816 (0.4801)  loss_vfl_dn_1: 0.5088 (0.5126)  loss_vfl_dn_2: 0.5283 (0.5400)  loss_vfl_dn_3: 0.5525 (0.5671)  loss_vfl_dn_4: 0.5815 (0.5957)  loss_vfl_dn_5: 0.6064 (0.6113)  loss_vfl_enc_0: 0.9329 (0.9222)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.1475  data: 1.1692  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0804  data: 0.2135  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0989 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.013\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.019\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.014\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.043\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.028\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.105\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.160\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.167\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.057\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.255\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.230\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.265\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.173\r\n",
      "best_stat: {'epoch': 25, 'coco_eval_bbox': 0.01283261920613831}\r\n",
      "Epoch: [26]  [ 0/79]  eta: 0:05:41  lr: 0.000020  loss: 30.4391 (30.4391)  loss_bbox: 0.2629 (0.2629)  loss_bbox_aux_0: 0.3053 (0.3053)  loss_bbox_aux_1: 0.2866 (0.2866)  loss_bbox_aux_2: 0.2714 (0.2714)  loss_bbox_aux_3: 0.2800 (0.2800)  loss_bbox_aux_4: 0.2616 (0.2616)  loss_bbox_dn_0: 0.5791 (0.5791)  loss_bbox_dn_1: 0.5376 (0.5376)  loss_bbox_dn_2: 0.5153 (0.5153)  loss_bbox_dn_3: 0.5020 (0.5020)  loss_bbox_dn_4: 0.4901 (0.4901)  loss_bbox_dn_5: 0.4884 (0.4884)  loss_bbox_enc_0: 0.3998 (0.3998)  loss_giou: 0.8163 (0.8163)  loss_giou_aux_0: 0.9090 (0.9090)  loss_giou_aux_1: 0.8956 (0.8956)  loss_giou_aux_2: 0.8667 (0.8667)  loss_giou_aux_3: 0.8652 (0.8652)  loss_giou_aux_4: 0.8208 (0.8208)  loss_giou_dn_0: 1.1376 (1.1376)  loss_giou_dn_1: 1.0578 (1.0578)  loss_giou_dn_2: 1.0184 (1.0184)  loss_giou_dn_3: 1.0033 (1.0033)  loss_giou_dn_4: 0.9786 (0.9786)  loss_giou_dn_5: 0.9778 (0.9778)  loss_giou_enc_0: 1.0763 (1.0763)  loss_vfl: 1.3977 (1.3977)  loss_vfl_aux_0: 1.3718 (1.3718)  loss_vfl_aux_1: 1.3325 (1.3325)  loss_vfl_aux_2: 1.3132 (1.3132)  loss_vfl_aux_3: 1.3098 (1.3098)  loss_vfl_aux_4: 1.3752 (1.3752)  loss_vfl_dn_0: 0.4943 (0.4943)  loss_vfl_dn_1: 0.5425 (0.5425)  loss_vfl_dn_2: 0.5781 (0.5781)  loss_vfl_dn_3: 0.6178 (0.6178)  loss_vfl_dn_4: 0.6461 (0.6461)  loss_vfl_dn_5: 0.6693 (0.6693)  loss_vfl_enc_0: 1.1873 (1.1873)  time: 4.3267  data: 2.9775  max mem: 10356\r\n",
      "Epoch: [26]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 30.9466 (30.7059)  loss_bbox: 0.3604 (0.3723)  loss_bbox_aux_0: 0.3710 (0.3995)  loss_bbox_aux_1: 0.3715 (0.3917)  loss_bbox_aux_2: 0.3610 (0.3832)  loss_bbox_aux_3: 0.3724 (0.3807)  loss_bbox_aux_4: 0.3692 (0.3737)  loss_bbox_dn_0: 0.4447 (0.4393)  loss_bbox_dn_1: 0.4249 (0.4166)  loss_bbox_dn_2: 0.4168 (0.4055)  loss_bbox_dn_3: 0.4191 (0.3994)  loss_bbox_dn_4: 0.4211 (0.3956)  loss_bbox_dn_5: 0.4222 (0.3951)  loss_bbox_enc_0: 0.4264 (0.4493)  loss_giou: 1.1045 (1.1435)  loss_giou_aux_0: 1.1458 (1.1746)  loss_giou_aux_1: 1.1178 (1.1682)  loss_giou_aux_2: 1.1317 (1.1585)  loss_giou_aux_3: 1.1304 (1.1512)  loss_giou_aux_4: 1.1246 (1.1466)  loss_giou_dn_0: 1.1784 (1.1891)  loss_giou_dn_1: 1.1135 (1.1268)  loss_giou_dn_2: 1.0808 (1.0956)  loss_giou_dn_3: 1.0690 (1.0798)  loss_giou_dn_4: 1.0536 (1.0687)  loss_giou_dn_5: 1.0521 (1.0675)  loss_giou_enc_0: 1.2345 (1.2781)  loss_vfl: 1.0537 (1.0820)  loss_vfl_aux_0: 1.0576 (1.0616)  loss_vfl_aux_1: 1.0439 (1.0590)  loss_vfl_aux_2: 1.0066 (1.0647)  loss_vfl_aux_3: 1.0713 (1.0730)  loss_vfl_aux_4: 1.0457 (1.0690)  loss_vfl_dn_0: 0.4778 (0.4786)  loss_vfl_dn_1: 0.5056 (0.5110)  loss_vfl_dn_2: 0.5437 (0.5387)  loss_vfl_dn_3: 0.5652 (0.5687)  loss_vfl_dn_4: 0.5917 (0.5951)  loss_vfl_dn_5: 0.6158 (0.6141)  loss_vfl_enc_0: 0.8992 (0.9403)  time: 0.9979  data: 0.0314  max mem: 10356\r\n",
      "Epoch: [26] Total time: 0:01:25 (1.0808 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 30.9466 (30.7059)  loss_bbox: 0.3604 (0.3723)  loss_bbox_aux_0: 0.3710 (0.3995)  loss_bbox_aux_1: 0.3715 (0.3917)  loss_bbox_aux_2: 0.3610 (0.3832)  loss_bbox_aux_3: 0.3724 (0.3807)  loss_bbox_aux_4: 0.3692 (0.3737)  loss_bbox_dn_0: 0.4447 (0.4393)  loss_bbox_dn_1: 0.4249 (0.4166)  loss_bbox_dn_2: 0.4168 (0.4055)  loss_bbox_dn_3: 0.4191 (0.3994)  loss_bbox_dn_4: 0.4211 (0.3956)  loss_bbox_dn_5: 0.4222 (0.3951)  loss_bbox_enc_0: 0.4264 (0.4493)  loss_giou: 1.1045 (1.1435)  loss_giou_aux_0: 1.1458 (1.1746)  loss_giou_aux_1: 1.1178 (1.1682)  loss_giou_aux_2: 1.1317 (1.1585)  loss_giou_aux_3: 1.1304 (1.1512)  loss_giou_aux_4: 1.1246 (1.1466)  loss_giou_dn_0: 1.1784 (1.1891)  loss_giou_dn_1: 1.1135 (1.1268)  loss_giou_dn_2: 1.0808 (1.0956)  loss_giou_dn_3: 1.0690 (1.0798)  loss_giou_dn_4: 1.0536 (1.0687)  loss_giou_dn_5: 1.0521 (1.0675)  loss_giou_enc_0: 1.2345 (1.2781)  loss_vfl: 1.0537 (1.0820)  loss_vfl_aux_0: 1.0576 (1.0616)  loss_vfl_aux_1: 1.0439 (1.0590)  loss_vfl_aux_2: 1.0066 (1.0647)  loss_vfl_aux_3: 1.0713 (1.0730)  loss_vfl_aux_4: 1.0457 (1.0690)  loss_vfl_dn_0: 0.4778 (0.4786)  loss_vfl_dn_1: 0.5056 (0.5110)  loss_vfl_dn_2: 0.5437 (0.5387)  loss_vfl_dn_3: 0.5652 (0.5687)  loss_vfl_dn_4: 0.5917 (0.5951)  loss_vfl_dn_5: 0.6158 (0.6141)  loss_vfl_enc_0: 0.8992 (0.9403)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.2800  data: 1.3286  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0750  data: 0.2215  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0935 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.012\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.017\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.013\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.041\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.016\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.104\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.171\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.178\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.052\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.257\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.256\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.262\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.196\r\n",
      "best_stat: {'epoch': 25, 'coco_eval_bbox': 0.01283261920613831}\r\n",
      "Epoch: [27]  [ 0/79]  eta: 0:06:09  lr: 0.000020  loss: 34.0641 (34.0641)  loss_bbox: 0.4372 (0.4372)  loss_bbox_aux_0: 0.4769 (0.4769)  loss_bbox_aux_1: 0.4608 (0.4608)  loss_bbox_aux_2: 0.4429 (0.4429)  loss_bbox_aux_3: 0.4608 (0.4608)  loss_bbox_aux_4: 0.4205 (0.4205)  loss_bbox_dn_0: 0.6909 (0.6909)  loss_bbox_dn_1: 0.6728 (0.6728)  loss_bbox_dn_2: 0.6665 (0.6665)  loss_bbox_dn_3: 0.6571 (0.6571)  loss_bbox_dn_4: 0.6561 (0.6561)  loss_bbox_dn_5: 0.6573 (0.6573)  loss_bbox_enc_0: 0.5146 (0.5146)  loss_giou: 0.9414 (0.9414)  loss_giou_aux_0: 1.0282 (1.0282)  loss_giou_aux_1: 1.0200 (1.0200)  loss_giou_aux_2: 0.9938 (0.9938)  loss_giou_aux_3: 0.9609 (0.9609)  loss_giou_aux_4: 0.9709 (0.9709)  loss_giou_dn_0: 1.1931 (1.1931)  loss_giou_dn_1: 1.1348 (1.1348)  loss_giou_dn_2: 1.0985 (1.0985)  loss_giou_dn_3: 1.0775 (1.0775)  loss_giou_dn_4: 1.0665 (1.0665)  loss_giou_dn_5: 1.0648 (1.0648)  loss_giou_enc_0: 1.1322 (1.1322)  loss_vfl: 1.3799 (1.3799)  loss_vfl_aux_0: 1.2966 (1.2966)  loss_vfl_aux_1: 1.3208 (1.3208)  loss_vfl_aux_2: 1.4268 (1.4268)  loss_vfl_aux_3: 1.4082 (1.4082)  loss_vfl_aux_4: 1.4370 (1.4370)  loss_vfl_dn_0: 0.5226 (0.5226)  loss_vfl_dn_1: 0.5736 (0.5736)  loss_vfl_dn_2: 0.6311 (0.6311)  loss_vfl_dn_3: 0.6633 (0.6633)  loss_vfl_dn_4: 0.6758 (0.6758)  loss_vfl_dn_5: 0.6763 (0.6763)  loss_vfl_enc_0: 1.1553 (1.1553)  time: 4.6790  data: 2.9919  max mem: 10356\r\n",
      "Epoch: [27]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 30.3435 (30.4361)  loss_bbox: 0.3505 (0.3616)  loss_bbox_aux_0: 0.3843 (0.3904)  loss_bbox_aux_1: 0.3740 (0.3805)  loss_bbox_aux_2: 0.3553 (0.3738)  loss_bbox_aux_3: 0.3512 (0.3699)  loss_bbox_aux_4: 0.3419 (0.3635)  loss_bbox_dn_0: 0.4689 (0.4236)  loss_bbox_dn_1: 0.4567 (0.4013)  loss_bbox_dn_2: 0.4506 (0.3902)  loss_bbox_dn_3: 0.4458 (0.3837)  loss_bbox_dn_4: 0.4421 (0.3798)  loss_bbox_dn_5: 0.4417 (0.3792)  loss_bbox_enc_0: 0.4455 (0.4338)  loss_giou: 1.0838 (1.1293)  loss_giou_aux_0: 1.1277 (1.1667)  loss_giou_aux_1: 1.0995 (1.1558)  loss_giou_aux_2: 1.0949 (1.1436)  loss_giou_aux_3: 1.0833 (1.1370)  loss_giou_aux_4: 1.0786 (1.1332)  loss_giou_dn_0: 1.1688 (1.1771)  loss_giou_dn_1: 1.1096 (1.1108)  loss_giou_dn_2: 1.0876 (1.0804)  loss_giou_dn_3: 1.0670 (1.0640)  loss_giou_dn_4: 1.0606 (1.0544)  loss_giou_dn_5: 1.0588 (1.0530)  loss_giou_enc_0: 1.1788 (1.2630)  loss_vfl: 1.0818 (1.0839)  loss_vfl_aux_0: 1.1013 (1.0634)  loss_vfl_aux_1: 1.1084 (1.0627)  loss_vfl_aux_2: 1.1309 (1.0709)  loss_vfl_aux_3: 1.1179 (1.0787)  loss_vfl_aux_4: 1.1123 (1.0814)  loss_vfl_dn_0: 0.4822 (0.4842)  loss_vfl_dn_1: 0.5135 (0.5196)  loss_vfl_dn_2: 0.5415 (0.5467)  loss_vfl_dn_3: 0.5596 (0.5762)  loss_vfl_dn_4: 0.5891 (0.5987)  loss_vfl_dn_5: 0.6062 (0.6167)  loss_vfl_enc_0: 0.9512 (0.9534)  time: 1.0048  data: 0.0316  max mem: 10356\r\n",
      "Epoch: [27] Total time: 0:01:27 (1.1033 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 30.3435 (30.4361)  loss_bbox: 0.3505 (0.3616)  loss_bbox_aux_0: 0.3843 (0.3904)  loss_bbox_aux_1: 0.3740 (0.3805)  loss_bbox_aux_2: 0.3553 (0.3738)  loss_bbox_aux_3: 0.3512 (0.3699)  loss_bbox_aux_4: 0.3419 (0.3635)  loss_bbox_dn_0: 0.4689 (0.4236)  loss_bbox_dn_1: 0.4567 (0.4013)  loss_bbox_dn_2: 0.4506 (0.3902)  loss_bbox_dn_3: 0.4458 (0.3837)  loss_bbox_dn_4: 0.4421 (0.3798)  loss_bbox_dn_5: 0.4417 (0.3792)  loss_bbox_enc_0: 0.4455 (0.4338)  loss_giou: 1.0838 (1.1293)  loss_giou_aux_0: 1.1277 (1.1667)  loss_giou_aux_1: 1.0995 (1.1558)  loss_giou_aux_2: 1.0949 (1.1436)  loss_giou_aux_3: 1.0833 (1.1370)  loss_giou_aux_4: 1.0786 (1.1332)  loss_giou_dn_0: 1.1688 (1.1771)  loss_giou_dn_1: 1.1096 (1.1108)  loss_giou_dn_2: 1.0876 (1.0804)  loss_giou_dn_3: 1.0670 (1.0640)  loss_giou_dn_4: 1.0606 (1.0544)  loss_giou_dn_5: 1.0588 (1.0530)  loss_giou_enc_0: 1.1788 (1.2630)  loss_vfl: 1.0818 (1.0839)  loss_vfl_aux_0: 1.1013 (1.0634)  loss_vfl_aux_1: 1.1084 (1.0627)  loss_vfl_aux_2: 1.1309 (1.0709)  loss_vfl_aux_3: 1.1179 (1.0787)  loss_vfl_aux_4: 1.1123 (1.0814)  loss_vfl_dn_0: 0.4822 (0.4842)  loss_vfl_dn_1: 0.5135 (0.5196)  loss_vfl_dn_2: 0.5415 (0.5467)  loss_vfl_dn_3: 0.5596 (0.5762)  loss_vfl_dn_4: 0.5891 (0.5987)  loss_vfl_dn_5: 0.6062 (0.6167)  loss_vfl_enc_0: 0.9512 (0.9534)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.4425  data: 1.4983  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0863  data: 0.2273  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1040 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.015\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.010\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.024\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.018\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.126\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.174\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.182\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.260\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.248\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.273\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.189\r\n",
      "best_stat: {'epoch': 25, 'coco_eval_bbox': 0.01283261920613831}\r\n",
      "Epoch: [28]  [ 0/79]  eta: 0:06:26  lr: 0.000020  loss: 30.5339 (30.5339)  loss_bbox: 0.4647 (0.4647)  loss_bbox_aux_0: 0.4681 (0.4681)  loss_bbox_aux_1: 0.4731 (0.4731)  loss_bbox_aux_2: 0.4705 (0.4705)  loss_bbox_aux_3: 0.4648 (0.4648)  loss_bbox_aux_4: 0.4693 (0.4693)  loss_bbox_dn_0: 0.3210 (0.3210)  loss_bbox_dn_1: 0.3119 (0.3119)  loss_bbox_dn_2: 0.3060 (0.3060)  loss_bbox_dn_3: 0.3033 (0.3033)  loss_bbox_dn_4: 0.2998 (0.2998)  loss_bbox_dn_5: 0.3003 (0.3003)  loss_bbox_enc_0: 0.4901 (0.4901)  loss_giou: 1.5711 (1.5711)  loss_giou_aux_0: 1.5515 (1.5515)  loss_giou_aux_1: 1.5567 (1.5567)  loss_giou_aux_2: 1.5586 (1.5586)  loss_giou_aux_3: 1.5808 (1.5808)  loss_giou_aux_4: 1.5769 (1.5769)  loss_giou_dn_0: 1.3059 (1.3059)  loss_giou_dn_1: 1.2886 (1.2886)  loss_giou_dn_2: 1.2801 (1.2801)  loss_giou_dn_3: 1.2746 (1.2746)  loss_giou_dn_4: 1.2714 (1.2714)  loss_giou_dn_5: 1.2737 (1.2737)  loss_giou_enc_0: 1.6356 (1.6356)  loss_vfl: 0.5852 (0.5852)  loss_vfl_aux_0: 0.6086 (0.6086)  loss_vfl_aux_1: 0.6111 (0.6111)  loss_vfl_aux_2: 0.5803 (0.5803)  loss_vfl_aux_3: 0.5719 (0.5719)  loss_vfl_aux_4: 0.5795 (0.5795)  loss_vfl_dn_0: 0.4131 (0.4131)  loss_vfl_dn_1: 0.4172 (0.4172)  loss_vfl_dn_2: 0.4224 (0.4224)  loss_vfl_dn_3: 0.4390 (0.4390)  loss_vfl_dn_4: 0.4503 (0.4503)  loss_vfl_dn_5: 0.4572 (0.4572)  loss_vfl_enc_0: 0.5299 (0.5299)  time: 4.8881  data: 2.6273  max mem: 10356\r\n",
      "Epoch: [28]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 30.7693 (30.5166)  loss_bbox: 0.3712 (0.3656)  loss_bbox_aux_0: 0.4005 (0.3931)  loss_bbox_aux_1: 0.4203 (0.3855)  loss_bbox_aux_2: 0.4051 (0.3741)  loss_bbox_aux_3: 0.3793 (0.3728)  loss_bbox_aux_4: 0.3718 (0.3673)  loss_bbox_dn_0: 0.4228 (0.4515)  loss_bbox_dn_1: 0.4035 (0.4280)  loss_bbox_dn_2: 0.3841 (0.4158)  loss_bbox_dn_3: 0.3783 (0.4087)  loss_bbox_dn_4: 0.3758 (0.4044)  loss_bbox_dn_5: 0.3753 (0.4035)  loss_bbox_enc_0: 0.4443 (0.4365)  loss_giou: 1.1138 (1.1027)  loss_giou_aux_0: 1.1904 (1.1419)  loss_giou_aux_1: 1.1327 (1.1262)  loss_giou_aux_2: 1.1205 (1.1110)  loss_giou_aux_3: 1.1194 (1.1104)  loss_giou_aux_4: 1.1164 (1.1024)  loss_giou_dn_0: 1.1596 (1.1721)  loss_giou_dn_1: 1.1002 (1.1062)  loss_giou_dn_2: 1.0537 (1.0734)  loss_giou_dn_3: 1.0315 (1.0568)  loss_giou_dn_4: 1.0245 (1.0458)  loss_giou_dn_5: 1.0230 (1.0447)  loss_giou_enc_0: 1.2379 (1.2360)  loss_vfl: 1.0510 (1.1131)  loss_vfl_aux_0: 1.0322 (1.0755)  loss_vfl_aux_1: 0.9968 (1.0797)  loss_vfl_aux_2: 1.0354 (1.0978)  loss_vfl_aux_3: 1.0532 (1.1026)  loss_vfl_aux_4: 1.0708 (1.1111)  loss_vfl_dn_0: 0.4845 (0.4853)  loss_vfl_dn_1: 0.5197 (0.5169)  loss_vfl_dn_2: 0.5513 (0.5448)  loss_vfl_dn_3: 0.5776 (0.5736)  loss_vfl_dn_4: 0.6105 (0.6006)  loss_vfl_dn_5: 0.6240 (0.6178)  loss_vfl_enc_0: 0.9387 (0.9616)  time: 0.9915  data: 0.0318  max mem: 10356\r\n",
      "Epoch: [28] Total time: 0:01:25 (1.0780 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 30.7693 (30.5166)  loss_bbox: 0.3712 (0.3656)  loss_bbox_aux_0: 0.4005 (0.3931)  loss_bbox_aux_1: 0.4203 (0.3855)  loss_bbox_aux_2: 0.4051 (0.3741)  loss_bbox_aux_3: 0.3793 (0.3728)  loss_bbox_aux_4: 0.3718 (0.3673)  loss_bbox_dn_0: 0.4228 (0.4515)  loss_bbox_dn_1: 0.4035 (0.4280)  loss_bbox_dn_2: 0.3841 (0.4158)  loss_bbox_dn_3: 0.3783 (0.4087)  loss_bbox_dn_4: 0.3758 (0.4044)  loss_bbox_dn_5: 0.3753 (0.4035)  loss_bbox_enc_0: 0.4443 (0.4365)  loss_giou: 1.1138 (1.1027)  loss_giou_aux_0: 1.1904 (1.1419)  loss_giou_aux_1: 1.1327 (1.1262)  loss_giou_aux_2: 1.1205 (1.1110)  loss_giou_aux_3: 1.1194 (1.1104)  loss_giou_aux_4: 1.1164 (1.1024)  loss_giou_dn_0: 1.1596 (1.1721)  loss_giou_dn_1: 1.1002 (1.1062)  loss_giou_dn_2: 1.0537 (1.0734)  loss_giou_dn_3: 1.0315 (1.0568)  loss_giou_dn_4: 1.0245 (1.0458)  loss_giou_dn_5: 1.0230 (1.0447)  loss_giou_enc_0: 1.2379 (1.2360)  loss_vfl: 1.0510 (1.1131)  loss_vfl_aux_0: 1.0322 (1.0755)  loss_vfl_aux_1: 0.9968 (1.0797)  loss_vfl_aux_2: 1.0354 (1.0978)  loss_vfl_aux_3: 1.0532 (1.1026)  loss_vfl_aux_4: 1.0708 (1.1111)  loss_vfl_dn_0: 0.4845 (0.4853)  loss_vfl_dn_1: 0.5197 (0.5169)  loss_vfl_dn_2: 0.5513 (0.5448)  loss_vfl_dn_3: 0.5776 (0.5736)  loss_vfl_dn_4: 0.6105 (0.6006)  loss_vfl_dn_5: 0.6240 (0.6178)  loss_vfl_enc_0: 0.9387 (0.9616)\r\n",
      "Test:  [0/8]  eta: 0:00:20    time: 2.5266  data: 1.5792  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0916  data: 0.2392  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1090 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.19s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.012\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.019\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.014\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.032\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.027\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.108\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.175\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.179\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.067\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.256\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.247\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.280\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.187\r\n",
      "best_stat: {'epoch': 25, 'coco_eval_bbox': 0.01283261920613831}\r\n",
      "Epoch: [29]  [ 0/79]  eta: 0:07:03  lr: 0.000020  loss: 28.6029 (28.6029)  loss_bbox: 0.3419 (0.3419)  loss_bbox_aux_0: 0.3342 (0.3342)  loss_bbox_aux_1: 0.3450 (0.3450)  loss_bbox_aux_2: 0.3495 (0.3495)  loss_bbox_aux_3: 0.3385 (0.3385)  loss_bbox_aux_4: 0.3338 (0.3338)  loss_bbox_dn_0: 0.2246 (0.2246)  loss_bbox_dn_1: 0.2074 (0.2074)  loss_bbox_dn_2: 0.1985 (0.1985)  loss_bbox_dn_3: 0.1936 (0.1936)  loss_bbox_dn_4: 0.1904 (0.1904)  loss_bbox_dn_5: 0.1898 (0.1898)  loss_bbox_enc_0: 0.3429 (0.3429)  loss_giou: 1.4181 (1.4181)  loss_giou_aux_0: 1.4433 (1.4433)  loss_giou_aux_1: 1.4393 (1.4393)  loss_giou_aux_2: 1.4422 (1.4422)  loss_giou_aux_3: 1.4303 (1.4303)  loss_giou_aux_4: 1.4259 (1.4259)  loss_giou_dn_0: 1.2856 (1.2856)  loss_giou_dn_1: 1.2571 (1.2571)  loss_giou_dn_2: 1.2299 (1.2299)  loss_giou_dn_3: 1.2249 (1.2249)  loss_giou_dn_4: 1.2233 (1.2233)  loss_giou_dn_5: 1.2199 (1.2199)  loss_giou_enc_0: 1.5669 (1.5669)  loss_vfl: 0.6687 (0.6687)  loss_vfl_aux_0: 0.6572 (0.6572)  loss_vfl_aux_1: 0.6494 (0.6494)  loss_vfl_aux_2: 0.6812 (0.6812)  loss_vfl_aux_3: 0.6919 (0.6919)  loss_vfl_aux_4: 0.6951 (0.6951)  loss_vfl_dn_0: 0.4219 (0.4219)  loss_vfl_dn_1: 0.4219 (0.4219)  loss_vfl_dn_2: 0.4391 (0.4391)  loss_vfl_dn_3: 0.4568 (0.4568)  loss_vfl_dn_4: 0.4851 (0.4851)  loss_vfl_dn_5: 0.5006 (0.5006)  loss_vfl_enc_0: 0.6375 (0.6375)  time: 5.3580  data: 3.3034  max mem: 10356\r\n",
      "Epoch: [29]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 30.6701 (30.6059)  loss_bbox: 0.3464 (0.3755)  loss_bbox_aux_0: 0.3719 (0.4057)  loss_bbox_aux_1: 0.3551 (0.3937)  loss_bbox_aux_2: 0.3618 (0.3892)  loss_bbox_aux_3: 0.3612 (0.3810)  loss_bbox_aux_4: 0.3455 (0.3773)  loss_bbox_dn_0: 0.4208 (0.4419)  loss_bbox_dn_1: 0.4082 (0.4163)  loss_bbox_dn_2: 0.3985 (0.4036)  loss_bbox_dn_3: 0.3905 (0.3960)  loss_bbox_dn_4: 0.3848 (0.3912)  loss_bbox_dn_5: 0.3834 (0.3903)  loss_bbox_enc_0: 0.4433 (0.4503)  loss_giou: 1.0343 (1.1313)  loss_giou_aux_0: 1.1115 (1.1679)  loss_giou_aux_1: 1.0551 (1.1570)  loss_giou_aux_2: 1.0485 (1.1442)  loss_giou_aux_3: 1.0424 (1.1382)  loss_giou_aux_4: 1.0160 (1.1303)  loss_giou_dn_0: 1.1619 (1.1691)  loss_giou_dn_1: 1.0728 (1.0991)  loss_giou_dn_2: 1.0474 (1.0668)  loss_giou_dn_3: 1.0279 (1.0498)  loss_giou_dn_4: 1.0178 (1.0381)  loss_giou_dn_5: 1.0170 (1.0367)  loss_giou_enc_0: 1.2174 (1.2605)  loss_vfl: 1.0991 (1.0864)  loss_vfl_aux_0: 1.0422 (1.0779)  loss_vfl_aux_1: 1.0637 (1.0709)  loss_vfl_aux_2: 1.0911 (1.0733)  loss_vfl_aux_3: 1.1094 (1.0799)  loss_vfl_aux_4: 1.1167 (1.0844)  loss_vfl_dn_0: 0.4824 (0.4896)  loss_vfl_dn_1: 0.5331 (0.5240)  loss_vfl_dn_2: 0.5593 (0.5491)  loss_vfl_dn_3: 0.5879 (0.5777)  loss_vfl_dn_4: 0.6306 (0.6043)  loss_vfl_dn_5: 0.6407 (0.6201)  loss_vfl_enc_0: 0.9443 (0.9672)  time: 1.0623  data: 0.0319  max mem: 10356\r\n",
      "Epoch: [29] Total time: 0:01:27 (1.1026 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 30.6701 (30.6059)  loss_bbox: 0.3464 (0.3755)  loss_bbox_aux_0: 0.3719 (0.4057)  loss_bbox_aux_1: 0.3551 (0.3937)  loss_bbox_aux_2: 0.3618 (0.3892)  loss_bbox_aux_3: 0.3612 (0.3810)  loss_bbox_aux_4: 0.3455 (0.3773)  loss_bbox_dn_0: 0.4208 (0.4419)  loss_bbox_dn_1: 0.4082 (0.4163)  loss_bbox_dn_2: 0.3985 (0.4036)  loss_bbox_dn_3: 0.3905 (0.3960)  loss_bbox_dn_4: 0.3848 (0.3912)  loss_bbox_dn_5: 0.3834 (0.3903)  loss_bbox_enc_0: 0.4433 (0.4503)  loss_giou: 1.0343 (1.1313)  loss_giou_aux_0: 1.1115 (1.1679)  loss_giou_aux_1: 1.0551 (1.1570)  loss_giou_aux_2: 1.0485 (1.1442)  loss_giou_aux_3: 1.0424 (1.1382)  loss_giou_aux_4: 1.0160 (1.1303)  loss_giou_dn_0: 1.1619 (1.1691)  loss_giou_dn_1: 1.0728 (1.0991)  loss_giou_dn_2: 1.0474 (1.0668)  loss_giou_dn_3: 1.0279 (1.0498)  loss_giou_dn_4: 1.0178 (1.0381)  loss_giou_dn_5: 1.0170 (1.0367)  loss_giou_enc_0: 1.2174 (1.2605)  loss_vfl: 1.0991 (1.0864)  loss_vfl_aux_0: 1.0422 (1.0779)  loss_vfl_aux_1: 1.0637 (1.0709)  loss_vfl_aux_2: 1.0911 (1.0733)  loss_vfl_aux_3: 1.1094 (1.0799)  loss_vfl_aux_4: 1.1167 (1.0844)  loss_vfl_dn_0: 0.4824 (0.4896)  loss_vfl_dn_1: 0.5331 (0.5240)  loss_vfl_dn_2: 0.5593 (0.5491)  loss_vfl_dn_3: 0.5879 (0.5777)  loss_vfl_dn_4: 0.6306 (0.6043)  loss_vfl_dn_5: 0.6407 (0.6201)  loss_vfl_enc_0: 0.9443 (0.9672)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.4098  data: 1.4508  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0916  data: 0.2315  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1087 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.014\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.020\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.016\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.015\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.033\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.023\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.178\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.186\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.059\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.277\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.240\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.267\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.191\r\n",
      "best_stat: {'epoch': 29, 'coco_eval_bbox': 0.013887634387616738}\r\n",
      "Epoch: [30]  [ 0/79]  eta: 0:05:44  lr: 0.000020  loss: 29.7733 (29.7733)  loss_bbox: 0.3836 (0.3836)  loss_bbox_aux_0: 0.4054 (0.4054)  loss_bbox_aux_1: 0.3903 (0.3903)  loss_bbox_aux_2: 0.4019 (0.4019)  loss_bbox_aux_3: 0.3888 (0.3888)  loss_bbox_aux_4: 0.3859 (0.3859)  loss_bbox_dn_0: 0.2417 (0.2417)  loss_bbox_dn_1: 0.2263 (0.2263)  loss_bbox_dn_2: 0.2180 (0.2180)  loss_bbox_dn_3: 0.2126 (0.2126)  loss_bbox_dn_4: 0.2097 (0.2097)  loss_bbox_dn_5: 0.2087 (0.2087)  loss_bbox_enc_0: 0.4185 (0.4185)  loss_giou: 1.6079 (1.6079)  loss_giou_aux_0: 1.6049 (1.6049)  loss_giou_aux_1: 1.6189 (1.6189)  loss_giou_aux_2: 1.5764 (1.5764)  loss_giou_aux_3: 1.5734 (1.5734)  loss_giou_aux_4: 1.5900 (1.5900)  loss_giou_dn_0: 1.2841 (1.2841)  loss_giou_dn_1: 1.2390 (1.2390)  loss_giou_dn_2: 1.2193 (1.2193)  loss_giou_dn_3: 1.2216 (1.2216)  loss_giou_dn_4: 1.2225 (1.2225)  loss_giou_dn_5: 1.2346 (1.2346)  loss_giou_enc_0: 1.6519 (1.6519)  loss_vfl: 0.6438 (0.6438)  loss_vfl_aux_0: 0.6355 (0.6355)  loss_vfl_aux_1: 0.6406 (0.6406)  loss_vfl_aux_2: 0.6187 (0.6187)  loss_vfl_aux_3: 0.6489 (0.6489)  loss_vfl_aux_4: 0.6367 (0.6367)  loss_vfl_dn_0: 0.4089 (0.4089)  loss_vfl_dn_1: 0.4248 (0.4248)  loss_vfl_dn_2: 0.4327 (0.4327)  loss_vfl_dn_3: 0.4493 (0.4493)  loss_vfl_dn_4: 0.4694 (0.4694)  loss_vfl_dn_5: 0.4707 (0.4707)  loss_vfl_enc_0: 0.5576 (0.5576)  time: 4.3545  data: 3.3610  max mem: 10356\r\n",
      "Epoch: [30]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 30.4002 (30.2956)  loss_bbox: 0.3037 (0.3465)  loss_bbox_aux_0: 0.3425 (0.3766)  loss_bbox_aux_1: 0.3271 (0.3696)  loss_bbox_aux_2: 0.3162 (0.3580)  loss_bbox_aux_3: 0.2980 (0.3521)  loss_bbox_aux_4: 0.3060 (0.3473)  loss_bbox_dn_0: 0.3950 (0.4251)  loss_bbox_dn_1: 0.3674 (0.3989)  loss_bbox_dn_2: 0.3503 (0.3858)  loss_bbox_dn_3: 0.3412 (0.3777)  loss_bbox_dn_4: 0.3398 (0.3730)  loss_bbox_dn_5: 0.3400 (0.3721)  loss_bbox_enc_0: 0.4012 (0.4208)  loss_giou: 1.0634 (1.1217)  loss_giou_aux_0: 1.1658 (1.1624)  loss_giou_aux_1: 1.0943 (1.1443)  loss_giou_aux_2: 1.0835 (1.1333)  loss_giou_aux_3: 1.0616 (1.1286)  loss_giou_aux_4: 1.0600 (1.1215)  loss_giou_dn_0: 1.1571 (1.1753)  loss_giou_dn_1: 1.0873 (1.1070)  loss_giou_dn_2: 1.0668 (1.0760)  loss_giou_dn_3: 1.0598 (1.0603)  loss_giou_dn_4: 1.0466 (1.0494)  loss_giou_dn_5: 1.0459 (1.0491)  loss_giou_enc_0: 1.2332 (1.2541)  loss_vfl: 1.1060 (1.0947)  loss_vfl_aux_0: 0.9951 (1.0714)  loss_vfl_aux_1: 1.0710 (1.0734)  loss_vfl_aux_2: 1.1016 (1.0826)  loss_vfl_aux_3: 1.1130 (1.0927)  loss_vfl_aux_4: 1.1064 (1.0972)  loss_vfl_dn_0: 0.4899 (0.4870)  loss_vfl_dn_1: 0.5210 (0.5208)  loss_vfl_dn_2: 0.5537 (0.5455)  loss_vfl_dn_3: 0.5754 (0.5709)  loss_vfl_dn_4: 0.5958 (0.5960)  loss_vfl_dn_5: 0.6235 (0.6127)  loss_vfl_enc_0: 0.9187 (0.9639)  time: 1.0152  data: 0.0322  max mem: 10356\r\n",
      "Epoch: [30] Total time: 0:01:24 (1.0742 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 30.4002 (30.2956)  loss_bbox: 0.3037 (0.3465)  loss_bbox_aux_0: 0.3425 (0.3766)  loss_bbox_aux_1: 0.3271 (0.3696)  loss_bbox_aux_2: 0.3162 (0.3580)  loss_bbox_aux_3: 0.2980 (0.3521)  loss_bbox_aux_4: 0.3060 (0.3473)  loss_bbox_dn_0: 0.3950 (0.4251)  loss_bbox_dn_1: 0.3674 (0.3989)  loss_bbox_dn_2: 0.3503 (0.3858)  loss_bbox_dn_3: 0.3412 (0.3777)  loss_bbox_dn_4: 0.3398 (0.3730)  loss_bbox_dn_5: 0.3400 (0.3721)  loss_bbox_enc_0: 0.4012 (0.4208)  loss_giou: 1.0634 (1.1217)  loss_giou_aux_0: 1.1658 (1.1624)  loss_giou_aux_1: 1.0943 (1.1443)  loss_giou_aux_2: 1.0835 (1.1333)  loss_giou_aux_3: 1.0616 (1.1286)  loss_giou_aux_4: 1.0600 (1.1215)  loss_giou_dn_0: 1.1571 (1.1753)  loss_giou_dn_1: 1.0873 (1.1070)  loss_giou_dn_2: 1.0668 (1.0760)  loss_giou_dn_3: 1.0598 (1.0603)  loss_giou_dn_4: 1.0466 (1.0494)  loss_giou_dn_5: 1.0459 (1.0491)  loss_giou_enc_0: 1.2332 (1.2541)  loss_vfl: 1.1060 (1.0947)  loss_vfl_aux_0: 0.9951 (1.0714)  loss_vfl_aux_1: 1.0710 (1.0734)  loss_vfl_aux_2: 1.1016 (1.0826)  loss_vfl_aux_3: 1.1130 (1.0927)  loss_vfl_aux_4: 1.1064 (1.0972)  loss_vfl_dn_0: 0.4899 (0.4870)  loss_vfl_dn_1: 0.5210 (0.5208)  loss_vfl_dn_2: 0.5537 (0.5455)  loss_vfl_dn_3: 0.5754 (0.5709)  loss_vfl_dn_4: 0.5958 (0.5960)  loss_vfl_dn_5: 0.6235 (0.6127)  loss_vfl_enc_0: 0.9187 (0.9639)\r\n",
      "Test:  [0/8]  eta: 0:00:16    time: 2.1119  data: 1.1611  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0669  data: 0.2103  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0862 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.011\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.018\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.010\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.024\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.029\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.121\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.182\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.193\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.059\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.249\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.298\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.283\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.217\r\n",
      "best_stat: {'epoch': 29, 'coco_eval_bbox': 0.013887634387616738}\r\n",
      "Epoch: [31]  [ 0/79]  eta: 0:07:05  lr: 0.000020  loss: 30.7949 (30.7949)  loss_bbox: 0.3754 (0.3754)  loss_bbox_aux_0: 0.3976 (0.3976)  loss_bbox_aux_1: 0.3823 (0.3823)  loss_bbox_aux_2: 0.3769 (0.3769)  loss_bbox_aux_3: 0.3909 (0.3909)  loss_bbox_aux_4: 0.3881 (0.3881)  loss_bbox_dn_0: 0.4100 (0.4100)  loss_bbox_dn_1: 0.3899 (0.3899)  loss_bbox_dn_2: 0.3743 (0.3743)  loss_bbox_dn_3: 0.3622 (0.3622)  loss_bbox_dn_4: 0.3545 (0.3545)  loss_bbox_dn_5: 0.3527 (0.3527)  loss_bbox_enc_0: 0.4349 (0.4349)  loss_giou: 1.1578 (1.1578)  loss_giou_aux_0: 1.2054 (1.2054)  loss_giou_aux_1: 1.1740 (1.1740)  loss_giou_aux_2: 1.1601 (1.1601)  loss_giou_aux_3: 1.1473 (1.1473)  loss_giou_aux_4: 1.1502 (1.1502)  loss_giou_dn_0: 1.1682 (1.1682)  loss_giou_dn_1: 1.0817 (1.0817)  loss_giou_dn_2: 1.0325 (1.0325)  loss_giou_dn_3: 1.0211 (1.0211)  loss_giou_dn_4: 1.0102 (1.0102)  loss_giou_dn_5: 1.0130 (1.0130)  loss_giou_enc_0: 1.3209 (1.3209)  loss_vfl: 1.1165 (1.1165)  loss_vfl_aux_0: 1.0056 (1.0056)  loss_vfl_aux_1: 1.1555 (1.1555)  loss_vfl_aux_2: 1.1477 (1.1477)  loss_vfl_aux_3: 1.1628 (1.1628)  loss_vfl_aux_4: 1.1206 (1.1206)  loss_vfl_dn_0: 0.4976 (0.4976)  loss_vfl_dn_1: 0.5658 (0.5658)  loss_vfl_dn_2: 0.5868 (0.5868)  loss_vfl_dn_3: 0.6238 (0.6238)  loss_vfl_dn_4: 0.6353 (0.6353)  loss_vfl_dn_5: 0.6418 (0.6418)  loss_vfl_enc_0: 0.9028 (0.9028)  time: 5.3862  data: 2.6403  max mem: 10356\r\n",
      "Epoch: [31]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 30.4260 (30.2746)  loss_bbox: 0.3483 (0.3555)  loss_bbox_aux_0: 0.3697 (0.3826)  loss_bbox_aux_1: 0.3659 (0.3757)  loss_bbox_aux_2: 0.3471 (0.3680)  loss_bbox_aux_3: 0.3558 (0.3628)  loss_bbox_aux_4: 0.3427 (0.3569)  loss_bbox_dn_0: 0.4686 (0.4316)  loss_bbox_dn_1: 0.4322 (0.4060)  loss_bbox_dn_2: 0.4148 (0.3931)  loss_bbox_dn_3: 0.4042 (0.3859)  loss_bbox_dn_4: 0.3972 (0.3818)  loss_bbox_dn_5: 0.3964 (0.3812)  loss_bbox_enc_0: 0.4206 (0.4256)  loss_giou: 1.1002 (1.1037)  loss_giou_aux_0: 1.1122 (1.1462)  loss_giou_aux_1: 1.1034 (1.1353)  loss_giou_aux_2: 1.1106 (1.1224)  loss_giou_aux_3: 1.1322 (1.1129)  loss_giou_aux_4: 1.1079 (1.1065)  loss_giou_dn_0: 1.1462 (1.1598)  loss_giou_dn_1: 1.0673 (1.0884)  loss_giou_dn_2: 1.0138 (1.0563)  loss_giou_dn_3: 0.9947 (1.0405)  loss_giou_dn_4: 0.9772 (1.0302)  loss_giou_dn_5: 0.9755 (1.0297)  loss_giou_enc_0: 1.2347 (1.2361)  loss_vfl: 1.0771 (1.1064)  loss_vfl_aux_0: 1.0562 (1.0833)  loss_vfl_aux_1: 1.0630 (1.0762)  loss_vfl_aux_2: 1.0327 (1.0810)  loss_vfl_aux_3: 1.0845 (1.0931)  loss_vfl_aux_4: 1.0698 (1.1014)  loss_vfl_dn_0: 0.4913 (0.4952)  loss_vfl_dn_1: 0.5295 (0.5296)  loss_vfl_dn_2: 0.5468 (0.5534)  loss_vfl_dn_3: 0.5771 (0.5779)  loss_vfl_dn_4: 0.5942 (0.6012)  loss_vfl_dn_5: 0.5916 (0.6172)  loss_vfl_enc_0: 1.0366 (0.9843)  time: 0.9647  data: 0.0315  max mem: 10356\r\n",
      "Epoch: [31] Total time: 0:01:25 (1.0823 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 30.4260 (30.2746)  loss_bbox: 0.3483 (0.3555)  loss_bbox_aux_0: 0.3697 (0.3826)  loss_bbox_aux_1: 0.3659 (0.3757)  loss_bbox_aux_2: 0.3471 (0.3680)  loss_bbox_aux_3: 0.3558 (0.3628)  loss_bbox_aux_4: 0.3427 (0.3569)  loss_bbox_dn_0: 0.4686 (0.4316)  loss_bbox_dn_1: 0.4322 (0.4060)  loss_bbox_dn_2: 0.4148 (0.3931)  loss_bbox_dn_3: 0.4042 (0.3859)  loss_bbox_dn_4: 0.3972 (0.3818)  loss_bbox_dn_5: 0.3964 (0.3812)  loss_bbox_enc_0: 0.4206 (0.4256)  loss_giou: 1.1002 (1.1037)  loss_giou_aux_0: 1.1122 (1.1462)  loss_giou_aux_1: 1.1034 (1.1353)  loss_giou_aux_2: 1.1106 (1.1224)  loss_giou_aux_3: 1.1322 (1.1129)  loss_giou_aux_4: 1.1079 (1.1065)  loss_giou_dn_0: 1.1462 (1.1598)  loss_giou_dn_1: 1.0673 (1.0884)  loss_giou_dn_2: 1.0138 (1.0563)  loss_giou_dn_3: 0.9947 (1.0405)  loss_giou_dn_4: 0.9772 (1.0302)  loss_giou_dn_5: 0.9755 (1.0297)  loss_giou_enc_0: 1.2347 (1.2361)  loss_vfl: 1.0771 (1.1064)  loss_vfl_aux_0: 1.0562 (1.0833)  loss_vfl_aux_1: 1.0630 (1.0762)  loss_vfl_aux_2: 1.0327 (1.0810)  loss_vfl_aux_3: 1.0845 (1.0931)  loss_vfl_aux_4: 1.0698 (1.1014)  loss_vfl_dn_0: 0.4913 (0.4952)  loss_vfl_dn_1: 0.5295 (0.5296)  loss_vfl_dn_2: 0.5468 (0.5534)  loss_vfl_dn_3: 0.5771 (0.5779)  loss_vfl_dn_4: 0.5942 (0.6012)  loss_vfl_dn_5: 0.5916 (0.6172)  loss_vfl_enc_0: 1.0366 (0.9843)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.3923  data: 1.4524  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0957  data: 0.2303  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1140 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.19s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.013\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.020\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.014\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.035\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.017\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.118\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.173\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.182\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.054\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.262\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.251\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.299\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.183\r\n",
      "best_stat: {'epoch': 29, 'coco_eval_bbox': 0.013887634387616738}\r\n",
      "Epoch: [32]  [ 0/79]  eta: 0:06:17  lr: 0.000020  loss: 31.6496 (31.6496)  loss_bbox: 0.4326 (0.4326)  loss_bbox_aux_0: 0.4719 (0.4719)  loss_bbox_aux_1: 0.4677 (0.4677)  loss_bbox_aux_2: 0.4721 (0.4721)  loss_bbox_aux_3: 0.4829 (0.4829)  loss_bbox_aux_4: 0.4734 (0.4734)  loss_bbox_dn_0: 0.6811 (0.6811)  loss_bbox_dn_1: 0.6438 (0.6438)  loss_bbox_dn_2: 0.6246 (0.6246)  loss_bbox_dn_3: 0.6128 (0.6128)  loss_bbox_dn_4: 0.6046 (0.6046)  loss_bbox_dn_5: 0.6037 (0.6037)  loss_bbox_enc_0: 0.5587 (0.5587)  loss_giou: 0.9731 (0.9731)  loss_giou_aux_0: 1.0311 (1.0311)  loss_giou_aux_1: 0.9771 (0.9771)  loss_giou_aux_2: 0.9383 (0.9383)  loss_giou_aux_3: 0.9507 (0.9507)  loss_giou_aux_4: 0.9589 (0.9589)  loss_giou_dn_0: 1.1526 (1.1526)  loss_giou_dn_1: 1.0828 (1.0828)  loss_giou_dn_2: 1.0504 (1.0504)  loss_giou_dn_3: 1.0347 (1.0347)  loss_giou_dn_4: 1.0246 (1.0246)  loss_giou_dn_5: 1.0247 (1.0247)  loss_giou_enc_0: 1.0781 (1.0781)  loss_vfl: 1.1267 (1.1267)  loss_vfl_aux_0: 1.1624 (1.1624)  loss_vfl_aux_1: 1.1973 (1.1973)  loss_vfl_aux_2: 1.1919 (1.1919)  loss_vfl_aux_3: 1.1565 (1.1565)  loss_vfl_aux_4: 1.1523 (1.1523)  loss_vfl_dn_0: 0.4735 (0.4735)  loss_vfl_dn_1: 0.5032 (0.5032)  loss_vfl_dn_2: 0.5225 (0.5225)  loss_vfl_dn_3: 0.5396 (0.5396)  loss_vfl_dn_4: 0.5604 (0.5604)  loss_vfl_dn_5: 0.5780 (0.5780)  loss_vfl_enc_0: 1.0786 (1.0786)  time: 4.7776  data: 3.3519  max mem: 10356\r\n",
      "Epoch: [32]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 30.0870 (30.3653)  loss_bbox: 0.3595 (0.3655)  loss_bbox_aux_0: 0.3709 (0.3922)  loss_bbox_aux_1: 0.3768 (0.3851)  loss_bbox_aux_2: 0.3727 (0.3790)  loss_bbox_aux_3: 0.3685 (0.3748)  loss_bbox_aux_4: 0.3689 (0.3680)  loss_bbox_dn_0: 0.4455 (0.4418)  loss_bbox_dn_1: 0.4205 (0.4146)  loss_bbox_dn_2: 0.4065 (0.4006)  loss_bbox_dn_3: 0.3979 (0.3919)  loss_bbox_dn_4: 0.3908 (0.3867)  loss_bbox_dn_5: 0.3900 (0.3857)  loss_bbox_enc_0: 0.3926 (0.4349)  loss_giou: 1.0072 (1.1235)  loss_giou_aux_0: 1.0364 (1.1611)  loss_giou_aux_1: 1.0352 (1.1493)  loss_giou_aux_2: 1.0150 (1.1371)  loss_giou_aux_3: 1.0229 (1.1315)  loss_giou_aux_4: 1.0194 (1.1253)  loss_giou_dn_0: 1.1391 (1.1670)  loss_giou_dn_1: 1.0539 (1.0969)  loss_giou_dn_2: 1.0211 (1.0643)  loss_giou_dn_3: 1.0051 (1.0478)  loss_giou_dn_4: 0.9936 (1.0361)  loss_giou_dn_5: 0.9902 (1.0348)  loss_giou_enc_0: 1.1440 (1.2413)  loss_vfl: 1.1111 (1.0825)  loss_vfl_aux_0: 1.0806 (1.0624)  loss_vfl_aux_1: 1.1294 (1.0660)  loss_vfl_aux_2: 1.0847 (1.0670)  loss_vfl_aux_3: 1.1455 (1.0820)  loss_vfl_aux_4: 1.1548 (1.0811)  loss_vfl_dn_0: 0.4919 (0.4860)  loss_vfl_dn_1: 0.5315 (0.5186)  loss_vfl_dn_2: 0.5557 (0.5418)  loss_vfl_dn_3: 0.5819 (0.5680)  loss_vfl_dn_4: 0.6021 (0.5908)  loss_vfl_dn_5: 0.6125 (0.6057)  loss_vfl_enc_0: 0.9238 (0.9769)  time: 1.0182  data: 0.0323  max mem: 10356\r\n",
      "Epoch: [32] Total time: 0:01:27 (1.1033 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 30.0870 (30.3653)  loss_bbox: 0.3595 (0.3655)  loss_bbox_aux_0: 0.3709 (0.3922)  loss_bbox_aux_1: 0.3768 (0.3851)  loss_bbox_aux_2: 0.3727 (0.3790)  loss_bbox_aux_3: 0.3685 (0.3748)  loss_bbox_aux_4: 0.3689 (0.3680)  loss_bbox_dn_0: 0.4455 (0.4418)  loss_bbox_dn_1: 0.4205 (0.4146)  loss_bbox_dn_2: 0.4065 (0.4006)  loss_bbox_dn_3: 0.3979 (0.3919)  loss_bbox_dn_4: 0.3908 (0.3867)  loss_bbox_dn_5: 0.3900 (0.3857)  loss_bbox_enc_0: 0.3926 (0.4349)  loss_giou: 1.0072 (1.1235)  loss_giou_aux_0: 1.0364 (1.1611)  loss_giou_aux_1: 1.0352 (1.1493)  loss_giou_aux_2: 1.0150 (1.1371)  loss_giou_aux_3: 1.0229 (1.1315)  loss_giou_aux_4: 1.0194 (1.1253)  loss_giou_dn_0: 1.1391 (1.1670)  loss_giou_dn_1: 1.0539 (1.0969)  loss_giou_dn_2: 1.0211 (1.0643)  loss_giou_dn_3: 1.0051 (1.0478)  loss_giou_dn_4: 0.9936 (1.0361)  loss_giou_dn_5: 0.9902 (1.0348)  loss_giou_enc_0: 1.1440 (1.2413)  loss_vfl: 1.1111 (1.0825)  loss_vfl_aux_0: 1.0806 (1.0624)  loss_vfl_aux_1: 1.1294 (1.0660)  loss_vfl_aux_2: 1.0847 (1.0670)  loss_vfl_aux_3: 1.1455 (1.0820)  loss_vfl_aux_4: 1.1548 (1.0811)  loss_vfl_dn_0: 0.4919 (0.4860)  loss_vfl_dn_1: 0.5315 (0.5186)  loss_vfl_dn_2: 0.5557 (0.5418)  loss_vfl_dn_3: 0.5819 (0.5680)  loss_vfl_dn_4: 0.6021 (0.5908)  loss_vfl_dn_5: 0.6125 (0.6057)  loss_vfl_enc_0: 0.9238 (0.9769)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.2508  data: 1.3080  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0770  data: 0.2190  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0946 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.014\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.024\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.015\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.027\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.023\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.122\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.178\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.188\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.066\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.275\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.253\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.309\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.185\r\n",
      "best_stat: {'epoch': 32, 'coco_eval_bbox': 0.014073498548035624}\r\n",
      "Epoch: [33]  [ 0/79]  eta: 0:05:06  lr: 0.000020  loss: 30.3265 (30.3265)  loss_bbox: 0.2766 (0.2766)  loss_bbox_aux_0: 0.3334 (0.3334)  loss_bbox_aux_1: 0.3532 (0.3532)  loss_bbox_aux_2: 0.3144 (0.3144)  loss_bbox_aux_3: 0.2897 (0.2897)  loss_bbox_aux_4: 0.2816 (0.2816)  loss_bbox_dn_0: 0.4801 (0.4801)  loss_bbox_dn_1: 0.4319 (0.4319)  loss_bbox_dn_2: 0.4147 (0.4147)  loss_bbox_dn_3: 0.4043 (0.4043)  loss_bbox_dn_4: 0.3960 (0.3960)  loss_bbox_dn_5: 0.3949 (0.3949)  loss_bbox_enc_0: 0.3786 (0.3786)  loss_giou: 0.9057 (0.9057)  loss_giou_aux_0: 0.9410 (0.9410)  loss_giou_aux_1: 0.9512 (0.9512)  loss_giou_aux_2: 0.9370 (0.9370)  loss_giou_aux_3: 0.9126 (0.9126)  loss_giou_aux_4: 0.8943 (0.8943)  loss_giou_dn_0: 1.1480 (1.1480)  loss_giou_dn_1: 1.0271 (1.0271)  loss_giou_dn_2: 0.9874 (0.9874)  loss_giou_dn_3: 0.9629 (0.9629)  loss_giou_dn_4: 0.9439 (0.9439)  loss_giou_dn_5: 0.9423 (0.9423)  loss_giou_enc_0: 1.0833 (1.0833)  loss_vfl: 1.3804 (1.3804)  loss_vfl_aux_0: 1.3521 (1.3521)  loss_vfl_aux_1: 1.3145 (1.3145)  loss_vfl_aux_2: 1.3066 (1.3066)  loss_vfl_aux_3: 1.3726 (1.3726)  loss_vfl_aux_4: 1.3892 (1.3892)  loss_vfl_dn_0: 0.4758 (0.4758)  loss_vfl_dn_1: 0.5574 (0.5574)  loss_vfl_dn_2: 0.5941 (0.5941)  loss_vfl_dn_3: 0.6309 (0.6309)  loss_vfl_dn_4: 0.6655 (0.6655)  loss_vfl_dn_5: 0.6868 (0.6868)  loss_vfl_enc_0: 1.2148 (1.2148)  time: 3.8753  data: 2.4166  max mem: 10356\r\n",
      "Epoch: [33]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 30.0504 (30.1444)  loss_bbox: 0.3622 (0.3487)  loss_bbox_aux_0: 0.3809 (0.3808)  loss_bbox_aux_1: 0.3879 (0.3713)  loss_bbox_aux_2: 0.3725 (0.3611)  loss_bbox_aux_3: 0.3766 (0.3557)  loss_bbox_aux_4: 0.3702 (0.3492)  loss_bbox_dn_0: 0.3807 (0.4248)  loss_bbox_dn_1: 0.3437 (0.3982)  loss_bbox_dn_2: 0.3247 (0.3854)  loss_bbox_dn_3: 0.3177 (0.3785)  loss_bbox_dn_4: 0.3123 (0.3742)  loss_bbox_dn_5: 0.3128 (0.3734)  loss_bbox_enc_0: 0.4258 (0.4285)  loss_giou: 1.1251 (1.1117)  loss_giou_aux_0: 1.1739 (1.1531)  loss_giou_aux_1: 1.1606 (1.1384)  loss_giou_aux_2: 1.1630 (1.1242)  loss_giou_aux_3: 1.1221 (1.1169)  loss_giou_aux_4: 1.1306 (1.1117)  loss_giou_dn_0: 1.1636 (1.1605)  loss_giou_dn_1: 1.0901 (1.0870)  loss_giou_dn_2: 1.0621 (1.0547)  loss_giou_dn_3: 1.0474 (1.0384)  loss_giou_dn_4: 1.0379 (1.0275)  loss_giou_dn_5: 1.0392 (1.0266)  loss_giou_enc_0: 1.2332 (1.2454)  loss_vfl: 0.9890 (1.1023)  loss_vfl_aux_0: 0.9321 (1.0807)  loss_vfl_aux_1: 0.9226 (1.0778)  loss_vfl_aux_2: 0.9563 (1.0864)  loss_vfl_aux_3: 0.9402 (1.0933)  loss_vfl_aux_4: 0.9646 (1.1002)  loss_vfl_dn_0: 0.4835 (0.4887)  loss_vfl_dn_1: 0.5179 (0.5223)  loss_vfl_dn_2: 0.5181 (0.5443)  loss_vfl_dn_3: 0.5496 (0.5686)  loss_vfl_dn_4: 0.5712 (0.5897)  loss_vfl_dn_5: 0.5779 (0.6049)  loss_vfl_enc_0: 0.7983 (0.9593)  time: 0.9966  data: 0.0324  max mem: 10356\r\n",
      "Epoch: [33] Total time: 0:01:23 (1.0558 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 30.0504 (30.1444)  loss_bbox: 0.3622 (0.3487)  loss_bbox_aux_0: 0.3809 (0.3808)  loss_bbox_aux_1: 0.3879 (0.3713)  loss_bbox_aux_2: 0.3725 (0.3611)  loss_bbox_aux_3: 0.3766 (0.3557)  loss_bbox_aux_4: 0.3702 (0.3492)  loss_bbox_dn_0: 0.3807 (0.4248)  loss_bbox_dn_1: 0.3437 (0.3982)  loss_bbox_dn_2: 0.3247 (0.3854)  loss_bbox_dn_3: 0.3177 (0.3785)  loss_bbox_dn_4: 0.3123 (0.3742)  loss_bbox_dn_5: 0.3128 (0.3734)  loss_bbox_enc_0: 0.4258 (0.4285)  loss_giou: 1.1251 (1.1117)  loss_giou_aux_0: 1.1739 (1.1531)  loss_giou_aux_1: 1.1606 (1.1384)  loss_giou_aux_2: 1.1630 (1.1242)  loss_giou_aux_3: 1.1221 (1.1169)  loss_giou_aux_4: 1.1306 (1.1117)  loss_giou_dn_0: 1.1636 (1.1605)  loss_giou_dn_1: 1.0901 (1.0870)  loss_giou_dn_2: 1.0621 (1.0547)  loss_giou_dn_3: 1.0474 (1.0384)  loss_giou_dn_4: 1.0379 (1.0275)  loss_giou_dn_5: 1.0392 (1.0266)  loss_giou_enc_0: 1.2332 (1.2454)  loss_vfl: 0.9890 (1.1023)  loss_vfl_aux_0: 0.9321 (1.0807)  loss_vfl_aux_1: 0.9226 (1.0778)  loss_vfl_aux_2: 0.9563 (1.0864)  loss_vfl_aux_3: 0.9402 (1.0933)  loss_vfl_aux_4: 0.9646 (1.1002)  loss_vfl_dn_0: 0.4835 (0.4887)  loss_vfl_dn_1: 0.5179 (0.5223)  loss_vfl_dn_2: 0.5181 (0.5443)  loss_vfl_dn_3: 0.5496 (0.5686)  loss_vfl_dn_4: 0.5712 (0.5897)  loss_vfl_dn_5: 0.5779 (0.6049)  loss_vfl_enc_0: 0.7983 (0.9593)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.2393  data: 1.3176  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0697  data: 0.2123  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0862 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.19s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.021\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.029\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.023\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.044\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.017\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.130\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.192\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.203\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.276\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.304\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.302\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.218\r\n",
      "best_stat: {'epoch': 33, 'coco_eval_bbox': 0.020907610098263505}\r\n",
      "Epoch: [34]  [ 0/79]  eta: 0:05:45  lr: 0.000020  loss: 30.6002 (30.6002)  loss_bbox: 0.3742 (0.3742)  loss_bbox_aux_0: 0.4097 (0.4097)  loss_bbox_aux_1: 0.3890 (0.3890)  loss_bbox_aux_2: 0.3968 (0.3968)  loss_bbox_aux_3: 0.3776 (0.3776)  loss_bbox_aux_4: 0.3566 (0.3566)  loss_bbox_dn_0: 0.3650 (0.3650)  loss_bbox_dn_1: 0.3402 (0.3402)  loss_bbox_dn_2: 0.3276 (0.3276)  loss_bbox_dn_3: 0.3197 (0.3197)  loss_bbox_dn_4: 0.3156 (0.3156)  loss_bbox_dn_5: 0.3141 (0.3141)  loss_bbox_enc_0: 0.4156 (0.4156)  loss_giou: 1.3185 (1.3185)  loss_giou_aux_0: 1.3403 (1.3403)  loss_giou_aux_1: 1.3368 (1.3368)  loss_giou_aux_2: 1.3414 (1.3414)  loss_giou_aux_3: 1.3290 (1.3290)  loss_giou_aux_4: 1.3536 (1.3536)  loss_giou_dn_0: 1.1960 (1.1960)  loss_giou_dn_1: 1.1325 (1.1325)  loss_giou_dn_2: 1.1042 (1.1042)  loss_giou_dn_3: 1.0892 (1.0892)  loss_giou_dn_4: 1.0813 (1.0813)  loss_giou_dn_5: 1.0786 (1.0786)  loss_giou_enc_0: 1.3803 (1.3803)  loss_vfl: 0.9810 (0.9810)  loss_vfl_aux_0: 0.8860 (0.8860)  loss_vfl_aux_1: 0.9673 (0.9673)  loss_vfl_aux_2: 0.9419 (0.9419)  loss_vfl_aux_3: 0.9878 (0.9878)  loss_vfl_aux_4: 0.9617 (0.9617)  loss_vfl_dn_0: 0.4626 (0.4626)  loss_vfl_dn_1: 0.4917 (0.4917)  loss_vfl_dn_2: 0.5198 (0.5198)  loss_vfl_dn_3: 0.5591 (0.5591)  loss_vfl_dn_4: 0.5674 (0.5674)  loss_vfl_dn_5: 0.5867 (0.5867)  loss_vfl_enc_0: 0.9041 (0.9041)  time: 4.3782  data: 2.9085  max mem: 10356\r\n",
      "Epoch: [34]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 29.6534 (30.1554)  loss_bbox: 0.3533 (0.3595)  loss_bbox_aux_0: 0.3530 (0.3862)  loss_bbox_aux_1: 0.3739 (0.3766)  loss_bbox_aux_2: 0.3697 (0.3699)  loss_bbox_aux_3: 0.3586 (0.3635)  loss_bbox_aux_4: 0.3440 (0.3611)  loss_bbox_dn_0: 0.3319 (0.4230)  loss_bbox_dn_1: 0.3158 (0.3964)  loss_bbox_dn_2: 0.3143 (0.3841)  loss_bbox_dn_3: 0.3139 (0.3767)  loss_bbox_dn_4: 0.3135 (0.3724)  loss_bbox_dn_5: 0.3137 (0.3718)  loss_bbox_enc_0: 0.4073 (0.4299)  loss_giou: 1.1867 (1.0892)  loss_giou_aux_0: 1.1943 (1.1289)  loss_giou_aux_1: 1.2142 (1.1158)  loss_giou_aux_2: 1.1895 (1.1038)  loss_giou_aux_3: 1.1867 (1.0978)  loss_giou_aux_4: 1.2027 (1.0913)  loss_giou_dn_0: 1.1754 (1.1437)  loss_giou_dn_1: 1.1016 (1.0688)  loss_giou_dn_2: 1.0721 (1.0349)  loss_giou_dn_3: 1.0520 (1.0179)  loss_giou_dn_4: 1.0461 (1.0071)  loss_giou_dn_5: 1.0457 (1.0063)  loss_giou_enc_0: 1.2961 (1.2205)  loss_vfl: 0.9021 (1.1177)  loss_vfl_aux_0: 0.9487 (1.1063)  loss_vfl_aux_1: 0.8728 (1.1025)  loss_vfl_aux_2: 0.9021 (1.1057)  loss_vfl_aux_3: 0.9150 (1.1141)  loss_vfl_aux_4: 0.9148 (1.1174)  loss_vfl_dn_0: 0.4861 (0.4995)  loss_vfl_dn_1: 0.5244 (0.5344)  loss_vfl_dn_2: 0.5321 (0.5572)  loss_vfl_dn_3: 0.5579 (0.5822)  loss_vfl_dn_4: 0.5696 (0.6040)  loss_vfl_dn_5: 0.5828 (0.6187)  loss_vfl_enc_0: 0.8896 (0.9986)  time: 1.0520  data: 0.0304  max mem: 10356\r\n",
      "Epoch: [34] Total time: 0:01:26 (1.0943 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 29.6534 (30.1554)  loss_bbox: 0.3533 (0.3595)  loss_bbox_aux_0: 0.3530 (0.3862)  loss_bbox_aux_1: 0.3739 (0.3766)  loss_bbox_aux_2: 0.3697 (0.3699)  loss_bbox_aux_3: 0.3586 (0.3635)  loss_bbox_aux_4: 0.3440 (0.3611)  loss_bbox_dn_0: 0.3319 (0.4230)  loss_bbox_dn_1: 0.3158 (0.3964)  loss_bbox_dn_2: 0.3143 (0.3841)  loss_bbox_dn_3: 0.3139 (0.3767)  loss_bbox_dn_4: 0.3135 (0.3724)  loss_bbox_dn_5: 0.3137 (0.3718)  loss_bbox_enc_0: 0.4073 (0.4299)  loss_giou: 1.1867 (1.0892)  loss_giou_aux_0: 1.1943 (1.1289)  loss_giou_aux_1: 1.2142 (1.1158)  loss_giou_aux_2: 1.1895 (1.1038)  loss_giou_aux_3: 1.1867 (1.0978)  loss_giou_aux_4: 1.2027 (1.0913)  loss_giou_dn_0: 1.1754 (1.1437)  loss_giou_dn_1: 1.1016 (1.0688)  loss_giou_dn_2: 1.0721 (1.0349)  loss_giou_dn_3: 1.0520 (1.0179)  loss_giou_dn_4: 1.0461 (1.0071)  loss_giou_dn_5: 1.0457 (1.0063)  loss_giou_enc_0: 1.2961 (1.2205)  loss_vfl: 0.9021 (1.1177)  loss_vfl_aux_0: 0.9487 (1.1063)  loss_vfl_aux_1: 0.8728 (1.1025)  loss_vfl_aux_2: 0.9021 (1.1057)  loss_vfl_aux_3: 0.9150 (1.1141)  loss_vfl_aux_4: 0.9148 (1.1174)  loss_vfl_dn_0: 0.4861 (0.4995)  loss_vfl_dn_1: 0.5244 (0.5344)  loss_vfl_dn_2: 0.5321 (0.5572)  loss_vfl_dn_3: 0.5579 (0.5822)  loss_vfl_dn_4: 0.5696 (0.6040)  loss_vfl_dn_5: 0.5828 (0.6187)  loss_vfl_enc_0: 0.8896 (0.9986)\r\n",
      "Test:  [0/8]  eta: 0:00:22    time: 2.8170  data: 1.2424  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0919  data: 0.2171  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1104 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.19s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.016\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.023\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.016\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.013\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.033\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.028\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.134\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.200\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.212\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.053\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.298\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.319\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.324\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.229\r\n",
      "best_stat: {'epoch': 33, 'coco_eval_bbox': 0.020907610098263505}\r\n",
      "Epoch: [35]  [ 0/79]  eta: 0:06:52  lr: 0.000020  loss: 33.3954 (33.3954)  loss_bbox: 0.4144 (0.4144)  loss_bbox_aux_0: 0.4125 (0.4125)  loss_bbox_aux_1: 0.4242 (0.4242)  loss_bbox_aux_2: 0.4007 (0.4007)  loss_bbox_aux_3: 0.4013 (0.4013)  loss_bbox_aux_4: 0.3964 (0.3964)  loss_bbox_dn_0: 0.6926 (0.6926)  loss_bbox_dn_1: 0.6470 (0.6470)  loss_bbox_dn_2: 0.6192 (0.6192)  loss_bbox_dn_3: 0.6041 (0.6041)  loss_bbox_dn_4: 0.5910 (0.5910)  loss_bbox_dn_5: 0.5889 (0.5889)  loss_bbox_enc_0: 0.4618 (0.4618)  loss_giou: 0.8499 (0.8499)  loss_giou_aux_0: 0.8690 (0.8690)  loss_giou_aux_1: 0.8471 (0.8471)  loss_giou_aux_2: 0.8314 (0.8314)  loss_giou_aux_3: 0.8623 (0.8623)  loss_giou_aux_4: 0.8527 (0.8527)  loss_giou_dn_0: 1.1129 (1.1129)  loss_giou_dn_1: 1.0320 (1.0320)  loss_giou_dn_2: 0.9992 (0.9992)  loss_giou_dn_3: 0.9851 (0.9851)  loss_giou_dn_4: 0.9726 (0.9726)  loss_giou_dn_5: 0.9707 (0.9707)  loss_giou_enc_0: 0.9098 (0.9098)  loss_vfl: 1.3979 (1.3979)  loss_vfl_aux_0: 1.5532 (1.5532)  loss_vfl_aux_1: 1.5244 (1.5244)  loss_vfl_aux_2: 1.5283 (1.5283)  loss_vfl_aux_3: 1.4551 (1.4551)  loss_vfl_aux_4: 1.4741 (1.4741)  loss_vfl_dn_0: 0.5889 (0.5889)  loss_vfl_dn_1: 0.6833 (0.6833)  loss_vfl_dn_2: 0.7205 (0.7205)  loss_vfl_dn_3: 0.7319 (0.7319)  loss_vfl_dn_4: 0.7644 (0.7644)  loss_vfl_dn_5: 0.7427 (0.7427)  loss_vfl_enc_0: 1.4819 (1.4819)  time: 5.2240  data: 3.3472  max mem: 10356\r\n",
      "Epoch: [35]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 30.1599 (30.1717)  loss_bbox: 0.3165 (0.3624)  loss_bbox_aux_0: 0.3626 (0.3932)  loss_bbox_aux_1: 0.3536 (0.3847)  loss_bbox_aux_2: 0.3205 (0.3740)  loss_bbox_aux_3: 0.3212 (0.3702)  loss_bbox_aux_4: 0.3246 (0.3640)  loss_bbox_dn_0: 0.4205 (0.4271)  loss_bbox_dn_1: 0.4001 (0.3994)  loss_bbox_dn_2: 0.3840 (0.3852)  loss_bbox_dn_3: 0.3778 (0.3769)  loss_bbox_dn_4: 0.3746 (0.3720)  loss_bbox_dn_5: 0.3740 (0.3712)  loss_bbox_enc_0: 0.4129 (0.4338)  loss_giou: 1.0488 (1.1180)  loss_giou_aux_0: 1.0960 (1.1572)  loss_giou_aux_1: 1.0749 (1.1455)  loss_giou_aux_2: 1.0718 (1.1327)  loss_giou_aux_3: 1.0662 (1.1278)  loss_giou_aux_4: 1.0313 (1.1194)  loss_giou_dn_0: 1.1434 (1.1464)  loss_giou_dn_1: 1.0757 (1.0735)  loss_giou_dn_2: 1.0432 (1.0411)  loss_giou_dn_3: 1.0301 (1.0242)  loss_giou_dn_4: 1.0163 (1.0129)  loss_giou_dn_5: 1.0147 (1.0117)  loss_giou_enc_0: 1.1776 (1.2475)  loss_vfl: 1.1245 (1.0874)  loss_vfl_aux_0: 1.0952 (1.0782)  loss_vfl_aux_1: 1.1201 (1.0704)  loss_vfl_aux_2: 1.1353 (1.0751)  loss_vfl_aux_3: 1.1113 (1.0765)  loss_vfl_aux_4: 1.1196 (1.0875)  loss_vfl_dn_0: 0.4943 (0.4967)  loss_vfl_dn_1: 0.5398 (0.5295)  loss_vfl_dn_2: 0.5619 (0.5498)  loss_vfl_dn_3: 0.5857 (0.5728)  loss_vfl_dn_4: 0.6074 (0.5933)  loss_vfl_dn_5: 0.6118 (0.6082)  loss_vfl_enc_0: 0.9568 (0.9742)  time: 1.0000  data: 0.0333  max mem: 10356\r\n",
      "Epoch: [35] Total time: 0:01:26 (1.0932 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 30.1599 (30.1717)  loss_bbox: 0.3165 (0.3624)  loss_bbox_aux_0: 0.3626 (0.3932)  loss_bbox_aux_1: 0.3536 (0.3847)  loss_bbox_aux_2: 0.3205 (0.3740)  loss_bbox_aux_3: 0.3212 (0.3702)  loss_bbox_aux_4: 0.3246 (0.3640)  loss_bbox_dn_0: 0.4205 (0.4271)  loss_bbox_dn_1: 0.4001 (0.3994)  loss_bbox_dn_2: 0.3840 (0.3852)  loss_bbox_dn_3: 0.3778 (0.3769)  loss_bbox_dn_4: 0.3746 (0.3720)  loss_bbox_dn_5: 0.3740 (0.3712)  loss_bbox_enc_0: 0.4129 (0.4338)  loss_giou: 1.0488 (1.1180)  loss_giou_aux_0: 1.0960 (1.1572)  loss_giou_aux_1: 1.0749 (1.1455)  loss_giou_aux_2: 1.0718 (1.1327)  loss_giou_aux_3: 1.0662 (1.1278)  loss_giou_aux_4: 1.0313 (1.1194)  loss_giou_dn_0: 1.1434 (1.1464)  loss_giou_dn_1: 1.0757 (1.0735)  loss_giou_dn_2: 1.0432 (1.0411)  loss_giou_dn_3: 1.0301 (1.0242)  loss_giou_dn_4: 1.0163 (1.0129)  loss_giou_dn_5: 1.0147 (1.0117)  loss_giou_enc_0: 1.1776 (1.2475)  loss_vfl: 1.1245 (1.0874)  loss_vfl_aux_0: 1.0952 (1.0782)  loss_vfl_aux_1: 1.1201 (1.0704)  loss_vfl_aux_2: 1.1353 (1.0751)  loss_vfl_aux_3: 1.1113 (1.0765)  loss_vfl_aux_4: 1.1196 (1.0875)  loss_vfl_dn_0: 0.4943 (0.4967)  loss_vfl_dn_1: 0.5398 (0.5295)  loss_vfl_dn_2: 0.5619 (0.5498)  loss_vfl_dn_3: 0.5857 (0.5728)  loss_vfl_dn_4: 0.6074 (0.5933)  loss_vfl_dn_5: 0.6118 (0.6082)  loss_vfl_enc_0: 0.9568 (0.9742)\r\n",
      "Test:  [0/8]  eta: 0:00:22    time: 2.8520  data: 1.3255  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0941  data: 0.2234  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1117 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.015\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.022\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.015\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.013\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.028\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.023\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.132\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.203\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.216\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.056\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.304\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.311\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.326\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.226\r\n",
      "best_stat: {'epoch': 33, 'coco_eval_bbox': 0.020907610098263505}\r\n",
      "Epoch: [36]  [ 0/79]  eta: 0:06:03  lr: 0.000020  loss: 28.8476 (28.8476)  loss_bbox: 0.3540 (0.3540)  loss_bbox_aux_0: 0.3554 (0.3554)  loss_bbox_aux_1: 0.3684 (0.3684)  loss_bbox_aux_2: 0.3562 (0.3562)  loss_bbox_aux_3: 0.3508 (0.3508)  loss_bbox_aux_4: 0.3671 (0.3671)  loss_bbox_dn_0: 0.3305 (0.3305)  loss_bbox_dn_1: 0.2967 (0.2967)  loss_bbox_dn_2: 0.2799 (0.2799)  loss_bbox_dn_3: 0.2718 (0.2718)  loss_bbox_dn_4: 0.2657 (0.2657)  loss_bbox_dn_5: 0.2641 (0.2641)  loss_bbox_enc_0: 0.4009 (0.4009)  loss_giou: 1.2022 (1.2022)  loss_giou_aux_0: 1.2315 (1.2315)  loss_giou_aux_1: 1.2679 (1.2679)  loss_giou_aux_2: 1.2545 (1.2545)  loss_giou_aux_3: 1.2125 (1.2125)  loss_giou_aux_4: 1.2305 (1.2305)  loss_giou_dn_0: 1.1667 (1.1667)  loss_giou_dn_1: 1.1005 (1.1005)  loss_giou_dn_2: 1.0616 (1.0616)  loss_giou_dn_3: 1.0541 (1.0541)  loss_giou_dn_4: 1.0448 (1.0448)  loss_giou_dn_5: 1.0475 (1.0475)  loss_giou_enc_0: 1.3104 (1.3104)  loss_vfl: 0.9248 (0.9248)  loss_vfl_aux_0: 0.9475 (0.9475)  loss_vfl_aux_1: 0.9141 (0.9141)  loss_vfl_aux_2: 0.9067 (0.9067)  loss_vfl_aux_3: 0.9319 (0.9319)  loss_vfl_aux_4: 0.8984 (0.8984)  loss_vfl_dn_0: 0.4713 (0.4713)  loss_vfl_dn_1: 0.4872 (0.4872)  loss_vfl_dn_2: 0.5023 (0.5023)  loss_vfl_dn_3: 0.5155 (0.5155)  loss_vfl_dn_4: 0.5254 (0.5254)  loss_vfl_dn_5: 0.5342 (0.5342)  loss_vfl_enc_0: 0.8420 (0.8420)  time: 4.5971  data: 3.0313  max mem: 10356\r\n",
      "Epoch: [36]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 29.1988 (29.7522)  loss_bbox: 0.2888 (0.3373)  loss_bbox_aux_0: 0.3001 (0.3662)  loss_bbox_aux_1: 0.3009 (0.3596)  loss_bbox_aux_2: 0.2954 (0.3479)  loss_bbox_aux_3: 0.2830 (0.3452)  loss_bbox_aux_4: 0.2847 (0.3409)  loss_bbox_dn_0: 0.3639 (0.4055)  loss_bbox_dn_1: 0.3359 (0.3772)  loss_bbox_dn_2: 0.3223 (0.3634)  loss_bbox_dn_3: 0.3127 (0.3557)  loss_bbox_dn_4: 0.3081 (0.3513)  loss_bbox_dn_5: 0.3091 (0.3505)  loss_bbox_enc_0: 0.3485 (0.4095)  loss_giou: 1.1146 (1.0999)  loss_giou_aux_0: 1.1523 (1.1378)  loss_giou_aux_1: 1.1181 (1.1258)  loss_giou_aux_2: 1.1061 (1.1126)  loss_giou_aux_3: 1.0902 (1.1059)  loss_giou_aux_4: 1.0946 (1.0974)  loss_giou_dn_0: 1.1227 (1.1438)  loss_giou_dn_1: 1.0523 (1.0712)  loss_giou_dn_2: 1.0284 (1.0394)  loss_giou_dn_3: 1.0222 (1.0233)  loss_giou_dn_4: 1.0131 (1.0132)  loss_giou_dn_5: 1.0101 (1.0121)  loss_giou_enc_0: 1.2295 (1.2249)  loss_vfl: 1.0137 (1.0920)  loss_vfl_aux_0: 1.0242 (1.0759)  loss_vfl_aux_1: 1.0378 (1.0728)  loss_vfl_aux_2: 1.0454 (1.0807)  loss_vfl_aux_3: 1.0557 (1.0866)  loss_vfl_aux_4: 1.0481 (1.0916)  loss_vfl_dn_0: 0.4923 (0.4975)  loss_vfl_dn_1: 0.5237 (0.5304)  loss_vfl_dn_2: 0.5405 (0.5507)  loss_vfl_dn_3: 0.5619 (0.5725)  loss_vfl_dn_4: 0.5837 (0.5920)  loss_vfl_dn_5: 0.5991 (0.6065)  loss_vfl_enc_0: 0.9585 (0.9854)  time: 1.0521  data: 0.0317  max mem: 10356\r\n",
      "Epoch: [36] Total time: 0:01:26 (1.0944 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 29.1988 (29.7522)  loss_bbox: 0.2888 (0.3373)  loss_bbox_aux_0: 0.3001 (0.3662)  loss_bbox_aux_1: 0.3009 (0.3596)  loss_bbox_aux_2: 0.2954 (0.3479)  loss_bbox_aux_3: 0.2830 (0.3452)  loss_bbox_aux_4: 0.2847 (0.3409)  loss_bbox_dn_0: 0.3639 (0.4055)  loss_bbox_dn_1: 0.3359 (0.3772)  loss_bbox_dn_2: 0.3223 (0.3634)  loss_bbox_dn_3: 0.3127 (0.3557)  loss_bbox_dn_4: 0.3081 (0.3513)  loss_bbox_dn_5: 0.3091 (0.3505)  loss_bbox_enc_0: 0.3485 (0.4095)  loss_giou: 1.1146 (1.0999)  loss_giou_aux_0: 1.1523 (1.1378)  loss_giou_aux_1: 1.1181 (1.1258)  loss_giou_aux_2: 1.1061 (1.1126)  loss_giou_aux_3: 1.0902 (1.1059)  loss_giou_aux_4: 1.0946 (1.0974)  loss_giou_dn_0: 1.1227 (1.1438)  loss_giou_dn_1: 1.0523 (1.0712)  loss_giou_dn_2: 1.0284 (1.0394)  loss_giou_dn_3: 1.0222 (1.0233)  loss_giou_dn_4: 1.0131 (1.0132)  loss_giou_dn_5: 1.0101 (1.0121)  loss_giou_enc_0: 1.2295 (1.2249)  loss_vfl: 1.0137 (1.0920)  loss_vfl_aux_0: 1.0242 (1.0759)  loss_vfl_aux_1: 1.0378 (1.0728)  loss_vfl_aux_2: 1.0454 (1.0807)  loss_vfl_aux_3: 1.0557 (1.0866)  loss_vfl_aux_4: 1.0481 (1.0916)  loss_vfl_dn_0: 0.4923 (0.4975)  loss_vfl_dn_1: 0.5237 (0.5304)  loss_vfl_dn_2: 0.5405 (0.5507)  loss_vfl_dn_3: 0.5619 (0.5725)  loss_vfl_dn_4: 0.5837 (0.5920)  loss_vfl_dn_5: 0.5991 (0.6065)  loss_vfl_enc_0: 0.9585 (0.9854)\r\n",
      "Test:  [0/8]  eta: 0:00:23    time: 2.9314  data: 1.4744  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0861  data: 0.2324  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1029 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.014\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.022\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.012\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.023\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.022\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.130\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.211\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.224\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.311\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.329\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.341\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.232\r\n",
      "best_stat: {'epoch': 33, 'coco_eval_bbox': 0.020907610098263505}\r\n",
      "Epoch: [37]  [ 0/79]  eta: 0:05:52  lr: 0.000020  loss: 28.5153 (28.5153)  loss_bbox: 0.3389 (0.3389)  loss_bbox_aux_0: 0.3439 (0.3439)  loss_bbox_aux_1: 0.3406 (0.3406)  loss_bbox_aux_2: 0.3534 (0.3534)  loss_bbox_aux_3: 0.3483 (0.3483)  loss_bbox_aux_4: 0.3543 (0.3543)  loss_bbox_dn_0: 0.3639 (0.3639)  loss_bbox_dn_1: 0.3334 (0.3334)  loss_bbox_dn_2: 0.3179 (0.3179)  loss_bbox_dn_3: 0.3081 (0.3081)  loss_bbox_dn_4: 0.3014 (0.3014)  loss_bbox_dn_5: 0.2997 (0.2997)  loss_bbox_enc_0: 0.3977 (0.3977)  loss_giou: 1.1300 (1.1300)  loss_giou_aux_0: 1.1808 (1.1808)  loss_giou_aux_1: 1.1458 (1.1458)  loss_giou_aux_2: 1.1619 (1.1619)  loss_giou_aux_3: 1.1578 (1.1578)  loss_giou_aux_4: 1.1382 (1.1382)  loss_giou_dn_0: 1.1563 (1.1563)  loss_giou_dn_1: 1.0889 (1.0889)  loss_giou_dn_2: 1.0554 (1.0554)  loss_giou_dn_3: 1.0426 (1.0426)  loss_giou_dn_4: 1.0277 (1.0277)  loss_giou_dn_5: 1.0251 (1.0251)  loss_giou_enc_0: 1.3058 (1.3058)  loss_vfl: 0.9417 (0.9417)  loss_vfl_aux_0: 0.8948 (0.8948)  loss_vfl_aux_1: 0.9187 (0.9187)  loss_vfl_aux_2: 0.8782 (0.8782)  loss_vfl_aux_3: 0.8945 (0.8945)  loss_vfl_aux_4: 0.9143 (0.9143)  loss_vfl_dn_0: 0.4885 (0.4885)  loss_vfl_dn_1: 0.5227 (0.5227)  loss_vfl_dn_2: 0.5427 (0.5427)  loss_vfl_dn_3: 0.5593 (0.5593)  loss_vfl_dn_4: 0.5774 (0.5774)  loss_vfl_dn_5: 0.6003 (0.6003)  loss_vfl_enc_0: 0.7642 (0.7642)  time: 4.4628  data: 2.4145  max mem: 10356\r\n",
      "Epoch: [37]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 29.5941 (30.0600)  loss_bbox: 0.3661 (0.3532)  loss_bbox_aux_0: 0.4120 (0.3864)  loss_bbox_aux_1: 0.3955 (0.3744)  loss_bbox_aux_2: 0.3826 (0.3641)  loss_bbox_aux_3: 0.3856 (0.3594)  loss_bbox_aux_4: 0.3684 (0.3560)  loss_bbox_dn_0: 0.3390 (0.4248)  loss_bbox_dn_1: 0.3074 (0.3962)  loss_bbox_dn_2: 0.2962 (0.3825)  loss_bbox_dn_3: 0.2916 (0.3744)  loss_bbox_dn_4: 0.2890 (0.3704)  loss_bbox_dn_5: 0.2888 (0.3697)  loss_bbox_enc_0: 0.4111 (0.4213)  loss_giou: 1.1286 (1.1048)  loss_giou_aux_0: 1.2218 (1.1394)  loss_giou_aux_1: 1.1672 (1.1308)  loss_giou_aux_2: 1.1595 (1.1192)  loss_giou_aux_3: 1.1371 (1.1108)  loss_giou_aux_4: 1.1255 (1.1043)  loss_giou_dn_0: 1.1606 (1.1390)  loss_giou_dn_1: 1.0763 (1.0629)  loss_giou_dn_2: 1.0426 (1.0293)  loss_giou_dn_3: 1.0296 (1.0122)  loss_giou_dn_4: 1.0215 (1.0012)  loss_giou_dn_5: 1.0213 (1.0003)  loss_giou_enc_0: 1.2352 (1.2294)  loss_vfl: 1.0063 (1.0922)  loss_vfl_aux_0: 1.0149 (1.1005)  loss_vfl_aux_1: 0.9944 (1.0858)  loss_vfl_aux_2: 1.0066 (1.0911)  loss_vfl_aux_3: 1.0361 (1.0978)  loss_vfl_aux_4: 1.0303 (1.1041)  loss_vfl_dn_0: 0.4899 (0.4994)  loss_vfl_dn_1: 0.5232 (0.5331)  loss_vfl_dn_2: 0.5405 (0.5528)  loss_vfl_dn_3: 0.5629 (0.5758)  loss_vfl_dn_4: 0.5808 (0.5957)  loss_vfl_dn_5: 0.5851 (0.6084)  loss_vfl_enc_0: 0.9976 (1.0068)  time: 0.9804  data: 0.0318  max mem: 10356\r\n",
      "Epoch: [37] Total time: 0:01:27 (1.1077 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 29.5941 (30.0600)  loss_bbox: 0.3661 (0.3532)  loss_bbox_aux_0: 0.4120 (0.3864)  loss_bbox_aux_1: 0.3955 (0.3744)  loss_bbox_aux_2: 0.3826 (0.3641)  loss_bbox_aux_3: 0.3856 (0.3594)  loss_bbox_aux_4: 0.3684 (0.3560)  loss_bbox_dn_0: 0.3390 (0.4248)  loss_bbox_dn_1: 0.3074 (0.3962)  loss_bbox_dn_2: 0.2962 (0.3825)  loss_bbox_dn_3: 0.2916 (0.3744)  loss_bbox_dn_4: 0.2890 (0.3704)  loss_bbox_dn_5: 0.2888 (0.3697)  loss_bbox_enc_0: 0.4111 (0.4213)  loss_giou: 1.1286 (1.1048)  loss_giou_aux_0: 1.2218 (1.1394)  loss_giou_aux_1: 1.1672 (1.1308)  loss_giou_aux_2: 1.1595 (1.1192)  loss_giou_aux_3: 1.1371 (1.1108)  loss_giou_aux_4: 1.1255 (1.1043)  loss_giou_dn_0: 1.1606 (1.1390)  loss_giou_dn_1: 1.0763 (1.0629)  loss_giou_dn_2: 1.0426 (1.0293)  loss_giou_dn_3: 1.0296 (1.0122)  loss_giou_dn_4: 1.0215 (1.0012)  loss_giou_dn_5: 1.0213 (1.0003)  loss_giou_enc_0: 1.2352 (1.2294)  loss_vfl: 1.0063 (1.0922)  loss_vfl_aux_0: 1.0149 (1.1005)  loss_vfl_aux_1: 0.9944 (1.0858)  loss_vfl_aux_2: 1.0066 (1.0911)  loss_vfl_aux_3: 1.0361 (1.0978)  loss_vfl_aux_4: 1.0303 (1.1041)  loss_vfl_dn_0: 0.4899 (0.4994)  loss_vfl_dn_1: 0.5232 (0.5331)  loss_vfl_dn_2: 0.5405 (0.5528)  loss_vfl_dn_3: 0.5629 (0.5758)  loss_vfl_dn_4: 0.5808 (0.5957)  loss_vfl_dn_5: 0.5851 (0.6084)  loss_vfl_enc_0: 0.9976 (1.0068)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.2278  data: 1.2793  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0226  data: 0.2196  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0369 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.011\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.018\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.011\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.021\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.036\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.110\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.175\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.192\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.054\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.262\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.290\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.300\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.194\r\n",
      "best_stat: {'epoch': 33, 'coco_eval_bbox': 0.020907610098263505}\r\n",
      "Epoch: [38]  [ 0/79]  eta: 0:05:39  lr: 0.000020  loss: 30.9807 (30.9807)  loss_bbox: 0.4350 (0.4350)  loss_bbox_aux_0: 0.4473 (0.4473)  loss_bbox_aux_1: 0.4385 (0.4385)  loss_bbox_aux_2: 0.4574 (0.4574)  loss_bbox_aux_3: 0.4590 (0.4590)  loss_bbox_aux_4: 0.4441 (0.4441)  loss_bbox_dn_0: 0.4143 (0.4143)  loss_bbox_dn_1: 0.3997 (0.3997)  loss_bbox_dn_2: 0.3958 (0.3958)  loss_bbox_dn_3: 0.3945 (0.3945)  loss_bbox_dn_4: 0.3932 (0.3932)  loss_bbox_dn_5: 0.3937 (0.3937)  loss_bbox_enc_0: 0.4648 (0.4648)  loss_giou: 1.2879 (1.2879)  loss_giou_aux_0: 1.2803 (1.2803)  loss_giou_aux_1: 1.2791 (1.2791)  loss_giou_aux_2: 1.2974 (1.2974)  loss_giou_aux_3: 1.3099 (1.3099)  loss_giou_aux_4: 1.3181 (1.3181)  loss_giou_dn_0: 1.1817 (1.1817)  loss_giou_dn_1: 1.1292 (1.1292)  loss_giou_dn_2: 1.1079 (1.1079)  loss_giou_dn_3: 1.1030 (1.1030)  loss_giou_dn_4: 1.0997 (1.0997)  loss_giou_dn_5: 1.0988 (1.0988)  loss_giou_enc_0: 1.3670 (1.3670)  loss_vfl: 0.8979 (0.8979)  loss_vfl_aux_0: 0.9690 (0.9690)  loss_vfl_aux_1: 0.9766 (0.9766)  loss_vfl_aux_2: 0.9390 (0.9390)  loss_vfl_aux_3: 0.9338 (0.9338)  loss_vfl_aux_4: 0.9036 (0.9036)  loss_vfl_dn_0: 0.4749 (0.4749)  loss_vfl_dn_1: 0.4994 (0.4994)  loss_vfl_dn_2: 0.5083 (0.5083)  loss_vfl_dn_3: 0.5231 (0.5231)  loss_vfl_dn_4: 0.5333 (0.5333)  loss_vfl_dn_5: 0.5425 (0.5425)  loss_vfl_enc_0: 0.8821 (0.8821)  time: 4.2925  data: 2.2975  max mem: 10356\r\n",
      "Epoch: [38]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 29.6441 (29.8262)  loss_bbox: 0.3338 (0.3348)  loss_bbox_aux_0: 0.3299 (0.3664)  loss_bbox_aux_1: 0.3385 (0.3554)  loss_bbox_aux_2: 0.3335 (0.3473)  loss_bbox_aux_3: 0.3319 (0.3423)  loss_bbox_aux_4: 0.3171 (0.3374)  loss_bbox_dn_0: 0.3642 (0.4101)  loss_bbox_dn_1: 0.3336 (0.3809)  loss_bbox_dn_2: 0.3182 (0.3672)  loss_bbox_dn_3: 0.3099 (0.3588)  loss_bbox_dn_4: 0.3095 (0.3540)  loss_bbox_dn_5: 0.3098 (0.3533)  loss_bbox_enc_0: 0.3788 (0.4105)  loss_giou: 0.9457 (1.0931)  loss_giou_aux_0: 0.9963 (1.1354)  loss_giou_aux_1: 0.9750 (1.1189)  loss_giou_aux_2: 0.9574 (1.1067)  loss_giou_aux_3: 0.9351 (1.1010)  loss_giou_aux_4: 0.9234 (1.0935)  loss_giou_dn_0: 1.1051 (1.1406)  loss_giou_dn_1: 1.0125 (1.0651)  loss_giou_dn_2: 0.9832 (1.0329)  loss_giou_dn_3: 0.9549 (1.0166)  loss_giou_dn_4: 0.9532 (1.0055)  loss_giou_dn_5: 0.9520 (1.0051)  loss_giou_enc_0: 1.1018 (1.2229)  loss_vfl: 1.1743 (1.1126)  loss_vfl_aux_0: 1.1667 (1.0979)  loss_vfl_aux_1: 1.1938 (1.0961)  loss_vfl_aux_2: 1.1880 (1.0978)  loss_vfl_aux_3: 1.2109 (1.1048)  loss_vfl_aux_4: 1.1584 (1.1109)  loss_vfl_dn_0: 0.4956 (0.4999)  loss_vfl_dn_1: 0.5273 (0.5330)  loss_vfl_dn_2: 0.5502 (0.5522)  loss_vfl_dn_3: 0.5640 (0.5735)  loss_vfl_dn_4: 0.5850 (0.5926)  loss_vfl_dn_5: 0.6008 (0.6056)  loss_vfl_enc_0: 0.9888 (0.9937)  time: 0.9745  data: 0.0323  max mem: 10356\r\n",
      "Epoch: [38] Total time: 0:01:25 (1.0860 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 29.6441 (29.8262)  loss_bbox: 0.3338 (0.3348)  loss_bbox_aux_0: 0.3299 (0.3664)  loss_bbox_aux_1: 0.3385 (0.3554)  loss_bbox_aux_2: 0.3335 (0.3473)  loss_bbox_aux_3: 0.3319 (0.3423)  loss_bbox_aux_4: 0.3171 (0.3374)  loss_bbox_dn_0: 0.3642 (0.4101)  loss_bbox_dn_1: 0.3336 (0.3809)  loss_bbox_dn_2: 0.3182 (0.3672)  loss_bbox_dn_3: 0.3099 (0.3588)  loss_bbox_dn_4: 0.3095 (0.3540)  loss_bbox_dn_5: 0.3098 (0.3533)  loss_bbox_enc_0: 0.3788 (0.4105)  loss_giou: 0.9457 (1.0931)  loss_giou_aux_0: 0.9963 (1.1354)  loss_giou_aux_1: 0.9750 (1.1189)  loss_giou_aux_2: 0.9574 (1.1067)  loss_giou_aux_3: 0.9351 (1.1010)  loss_giou_aux_4: 0.9234 (1.0935)  loss_giou_dn_0: 1.1051 (1.1406)  loss_giou_dn_1: 1.0125 (1.0651)  loss_giou_dn_2: 0.9832 (1.0329)  loss_giou_dn_3: 0.9549 (1.0166)  loss_giou_dn_4: 0.9532 (1.0055)  loss_giou_dn_5: 0.9520 (1.0051)  loss_giou_enc_0: 1.1018 (1.2229)  loss_vfl: 1.1743 (1.1126)  loss_vfl_aux_0: 1.1667 (1.0979)  loss_vfl_aux_1: 1.1938 (1.0961)  loss_vfl_aux_2: 1.1880 (1.0978)  loss_vfl_aux_3: 1.2109 (1.1048)  loss_vfl_aux_4: 1.1584 (1.1109)  loss_vfl_dn_0: 0.4956 (0.4999)  loss_vfl_dn_1: 0.5273 (0.5330)  loss_vfl_dn_2: 0.5502 (0.5522)  loss_vfl_dn_3: 0.5640 (0.5735)  loss_vfl_dn_4: 0.5850 (0.5926)  loss_vfl_dn_5: 0.6008 (0.6056)  loss_vfl_enc_0: 0.9888 (0.9937)\r\n",
      "Test:  [0/8]  eta: 0:00:16    time: 2.0923  data: 1.1490  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0008  data: 0.2052  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0148 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.29s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.018\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.027\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.018\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.038\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.024\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.132\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.202\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.220\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.057\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.320\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.340\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.329\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.218\r\n",
      "best_stat: {'epoch': 33, 'coco_eval_bbox': 0.020907610098263505}\r\n",
      "Epoch: [39]  [ 0/79]  eta: 0:06:32  lr: 0.000020  loss: 28.6064 (28.6064)  loss_bbox: 0.3226 (0.3226)  loss_bbox_aux_0: 0.3619 (0.3619)  loss_bbox_aux_1: 0.3532 (0.3532)  loss_bbox_aux_2: 0.3658 (0.3658)  loss_bbox_aux_3: 0.3244 (0.3244)  loss_bbox_aux_4: 0.3370 (0.3370)  loss_bbox_dn_0: 0.3511 (0.3511)  loss_bbox_dn_1: 0.3243 (0.3243)  loss_bbox_dn_2: 0.3132 (0.3132)  loss_bbox_dn_3: 0.3079 (0.3079)  loss_bbox_dn_4: 0.3042 (0.3042)  loss_bbox_dn_5: 0.3036 (0.3036)  loss_bbox_enc_0: 0.4096 (0.4096)  loss_giou: 1.0149 (1.0149)  loss_giou_aux_0: 1.0469 (1.0469)  loss_giou_aux_1: 1.0371 (1.0371)  loss_giou_aux_2: 0.9927 (0.9927)  loss_giou_aux_3: 1.0862 (1.0862)  loss_giou_aux_4: 1.0606 (1.0606)  loss_giou_dn_0: 1.0617 (1.0617)  loss_giou_dn_1: 0.9586 (0.9586)  loss_giou_dn_2: 0.9105 (0.9105)  loss_giou_dn_3: 0.9028 (0.9028)  loss_giou_dn_4: 0.8869 (0.8869)  loss_giou_dn_5: 0.8859 (0.8859)  loss_giou_enc_0: 1.2266 (1.2266)  loss_vfl: 1.1362 (1.1362)  loss_vfl_aux_0: 1.0898 (1.0898)  loss_vfl_aux_1: 1.1260 (1.1260)  loss_vfl_aux_2: 1.1426 (1.1426)  loss_vfl_aux_3: 1.0981 (1.0981)  loss_vfl_aux_4: 1.0957 (1.0957)  loss_vfl_dn_0: 0.5050 (0.5050)  loss_vfl_dn_1: 0.5532 (0.5532)  loss_vfl_dn_2: 0.5701 (0.5701)  loss_vfl_dn_3: 0.6023 (0.6023)  loss_vfl_dn_4: 0.6289 (0.6289)  loss_vfl_dn_5: 0.6465 (0.6465)  loss_vfl_enc_0: 0.9619 (0.9619)  time: 4.9664  data: 3.2018  max mem: 10356\r\n",
      "Epoch: [39]  [78/79]  eta: 0:00:01  lr: 0.000020  loss: 30.0744 (29.6534)  loss_bbox: 0.3189 (0.3199)  loss_bbox_aux_0: 0.3552 (0.3532)  loss_bbox_aux_1: 0.3530 (0.3418)  loss_bbox_aux_2: 0.3374 (0.3319)  loss_bbox_aux_3: 0.3349 (0.3271)  loss_bbox_aux_4: 0.3190 (0.3230)  loss_bbox_dn_0: 0.4364 (0.4119)  loss_bbox_dn_1: 0.3951 (0.3825)  loss_bbox_dn_2: 0.3750 (0.3686)  loss_bbox_dn_3: 0.3695 (0.3604)  loss_bbox_dn_4: 0.3653 (0.3558)  loss_bbox_dn_5: 0.3661 (0.3551)  loss_bbox_enc_0: 0.4212 (0.4043)  loss_giou: 0.9596 (1.0639)  loss_giou_aux_0: 1.0025 (1.1085)  loss_giou_aux_1: 0.9962 (1.0951)  loss_giou_aux_2: 0.9874 (1.0783)  loss_giou_aux_3: 0.9774 (1.0722)  loss_giou_aux_4: 0.9647 (1.0646)  loss_giou_dn_0: 1.1237 (1.1314)  loss_giou_dn_1: 1.0515 (1.0516)  loss_giou_dn_2: 1.0065 (1.0177)  loss_giou_dn_3: 1.0004 (1.0010)  loss_giou_dn_4: 0.9849 (0.9897)  loss_giou_dn_5: 0.9850 (0.9886)  loss_giou_enc_0: 1.1240 (1.2022)  loss_vfl: 1.2266 (1.1351)  loss_vfl_aux_0: 1.2124 (1.1209)  loss_vfl_aux_1: 1.2114 (1.1142)  loss_vfl_aux_2: 1.2158 (1.1263)  loss_vfl_aux_3: 1.1992 (1.1362)  loss_vfl_aux_4: 1.2153 (1.1359)  loss_vfl_dn_0: 0.5052 (0.5040)  loss_vfl_dn_1: 0.5447 (0.5370)  loss_vfl_dn_2: 0.5702 (0.5562)  loss_vfl_dn_3: 0.5896 (0.5762)  loss_vfl_dn_4: 0.6125 (0.5953)  loss_vfl_dn_5: 0.6262 (0.6084)  loss_vfl_enc_0: 1.0420 (1.0074)  time: 1.0346  data: 0.0312  max mem: 10356\r\n",
      "Epoch: [39] Total time: 0:01:26 (1.0958 s / it)\r\n",
      "Averaged stats: lr: 0.000020  loss: 30.0744 (29.6534)  loss_bbox: 0.3189 (0.3199)  loss_bbox_aux_0: 0.3552 (0.3532)  loss_bbox_aux_1: 0.3530 (0.3418)  loss_bbox_aux_2: 0.3374 (0.3319)  loss_bbox_aux_3: 0.3349 (0.3271)  loss_bbox_aux_4: 0.3190 (0.3230)  loss_bbox_dn_0: 0.4364 (0.4119)  loss_bbox_dn_1: 0.3951 (0.3825)  loss_bbox_dn_2: 0.3750 (0.3686)  loss_bbox_dn_3: 0.3695 (0.3604)  loss_bbox_dn_4: 0.3653 (0.3558)  loss_bbox_dn_5: 0.3661 (0.3551)  loss_bbox_enc_0: 0.4212 (0.4043)  loss_giou: 0.9596 (1.0639)  loss_giou_aux_0: 1.0025 (1.1085)  loss_giou_aux_1: 0.9962 (1.0951)  loss_giou_aux_2: 0.9874 (1.0783)  loss_giou_aux_3: 0.9774 (1.0722)  loss_giou_aux_4: 0.9647 (1.0646)  loss_giou_dn_0: 1.1237 (1.1314)  loss_giou_dn_1: 1.0515 (1.0516)  loss_giou_dn_2: 1.0065 (1.0177)  loss_giou_dn_3: 1.0004 (1.0010)  loss_giou_dn_4: 0.9849 (0.9897)  loss_giou_dn_5: 0.9850 (0.9886)  loss_giou_enc_0: 1.1240 (1.2022)  loss_vfl: 1.2266 (1.1351)  loss_vfl_aux_0: 1.2124 (1.1209)  loss_vfl_aux_1: 1.2114 (1.1142)  loss_vfl_aux_2: 1.2158 (1.1263)  loss_vfl_aux_3: 1.1992 (1.1362)  loss_vfl_aux_4: 1.2153 (1.1359)  loss_vfl_dn_0: 0.5052 (0.5040)  loss_vfl_dn_1: 0.5447 (0.5370)  loss_vfl_dn_2: 0.5702 (0.5562)  loss_vfl_dn_3: 0.5896 (0.5762)  loss_vfl_dn_4: 0.6125 (0.5953)  loss_vfl_dn_5: 0.6262 (0.6084)  loss_vfl_enc_0: 1.0420 (1.0074)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.4195  data: 1.4626  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0233  data: 0.2301  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0369 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.022\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.034\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.022\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.041\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.028\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.136\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.218\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.052\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.303\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.320\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.316\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.224\r\n",
      "best_stat: {'epoch': 39, 'coco_eval_bbox': 0.022143492214398586}\r\n",
      "Epoch: [40]  [ 0/79]  eta: 0:05:20  lr: 0.000002  loss: 31.3722 (31.3722)  loss_bbox: 0.3996 (0.3996)  loss_bbox_aux_0: 0.4018 (0.4018)  loss_bbox_aux_1: 0.3895 (0.3895)  loss_bbox_aux_2: 0.3945 (0.3945)  loss_bbox_aux_3: 0.4085 (0.4085)  loss_bbox_aux_4: 0.4206 (0.4206)  loss_bbox_dn_0: 0.7799 (0.7799)  loss_bbox_dn_1: 0.6937 (0.6937)  loss_bbox_dn_2: 0.6517 (0.6517)  loss_bbox_dn_3: 0.6246 (0.6246)  loss_bbox_dn_4: 0.6086 (0.6086)  loss_bbox_dn_5: 0.6043 (0.6043)  loss_bbox_enc_0: 0.5198 (0.5198)  loss_giou: 0.7536 (0.7536)  loss_giou_aux_0: 0.7610 (0.7610)  loss_giou_aux_1: 0.7370 (0.7370)  loss_giou_aux_2: 0.7306 (0.7306)  loss_giou_aux_3: 0.7346 (0.7346)  loss_giou_aux_4: 0.7290 (0.7290)  loss_giou_dn_0: 1.0316 (1.0316)  loss_giou_dn_1: 0.8821 (0.8821)  loss_giou_dn_2: 0.8165 (0.8165)  loss_giou_dn_3: 0.7757 (0.7757)  loss_giou_dn_4: 0.7480 (0.7480)  loss_giou_dn_5: 0.7453 (0.7453)  loss_giou_enc_0: 0.9294 (0.9294)  loss_vfl: 1.3389 (1.3389)  loss_vfl_aux_0: 1.6826 (1.6826)  loss_vfl_aux_1: 1.6118 (1.6118)  loss_vfl_aux_2: 1.4326 (1.4326)  loss_vfl_aux_3: 1.4219 (1.4219)  loss_vfl_aux_4: 1.3608 (1.3608)  loss_vfl_dn_0: 0.5447 (0.5447)  loss_vfl_dn_1: 0.6235 (0.6235)  loss_vfl_dn_2: 0.6350 (0.6350)  loss_vfl_dn_3: 0.6721 (0.6721)  loss_vfl_dn_4: 0.6973 (0.6973)  loss_vfl_dn_5: 0.7183 (0.7183)  loss_vfl_enc_0: 1.3613 (1.3613)  time: 4.0546  data: 2.8562  max mem: 10356\r\n",
      "Epoch: [40]  [78/79]  eta: 0:00:01  lr: 0.000002  loss: 28.7708 (29.4911)  loss_bbox: 0.2896 (0.3267)  loss_bbox_aux_0: 0.3131 (0.3581)  loss_bbox_aux_1: 0.3019 (0.3451)  loss_bbox_aux_2: 0.2963 (0.3353)  loss_bbox_aux_3: 0.2777 (0.3305)  loss_bbox_aux_4: 0.2929 (0.3270)  loss_bbox_dn_0: 0.3473 (0.4189)  loss_bbox_dn_1: 0.3169 (0.3870)  loss_bbox_dn_2: 0.3092 (0.3717)  loss_bbox_dn_3: 0.3055 (0.3627)  loss_bbox_dn_4: 0.3040 (0.3576)  loss_bbox_dn_5: 0.3037 (0.3566)  loss_bbox_enc_0: 0.3505 (0.3937)  loss_giou: 1.0625 (1.0608)  loss_giou_aux_0: 1.0958 (1.0999)  loss_giou_aux_1: 1.0875 (1.0852)  loss_giou_aux_2: 1.0682 (1.0714)  loss_giou_aux_3: 1.0599 (1.0655)  loss_giou_aux_4: 1.0590 (1.0627)  loss_giou_dn_0: 1.1226 (1.1211)  loss_giou_dn_1: 1.0421 (1.0397)  loss_giou_dn_2: 1.0099 (1.0047)  loss_giou_dn_3: 0.9908 (0.9879)  loss_giou_dn_4: 0.9766 (0.9769)  loss_giou_dn_5: 0.9764 (0.9756)  loss_giou_enc_0: 1.1724 (1.1923)  loss_vfl: 1.0066 (1.1071)  loss_vfl_aux_0: 1.0554 (1.1346)  loss_vfl_aux_1: 0.9944 (1.1126)  loss_vfl_aux_2: 0.9915 (1.1037)  loss_vfl_aux_3: 1.0278 (1.1066)  loss_vfl_aux_4: 1.0220 (1.1133)  loss_vfl_dn_0: 0.5020 (0.5058)  loss_vfl_dn_1: 0.5276 (0.5389)  loss_vfl_dn_2: 0.5483 (0.5564)  loss_vfl_dn_3: 0.5657 (0.5752)  loss_vfl_dn_4: 0.5820 (0.5961)  loss_vfl_dn_5: 0.5876 (0.6074)  loss_vfl_enc_0: 0.9375 (1.0190)  time: 1.0050  data: 0.0325  max mem: 10356\r\n",
      "Epoch: [40] Total time: 0:01:26 (1.0926 s / it)\r\n",
      "Averaged stats: lr: 0.000002  loss: 28.7708 (29.4911)  loss_bbox: 0.2896 (0.3267)  loss_bbox_aux_0: 0.3131 (0.3581)  loss_bbox_aux_1: 0.3019 (0.3451)  loss_bbox_aux_2: 0.2963 (0.3353)  loss_bbox_aux_3: 0.2777 (0.3305)  loss_bbox_aux_4: 0.2929 (0.3270)  loss_bbox_dn_0: 0.3473 (0.4189)  loss_bbox_dn_1: 0.3169 (0.3870)  loss_bbox_dn_2: 0.3092 (0.3717)  loss_bbox_dn_3: 0.3055 (0.3627)  loss_bbox_dn_4: 0.3040 (0.3576)  loss_bbox_dn_5: 0.3037 (0.3566)  loss_bbox_enc_0: 0.3505 (0.3937)  loss_giou: 1.0625 (1.0608)  loss_giou_aux_0: 1.0958 (1.0999)  loss_giou_aux_1: 1.0875 (1.0852)  loss_giou_aux_2: 1.0682 (1.0714)  loss_giou_aux_3: 1.0599 (1.0655)  loss_giou_aux_4: 1.0590 (1.0627)  loss_giou_dn_0: 1.1226 (1.1211)  loss_giou_dn_1: 1.0421 (1.0397)  loss_giou_dn_2: 1.0099 (1.0047)  loss_giou_dn_3: 0.9908 (0.9879)  loss_giou_dn_4: 0.9766 (0.9769)  loss_giou_dn_5: 0.9764 (0.9756)  loss_giou_enc_0: 1.1724 (1.1923)  loss_vfl: 1.0066 (1.1071)  loss_vfl_aux_0: 1.0554 (1.1346)  loss_vfl_aux_1: 0.9944 (1.1126)  loss_vfl_aux_2: 0.9915 (1.1037)  loss_vfl_aux_3: 1.0278 (1.1066)  loss_vfl_aux_4: 1.0220 (1.1133)  loss_vfl_dn_0: 0.5020 (0.5058)  loss_vfl_dn_1: 0.5276 (0.5389)  loss_vfl_dn_2: 0.5483 (0.5564)  loss_vfl_dn_3: 0.5657 (0.5752)  loss_vfl_dn_4: 0.5820 (0.5961)  loss_vfl_dn_5: 0.5876 (0.6074)  loss_vfl_enc_0: 0.9375 (1.0190)\r\n",
      "Test:  [0/8]  eta: 0:00:23    time: 2.9098  data: 1.4234  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0836  data: 0.2260  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1018 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.026\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.035\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.027\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.050\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.029\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.154\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.223\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.235\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.316\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.340\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.340\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.239\r\n",
      "best_stat: {'epoch': 40, 'coco_eval_bbox': 0.026091777187752605}\r\n",
      "Epoch: [41]  [ 0/79]  eta: 0:06:15  lr: 0.000002  loss: 29.1195 (29.1195)  loss_bbox: 0.3065 (0.3065)  loss_bbox_aux_0: 0.3279 (0.3279)  loss_bbox_aux_1: 0.3481 (0.3481)  loss_bbox_aux_2: 0.3101 (0.3101)  loss_bbox_aux_3: 0.3092 (0.3092)  loss_bbox_aux_4: 0.3333 (0.3333)  loss_bbox_dn_0: 0.3037 (0.3037)  loss_bbox_dn_1: 0.2860 (0.2860)  loss_bbox_dn_2: 0.2777 (0.2777)  loss_bbox_dn_3: 0.2730 (0.2730)  loss_bbox_dn_4: 0.2739 (0.2739)  loss_bbox_dn_5: 0.2747 (0.2747)  loss_bbox_enc_0: 0.3548 (0.3548)  loss_giou: 1.1601 (1.1601)  loss_giou_aux_0: 1.1217 (1.1217)  loss_giou_aux_1: 1.1441 (1.1441)  loss_giou_aux_2: 1.1705 (1.1705)  loss_giou_aux_3: 1.1572 (1.1572)  loss_giou_aux_4: 1.1778 (1.1778)  loss_giou_dn_0: 1.0823 (1.0823)  loss_giou_dn_1: 1.0090 (1.0090)  loss_giou_dn_2: 0.9747 (0.9747)  loss_giou_dn_3: 0.9524 (0.9524)  loss_giou_dn_4: 0.9417 (0.9417)  loss_giou_dn_5: 0.9414 (0.9414)  loss_giou_enc_0: 1.2721 (1.2721)  loss_vfl: 1.0210 (1.0210)  loss_vfl_aux_0: 1.2095 (1.2095)  loss_vfl_aux_1: 1.1050 (1.1050)  loss_vfl_aux_2: 1.0361 (1.0361)  loss_vfl_aux_3: 1.0300 (1.0300)  loss_vfl_aux_4: 1.0012 (1.0012)  loss_vfl_dn_0: 0.5391 (0.5391)  loss_vfl_dn_1: 0.5671 (0.5671)  loss_vfl_dn_2: 0.5840 (0.5840)  loss_vfl_dn_3: 0.6013 (0.6013)  loss_vfl_dn_4: 0.6248 (0.6248)  loss_vfl_dn_5: 0.6438 (0.6438)  loss_vfl_enc_0: 1.0728 (1.0728)  time: 4.7593  data: 3.3418  max mem: 10356\r\n",
      "Epoch: [41]  [78/79]  eta: 0:00:01  lr: 0.000002  loss: 28.6003 (29.5285)  loss_bbox: 0.3044 (0.3324)  loss_bbox_aux_0: 0.3161 (0.3601)  loss_bbox_aux_1: 0.3111 (0.3510)  loss_bbox_aux_2: 0.3149 (0.3445)  loss_bbox_aux_3: 0.3051 (0.3388)  loss_bbox_aux_4: 0.3082 (0.3328)  loss_bbox_dn_0: 0.3848 (0.4057)  loss_bbox_dn_1: 0.3504 (0.3741)  loss_bbox_dn_2: 0.3336 (0.3590)  loss_bbox_dn_3: 0.3221 (0.3503)  loss_bbox_dn_4: 0.3139 (0.3453)  loss_bbox_dn_5: 0.3124 (0.3444)  loss_bbox_enc_0: 0.3826 (0.3992)  loss_giou: 1.0254 (1.0854)  loss_giou_aux_0: 1.0797 (1.1213)  loss_giou_aux_1: 1.0608 (1.1098)  loss_giou_aux_2: 1.0328 (1.0959)  loss_giou_aux_3: 1.0302 (1.0934)  loss_giou_aux_4: 1.0286 (1.0880)  loss_giou_dn_0: 1.1055 (1.1259)  loss_giou_dn_1: 1.0111 (1.0443)  loss_giou_dn_2: 0.9801 (1.0077)  loss_giou_dn_3: 0.9575 (0.9895)  loss_giou_dn_4: 0.9476 (0.9774)  loss_giou_dn_5: 0.9476 (0.9763)  loss_giou_enc_0: 1.1774 (1.2157)  loss_vfl: 1.1104 (1.0889)  loss_vfl_aux_0: 1.0903 (1.1124)  loss_vfl_aux_1: 1.1174 (1.0978)  loss_vfl_aux_2: 1.1321 (1.0926)  loss_vfl_aux_3: 1.1101 (1.0962)  loss_vfl_aux_4: 1.1282 (1.0929)  loss_vfl_dn_0: 0.5004 (0.5042)  loss_vfl_dn_1: 0.5530 (0.5382)  loss_vfl_dn_2: 0.5686 (0.5572)  loss_vfl_dn_3: 0.5918 (0.5763)  loss_vfl_dn_4: 0.6128 (0.5956)  loss_vfl_dn_5: 0.6143 (0.6066)  loss_vfl_enc_0: 1.0015 (1.0015)  time: 0.9896  data: 0.0326  max mem: 10356\r\n",
      "Epoch: [41] Total time: 0:01:25 (1.0824 s / it)\r\n",
      "Averaged stats: lr: 0.000002  loss: 28.6003 (29.5285)  loss_bbox: 0.3044 (0.3324)  loss_bbox_aux_0: 0.3161 (0.3601)  loss_bbox_aux_1: 0.3111 (0.3510)  loss_bbox_aux_2: 0.3149 (0.3445)  loss_bbox_aux_3: 0.3051 (0.3388)  loss_bbox_aux_4: 0.3082 (0.3328)  loss_bbox_dn_0: 0.3848 (0.4057)  loss_bbox_dn_1: 0.3504 (0.3741)  loss_bbox_dn_2: 0.3336 (0.3590)  loss_bbox_dn_3: 0.3221 (0.3503)  loss_bbox_dn_4: 0.3139 (0.3453)  loss_bbox_dn_5: 0.3124 (0.3444)  loss_bbox_enc_0: 0.3826 (0.3992)  loss_giou: 1.0254 (1.0854)  loss_giou_aux_0: 1.0797 (1.1213)  loss_giou_aux_1: 1.0608 (1.1098)  loss_giou_aux_2: 1.0328 (1.0959)  loss_giou_aux_3: 1.0302 (1.0934)  loss_giou_aux_4: 1.0286 (1.0880)  loss_giou_dn_0: 1.1055 (1.1259)  loss_giou_dn_1: 1.0111 (1.0443)  loss_giou_dn_2: 0.9801 (1.0077)  loss_giou_dn_3: 0.9575 (0.9895)  loss_giou_dn_4: 0.9476 (0.9774)  loss_giou_dn_5: 0.9476 (0.9763)  loss_giou_enc_0: 1.1774 (1.2157)  loss_vfl: 1.1104 (1.0889)  loss_vfl_aux_0: 1.0903 (1.1124)  loss_vfl_aux_1: 1.1174 (1.0978)  loss_vfl_aux_2: 1.1321 (1.0926)  loss_vfl_aux_3: 1.1101 (1.0962)  loss_vfl_aux_4: 1.1282 (1.0929)  loss_vfl_dn_0: 0.5004 (0.5042)  loss_vfl_dn_1: 0.5530 (0.5382)  loss_vfl_dn_2: 0.5686 (0.5572)  loss_vfl_dn_3: 0.5918 (0.5763)  loss_vfl_dn_4: 0.6128 (0.5956)  loss_vfl_dn_5: 0.6143 (0.6066)  loss_vfl_enc_0: 1.0015 (1.0015)\r\n",
      "Test:  [0/8]  eta: 0:00:21    time: 2.7141  data: 1.2292  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0679  data: 0.2062  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0841 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.024\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.032\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.025\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.048\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.028\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.155\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.216\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.231\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.320\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.329\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.331\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.236\r\n",
      "best_stat: {'epoch': 40, 'coco_eval_bbox': 0.026091777187752605}\r\n",
      "Epoch: [42]  [ 0/79]  eta: 0:05:40  lr: 0.000002  loss: 29.4029 (29.4029)  loss_bbox: 0.3330 (0.3330)  loss_bbox_aux_0: 0.3390 (0.3390)  loss_bbox_aux_1: 0.3207 (0.3207)  loss_bbox_aux_2: 0.3211 (0.3211)  loss_bbox_aux_3: 0.3315 (0.3315)  loss_bbox_aux_4: 0.3356 (0.3356)  loss_bbox_dn_0: 0.4294 (0.4294)  loss_bbox_dn_1: 0.3880 (0.3880)  loss_bbox_dn_2: 0.3727 (0.3727)  loss_bbox_dn_3: 0.3644 (0.3644)  loss_bbox_dn_4: 0.3597 (0.3597)  loss_bbox_dn_5: 0.3586 (0.3586)  loss_bbox_enc_0: 0.4221 (0.4221)  loss_giou: 0.8419 (0.8419)  loss_giou_aux_0: 0.9460 (0.9460)  loss_giou_aux_1: 0.8586 (0.8586)  loss_giou_aux_2: 0.8880 (0.8880)  loss_giou_aux_3: 0.8597 (0.8597)  loss_giou_aux_4: 0.8593 (0.8593)  loss_giou_dn_0: 1.0545 (1.0545)  loss_giou_dn_1: 0.9349 (0.9349)  loss_giou_dn_2: 0.9012 (0.9012)  loss_giou_dn_3: 0.8813 (0.8813)  loss_giou_dn_4: 0.8683 (0.8683)  loss_giou_dn_5: 0.8676 (0.8676)  loss_giou_enc_0: 1.1277 (1.1277)  loss_vfl: 1.3647 (1.3647)  loss_vfl_aux_0: 1.3447 (1.3447)  loss_vfl_aux_1: 1.3838 (1.3838)  loss_vfl_aux_2: 1.3184 (1.3184)  loss_vfl_aux_3: 1.3350 (1.3350)  loss_vfl_aux_4: 1.2993 (1.2993)  loss_vfl_dn_0: 0.5417 (0.5417)  loss_vfl_dn_1: 0.5820 (0.5820)  loss_vfl_dn_2: 0.6050 (0.6050)  loss_vfl_dn_3: 0.6526 (0.6526)  loss_vfl_dn_4: 0.6553 (0.6553)  loss_vfl_dn_5: 0.6885 (0.6885)  loss_vfl_enc_0: 1.0669 (1.0669)  time: 4.3069  data: 2.6614  max mem: 10356\r\n",
      "Epoch: [42]  [78/79]  eta: 0:00:01  lr: 0.000002  loss: 28.5312 (29.5210)  loss_bbox: 0.2733 (0.3164)  loss_bbox_aux_0: 0.2981 (0.3497)  loss_bbox_aux_1: 0.2950 (0.3372)  loss_bbox_aux_2: 0.2884 (0.3284)  loss_bbox_aux_3: 0.2737 (0.3234)  loss_bbox_aux_4: 0.2700 (0.3175)  loss_bbox_dn_0: 0.3763 (0.4059)  loss_bbox_dn_1: 0.3381 (0.3731)  loss_bbox_dn_2: 0.3086 (0.3578)  loss_bbox_dn_3: 0.2926 (0.3488)  loss_bbox_dn_4: 0.2898 (0.3440)  loss_bbox_dn_5: 0.2900 (0.3431)  loss_bbox_enc_0: 0.3610 (0.3931)  loss_giou: 1.1252 (1.0830)  loss_giou_aux_0: 1.1340 (1.1251)  loss_giou_aux_1: 1.1127 (1.1099)  loss_giou_aux_2: 1.1111 (1.0955)  loss_giou_aux_3: 1.1135 (1.0905)  loss_giou_aux_4: 1.1342 (1.0840)  loss_giou_dn_0: 1.1099 (1.1278)  loss_giou_dn_1: 1.0348 (1.0462)  loss_giou_dn_2: 0.9956 (1.0105)  loss_giou_dn_3: 0.9848 (0.9933)  loss_giou_dn_4: 0.9784 (0.9817)  loss_giou_dn_5: 0.9781 (0.9802)  loss_giou_enc_0: 1.1900 (1.2125)  loss_vfl: 1.0525 (1.1067)  loss_vfl_aux_0: 1.0352 (1.1110)  loss_vfl_aux_1: 1.0930 (1.1037)  loss_vfl_aux_2: 1.0854 (1.1085)  loss_vfl_aux_3: 1.0647 (1.1102)  loss_vfl_aux_4: 1.0515 (1.1109)  loss_vfl_dn_0: 0.5016 (0.5057)  loss_vfl_dn_1: 0.5303 (0.5391)  loss_vfl_dn_2: 0.5497 (0.5572)  loss_vfl_dn_3: 0.5627 (0.5767)  loss_vfl_dn_4: 0.5771 (0.5954)  loss_vfl_dn_5: 0.5934 (0.6068)  loss_vfl_enc_0: 0.9824 (1.0107)  time: 1.0497  data: 0.0325  max mem: 10356\r\n",
      "Epoch: [42] Total time: 0:01:25 (1.0860 s / it)\r\n",
      "Averaged stats: lr: 0.000002  loss: 28.5312 (29.5210)  loss_bbox: 0.2733 (0.3164)  loss_bbox_aux_0: 0.2981 (0.3497)  loss_bbox_aux_1: 0.2950 (0.3372)  loss_bbox_aux_2: 0.2884 (0.3284)  loss_bbox_aux_3: 0.2737 (0.3234)  loss_bbox_aux_4: 0.2700 (0.3175)  loss_bbox_dn_0: 0.3763 (0.4059)  loss_bbox_dn_1: 0.3381 (0.3731)  loss_bbox_dn_2: 0.3086 (0.3578)  loss_bbox_dn_3: 0.2926 (0.3488)  loss_bbox_dn_4: 0.2898 (0.3440)  loss_bbox_dn_5: 0.2900 (0.3431)  loss_bbox_enc_0: 0.3610 (0.3931)  loss_giou: 1.1252 (1.0830)  loss_giou_aux_0: 1.1340 (1.1251)  loss_giou_aux_1: 1.1127 (1.1099)  loss_giou_aux_2: 1.1111 (1.0955)  loss_giou_aux_3: 1.1135 (1.0905)  loss_giou_aux_4: 1.1342 (1.0840)  loss_giou_dn_0: 1.1099 (1.1278)  loss_giou_dn_1: 1.0348 (1.0462)  loss_giou_dn_2: 0.9956 (1.0105)  loss_giou_dn_3: 0.9848 (0.9933)  loss_giou_dn_4: 0.9784 (0.9817)  loss_giou_dn_5: 0.9781 (0.9802)  loss_giou_enc_0: 1.1900 (1.2125)  loss_vfl: 1.0525 (1.1067)  loss_vfl_aux_0: 1.0352 (1.1110)  loss_vfl_aux_1: 1.0930 (1.1037)  loss_vfl_aux_2: 1.0854 (1.1085)  loss_vfl_aux_3: 1.0647 (1.1102)  loss_vfl_aux_4: 1.0515 (1.1109)  loss_vfl_dn_0: 0.5016 (0.5057)  loss_vfl_dn_1: 0.5303 (0.5391)  loss_vfl_dn_2: 0.5497 (0.5572)  loss_vfl_dn_3: 0.5627 (0.5767)  loss_vfl_dn_4: 0.5771 (0.5954)  loss_vfl_dn_5: 0.5934 (0.6068)  loss_vfl_enc_0: 0.9824 (1.0107)\r\n",
      "Test:  [0/8]  eta: 0:00:23    time: 2.9501  data: 1.5189  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0812  data: 0.2317  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0985 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.024\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.031\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.024\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.048\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.029\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.156\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.215\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.228\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.062\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.302\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.337\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.336\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.224\r\n",
      "best_stat: {'epoch': 40, 'coco_eval_bbox': 0.026091777187752605}\r\n",
      "Epoch: [43]  [ 0/79]  eta: 0:06:02  lr: 0.000002  loss: 31.3779 (31.3779)  loss_bbox: 0.4319 (0.4319)  loss_bbox_aux_0: 0.5057 (0.5057)  loss_bbox_aux_1: 0.4630 (0.4630)  loss_bbox_aux_2: 0.4645 (0.4645)  loss_bbox_aux_3: 0.4596 (0.4596)  loss_bbox_aux_4: 0.4483 (0.4483)  loss_bbox_dn_0: 0.6414 (0.6414)  loss_bbox_dn_1: 0.6011 (0.6011)  loss_bbox_dn_2: 0.5844 (0.5844)  loss_bbox_dn_3: 0.5719 (0.5719)  loss_bbox_dn_4: 0.5631 (0.5631)  loss_bbox_dn_5: 0.5619 (0.5619)  loss_bbox_enc_0: 0.5373 (0.5373)  loss_giou: 0.7951 (0.7951)  loss_giou_aux_0: 0.9103 (0.9103)  loss_giou_aux_1: 0.8492 (0.8492)  loss_giou_aux_2: 0.8332 (0.8332)  loss_giou_aux_3: 0.8312 (0.8312)  loss_giou_aux_4: 0.8082 (0.8082)  loss_giou_dn_0: 1.0297 (1.0297)  loss_giou_dn_1: 0.9307 (0.9307)  loss_giou_dn_2: 0.8827 (0.8827)  loss_giou_dn_3: 0.8556 (0.8556)  loss_giou_dn_4: 0.8318 (0.8318)  loss_giou_dn_5: 0.8320 (0.8320)  loss_giou_enc_0: 1.0158 (1.0158)  loss_vfl: 1.4312 (1.4312)  loss_vfl_aux_0: 1.4062 (1.4062)  loss_vfl_aux_1: 1.3706 (1.3706)  loss_vfl_aux_2: 1.3491 (1.3491)  loss_vfl_aux_3: 1.3442 (1.3442)  loss_vfl_aux_4: 1.4014 (1.4014)  loss_vfl_dn_0: 0.5298 (0.5298)  loss_vfl_dn_1: 0.5581 (0.5581)  loss_vfl_dn_2: 0.5818 (0.5818)  loss_vfl_dn_3: 0.6074 (0.6074)  loss_vfl_dn_4: 0.6216 (0.6216)  loss_vfl_dn_5: 0.6418 (0.6418)  loss_vfl_enc_0: 1.2949 (1.2949)  time: 4.5861  data: 2.2273  max mem: 10356\r\n",
      "Epoch: [43]  [78/79]  eta: 0:00:01  lr: 0.000002  loss: 29.3796 (29.4804)  loss_bbox: 0.3119 (0.3245)  loss_bbox_aux_0: 0.3326 (0.3494)  loss_bbox_aux_1: 0.3215 (0.3413)  loss_bbox_aux_2: 0.3184 (0.3346)  loss_bbox_aux_3: 0.3226 (0.3303)  loss_bbox_aux_4: 0.3082 (0.3264)  loss_bbox_dn_0: 0.3520 (0.4194)  loss_bbox_dn_1: 0.3157 (0.3879)  loss_bbox_dn_2: 0.2972 (0.3728)  loss_bbox_dn_3: 0.2862 (0.3642)  loss_bbox_dn_4: 0.2807 (0.3592)  loss_bbox_dn_5: 0.2802 (0.3582)  loss_bbox_enc_0: 0.3741 (0.3945)  loss_giou: 1.0322 (1.0633)  loss_giou_aux_0: 1.0905 (1.1043)  loss_giou_aux_1: 1.0610 (1.0898)  loss_giou_aux_2: 1.0756 (1.0776)  loss_giou_aux_3: 1.0947 (1.0707)  loss_giou_aux_4: 1.0442 (1.0621)  loss_giou_dn_0: 1.1478 (1.1312)  loss_giou_dn_1: 1.0601 (1.0494)  loss_giou_dn_2: 1.0211 (1.0137)  loss_giou_dn_3: 1.0079 (0.9962)  loss_giou_dn_4: 1.0045 (0.9848)  loss_giou_dn_5: 1.0028 (0.9834)  loss_giou_enc_0: 1.2232 (1.1890)  loss_vfl: 1.0681 (1.0950)  loss_vfl_aux_0: 1.0374 (1.1132)  loss_vfl_aux_1: 1.0615 (1.1044)  loss_vfl_aux_2: 1.0505 (1.1019)  loss_vfl_aux_3: 1.0479 (1.1039)  loss_vfl_aux_4: 1.0610 (1.1043)  loss_vfl_dn_0: 0.4891 (0.5023)  loss_vfl_dn_1: 0.5304 (0.5366)  loss_vfl_dn_2: 0.5460 (0.5545)  loss_vfl_dn_3: 0.5682 (0.5740)  loss_vfl_dn_4: 0.5841 (0.5919)  loss_vfl_dn_5: 0.5928 (0.6027)  loss_vfl_enc_0: 0.8840 (1.0176)  time: 1.0084  data: 0.0334  max mem: 10356\r\n",
      "Epoch: [43] Total time: 0:01:26 (1.0935 s / it)\r\n",
      "Averaged stats: lr: 0.000002  loss: 29.3796 (29.4804)  loss_bbox: 0.3119 (0.3245)  loss_bbox_aux_0: 0.3326 (0.3494)  loss_bbox_aux_1: 0.3215 (0.3413)  loss_bbox_aux_2: 0.3184 (0.3346)  loss_bbox_aux_3: 0.3226 (0.3303)  loss_bbox_aux_4: 0.3082 (0.3264)  loss_bbox_dn_0: 0.3520 (0.4194)  loss_bbox_dn_1: 0.3157 (0.3879)  loss_bbox_dn_2: 0.2972 (0.3728)  loss_bbox_dn_3: 0.2862 (0.3642)  loss_bbox_dn_4: 0.2807 (0.3592)  loss_bbox_dn_5: 0.2802 (0.3582)  loss_bbox_enc_0: 0.3741 (0.3945)  loss_giou: 1.0322 (1.0633)  loss_giou_aux_0: 1.0905 (1.1043)  loss_giou_aux_1: 1.0610 (1.0898)  loss_giou_aux_2: 1.0756 (1.0776)  loss_giou_aux_3: 1.0947 (1.0707)  loss_giou_aux_4: 1.0442 (1.0621)  loss_giou_dn_0: 1.1478 (1.1312)  loss_giou_dn_1: 1.0601 (1.0494)  loss_giou_dn_2: 1.0211 (1.0137)  loss_giou_dn_3: 1.0079 (0.9962)  loss_giou_dn_4: 1.0045 (0.9848)  loss_giou_dn_5: 1.0028 (0.9834)  loss_giou_enc_0: 1.2232 (1.1890)  loss_vfl: 1.0681 (1.0950)  loss_vfl_aux_0: 1.0374 (1.1132)  loss_vfl_aux_1: 1.0615 (1.1044)  loss_vfl_aux_2: 1.0505 (1.1019)  loss_vfl_aux_3: 1.0479 (1.1039)  loss_vfl_aux_4: 1.0610 (1.1043)  loss_vfl_dn_0: 0.4891 (0.5023)  loss_vfl_dn_1: 0.5304 (0.5366)  loss_vfl_dn_2: 0.5460 (0.5545)  loss_vfl_dn_3: 0.5682 (0.5740)  loss_vfl_dn_4: 0.5841 (0.5919)  loss_vfl_dn_5: 0.5928 (0.6027)  loss_vfl_enc_0: 0.8840 (1.0176)\r\n",
      "Test:  [0/8]  eta: 0:00:22    time: 2.8057  data: 1.2362  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0819  data: 0.2175  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1005 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.026\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.035\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.027\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.049\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.030\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.139\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.221\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.233\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.064\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.317\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.338\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.342\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.234\r\n",
      "best_stat: {'epoch': 40, 'coco_eval_bbox': 0.026091777187752605}\r\n",
      "Epoch: [44]  [ 0/79]  eta: 0:06:47  lr: 0.000002  loss: 30.3720 (30.3720)  loss_bbox: 0.3664 (0.3664)  loss_bbox_aux_0: 0.3940 (0.3940)  loss_bbox_aux_1: 0.3834 (0.3834)  loss_bbox_aux_2: 0.3674 (0.3674)  loss_bbox_aux_3: 0.3683 (0.3683)  loss_bbox_aux_4: 0.3667 (0.3667)  loss_bbox_dn_0: 0.3852 (0.3852)  loss_bbox_dn_1: 0.3722 (0.3722)  loss_bbox_dn_2: 0.3643 (0.3643)  loss_bbox_dn_3: 0.3612 (0.3612)  loss_bbox_dn_4: 0.3579 (0.3579)  loss_bbox_dn_5: 0.3583 (0.3583)  loss_bbox_enc_0: 0.4401 (0.4401)  loss_giou: 1.3080 (1.3080)  loss_giou_aux_0: 1.3526 (1.3526)  loss_giou_aux_1: 1.3288 (1.3288)  loss_giou_aux_2: 1.3477 (1.3477)  loss_giou_aux_3: 1.3261 (1.3261)  loss_giou_aux_4: 1.3122 (1.3122)  loss_giou_dn_0: 1.2181 (1.2181)  loss_giou_dn_1: 1.1788 (1.1788)  loss_giou_dn_2: 1.1617 (1.1617)  loss_giou_dn_3: 1.1561 (1.1561)  loss_giou_dn_4: 1.1510 (1.1510)  loss_giou_dn_5: 1.1500 (1.1500)  loss_giou_enc_0: 1.3655 (1.3655)  loss_vfl: 0.9490 (0.9490)  loss_vfl_aux_0: 0.8511 (0.8511)  loss_vfl_aux_1: 0.8889 (0.8889)  loss_vfl_aux_2: 0.9182 (0.9182)  loss_vfl_aux_3: 0.9304 (0.9304)  loss_vfl_aux_4: 0.9790 (0.9790)  loss_vfl_dn_0: 0.4423 (0.4423)  loss_vfl_dn_1: 0.4474 (0.4474)  loss_vfl_dn_2: 0.4500 (0.4500)  loss_vfl_dn_3: 0.4513 (0.4513)  loss_vfl_dn_4: 0.4691 (0.4691)  loss_vfl_dn_5: 0.4670 (0.4670)  loss_vfl_enc_0: 0.8862 (0.8862)  time: 5.1637  data: 3.1816  max mem: 10356\r\n",
      "Epoch: [44]  [78/79]  eta: 0:00:01  lr: 0.000002  loss: 28.4351 (29.4454)  loss_bbox: 0.2644 (0.3264)  loss_bbox_aux_0: 0.3120 (0.3555)  loss_bbox_aux_1: 0.2943 (0.3475)  loss_bbox_aux_2: 0.2785 (0.3369)  loss_bbox_aux_3: 0.2693 (0.3317)  loss_bbox_aux_4: 0.2728 (0.3281)  loss_bbox_dn_0: 0.3006 (0.4041)  loss_bbox_dn_1: 0.2734 (0.3717)  loss_bbox_dn_2: 0.2561 (0.3555)  loss_bbox_dn_3: 0.2542 (0.3458)  loss_bbox_dn_4: 0.2511 (0.3405)  loss_bbox_dn_5: 0.2502 (0.3394)  loss_bbox_enc_0: 0.3444 (0.3965)  loss_giou: 1.1307 (1.0787)  loss_giou_aux_0: 1.1667 (1.1169)  loss_giou_aux_1: 1.1663 (1.1081)  loss_giou_aux_2: 1.1560 (1.0937)  loss_giou_aux_3: 1.1351 (1.0881)  loss_giou_aux_4: 1.1318 (1.0803)  loss_giou_dn_0: 1.1376 (1.1287)  loss_giou_dn_1: 1.0417 (1.0468)  loss_giou_dn_2: 0.9911 (1.0093)  loss_giou_dn_3: 0.9644 (0.9907)  loss_giou_dn_4: 0.9659 (0.9784)  loss_giou_dn_5: 0.9662 (0.9766)  loss_giou_enc_0: 1.2323 (1.1995)  loss_vfl: 1.0132 (1.0906)  loss_vfl_aux_0: 1.0132 (1.1116)  loss_vfl_aux_1: 1.0122 (1.0886)  loss_vfl_aux_2: 0.9814 (1.0955)  loss_vfl_aux_3: 0.9863 (1.0965)  loss_vfl_aux_4: 1.0198 (1.0963)  loss_vfl_dn_0: 0.4965 (0.5044)  loss_vfl_dn_1: 0.5272 (0.5382)  loss_vfl_dn_2: 0.5480 (0.5568)  loss_vfl_dn_3: 0.5726 (0.5751)  loss_vfl_dn_4: 0.5850 (0.5933)  loss_vfl_dn_5: 0.6042 (0.6033)  loss_vfl_enc_0: 0.8994 (1.0198)  time: 0.9681  data: 0.0322  max mem: 10356\r\n",
      "Epoch: [44] Total time: 0:01:27 (1.1093 s / it)\r\n",
      "Averaged stats: lr: 0.000002  loss: 28.4351 (29.4454)  loss_bbox: 0.2644 (0.3264)  loss_bbox_aux_0: 0.3120 (0.3555)  loss_bbox_aux_1: 0.2943 (0.3475)  loss_bbox_aux_2: 0.2785 (0.3369)  loss_bbox_aux_3: 0.2693 (0.3317)  loss_bbox_aux_4: 0.2728 (0.3281)  loss_bbox_dn_0: 0.3006 (0.4041)  loss_bbox_dn_1: 0.2734 (0.3717)  loss_bbox_dn_2: 0.2561 (0.3555)  loss_bbox_dn_3: 0.2542 (0.3458)  loss_bbox_dn_4: 0.2511 (0.3405)  loss_bbox_dn_5: 0.2502 (0.3394)  loss_bbox_enc_0: 0.3444 (0.3965)  loss_giou: 1.1307 (1.0787)  loss_giou_aux_0: 1.1667 (1.1169)  loss_giou_aux_1: 1.1663 (1.1081)  loss_giou_aux_2: 1.1560 (1.0937)  loss_giou_aux_3: 1.1351 (1.0881)  loss_giou_aux_4: 1.1318 (1.0803)  loss_giou_dn_0: 1.1376 (1.1287)  loss_giou_dn_1: 1.0417 (1.0468)  loss_giou_dn_2: 0.9911 (1.0093)  loss_giou_dn_3: 0.9644 (0.9907)  loss_giou_dn_4: 0.9659 (0.9784)  loss_giou_dn_5: 0.9662 (0.9766)  loss_giou_enc_0: 1.2323 (1.1995)  loss_vfl: 1.0132 (1.0906)  loss_vfl_aux_0: 1.0132 (1.1116)  loss_vfl_aux_1: 1.0122 (1.0886)  loss_vfl_aux_2: 0.9814 (1.0955)  loss_vfl_aux_3: 0.9863 (1.0965)  loss_vfl_aux_4: 1.0198 (1.0963)  loss_vfl_dn_0: 0.4965 (0.5044)  loss_vfl_dn_1: 0.5272 (0.5382)  loss_vfl_dn_2: 0.5480 (0.5568)  loss_vfl_dn_3: 0.5726 (0.5751)  loss_vfl_dn_4: 0.5850 (0.5933)  loss_vfl_dn_5: 0.6042 (0.6033)  loss_vfl_enc_0: 0.8994 (1.0198)\r\n",
      "Test:  [0/8]  eta: 0:00:23    time: 2.9316  data: 1.4440  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0800  data: 0.2215  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0979 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.19s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.028\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.037\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.029\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.054\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.029\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.150\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.214\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.230\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.064\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.301\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.343\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.345\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.226\r\n",
      "best_stat: {'epoch': 44, 'coco_eval_bbox': 0.027856668230323605}\r\n",
      "Epoch: [45]  [ 0/79]  eta: 0:05:03  lr: 0.000002  loss: 27.9206 (27.9206)  loss_bbox: 0.2537 (0.2537)  loss_bbox_aux_0: 0.2856 (0.2856)  loss_bbox_aux_1: 0.2679 (0.2679)  loss_bbox_aux_2: 0.2590 (0.2590)  loss_bbox_aux_3: 0.2560 (0.2560)  loss_bbox_aux_4: 0.2513 (0.2513)  loss_bbox_dn_0: 0.3154 (0.3154)  loss_bbox_dn_1: 0.2881 (0.2881)  loss_bbox_dn_2: 0.2766 (0.2766)  loss_bbox_dn_3: 0.2720 (0.2720)  loss_bbox_dn_4: 0.2676 (0.2676)  loss_bbox_dn_5: 0.2669 (0.2669)  loss_bbox_enc_0: 0.3463 (0.3463)  loss_giou: 1.1318 (1.1318)  loss_giou_aux_0: 1.2160 (1.2160)  loss_giou_aux_1: 1.1743 (1.1743)  loss_giou_aux_2: 1.1384 (1.1384)  loss_giou_aux_3: 1.1412 (1.1412)  loss_giou_aux_4: 1.1279 (1.1279)  loss_giou_dn_0: 1.1521 (1.1521)  loss_giou_dn_1: 1.0723 (1.0723)  loss_giou_dn_2: 1.0430 (1.0430)  loss_giou_dn_3: 1.0246 (1.0246)  loss_giou_dn_4: 1.0150 (1.0150)  loss_giou_dn_5: 1.0116 (1.0116)  loss_giou_enc_0: 1.2733 (1.2733)  loss_vfl: 0.9607 (0.9607)  loss_vfl_aux_0: 0.9121 (0.9121)  loss_vfl_aux_1: 0.9595 (0.9595)  loss_vfl_aux_2: 0.9907 (0.9907)  loss_vfl_aux_3: 0.9607 (0.9607)  loss_vfl_aux_4: 0.9507 (0.9507)  loss_vfl_dn_0: 0.4819 (0.4819)  loss_vfl_dn_1: 0.5137 (0.5137)  loss_vfl_dn_2: 0.5276 (0.5276)  loss_vfl_dn_3: 0.5420 (0.5420)  loss_vfl_dn_4: 0.5587 (0.5587)  loss_vfl_dn_5: 0.5792 (0.5792)  loss_vfl_enc_0: 0.8549 (0.8549)  time: 3.8472  data: 2.1530  max mem: 10356\r\n",
      "Epoch: [45]  [78/79]  eta: 0:00:01  lr: 0.000002  loss: 28.7935 (29.4164)  loss_bbox: 0.3051 (0.3219)  loss_bbox_aux_0: 0.3389 (0.3500)  loss_bbox_aux_1: 0.3443 (0.3384)  loss_bbox_aux_2: 0.3334 (0.3323)  loss_bbox_aux_3: 0.3126 (0.3255)  loss_bbox_aux_4: 0.3074 (0.3231)  loss_bbox_dn_0: 0.3178 (0.4143)  loss_bbox_dn_1: 0.2881 (0.3811)  loss_bbox_dn_2: 0.2850 (0.3663)  loss_bbox_dn_3: 0.2830 (0.3572)  loss_bbox_dn_4: 0.2828 (0.3521)  loss_bbox_dn_5: 0.2836 (0.3510)  loss_bbox_enc_0: 0.3834 (0.3953)  loss_giou: 1.1272 (1.0620)  loss_giou_aux_0: 1.1303 (1.0987)  loss_giou_aux_1: 1.1567 (1.0860)  loss_giou_aux_2: 1.1249 (1.0743)  loss_giou_aux_3: 1.1157 (1.0677)  loss_giou_aux_4: 1.1268 (1.0628)  loss_giou_dn_0: 1.1382 (1.1268)  loss_giou_dn_1: 1.0628 (1.0444)  loss_giou_dn_2: 1.0200 (1.0086)  loss_giou_dn_3: 0.9994 (0.9903)  loss_giou_dn_4: 0.9788 (0.9774)  loss_giou_dn_5: 0.9769 (0.9758)  loss_giou_enc_0: 1.2052 (1.1921)  loss_vfl: 0.9456 (1.1013)  loss_vfl_aux_0: 0.9543 (1.1257)  loss_vfl_aux_1: 0.9937 (1.1163)  loss_vfl_aux_2: 0.9373 (1.1084)  loss_vfl_aux_3: 0.9531 (1.1094)  loss_vfl_aux_4: 0.9541 (1.1025)  loss_vfl_dn_0: 0.4955 (0.5047)  loss_vfl_dn_1: 0.5172 (0.5376)  loss_vfl_dn_2: 0.5322 (0.5554)  loss_vfl_dn_3: 0.5502 (0.5756)  loss_vfl_dn_4: 0.5613 (0.5927)  loss_vfl_dn_5: 0.5736 (0.6028)  loss_vfl_enc_0: 0.8438 (1.0085)  time: 0.9520  data: 0.0316  max mem: 10356\r\n",
      "Epoch: [45] Total time: 0:01:23 (1.0523 s / it)\r\n",
      "Averaged stats: lr: 0.000002  loss: 28.7935 (29.4164)  loss_bbox: 0.3051 (0.3219)  loss_bbox_aux_0: 0.3389 (0.3500)  loss_bbox_aux_1: 0.3443 (0.3384)  loss_bbox_aux_2: 0.3334 (0.3323)  loss_bbox_aux_3: 0.3126 (0.3255)  loss_bbox_aux_4: 0.3074 (0.3231)  loss_bbox_dn_0: 0.3178 (0.4143)  loss_bbox_dn_1: 0.2881 (0.3811)  loss_bbox_dn_2: 0.2850 (0.3663)  loss_bbox_dn_3: 0.2830 (0.3572)  loss_bbox_dn_4: 0.2828 (0.3521)  loss_bbox_dn_5: 0.2836 (0.3510)  loss_bbox_enc_0: 0.3834 (0.3953)  loss_giou: 1.1272 (1.0620)  loss_giou_aux_0: 1.1303 (1.0987)  loss_giou_aux_1: 1.1567 (1.0860)  loss_giou_aux_2: 1.1249 (1.0743)  loss_giou_aux_3: 1.1157 (1.0677)  loss_giou_aux_4: 1.1268 (1.0628)  loss_giou_dn_0: 1.1382 (1.1268)  loss_giou_dn_1: 1.0628 (1.0444)  loss_giou_dn_2: 1.0200 (1.0086)  loss_giou_dn_3: 0.9994 (0.9903)  loss_giou_dn_4: 0.9788 (0.9774)  loss_giou_dn_5: 0.9769 (0.9758)  loss_giou_enc_0: 1.2052 (1.1921)  loss_vfl: 0.9456 (1.1013)  loss_vfl_aux_0: 0.9543 (1.1257)  loss_vfl_aux_1: 0.9937 (1.1163)  loss_vfl_aux_2: 0.9373 (1.1084)  loss_vfl_aux_3: 0.9531 (1.1094)  loss_vfl_aux_4: 0.9541 (1.1025)  loss_vfl_dn_0: 0.4955 (0.5047)  loss_vfl_dn_1: 0.5172 (0.5376)  loss_vfl_dn_2: 0.5322 (0.5554)  loss_vfl_dn_3: 0.5502 (0.5756)  loss_vfl_dn_4: 0.5613 (0.5927)  loss_vfl_dn_5: 0.5736 (0.6028)  loss_vfl_enc_0: 0.8438 (1.0085)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.2492  data: 1.2513  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0808  data: 0.2182  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0986 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.19s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.028\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.037\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.029\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.051\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.027\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.162\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.224\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.238\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.066\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.307\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.352\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.351\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.246\r\n",
      "best_stat: {'epoch': 44, 'coco_eval_bbox': 0.027856668230323605}\r\n",
      "Epoch: [46]  [ 0/79]  eta: 0:06:41  lr: 0.000002  loss: 27.9567 (27.9567)  loss_bbox: 0.2239 (0.2239)  loss_bbox_aux_0: 0.2903 (0.2903)  loss_bbox_aux_1: 0.2417 (0.2417)  loss_bbox_aux_2: 0.2615 (0.2615)  loss_bbox_aux_3: 0.2199 (0.2199)  loss_bbox_aux_4: 0.2265 (0.2265)  loss_bbox_dn_0: 0.3967 (0.3967)  loss_bbox_dn_1: 0.3480 (0.3480)  loss_bbox_dn_2: 0.3304 (0.3304)  loss_bbox_dn_3: 0.3202 (0.3202)  loss_bbox_dn_4: 0.3116 (0.3116)  loss_bbox_dn_5: 0.3098 (0.3098)  loss_bbox_enc_0: 0.3274 (0.3274)  loss_giou: 0.6839 (0.6839)  loss_giou_aux_0: 0.7858 (0.7858)  loss_giou_aux_1: 0.7473 (0.7473)  loss_giou_aux_2: 0.7511 (0.7511)  loss_giou_aux_3: 0.7059 (0.7059)  loss_giou_aux_4: 0.6887 (0.6887)  loss_giou_dn_0: 0.9699 (0.9699)  loss_giou_dn_1: 0.8451 (0.8451)  loss_giou_dn_2: 0.7926 (0.7926)  loss_giou_dn_3: 0.7716 (0.7716)  loss_giou_dn_4: 0.7450 (0.7450)  loss_giou_dn_5: 0.7411 (0.7411)  loss_giou_enc_0: 0.9246 (0.9246)  loss_vfl: 1.5679 (1.5679)  loss_vfl_aux_0: 1.4517 (1.4517)  loss_vfl_aux_1: 1.4829 (1.4829)  loss_vfl_aux_2: 1.3950 (1.3950)  loss_vfl_aux_3: 1.5254 (1.5254)  loss_vfl_aux_4: 1.5327 (1.5327)  loss_vfl_dn_0: 0.5443 (0.5443)  loss_vfl_dn_1: 0.5884 (0.5884)  loss_vfl_dn_2: 0.6021 (0.6021)  loss_vfl_dn_3: 0.6370 (0.6370)  loss_vfl_dn_4: 0.6597 (0.6597)  loss_vfl_dn_5: 0.6833 (0.6833)  loss_vfl_enc_0: 1.3257 (1.3257)  time: 5.0804  data: 3.1876  max mem: 10356\r\n",
      "Epoch: [46]  [78/79]  eta: 0:00:01  lr: 0.000002  loss: 29.5814 (29.0968)  loss_bbox: 0.2916 (0.3062)  loss_bbox_aux_0: 0.3425 (0.3330)  loss_bbox_aux_1: 0.3402 (0.3223)  loss_bbox_aux_2: 0.3020 (0.3139)  loss_bbox_aux_3: 0.2911 (0.3103)  loss_bbox_aux_4: 0.2790 (0.3062)  loss_bbox_dn_0: 0.4090 (0.4000)  loss_bbox_dn_1: 0.3906 (0.3670)  loss_bbox_dn_2: 0.3722 (0.3517)  loss_bbox_dn_3: 0.3590 (0.3425)  loss_bbox_dn_4: 0.3508 (0.3375)  loss_bbox_dn_5: 0.3484 (0.3366)  loss_bbox_enc_0: 0.3568 (0.3792)  loss_giou: 1.0004 (1.0337)  loss_giou_aux_0: 1.0354 (1.0758)  loss_giou_aux_1: 1.0422 (1.0613)  loss_giou_aux_2: 1.0283 (1.0458)  loss_giou_aux_3: 1.0040 (1.0428)  loss_giou_aux_4: 0.9974 (1.0351)  loss_giou_dn_0: 1.1270 (1.1195)  loss_giou_dn_1: 1.0418 (1.0368)  loss_giou_dn_2: 1.0062 (0.9994)  loss_giou_dn_3: 0.9865 (0.9805)  loss_giou_dn_4: 0.9739 (0.9679)  loss_giou_dn_5: 0.9743 (0.9662)  loss_giou_enc_0: 1.1206 (1.1739)  loss_vfl: 1.0781 (1.1088)  loss_vfl_aux_0: 1.1748 (1.1401)  loss_vfl_aux_1: 1.1309 (1.1249)  loss_vfl_aux_2: 1.1060 (1.1158)  loss_vfl_aux_3: 1.1021 (1.1195)  loss_vfl_aux_4: 1.1133 (1.1168)  loss_vfl_dn_0: 0.5016 (0.5080)  loss_vfl_dn_1: 0.5371 (0.5414)  loss_vfl_dn_2: 0.5566 (0.5600)  loss_vfl_dn_3: 0.5869 (0.5802)  loss_vfl_dn_4: 0.6116 (0.5985)  loss_vfl_dn_5: 0.6155 (0.6083)  loss_vfl_enc_0: 1.0095 (1.0295)  time: 0.9747  data: 0.0312  max mem: 10356\r\n",
      "Epoch: [46] Total time: 0:01:26 (1.1006 s / it)\r\n",
      "Averaged stats: lr: 0.000002  loss: 29.5814 (29.0968)  loss_bbox: 0.2916 (0.3062)  loss_bbox_aux_0: 0.3425 (0.3330)  loss_bbox_aux_1: 0.3402 (0.3223)  loss_bbox_aux_2: 0.3020 (0.3139)  loss_bbox_aux_3: 0.2911 (0.3103)  loss_bbox_aux_4: 0.2790 (0.3062)  loss_bbox_dn_0: 0.4090 (0.4000)  loss_bbox_dn_1: 0.3906 (0.3670)  loss_bbox_dn_2: 0.3722 (0.3517)  loss_bbox_dn_3: 0.3590 (0.3425)  loss_bbox_dn_4: 0.3508 (0.3375)  loss_bbox_dn_5: 0.3484 (0.3366)  loss_bbox_enc_0: 0.3568 (0.3792)  loss_giou: 1.0004 (1.0337)  loss_giou_aux_0: 1.0354 (1.0758)  loss_giou_aux_1: 1.0422 (1.0613)  loss_giou_aux_2: 1.0283 (1.0458)  loss_giou_aux_3: 1.0040 (1.0428)  loss_giou_aux_4: 0.9974 (1.0351)  loss_giou_dn_0: 1.1270 (1.1195)  loss_giou_dn_1: 1.0418 (1.0368)  loss_giou_dn_2: 1.0062 (0.9994)  loss_giou_dn_3: 0.9865 (0.9805)  loss_giou_dn_4: 0.9739 (0.9679)  loss_giou_dn_5: 0.9743 (0.9662)  loss_giou_enc_0: 1.1206 (1.1739)  loss_vfl: 1.0781 (1.1088)  loss_vfl_aux_0: 1.1748 (1.1401)  loss_vfl_aux_1: 1.1309 (1.1249)  loss_vfl_aux_2: 1.1060 (1.1158)  loss_vfl_aux_3: 1.1021 (1.1195)  loss_vfl_aux_4: 1.1133 (1.1168)  loss_vfl_dn_0: 0.5016 (0.5080)  loss_vfl_dn_1: 0.5371 (0.5414)  loss_vfl_dn_2: 0.5566 (0.5600)  loss_vfl_dn_3: 0.5869 (0.5802)  loss_vfl_dn_4: 0.6116 (0.5985)  loss_vfl_dn_5: 0.6155 (0.6083)  loss_vfl_enc_0: 1.0095 (1.0295)\r\n",
      "Test:  [0/8]  eta: 0:00:19    time: 2.4273  data: 1.4955  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0910  data: 0.2317  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1085 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.025\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.035\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.026\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.052\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.030\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.153\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.224\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.241\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.068\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.311\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.362\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.349\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.238\r\n",
      "best_stat: {'epoch': 44, 'coco_eval_bbox': 0.027856668230323605}\r\n",
      "Epoch: [47]  [ 0/79]  eta: 0:06:19  lr: 0.000002  loss: 30.7668 (30.7668)  loss_bbox: 0.4832 (0.4832)  loss_bbox_aux_0: 0.5237 (0.5237)  loss_bbox_aux_1: 0.5116 (0.5116)  loss_bbox_aux_2: 0.5079 (0.5079)  loss_bbox_aux_3: 0.4788 (0.4788)  loss_bbox_aux_4: 0.4773 (0.4773)  loss_bbox_dn_0: 0.5021 (0.5021)  loss_bbox_dn_1: 0.4776 (0.4776)  loss_bbox_dn_2: 0.4687 (0.4687)  loss_bbox_dn_3: 0.4641 (0.4641)  loss_bbox_dn_4: 0.4623 (0.4623)  loss_bbox_dn_5: 0.4618 (0.4618)  loss_bbox_enc_0: 0.5471 (0.5471)  loss_giou: 1.3115 (1.3115)  loss_giou_aux_0: 1.3379 (1.3379)  loss_giou_aux_1: 1.3179 (1.3179)  loss_giou_aux_2: 1.3176 (1.3176)  loss_giou_aux_3: 1.3162 (1.3162)  loss_giou_aux_4: 1.3092 (1.3092)  loss_giou_dn_0: 1.2196 (1.2196)  loss_giou_dn_1: 1.1610 (1.1610)  loss_giou_dn_2: 1.1468 (1.1468)  loss_giou_dn_3: 1.1358 (1.1358)  loss_giou_dn_4: 1.1339 (1.1339)  loss_giou_dn_5: 1.1335 (1.1335)  loss_giou_enc_0: 1.3780 (1.3780)  loss_vfl: 0.7861 (0.7861)  loss_vfl_aux_0: 0.7458 (0.7458)  loss_vfl_aux_1: 0.7644 (0.7644)  loss_vfl_aux_2: 0.7830 (0.7830)  loss_vfl_aux_3: 0.7966 (0.7966)  loss_vfl_aux_4: 0.7737 (0.7737)  loss_vfl_dn_0: 0.4460 (0.4460)  loss_vfl_dn_1: 0.4590 (0.4590)  loss_vfl_dn_2: 0.4586 (0.4586)  loss_vfl_dn_3: 0.4708 (0.4708)  loss_vfl_dn_4: 0.4767 (0.4767)  loss_vfl_dn_5: 0.4832 (0.4832)  loss_vfl_enc_0: 0.7377 (0.7377)  time: 4.7986  data: 2.6703  max mem: 10356\r\n",
      "Epoch: [47]  [78/79]  eta: 0:00:01  lr: 0.000002  loss: 29.8041 (29.4680)  loss_bbox: 0.3261 (0.3247)  loss_bbox_aux_0: 0.3451 (0.3569)  loss_bbox_aux_1: 0.3233 (0.3412)  loss_bbox_aux_2: 0.3277 (0.3340)  loss_bbox_aux_3: 0.3259 (0.3313)  loss_bbox_aux_4: 0.3292 (0.3246)  loss_bbox_dn_0: 0.3879 (0.4189)  loss_bbox_dn_1: 0.3431 (0.3856)  loss_bbox_dn_2: 0.3241 (0.3700)  loss_bbox_dn_3: 0.3125 (0.3604)  loss_bbox_dn_4: 0.3128 (0.3552)  loss_bbox_dn_5: 0.3113 (0.3542)  loss_bbox_enc_0: 0.4143 (0.4042)  loss_giou: 1.1082 (1.0579)  loss_giou_aux_0: 1.1447 (1.0948)  loss_giou_aux_1: 1.1196 (1.0829)  loss_giou_aux_2: 1.1239 (1.0685)  loss_giou_aux_3: 1.1306 (1.0661)  loss_giou_aux_4: 1.1404 (1.0610)  loss_giou_dn_0: 1.1199 (1.1159)  loss_giou_dn_1: 1.0532 (1.0334)  loss_giou_dn_2: 1.0124 (0.9970)  loss_giou_dn_3: 0.9909 (0.9784)  loss_giou_dn_4: 0.9759 (0.9673)  loss_giou_dn_5: 0.9740 (0.9659)  loss_giou_enc_0: 1.2104 (1.1848)  loss_vfl: 1.0994 (1.0992)  loss_vfl_aux_0: 1.0520 (1.1405)  loss_vfl_aux_1: 1.0759 (1.1236)  loss_vfl_aux_2: 1.1013 (1.1147)  loss_vfl_aux_3: 1.0859 (1.1105)  loss_vfl_aux_4: 1.0664 (1.1061)  loss_vfl_dn_0: 0.5087 (0.5126)  loss_vfl_dn_1: 0.5444 (0.5460)  loss_vfl_dn_2: 0.5582 (0.5641)  loss_vfl_dn_3: 0.5875 (0.5814)  loss_vfl_dn_4: 0.6023 (0.5965)  loss_vfl_dn_5: 0.6104 (0.6051)  loss_vfl_enc_0: 0.9836 (1.0324)  time: 0.9524  data: 0.0320  max mem: 10356\r\n",
      "Epoch: [47] Total time: 0:01:25 (1.0801 s / it)\r\n",
      "Averaged stats: lr: 0.000002  loss: 29.8041 (29.4680)  loss_bbox: 0.3261 (0.3247)  loss_bbox_aux_0: 0.3451 (0.3569)  loss_bbox_aux_1: 0.3233 (0.3412)  loss_bbox_aux_2: 0.3277 (0.3340)  loss_bbox_aux_3: 0.3259 (0.3313)  loss_bbox_aux_4: 0.3292 (0.3246)  loss_bbox_dn_0: 0.3879 (0.4189)  loss_bbox_dn_1: 0.3431 (0.3856)  loss_bbox_dn_2: 0.3241 (0.3700)  loss_bbox_dn_3: 0.3125 (0.3604)  loss_bbox_dn_4: 0.3128 (0.3552)  loss_bbox_dn_5: 0.3113 (0.3542)  loss_bbox_enc_0: 0.4143 (0.4042)  loss_giou: 1.1082 (1.0579)  loss_giou_aux_0: 1.1447 (1.0948)  loss_giou_aux_1: 1.1196 (1.0829)  loss_giou_aux_2: 1.1239 (1.0685)  loss_giou_aux_3: 1.1306 (1.0661)  loss_giou_aux_4: 1.1404 (1.0610)  loss_giou_dn_0: 1.1199 (1.1159)  loss_giou_dn_1: 1.0532 (1.0334)  loss_giou_dn_2: 1.0124 (0.9970)  loss_giou_dn_3: 0.9909 (0.9784)  loss_giou_dn_4: 0.9759 (0.9673)  loss_giou_dn_5: 0.9740 (0.9659)  loss_giou_enc_0: 1.2104 (1.1848)  loss_vfl: 1.0994 (1.0992)  loss_vfl_aux_0: 1.0520 (1.1405)  loss_vfl_aux_1: 1.0759 (1.1236)  loss_vfl_aux_2: 1.1013 (1.1147)  loss_vfl_aux_3: 1.0859 (1.1105)  loss_vfl_aux_4: 1.0664 (1.1061)  loss_vfl_dn_0: 0.5087 (0.5126)  loss_vfl_dn_1: 0.5444 (0.5460)  loss_vfl_dn_2: 0.5582 (0.5641)  loss_vfl_dn_3: 0.5875 (0.5814)  loss_vfl_dn_4: 0.6023 (0.5965)  loss_vfl_dn_5: 0.6104 (0.6051)  loss_vfl_enc_0: 0.9836 (1.0324)\r\n",
      "Test:  [0/8]  eta: 0:00:18    time: 2.3035  data: 1.3230  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0704  data: 0.2120  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0900 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.19s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.023\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.031\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.024\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.051\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.027\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.160\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.223\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.236\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.304\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.355\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.345\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.233\r\n",
      "best_stat: {'epoch': 44, 'coco_eval_bbox': 0.027856668230323605}\r\n",
      "Epoch: [48]  [ 0/79]  eta: 0:06:33  lr: 0.000002  loss: 31.9730 (31.9730)  loss_bbox: 0.5289 (0.5289)  loss_bbox_aux_0: 0.4827 (0.4827)  loss_bbox_aux_1: 0.4998 (0.4998)  loss_bbox_aux_2: 0.5131 (0.5131)  loss_bbox_aux_3: 0.4978 (0.4978)  loss_bbox_aux_4: 0.4912 (0.4912)  loss_bbox_dn_0: 0.2235 (0.2235)  loss_bbox_dn_1: 0.2077 (0.2077)  loss_bbox_dn_2: 0.2072 (0.2072)  loss_bbox_dn_3: 0.2061 (0.2061)  loss_bbox_dn_4: 0.2048 (0.2048)  loss_bbox_dn_5: 0.2047 (0.2047)  loss_bbox_enc_0: 0.5621 (0.5621)  loss_giou: 1.7196 (1.7196)  loss_giou_aux_0: 1.7956 (1.7956)  loss_giou_aux_1: 1.7626 (1.7626)  loss_giou_aux_2: 1.7380 (1.7380)  loss_giou_aux_3: 1.7368 (1.7368)  loss_giou_aux_4: 1.7299 (1.7299)  loss_giou_dn_0: 1.1945 (1.1945)  loss_giou_dn_1: 1.1485 (1.1485)  loss_giou_dn_2: 1.1421 (1.1421)  loss_giou_dn_3: 1.1279 (1.1279)  loss_giou_dn_4: 1.1322 (1.1322)  loss_giou_dn_5: 1.1302 (1.1302)  loss_giou_enc_0: 1.8230 (1.8230)  loss_vfl: 0.6948 (0.6948)  loss_vfl_aux_0: 0.7537 (0.7537)  loss_vfl_aux_1: 0.7314 (0.7314)  loss_vfl_aux_2: 0.7114 (0.7114)  loss_vfl_aux_3: 0.7451 (0.7451)  loss_vfl_aux_4: 0.7358 (0.7358)  loss_vfl_dn_0: 0.4840 (0.4840)  loss_vfl_dn_1: 0.4915 (0.4915)  loss_vfl_dn_2: 0.5016 (0.5016)  loss_vfl_dn_3: 0.5081 (0.5081)  loss_vfl_dn_4: 0.5021 (0.5021)  loss_vfl_dn_5: 0.5068 (0.5068)  loss_vfl_enc_0: 0.5962 (0.5962)  time: 4.9822  data: 3.5407  max mem: 10356\r\n",
      "Epoch: [48]  [78/79]  eta: 0:00:01  lr: 0.000002  loss: 29.1181 (29.4238)  loss_bbox: 0.2925 (0.3187)  loss_bbox_aux_0: 0.3095 (0.3433)  loss_bbox_aux_1: 0.3043 (0.3361)  loss_bbox_aux_2: 0.2987 (0.3258)  loss_bbox_aux_3: 0.2978 (0.3228)  loss_bbox_aux_4: 0.2973 (0.3202)  loss_bbox_dn_0: 0.3718 (0.4216)  loss_bbox_dn_1: 0.3409 (0.3876)  loss_bbox_dn_2: 0.3298 (0.3714)  loss_bbox_dn_3: 0.3241 (0.3616)  loss_bbox_dn_4: 0.3157 (0.3564)  loss_bbox_dn_5: 0.3138 (0.3553)  loss_bbox_enc_0: 0.3341 (0.3909)  loss_giou: 0.9484 (1.0467)  loss_giou_aux_0: 1.0081 (1.0953)  loss_giou_aux_1: 0.9909 (1.0787)  loss_giou_aux_2: 0.9457 (1.0628)  loss_giou_aux_3: 0.9401 (1.0549)  loss_giou_aux_4: 0.9438 (1.0445)  loss_giou_dn_0: 1.0830 (1.1168)  loss_giou_dn_1: 0.9906 (1.0343)  loss_giou_dn_2: 0.9574 (0.9971)  loss_giou_dn_3: 0.9469 (0.9786)  loss_giou_dn_4: 0.9305 (0.9661)  loss_giou_dn_5: 0.9260 (0.9642)  loss_giou_enc_0: 1.0717 (1.1826)  loss_vfl: 1.1704 (1.1169)  loss_vfl_aux_0: 1.1453 (1.1369)  loss_vfl_aux_1: 1.1836 (1.1279)  loss_vfl_aux_2: 1.1782 (1.1225)  loss_vfl_aux_3: 1.2051 (1.1248)  loss_vfl_aux_4: 1.2075 (1.1263)  loss_vfl_dn_0: 0.5219 (0.5098)  loss_vfl_dn_1: 0.5608 (0.5455)  loss_vfl_dn_2: 0.5850 (0.5632)  loss_vfl_dn_3: 0.6028 (0.5821)  loss_vfl_dn_4: 0.6333 (0.5985)  loss_vfl_dn_5: 0.6411 (0.6084)  loss_vfl_enc_0: 1.0625 (1.0272)  time: 1.0364  data: 0.0318  max mem: 10356\r\n",
      "Epoch: [48] Total time: 0:01:26 (1.0952 s / it)\r\n",
      "Averaged stats: lr: 0.000002  loss: 29.1181 (29.4238)  loss_bbox: 0.2925 (0.3187)  loss_bbox_aux_0: 0.3095 (0.3433)  loss_bbox_aux_1: 0.3043 (0.3361)  loss_bbox_aux_2: 0.2987 (0.3258)  loss_bbox_aux_3: 0.2978 (0.3228)  loss_bbox_aux_4: 0.2973 (0.3202)  loss_bbox_dn_0: 0.3718 (0.4216)  loss_bbox_dn_1: 0.3409 (0.3876)  loss_bbox_dn_2: 0.3298 (0.3714)  loss_bbox_dn_3: 0.3241 (0.3616)  loss_bbox_dn_4: 0.3157 (0.3564)  loss_bbox_dn_5: 0.3138 (0.3553)  loss_bbox_enc_0: 0.3341 (0.3909)  loss_giou: 0.9484 (1.0467)  loss_giou_aux_0: 1.0081 (1.0953)  loss_giou_aux_1: 0.9909 (1.0787)  loss_giou_aux_2: 0.9457 (1.0628)  loss_giou_aux_3: 0.9401 (1.0549)  loss_giou_aux_4: 0.9438 (1.0445)  loss_giou_dn_0: 1.0830 (1.1168)  loss_giou_dn_1: 0.9906 (1.0343)  loss_giou_dn_2: 0.9574 (0.9971)  loss_giou_dn_3: 0.9469 (0.9786)  loss_giou_dn_4: 0.9305 (0.9661)  loss_giou_dn_5: 0.9260 (0.9642)  loss_giou_enc_0: 1.0717 (1.1826)  loss_vfl: 1.1704 (1.1169)  loss_vfl_aux_0: 1.1453 (1.1369)  loss_vfl_aux_1: 1.1836 (1.1279)  loss_vfl_aux_2: 1.1782 (1.1225)  loss_vfl_aux_3: 1.2051 (1.1248)  loss_vfl_aux_4: 1.2075 (1.1263)  loss_vfl_dn_0: 0.5219 (0.5098)  loss_vfl_dn_1: 0.5608 (0.5455)  loss_vfl_dn_2: 0.5850 (0.5632)  loss_vfl_dn_3: 0.6028 (0.5821)  loss_vfl_dn_4: 0.6333 (0.5985)  loss_vfl_dn_5: 0.6411 (0.6084)  loss_vfl_enc_0: 1.0625 (1.0272)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.1471  data: 1.2002  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0726  data: 0.2116  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.0905 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.18s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.025\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.033\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.025\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.053\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.027\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.147\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.212\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.226\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.062\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.296\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.339\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.338\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.226\r\n",
      "best_stat: {'epoch': 44, 'coco_eval_bbox': 0.027856668230323605}\r\n",
      "Epoch: [49]  [ 0/79]  eta: 0:05:24  lr: 0.000002  loss: 28.0766 (28.0766)  loss_bbox: 0.2316 (0.2316)  loss_bbox_aux_0: 0.2611 (0.2611)  loss_bbox_aux_1: 0.2382 (0.2382)  loss_bbox_aux_2: 0.2340 (0.2340)  loss_bbox_aux_3: 0.2273 (0.2273)  loss_bbox_aux_4: 0.2308 (0.2308)  loss_bbox_dn_0: 0.3162 (0.3162)  loss_bbox_dn_1: 0.2834 (0.2834)  loss_bbox_dn_2: 0.2684 (0.2684)  loss_bbox_dn_3: 0.2554 (0.2554)  loss_bbox_dn_4: 0.2493 (0.2493)  loss_bbox_dn_5: 0.2476 (0.2476)  loss_bbox_enc_0: 0.3119 (0.3119)  loss_giou: 1.0311 (1.0311)  loss_giou_aux_0: 1.0797 (1.0797)  loss_giou_aux_1: 1.0492 (1.0492)  loss_giou_aux_2: 1.0584 (1.0584)  loss_giou_aux_3: 1.0461 (1.0461)  loss_giou_aux_4: 1.0294 (1.0294)  loss_giou_dn_0: 1.1507 (1.1507)  loss_giou_dn_1: 1.0630 (1.0630)  loss_giou_dn_2: 1.0233 (1.0233)  loss_giou_dn_3: 0.9959 (0.9959)  loss_giou_dn_4: 0.9882 (0.9882)  loss_giou_dn_5: 0.9910 (0.9910)  loss_giou_enc_0: 1.2318 (1.2318)  loss_vfl: 1.1204 (1.1204)  loss_vfl_aux_0: 1.1035 (1.1035)  loss_vfl_aux_1: 1.1245 (1.1245)  loss_vfl_aux_2: 1.1077 (1.1077)  loss_vfl_aux_3: 1.1370 (1.1370)  loss_vfl_aux_4: 1.1367 (1.1367)  loss_vfl_dn_0: 0.4788 (0.4788)  loss_vfl_dn_1: 0.5105 (0.5105)  loss_vfl_dn_2: 0.5375 (0.5375)  loss_vfl_dn_3: 0.5624 (0.5624)  loss_vfl_dn_4: 0.5793 (0.5793)  loss_vfl_dn_5: 0.5890 (0.5890)  loss_vfl_enc_0: 0.9966 (0.9966)  time: 4.1024  data: 2.3941  max mem: 10356\r\n",
      "Epoch: [49]  [78/79]  eta: 0:00:01  lr: 0.000002  loss: 28.8417 (29.3672)  loss_bbox: 0.3053 (0.3184)  loss_bbox_aux_0: 0.3406 (0.3508)  loss_bbox_aux_1: 0.3399 (0.3388)  loss_bbox_aux_2: 0.3145 (0.3280)  loss_bbox_aux_3: 0.3199 (0.3247)  loss_bbox_aux_4: 0.3104 (0.3206)  loss_bbox_dn_0: 0.4316 (0.4155)  loss_bbox_dn_1: 0.3807 (0.3807)  loss_bbox_dn_2: 0.3599 (0.3641)  loss_bbox_dn_3: 0.3477 (0.3544)  loss_bbox_dn_4: 0.3382 (0.3490)  loss_bbox_dn_5: 0.3374 (0.3479)  loss_bbox_enc_0: 0.3776 (0.3929)  loss_giou: 0.9617 (1.0400)  loss_giou_aux_0: 1.0091 (1.0821)  loss_giou_aux_1: 1.0033 (1.0674)  loss_giou_aux_2: 0.9877 (1.0532)  loss_giou_aux_3: 0.9970 (1.0467)  loss_giou_aux_4: 0.9677 (1.0415)  loss_giou_dn_0: 1.1169 (1.1198)  loss_giou_dn_1: 1.0282 (1.0341)  loss_giou_dn_2: 0.9875 (0.9958)  loss_giou_dn_3: 0.9686 (0.9766)  loss_giou_dn_4: 0.9529 (0.9643)  loss_giou_dn_5: 0.9517 (0.9626)  loss_giou_enc_0: 1.0943 (1.1677)  loss_vfl: 1.1455 (1.1213)  loss_vfl_aux_0: 1.1633 (1.1427)  loss_vfl_aux_1: 1.1521 (1.1292)  loss_vfl_aux_2: 1.1606 (1.1278)  loss_vfl_aux_3: 1.1714 (1.1321)  loss_vfl_aux_4: 1.1753 (1.1303)  loss_vfl_dn_0: 0.5117 (0.5082)  loss_vfl_dn_1: 0.5576 (0.5444)  loss_vfl_dn_2: 0.5672 (0.5625)  loss_vfl_dn_3: 0.5974 (0.5825)  loss_vfl_dn_4: 0.6038 (0.5991)  loss_vfl_dn_5: 0.6191 (0.6078)  loss_vfl_enc_0: 1.0981 (1.0421)  time: 1.0087  data: 0.0339  max mem: 10356\r\n",
      "Epoch: [49] Total time: 0:01:26 (1.0920 s / it)\r\n",
      "Averaged stats: lr: 0.000002  loss: 28.8417 (29.3672)  loss_bbox: 0.3053 (0.3184)  loss_bbox_aux_0: 0.3406 (0.3508)  loss_bbox_aux_1: 0.3399 (0.3388)  loss_bbox_aux_2: 0.3145 (0.3280)  loss_bbox_aux_3: 0.3199 (0.3247)  loss_bbox_aux_4: 0.3104 (0.3206)  loss_bbox_dn_0: 0.4316 (0.4155)  loss_bbox_dn_1: 0.3807 (0.3807)  loss_bbox_dn_2: 0.3599 (0.3641)  loss_bbox_dn_3: 0.3477 (0.3544)  loss_bbox_dn_4: 0.3382 (0.3490)  loss_bbox_dn_5: 0.3374 (0.3479)  loss_bbox_enc_0: 0.3776 (0.3929)  loss_giou: 0.9617 (1.0400)  loss_giou_aux_0: 1.0091 (1.0821)  loss_giou_aux_1: 1.0033 (1.0674)  loss_giou_aux_2: 0.9877 (1.0532)  loss_giou_aux_3: 0.9970 (1.0467)  loss_giou_aux_4: 0.9677 (1.0415)  loss_giou_dn_0: 1.1169 (1.1198)  loss_giou_dn_1: 1.0282 (1.0341)  loss_giou_dn_2: 0.9875 (0.9958)  loss_giou_dn_3: 0.9686 (0.9766)  loss_giou_dn_4: 0.9529 (0.9643)  loss_giou_dn_5: 0.9517 (0.9626)  loss_giou_enc_0: 1.0943 (1.1677)  loss_vfl: 1.1455 (1.1213)  loss_vfl_aux_0: 1.1633 (1.1427)  loss_vfl_aux_1: 1.1521 (1.1292)  loss_vfl_aux_2: 1.1606 (1.1278)  loss_vfl_aux_3: 1.1714 (1.1321)  loss_vfl_aux_4: 1.1753 (1.1303)  loss_vfl_dn_0: 0.5117 (0.5082)  loss_vfl_dn_1: 0.5576 (0.5444)  loss_vfl_dn_2: 0.5672 (0.5625)  loss_vfl_dn_3: 0.5974 (0.5825)  loss_vfl_dn_4: 0.6038 (0.5991)  loss_vfl_dn_5: 0.6191 (0.6078)  loss_vfl_enc_0: 1.0981 (1.0421)\r\n",
      "Test:  [0/8]  eta: 0:00:17    time: 2.2408  data: 1.2597  max mem: 10356\r\n",
      "Test:  [7/8]  eta: 0:00:01    time: 1.0861  data: 0.2201  max mem: 10356\r\n",
      "Test: Total time: 0:00:08 (1.1041 s / it)\r\n",
      "Averaged stats: \r\n",
      "Accumulating evaluation results...\r\n",
      "COCOeval_opt.accumulate() finished...\r\n",
      "DONE (t=0.19s).\r\n",
      "IoU metric: bbox\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.031\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.040\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.032\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.063\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.027\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.149\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.217\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.230\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.062\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.302\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.337\r\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.337\r\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.228\r\n",
      "best_stat: {'epoch': 49, 'coco_eval_bbox': 0.031008108067245268}\r\n",
      "Training time 1:23:07\r\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/RT-DETR/rtdetrv2_pytorch/\n",
    "\n",
    "!torchrun --nproc_per_node=2 tools/train.py \\\n",
    "    -c configs/rtdetrv2/rtdetrv2_taco_finetune_BASELINE.yml \\\n",
    "    --use-amp \\\n",
    "    --seed=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fd022ba",
   "metadata": {
    "_cell_guid": "bed7aa4d-bf4d-450f-8061-0b4716429db7",
    "_uuid": "1df19610-9e58-4223-b9e9-94f8ad3cbfdd",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-31T00:20:51.237999Z",
     "iopub.status.busy": "2025-10-31T00:20:51.237322Z",
     "iopub.status.idle": "2025-10-31T00:20:51.383431Z",
     "shell.execute_reply": "2025-10-31T00:20:51.382396Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.538463,
     "end_time": "2025-10-31T00:20:51.384672",
     "exception": false,
     "start_time": "2025-10-31T00:20:50.846209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/working/RT-DETR/rtdetrv2_pytorch/configs/rtdetrv2/* /kaggle/working/FINAL/CONFIG/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf194437",
   "metadata": {
    "_cell_guid": "2bb9057e-a7fc-44be-bd5c-e48cebb6b9ee",
    "_uuid": "84227b0c-4e96-448a-9c02-a0802cd690ad",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-31T00:20:51.943685Z",
     "iopub.status.busy": "2025-10-31T00:20:51.943394Z",
     "iopub.status.idle": "2025-10-31T00:20:55.480801Z",
     "shell.execute_reply": "2025-10-31T00:20:55.479928Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.81477,
     "end_time": "2025-10-31T00:20:55.482027",
     "exception": false,
     "start_time": "2025-10-31T00:20:51.667257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "!pip install -q ultralytics\n",
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e9cc1e1",
   "metadata": {
    "_cell_guid": "2b832077-2a48-4efa-84d2-d5286487d242",
    "_uuid": "46faa72d-4ef6-4e38-92ea-53ed9cfaaece",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-31T00:20:56.065039Z",
     "iopub.status.busy": "2025-10-31T00:20:56.064301Z",
     "iopub.status.idle": "2025-10-31T00:25:22.048049Z",
     "shell.execute_reply": "2025-10-31T00:25:22.047252Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 266.27171,
     "end_time": "2025-10-31T00:25:22.049706",
     "exception": false,
     "start_time": "2025-10-31T00:20:55.777996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n",
      "fatal: destination path 'RT-DETR' already exists and is not an empty directory.\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "google-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 6.33.0 which is incompatible.\r\n",
      "google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 6.33.0 which is incompatible.\r\n",
      "google-cloud-bigtable 2.32.0 requires google-api-core[grpc]<3.0.0,>=2.17.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.0 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.1 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "google-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\r\n",
      "dataproc-spark-connect 0.8.3 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "google-cloud-bigtable 2.32.0 requires google-api-core[grpc]<3.0.0,>=2.17.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.1 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "google-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "dataproc-spark-connect 0.8.3 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "lightly-train 0.11.4 requires torch<2.6,>=2.1.0, but you have torch 2.9.0+cu126 which is incompatible.\r\n",
      "fastai 2.8.4 requires torch<2.9,>=1.10, but you have torch 2.9.0+cu126 which is incompatible.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "lightly-train 0.11.4 requires torch<2.6,>=2.1.0, but you have torch 2.9.0+cu126 which is incompatible.\r\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.4 which is incompatible.\r\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.16.3 which is incompatible.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.4 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.4 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.4 which is incompatible.\r\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\r\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires matplotlib<=3.10,>=3.5, but you have matplotlib 3.10.7 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.3.4 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires scipy<1.16,>=1.4.1, but you have scipy 1.16.3 which is incompatible.\r\n",
      "fastai 2.8.4 requires torch<2.9,>=1.10, but you have torch 2.9.0+cu126 which is incompatible.\r\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.2 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.2 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\r\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\r\n",
      "gradio 5.38.1 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.4 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.5.1 which is incompatible.\r\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.6 which is incompatible.\r\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.16.3 which is incompatible.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\r\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires matplotlib<=3.10,>=3.5, but you have matplotlib 3.10.7 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.6 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires scipy<1.16,>=1.4.1, but you have scipy 1.16.3 which is incompatible.\r\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.2 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.2 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.0.2 which is incompatible.\r\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.16.3 which is incompatible.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.0.2 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.0.2 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.0.2 which is incompatible.\r\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires matplotlib<=3.10,>=3.5, but you have matplotlib 3.10.7 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires scipy<1.16,>=1.4.1, but you have scipy 1.16.3 which is incompatible.\r\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.2 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.2 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "ibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\r\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "jupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\r\n",
      "dataproc-spark-connect 0.8.3 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working\n",
    "!git clone https://github.com/lyuwenyu/RT-DETR.git\n",
    "!cd RT-DETR/rtdetrv2_pytorch && pip install -r requirements.txt -q\n",
    "!pip install -q protobuf==3.20.3\n",
    "!pip install -q tensorboard\n",
    "!pip install -q --upgrade pip\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n",
    "!pip install -q --upgrade numpy scipy scikit-learn\n",
    "!pip install -q timm pycocotools faster-coco-eval\n",
    "!pip install -q --upgrade transformers lightly-train\n",
    "!pip install -q wandb\n",
    "!pip install -q -U \"numpy<2.1\" matplotlib --force-reinstall --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db5ee2b2",
   "metadata": {
    "_cell_guid": "1e39d7b5-5b85-4c42-9c58-aa5e3366930a",
    "_uuid": "cbad41b2-3b3c-4ba5-91a1-bd5be887a052",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-31T00:25:22.706333Z",
     "iopub.status.busy": "2025-10-31T00:25:22.705665Z",
     "iopub.status.idle": "2025-10-31T00:25:25.174590Z",
     "shell.execute_reply": "2025-10-31T00:25:25.173781Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.758685,
     "end_time": "2025-10-31T00:25:25.175680",
     "exception": false,
     "start_time": "2025-10-31T00:25:22.416995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting instances_train2017.json: 100%|██████████| 4004/4004 [00:00<00:00, 28758.61it/s]\n",
      "Converting instances_val2017.json: 100%|██████████| 776/776 [00:00<00:00, 28581.54it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "YOLO_DATA_ROOT = '/kaggle/working/FINAL/YOLO/taco_yolo'\n",
    "IMAGE_TRAIN_DIR_DEST = os.path.join(YOLO_DATA_ROOT, 'images', 'train')\n",
    "IMAGE_VAL_DIR_DEST = os.path.join(YOLO_DATA_ROOT, 'images', 'val')\n",
    "LABEL_TRAIN_DIR_DEST = os.path.join(YOLO_DATA_ROOT, 'labels', 'train')\n",
    "LABEL_VAL_DIR_DEST = os.path.join(YOLO_DATA_ROOT, 'labels', 'val')\n",
    "\n",
    "os.makedirs(IMAGE_TRAIN_DIR_DEST, exist_ok=True)\n",
    "os.makedirs(IMAGE_VAL_DIR_DEST, exist_ok=True)\n",
    "os.makedirs(LABEL_TRAIN_DIR_DEST, exist_ok=True)\n",
    "os.makedirs(LABEL_VAL_DIR_DEST, exist_ok=True)\n",
    "\n",
    "IMAGE_TRAIN_DIR_SRC = '/kaggle/input/dsp-pre-final/processed_taco_coco/train2017'\n",
    "IMAGE_VAL_DIR_SRC = '/kaggle/input/dsp-pre-final/processed_taco_coco/val2017'\n",
    "\n",
    "!cp -n {IMAGE_TRAIN_DIR_SRC}/* {IMAGE_TRAIN_DIR_DEST}/\n",
    "!cp -n {IMAGE_VAL_DIR_SRC}/* {IMAGE_VAL_DIR_DEST}/\n",
    "\n",
    "COCO_ANNOTATIONS_TRAIN = '/kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_train2017.json'\n",
    "COCO_ANNOTATIONS_VAL = '/kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_val2017.json'\n",
    "\n",
    "def convert_coco_to_yolo(json_file, output_labels_dir):\n",
    "    with open(json_file) as f: data = json.load(f)\n",
    "    images_map = {img['id']: (img['file_name'], img['width'], img['height']) for img in data['images']}\n",
    "    for ann in tqdm(data['annotations'], desc=f\"Converting {os.path.basename(json_file)}\"):\n",
    "        image_id, class_id = ann['image_id'], ann['category_id']\n",
    "        if image_id not in images_map: continue\n",
    "        file_name, img_w, img_h = images_map[image_id]\n",
    "        box = ann['bbox']\n",
    "        x, y, w, h = box\n",
    "        x_center, y_center = (x + w / 2) / img_w, (y + h / 2) / img_h\n",
    "        norm_w, norm_h = w / img_w, h / img_h\n",
    "        label_file_name = os.path.splitext(file_name)[0] + '.txt'\n",
    "        label_file_path = os.path.join(output_labels_dir, label_file_name)\n",
    "        with open(label_file_path, 'a') as f:\n",
    "            f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {norm_w:.6f} {norm_h:.6f}\\n\")\n",
    "\n",
    "convert_coco_to_yolo(COCO_ANNOTATIONS_TRAIN, LABEL_TRAIN_DIR_DEST)\n",
    "convert_coco_to_yolo(COCO_ANNOTATIONS_VAL, LABEL_VAL_DIR_DEST)\n",
    "\n",
    "with open(COCO_ANNOTATIONS_TRAIN) as f: coco_data = json.load(f)\n",
    "categories = sorted(coco_data['categories'], key=lambda x: x['id'])\n",
    "class_names = [cat['name'] for cat in categories]\n",
    "\n",
    "taco_yaml_content = {\n",
    "    'path': YOLO_DATA_ROOT, 'train': 'images/train', 'val': 'images/val',\n",
    "    'nc': len(class_names), 'names': class_names\n",
    "}\n",
    "\n",
    "YAML_PATH = os.path.join(YOLO_DATA_ROOT, 'taco.yaml')\n",
    "with open(YAML_PATH, 'w') as f: yaml.dump(taco_yaml_content, f, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "886051fe",
   "metadata": {
    "_cell_guid": "08c5f1e2-4bf6-47a3-80b0-aa4d052344d6",
    "_uuid": "cf812f2b-5a1b-4138-8cb3-e6fd250c2fb2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-31T00:25:25.748973Z",
     "iopub.status.busy": "2025-10-31T00:25:25.748349Z",
     "iopub.status.idle": "2025-10-31T00:25:25.768977Z",
     "shell.execute_reply": "2025-10-31T00:25:25.768397Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.303729,
     "end_time": "2025-10-31T00:25:25.769978",
     "exception": false,
     "start_time": "2025-10-31T00:25:25.466249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: /kaggle/working/FINAL/YOLO/taco_yolo\n",
      "train: images/train\n",
      "val: images/val\n",
      "nc: 60\n",
      "names:\n",
      "- Aluminium foil\n",
      "- Battery\n",
      "- Aluminium blister pack\n",
      "- Carded blister pack\n",
      "- Other plastic bottle\n",
      "- Clear plastic bottle\n",
      "- Glass bottle\n",
      "- Plastic bottle cap\n",
      "- Metal bottle cap\n",
      "- Broken glass\n",
      "- Food Can\n",
      "- Aerosol\n",
      "- Drink can\n",
      "- Toilet tube\n",
      "- Other carton\n",
      "- Egg carton\n",
      "- Drink carton\n",
      "- Corrugated carton\n",
      "- Meal carton\n",
      "- Pizza box\n",
      "- Paper cup\n",
      "- Disposable plastic cup\n",
      "- Foam cup\n",
      "- Glass cup\n",
      "- Other plastic cup\n",
      "- Food waste\n",
      "- Glass jar\n",
      "- Plastic lid\n",
      "- Metal lid\n",
      "- Other plastic\n",
      "- Magazine paper\n",
      "- Tissues\n",
      "- Wrapping paper\n",
      "- Normal paper\n",
      "- Paper bag\n",
      "- Plastified paper bag\n",
      "- Plastic film\n",
      "- Six pack rings\n",
      "- Garbage bag\n",
      "- Other plastic wrapper\n",
      "- Single-use carrier bag\n",
      "- Polypropylene bag\n",
      "- Crisp packet\n",
      "- Spread tub\n",
      "- Tupperware\n",
      "- Disposable food container\n",
      "- Foam food container\n",
      "- Other plastic container\n",
      "- Plastic glooves\n",
      "- Plastic utensils\n",
      "- Pop tab\n",
      "- Rope & strings\n",
      "- Scrap metal\n",
      "- Shoe\n",
      "- Squeezable tube\n",
      "- Plastic straw\n",
      "- Paper straw\n",
      "- Styrofoam piece\n",
      "- Unlabeled litter\n",
      "- Cigarette\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import json\n",
    "import os\n",
    "\n",
    "COCO_ANNOTATIONS_TRAIN = '/kaggle/input/dsp-pre-final/processed_taco_coco/annotations/instances_train2017.json'\n",
    "YOLO_DATA_ROOT = '/kaggle/working/FINAL/YOLO/taco_yolo'\n",
    "\n",
    "with open(COCO_ANNOTATIONS_TRAIN) as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "categories = sorted(coco_data['categories'], key=lambda x: x['id'])\n",
    "class_names = [cat['name'] for cat in categories]\n",
    "\n",
    "taco_yaml_content = {\n",
    "    'path': YOLO_DATA_ROOT,\n",
    "    'train': 'images/train',\n",
    "    'val': 'images/val',\n",
    "    'nc': len(class_names),\n",
    "    'names': class_names\n",
    "}\n",
    "\n",
    "YAML_PATH = os.path.join(YOLO_DATA_ROOT, 'taco.yaml')\n",
    "with open(YAML_PATH, 'w') as f:\n",
    "    yaml.dump(taco_yaml_content, f, sort_keys=False)\n",
    "\n",
    "with open(YAML_PATH, 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "755273e7",
   "metadata": {
    "_cell_guid": "154f79b7-981d-4949-81ba-ea9230173062",
    "_uuid": "7d22f313-9222-47ab-9324-e79871159ce4",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-31T00:25:26.336456Z",
     "iopub.status.busy": "2025-10-31T00:25:26.336188Z",
     "iopub.status.idle": "2025-10-31T00:25:26.341348Z",
     "shell.execute_reply": "2025-10-31T00:25:26.340738Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.284025,
     "end_time": "2025-10-31T00:25:26.342484",
     "exception": false,
     "start_time": "2025-10-31T00:25:26.058459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing training_yolov11.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile training_yolov11.py\n",
    "from ultralytics import YOLO\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "output_path = '/kaggle/working/FINAL/YOLO/yolo_checkpoints'\n",
    "data_yaml_path = '/kaggle/working/FINAL/YOLO/taco_yolo/taco.yaml' \n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    secrets = UserSecretsClient()\n",
    "    wandb_key = secrets.get_secret(\"WANDB_API_KEY\")\n",
    "    wandb.login(key=wandb_key)\n",
    "except Exception as e:\n",
    "    print(f\"{e}\")\n",
    "    \n",
    "wandb.init(\n",
    "    project='yolo_runs_taco',\n",
    "    name='yolo11l_taco_finetune_baseline',\n",
    "    job_type='fine-tuning',\n",
    "    dir='/kaggle/working/FINAL/YOLO/'\n",
    ")\n",
    "\n",
    "model = YOLO('yolo11l.pt')\n",
    "\n",
    "results = model.train(\n",
    "    data=data_yaml_path,\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=32,\n",
    "    project=output_path,\n",
    "    name='yolo11l_finetune_baseline',\n",
    "    exist_ok=True,\n",
    "    device=[0, 1]\n",
    ")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6ba0796",
   "metadata": {
    "_cell_guid": "21a13b87-c85e-48c8-9fcf-4b70b3823f90",
    "_uuid": "dd1d7eee-d434-4790-a726-48a913514bf5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-31T00:25:26.990529Z",
     "iopub.status.busy": "2025-10-31T00:25:26.989959Z",
     "iopub.status.idle": "2025-10-31T00:58:09.581953Z",
     "shell.execute_reply": "2025-10-31T00:58:09.581197Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1962.955956,
     "end_time": "2025-10-31T00:58:09.583397",
     "exception": false,
     "start_time": "2025-10-31T00:25:26.627441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \r\n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\r\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnamthse182380\u001b[0m (\u001b[33mnamthse182380-fpt-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.0\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/FINAL/YOLO/wandb/run-20251031_002530-fsq4qebx\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myolo11l_taco_finetune_baseline\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/namthse182380-fpt-university/yolo_runs_taco\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/namthse182380-fpt-university/yolo_runs_taco/runs/fsq4qebx\u001b[0m\r\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11l.pt to 'yolo11l.pt': 100% ━━━━━━━━━━━━ 49.0MB 89.9MB/s 0.5s\r\n",
      "Ultralytics 8.3.223 🚀 Python-3.11.13 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\r\n",
      "                                                       CUDA:1 (Tesla T4, 15095MiB)\r\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/FINAL/YOLO/taco_yolo/taco.yaml, degrees=0.0, deterministic=True, device=0,1, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo11l_finetune_baseline, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/FINAL/YOLO/yolo_checkpoints, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/FINAL/YOLO/yolo_checkpoints/yolo11l_finetune_baseline, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\r\n",
      "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 16.8MB/s 0.0s\r\n",
      "Overriding model.yaml nc=80 with nc=60\r\n",
      "\r\n",
      "                   from  n    params  module                                       arguments                     \r\n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \r\n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \r\n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \r\n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \r\n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \r\n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \r\n",
      "  6                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \r\n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \r\n",
      "  8                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \r\n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \r\n",
      " 10                  -1  2   1455616  ultralytics.nn.modules.block.C2PSA           [512, 512, 2]                 \r\n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 13                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \r\n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 16                  -1  2    756736  ultralytics.nn.modules.block.C3k2            [1024, 256, 2, True]          \r\n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \r\n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 19                  -1  2   2365440  ultralytics.nn.modules.block.C3k2            [768, 512, 2, True]           \r\n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \r\n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 22                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \r\n",
      " 23        [16, 19, 22]  1   1457284  ultralytics.nn.modules.head.Detect           [60, [256, 512, 512]]         \r\n",
      "YOLO11l summary: 357 layers, 25,356,740 parameters, 25,356,724 gradients, 87.5 GFLOPs\r\n",
      "\r\n",
      "Transferred 1009/1015 items from pretrained weights\r\n",
      "\u001b[34m\u001b[1mDDP:\u001b[0m debug command /usr/bin/python3 -m torch.distributed.run --nproc_per_node 2 --master_port 48505 /root/.config/Ultralytics/DDP/_temp_tcpdx4ry139803800528848.py\r\n",
      "Ultralytics 8.3.223 🚀 Python-3.11.13 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\r\n",
      "                                                       CUDA:1 (Tesla T4, 15095MiB)\r\n",
      "Overriding model.yaml nc=80 with nc=60\r\n",
      "Transferred 1009/1015 items from pretrained weights\r\n",
      "Freezing layer 'model.23.dfl.conv.weight'\r\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\r\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4MB 65.0MB/s 0.1s\r\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 3054.2±651.3 MB/s, size: 260.9 KB)\r\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/FINAL/YOLO/taco_yolo/labels/train... 1273 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1273/1273 1.4Kit/s 0.9s\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/FINAL/YOLO/taco_yolo/labels/train.cache\r\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1691.9±1171.5 MB/s, size: 234.5 KB)\r\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/FINAL/YOLO/taco_yolo/labels/val... 225 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 225/225 1.6Kit/s 0.1s\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/FINAL/YOLO/taco_yolo/labels/val.cache\r\n",
      "Plotting labels to /kaggle/working/FINAL/YOLO/yolo_checkpoints/yolo11l_finetune_baseline/labels.jpg... \r\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \r\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000156, momentum=0.9) with parameter groups 167 weight(decay=0.0), 174 weight(decay=0.0005), 173 bias(decay=0.0)\r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 4 dataloader workers\r\n",
      "Logging results to \u001b[1m/kaggle/working/FINAL/YOLO/yolo_checkpoints/yolo11l_finetune_baseline\u001b[0m\r\n",
      "Starting training for 50 epochs...\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K       1/50      10.2G      1.169      4.975      1.255         44        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 32.8s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.2it/s 3.4s\r\n",
      "                   all        225        776      0.578     0.0979     0.0596     0.0482\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K       2/50      10.3G      1.119      3.439      1.199         57        640: 100% ━━━━━━━━━━━━ 40/40 1.3it/s 31.9s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.5s\r\n",
      "                   all        225        776      0.317      0.164     0.0892     0.0703\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K       3/50      10.3G      1.114      3.135      1.191         33        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.2s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.4it/s 2.8s\r\n",
      "                   all        225        776      0.417      0.159      0.109     0.0893\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K       4/50      10.3G      1.114      2.797        1.2         48        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 34.0s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.8s\r\n",
      "                   all        225        776      0.512      0.146      0.134      0.104\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K       5/50      10.4G      1.087      2.634      1.194         56        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.3s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.4it/s 2.8s\r\n",
      "                   all        225        776      0.355      0.178      0.124     0.0872\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K       6/50      10.3G      1.021      2.395      1.156         53        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.8s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.372       0.22       0.16      0.125\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K       7/50      10.3G      1.044       2.39      1.168         40        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.4s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.458      0.187      0.196       0.16\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K       8/50      10.3G      0.989      2.159      1.119         44        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.7s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776       0.39      0.226      0.192      0.155\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K       9/50      10.3G     0.9747      2.023      1.126         62        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.6s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.6s\r\n",
      "                   all        225        776      0.441      0.218      0.209      0.169\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      10/50      10.3G     0.9787       1.99      1.147         53        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.5s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.379      0.232      0.193      0.157\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      11/50      10.3G      1.003      1.961      1.153         37        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.5s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.473      0.209      0.203      0.165\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      12/50      10.4G     0.9543      1.827      1.112         70        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.6s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.328      0.265      0.223      0.177\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      13/50      10.3G     0.9682      1.745      1.115         69        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.4s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.6s\r\n",
      "                   all        225        776      0.428      0.257      0.227      0.184\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      14/50      10.3G     0.9271      1.654      1.092         72        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.5s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.455      0.231      0.223      0.186\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      15/50      10.3G     0.8749      1.559      1.063         39        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.4s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.521      0.211      0.221      0.184\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      16/50      10.3G     0.9135      1.545      1.084         71        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.5s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.534       0.19      0.217      0.173\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      17/50      10.3G     0.8896      1.386      1.071         48        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.5s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.374      0.277      0.251      0.206\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      18/50      10.3G      0.876      1.408      1.056         74        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.7s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.8s\r\n",
      "                   all        225        776      0.363      0.256      0.246      0.207\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      19/50      10.4G     0.8378        1.3      1.044         89        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.4s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.482       0.21      0.226      0.181\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      20/50      10.3G     0.8527      1.321      1.061         34        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.6s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.469      0.251      0.243        0.2\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      21/50      10.4G     0.8642      1.276      1.062         64        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.5s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.6s\r\n",
      "                   all        225        776      0.559       0.23       0.25      0.205\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      22/50      10.4G     0.8174      1.134      1.021         76        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.6s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.293      0.274      0.241      0.194\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      23/50      10.4G     0.8279       1.12      1.039         99        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.7s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.6s\r\n",
      "                   all        225        776      0.324      0.257      0.239      0.195\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      24/50      10.4G      0.798      1.096      1.023         24        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.6s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.436      0.233      0.236      0.194\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      25/50      10.3G     0.7902      1.016       1.02         33        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.5s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.6s\r\n",
      "                   all        225        776      0.413       0.21      0.222       0.18\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      26/50      10.3G     0.8281      1.015      1.023         45        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.5s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.483      0.217      0.232      0.189\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      27/50      10.4G     0.7666     0.9764      1.015         58        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.6s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.451      0.246       0.25      0.208\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      28/50      10.4G     0.7668     0.9272      1.006         91        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.6s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.522      0.221      0.242      0.199\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      29/50      10.3G      0.782     0.9405      1.016         66        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.6s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.408      0.263      0.259      0.218\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      30/50      10.4G      0.756     0.8934      1.007         51        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.7s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.478       0.23      0.238      0.197\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      31/50      10.3G     0.7353     0.8251     0.9895         77        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.6s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.8s\r\n",
      "                   all        225        776      0.362       0.26      0.256      0.219\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      32/50      10.4G     0.7459     0.8319     0.9866         81        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.5s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.537       0.19       0.24      0.201\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      33/50      10.3G     0.7381     0.8245     0.9879         35        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.6s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.505      0.182      0.218      0.182\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      34/50      10.4G     0.7394     0.8337     0.9751         81        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.5s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.667       0.18      0.237        0.2\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      35/50      10.3G     0.7348     0.7913     0.9929         82        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.6s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.451      0.213       0.23      0.193\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      36/50      10.4G     0.7443     0.7646     0.9861         40        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.5s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.444      0.211      0.237        0.2\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      37/50      10.4G     0.7168     0.7411     0.9875         67        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.6s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.338      0.252      0.235      0.191\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      38/50      10.4G     0.6805     0.6963     0.9786         72        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.4s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.476      0.213      0.249      0.214\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      39/50      10.4G      0.669     0.7051     0.9743         51        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.5s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.6s\r\n",
      "                   all        225        776      0.524      0.227      0.252      0.214\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      40/50      10.3G     0.6572     0.6701     0.9516         27        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.3s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.609      0.187      0.242      0.206\r\n",
      "Closing dataloader mosaic\r\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      41/50      10.4G     0.5974     0.5814     0.9061         20        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 34.8s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.8s\r\n",
      "                   all        225        776      0.602      0.207      0.235      0.198\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      42/50      10.4G     0.5851     0.5371     0.8971         20        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.4s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.429      0.253       0.26      0.221\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      43/50      10.3G     0.5881     0.5192     0.8884         40        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.5s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.393      0.266      0.253      0.216\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      44/50      10.3G     0.5822     0.5143     0.8918         26        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.3s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.465      0.236      0.253      0.212\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      45/50      10.4G     0.5982     0.4988     0.8865         39        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.5s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.471      0.234      0.245      0.209\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      46/50      10.3G     0.5825     0.4941     0.8869         36        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.4s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.529      0.237      0.251      0.214\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      47/50      10.3G      0.576     0.5021     0.8994         61        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.5s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776       0.35      0.275      0.259      0.223\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      48/50      10.3G     0.5473     0.4641     0.8748         29        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.3s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.6s\r\n",
      "                   all        225        776      0.403      0.266      0.263       0.23\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      49/50      10.3G     0.5672     0.4721     0.8772         21        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.4s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.485      0.225      0.262      0.227\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "\u001b[K      50/50      10.4G     0.5314     0.4509     0.8719         42        640: 100% ━━━━━━━━━━━━ 40/40 1.2it/s 33.3s\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.5it/s 2.7s\r\n",
      "                   all        225        776      0.406      0.264      0.265      0.229\r\n",
      "\r\n",
      "50 epochs completed in 0.533 hours.\r\n",
      "Optimizer stripped from /kaggle/working/FINAL/YOLO/yolo_checkpoints/yolo11l_finetune_baseline/weights/last.pt, 51.3MB\r\n",
      "Optimizer stripped from /kaggle/working/FINAL/YOLO/yolo_checkpoints/yolo11l_finetune_baseline/weights/best.pt, 51.3MB\r\n",
      "\r\n",
      "Validating /kaggle/working/FINAL/YOLO/yolo_checkpoints/yolo11l_finetune_baseline/weights/best.pt...\r\n",
      "YOLO11l summary (fused): 190 layers, 25,325,572 parameters, 0 gradients, 86.8 GFLOPs\r\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.3it/s 3.1s\r\n",
      "                   all        225        776      0.403      0.265      0.263       0.23\r\n",
      "        Aluminium foil          6          7          0          0     0.0521     0.0402\r\n",
      "  Other plastic bottle          7          8      0.203       0.25      0.221      0.214\r\n",
      "  Clear plastic bottle         36         46      0.578       0.63       0.64       0.53\r\n",
      "          Glass bottle          5          6      0.204      0.167       0.13      0.124\r\n",
      "    Plastic bottle cap         36         44      0.547      0.412      0.475      0.318\r\n",
      "      Metal bottle cap         10         10      0.527        0.6      0.627       0.56\r\n",
      "          Broken glass          3          8          0          0          0          0\r\n",
      "              Food Can          3          8      0.111      0.125      0.207       0.18\r\n",
      "               Aerosol          3          3      0.309      0.333      0.349      0.349\r\n",
      "             Drink can         24         46      0.619      0.635      0.611      0.447\r\n",
      "          Other carton          9          9     0.0474      0.111      0.161       0.15\r\n",
      "            Egg carton          2          3          1          0          0          0\r\n",
      "          Drink carton          5          5      0.211        0.2      0.245      0.222\r\n",
      "     Corrugated carton          5          7      0.482      0.714      0.582      0.551\r\n",
      "           Meal carton          3          4       0.67        0.5      0.559      0.482\r\n",
      "             Paper cup         11         11      0.137     0.0909      0.183      0.106\r\n",
      "Disposable plastic cup          8         10      0.483        0.6      0.434      0.337\r\n",
      "              Foam cup          3          4          0          0          0          0\r\n",
      "             Glass cup          1          1          1          0          0          0\r\n",
      "            Food waste          2          2          0          0          0          0\r\n",
      "             Glass jar          1          2      0.878        0.5      0.578      0.578\r\n",
      "           Plastic lid         14         18       0.54      0.278      0.272      0.221\r\n",
      "             Metal lid          2          3          1          0          0          0\r\n",
      "         Other plastic         32         44      0.212      0.178       0.15      0.118\r\n",
      "               Tissues          5          6      0.209      0.167     0.0623     0.0544\r\n",
      "        Wrapping paper          5          5          0          0     0.0259     0.0186\r\n",
      "          Normal paper         11         15      0.125      0.133      0.131      0.117\r\n",
      "             Paper bag          3          3      0.633      0.667      0.448      0.448\r\n",
      "          Plastic film         40         60        0.3      0.317      0.268      0.221\r\n",
      "        Six pack rings          1          1      0.609          1      0.995      0.995\r\n",
      "           Garbage bag          3          4      0.251       0.25      0.268      0.243\r\n",
      " Other plastic wrapper         26         61       0.22      0.286      0.234      0.157\r\n",
      "Single-use carrier bag          7          9      0.112      0.222      0.152      0.118\r\n",
      "          Crisp packet          7          8      0.172       0.25      0.255      0.204\r\n",
      "            Spread tub          2          2          1          0          0          0\r\n",
      "Disposable food container          6          6      0.359      0.333      0.345      0.345\r\n",
      "   Foam food container          2          3      0.631          1      0.995      0.963\r\n",
      "       Plastic glooves          2          2      0.685        0.5      0.523      0.523\r\n",
      "      Plastic utensils          3          3          1          0     0.0601     0.0601\r\n",
      "               Pop tab         15         24      0.445      0.102      0.117     0.0865\r\n",
      "        Rope & strings          4          4      0.234       0.25      0.249      0.149\r\n",
      "                  Shoe          1          2          0          0          0          0\r\n",
      "       Squeezable tube          2          2          0          0          0          0\r\n",
      "         Plastic straw         18         22       0.58      0.318      0.348       0.28\r\n",
      "           Paper straw          2          2          1          0          0          0\r\n",
      "       Styrofoam piece         15         20      0.522        0.4      0.465      0.407\r\n",
      "      Unlabeled litter         44        124      0.205     0.0968     0.0725     0.0321\r\n",
      "             Cigarette         29         79      0.302      0.127      0.144     0.0741\r\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.0ms loss, 1.8ms postprocess per image\r\n",
      "Results saved to \u001b[1m/kaggle/working/FINAL/YOLO/yolo_checkpoints/yolo11l_finetune_baseline\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33myolo11l_taco_finetune_baseline\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/namthse182380-fpt-university/yolo_runs_taco/runs/fsq4qebx\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/namthse182380-fpt-university/yolo_runs_taco\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./FINAL/YOLO/wandb/run-20251031_002530-fsq4qebx/logs\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python training_yolov11.py"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8469591,
     "sourceId": 13441245,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 33862.634166,
   "end_time": "2025-10-31T00:58:10.384843",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-30T15:33:47.750677",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
